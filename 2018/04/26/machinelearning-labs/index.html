<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  <title>ã€Šæœºå™¨å­¦ä¹ ã€‹è¯¾ç¨‹å®éªŒå›é¡¾ | Ebby&#39;s Notes</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
    <meta name="keywords" content="äººå·¥æ™ºèƒ½,æ·±åº¦å­¦ä¹ ,æŠ€æœ¯,ç®—æ³•">
  
  
  
  
  <meta name="description" content="æ‘˜è¦ï¼š Couseraä¸Šæœºå™¨å­¦ä¹ è¯¾ç¨‹æä¾›äº†å…«ä¸ªå®éªŒä½œä¸šï¼Œä½¿ç”¨MATLABè¿›è¡ŒåŠ¨æ‰‹å®éªŒï¼Œç†Ÿæ‚‰ç›¸å…³æŠ€æœ¯ï¼Œæœ¬æ–‡å¯¹å®éªŒä¸­çš„å…³é”®å†…å®¹è¿›è¡Œæ€»ç»“å½’çº³ï¼Œæ–¹ä¾¿ä»¥ååŠæ—¶æŸ¥æ‰¾ã€‚  æ¦‚è¦ å¯ä»¥ä½¿ç”¨Matlab Onlineè¿›è¡Œä»£ç æµ‹è¯•ï¼Œåœ°å€; ç›¸å…³ä»£ç å·²ç»ä¼ è¾“è‡³Githubï¼š https://github.com/ddebby/machine_learning_cousera.git  Lab1: çº¿æ€§å›å½’1. ç®€å•çº¿æ€§">
<meta name="keywords" content="äººå·¥æ™ºèƒ½,æ·±åº¦å­¦ä¹ ,æŠ€æœ¯,ç®—æ³•">
<meta property="og:type" content="article">
<meta property="og:title" content="ã€Šæœºå™¨å­¦ä¹ ã€‹è¯¾ç¨‹å®éªŒå›é¡¾">
<meta property="og:url" content="http://blog.a-stack.com/2018/04/26/machinelearning-labs/index.html">
<meta property="og:site_name" content="Ebby&#39;s Notes">
<meta property="og:description" content="æ‘˜è¦ï¼š Couseraä¸Šæœºå™¨å­¦ä¹ è¯¾ç¨‹æä¾›äº†å…«ä¸ªå®éªŒä½œä¸šï¼Œä½¿ç”¨MATLABè¿›è¡ŒåŠ¨æ‰‹å®éªŒï¼Œç†Ÿæ‚‰ç›¸å…³æŠ€æœ¯ï¼Œæœ¬æ–‡å¯¹å®éªŒä¸­çš„å…³é”®å†…å®¹è¿›è¡Œæ€»ç»“å½’çº³ï¼Œæ–¹ä¾¿ä»¥ååŠæ—¶æŸ¥æ‰¾ã€‚  æ¦‚è¦ å¯ä»¥ä½¿ç”¨Matlab Onlineè¿›è¡Œä»£ç æµ‹è¯•ï¼Œåœ°å€; ç›¸å…³ä»£ç å·²ç»ä¼ è¾“è‡³Githubï¼š https://github.com/ddebby/machine_learning_cousera.git  Lab1: çº¿æ€§å›å½’1. ç®€å•çº¿æ€§">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://blog.a-stack.com/OneDrive%20-%20%E5%BE%90%E6%B1%87%E5%8C%BA%E4%BA%BA%E6%B0%91%E6%94%BF%E5%BA%9C%E6%BC%95%E6%B2%B3%E6%B3%BE%E5%BC%80%E5%8F%91%E5%8C%BA%E5%90%88%E4%BD%9C%E7%BB%BC%E5%90%88%E5%8D%8F%E8%B0%83%E5%8A%9E%E5%85%AC%E5%AE%A4/Ebby/blog/qnsource/images/2018-04-25-machine-learning-notes/linear_regression_01.jpg">
<meta property="og:image" content="http://blog.a-stack.com/OneDrive%20-%20%E5%BE%90%E6%B1%87%E5%8C%BA%E4%BA%BA%E6%B0%91%E6%94%BF%E5%BA%9C%E6%BC%95%E6%B2%B3%E6%B3%BE%E5%BC%80%E5%8F%91%E5%8C%BA%E5%90%88%E4%BD%9C%E7%BB%BC%E5%90%88%E5%8D%8F%E8%B0%83%E5%8A%9E%E5%85%AC%E5%AE%A4/Ebby/blog/qnsource/images/2018-04-25-machine-learning-notes/linear_regression_02.jpg">
<meta property="og:image" content="http://blog.a-stack.com/OneDrive%20-%20%E5%BE%90%E6%B1%87%E5%8C%BA%E4%BA%BA%E6%B0%91%E6%94%BF%E5%BA%9C%E6%BC%95%E6%B2%B3%E6%B3%BE%E5%BC%80%E5%8F%91%E5%8C%BA%E5%90%88%E4%BD%9C%E7%BB%BC%E5%90%88%E5%8D%8F%E8%B0%83%E5%8A%9E%E5%85%AC%E5%AE%A4/Ebby/blog/qnsource/images/2018-04-25-machine-learning-notes/linear_regression_03.jpg">
<meta property="og:image" content="http://blog.a-stack.com/OneDrive%20-%20%E5%BE%90%E6%B1%87%E5%8C%BA%E4%BA%BA%E6%B0%91%E6%94%BF%E5%BA%9C%E6%BC%95%E6%B2%B3%E6%B3%BE%E5%BC%80%E5%8F%91%E5%8C%BA%E5%90%88%E4%BD%9C%E7%BB%BC%E5%90%88%E5%8D%8F%E8%B0%83%E5%8A%9E%E5%85%AC%E5%AE%A4/Ebby/blog/qnsource/images/2018-04-25-machine-learning-notes/linear_regression_04.jpg">
<meta property="og:image" content="http://blog.a-stack.com/2018/04/qnsource/images/2018-04-26-machinelearning-labs/lab7_01.png">
<meta property="og:image" content="http://blog.a-stack.com/2018/04/qnsource/images/2018-04-26-machinelearning-labs/lab7_02.png">
<meta property="og:image" content="http://blog.a-stack.com/2018/04/qnsource/images/2018-04-26-machinelearning-labs/lab7_03.png">
<meta property="og:image" content="http://blog.a-stack.com/2018/04/qnsource/images/2018-04-26-machinelearning-labs/lab7_04.png">
<meta property="og:image" content="http://blog.a-stack.com/2018/04/qnsource/images/2018-04-26-machinelearning-labs/lab7_05.png">
<meta property="og:image" content="http://blog.a-stack.com/2018/04/qnsource/images/2018-04-26-machinelearning-labs/lab7_10.png">
<meta property="og:image" content="http://blog.a-stack.com/2018/04/qnsource/images/2018-04-26-machinelearning-labs/lab7_09.png">
<meta property="og:image" content="http://blog.a-stack.com/2018/04/qnsource/images/2018-04-26-machinelearning-labs/lab8_01.png">
<meta property="og:image" content="http://blog.a-stack.com/2018/04/qnsource/images/2018-04-26-machinelearning-labs/lab8_02.png">
<meta property="og:image" content="http://blog.a-stack.com/2018/04/qnsource/images/2018-04-26-machinelearning-labs/lab8_03.png">
<meta property="og:updated_time" content="2018-05-15T09:14:33.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ã€Šæœºå™¨å­¦ä¹ ã€‹è¯¾ç¨‹å®éªŒå›é¡¾">
<meta name="twitter:description" content="æ‘˜è¦ï¼š Couseraä¸Šæœºå™¨å­¦ä¹ è¯¾ç¨‹æä¾›äº†å…«ä¸ªå®éªŒä½œä¸šï¼Œä½¿ç”¨MATLABè¿›è¡ŒåŠ¨æ‰‹å®éªŒï¼Œç†Ÿæ‚‰ç›¸å…³æŠ€æœ¯ï¼Œæœ¬æ–‡å¯¹å®éªŒä¸­çš„å…³é”®å†…å®¹è¿›è¡Œæ€»ç»“å½’çº³ï¼Œæ–¹ä¾¿ä»¥ååŠæ—¶æŸ¥æ‰¾ã€‚  æ¦‚è¦ å¯ä»¥ä½¿ç”¨Matlab Onlineè¿›è¡Œä»£ç æµ‹è¯•ï¼Œåœ°å€; ç›¸å…³ä»£ç å·²ç»ä¼ è¾“è‡³Githubï¼š https://github.com/ddebby/machine_learning_cousera.git  Lab1: çº¿æ€§å›å½’1. ç®€å•çº¿æ€§">
<meta name="twitter:image" content="http://blog.a-stack.com/OneDrive%20-%20%E5%BE%90%E6%B1%87%E5%8C%BA%E4%BA%BA%E6%B0%91%E6%94%BF%E5%BA%9C%E6%BC%95%E6%B2%B3%E6%B3%BE%E5%BC%80%E5%8F%91%E5%8C%BA%E5%90%88%E4%BD%9C%E7%BB%BC%E5%90%88%E5%8D%8F%E8%B0%83%E5%8A%9E%E5%85%AC%E5%AE%A4/Ebby/blog/qnsource/images/2018-04-25-machine-learning-notes/linear_regression_01.jpg">
  
    <link rel="alternate" href="/atom.xml" title="Ebby&#39;s Notes" type="application/atom+xml">
  

  

  <link rel="icon" href="/css/images/logo.png">
  <link rel="apple-touch-icon" href="/css/images/logo.png">
  
    <link href="/qnsource/css/Source+Code+Pro.css" rel="stylesheet" type="text/css">
  
  <link href="/qnsource/css/Open+Sans-Montserrat-700.css" rel="stylesheet" type="text/css">
  <link href="/qnsource/css/Roboto-400-300.css" rel="stylesheet" type="text/css">
  <link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <link rel="stylesheet" href="/css/style.css">

  <script src="/js/jquery-3.1.1.min.js"></script>
  <script src="/js/bootstrap.js"></script>

  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="/css/bootstrap.css">

  
    <link rel="stylesheet" href="/css/dialog.css">
  

  

  
    <link rel="stylesheet" href="/css/header-post.css">
  

  
  
  
    <link rel="stylesheet" href="/css/vdonate.css">
  

</head>
</html>


  <body data-spy="scroll" data-target="#toc" data-offset="50">


  
  <div id="container">
    <div id="wrap">
      
        <header>

    <div id="allheader" class="navbar navbar-default navbar-static-top" role="navigation">
        <div class="navbar-inner">
          
          <div class="container"> 
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>

            
              <a class="brand" style="
                 border-width: 0px;  margin-top: 0px;"  
                href="#" data-toggle="modal" data-target="#myModal" >
                  <img width="200px" height="100px" alt="Hike News" src="/css/images/logo.png">
              </a>
            
            
            <div class="navbar-collapse collapse">
              <ul class="hnav navbar-nav">
                
                  <li> <a class="main-nav-link" href="/">é¦–é¡µ</a> </li>
                
                  <li> <a class="main-nav-link" href="/archives">å½’æ¡£</a> </li>
                
                  <li> <a class="main-nav-link" href="/categories">åˆ†ç±»</a> </li>
                
                  <li> <a class="main-nav-link" href="/tags">æ ‡ç­¾</a> </li>
                
                  <li> <a class="main-nav-link" href="/about">å…³äº</a> </li>
                
                  <li> <a class="main-nav-link" href="/reading">è¯»ä¹¦</a> </li>
                
                  <li> <a class="main-nav-link" href="/resources">èµ„æº</a> </li>
                
                  <li> <a class="main-nav-link" href="/notebooks">ğŸ“</a> </li>
                
                  <li><div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="è¯·è¾“å…¥å…³é”®è¯..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'æ–‡ç« ',
            PAGES: 'é¡µé¢',
            CATEGORIES: 'åˆ†ç±»',
            TAGS: 'æ ‡ç­¾',
            UNTITLED: '(æ— æ ‡é¢˜)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div></li>
            </div>
          </div>
                
      </div>
    </div>

</header>



      
            
      <div id="content" class="outer">
        
          <section id="main" style="float:none;"><article id="post-machinelearning-labs" style="width: 75%; float:left;" class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" class="article-title" itemprop="name">
      ã€Šæœºå™¨å­¦ä¹ ã€‹è¯¾ç¨‹å®éªŒå›é¡¾
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2018/04/26/machinelearning-labs/" class="article-date">
	  <time datetime="2018-04-26T05:56:28.000Z" itemprop="datePublished">2018-04-26</time>
	</a>

      
    <a class="article-category-link" href="/categories/åŠ¨æ‰‹å®è·µè¥/">åŠ¨æ‰‹å®è·µè¥</a>

      
      

    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>æ‘˜è¦ï¼š</strong> Couseraä¸Šæœºå™¨å­¦ä¹ è¯¾ç¨‹æä¾›äº†å…«ä¸ªå®éªŒä½œä¸šï¼Œä½¿ç”¨MATLABè¿›è¡ŒåŠ¨æ‰‹å®éªŒï¼Œç†Ÿæ‚‰ç›¸å…³æŠ€æœ¯ï¼Œæœ¬æ–‡å¯¹å®éªŒä¸­çš„å…³é”®å†…å®¹è¿›è¡Œæ€»ç»“å½’çº³ï¼Œæ–¹ä¾¿ä»¥ååŠæ—¶æŸ¥æ‰¾ã€‚</p>
<!-- excerpt -->
<h2 id="æ¦‚è¦"><a href="#æ¦‚è¦" class="headerlink" title="æ¦‚è¦"></a>æ¦‚è¦</h2><ul>
<li>å¯ä»¥ä½¿ç”¨Matlab Onlineè¿›è¡Œä»£ç æµ‹è¯•ï¼Œ<a href="https://matlab.mathworks.com/" target="_blank" rel="noopener">åœ°å€</a>;</li>
<li>ç›¸å…³ä»£ç å·²ç»ä¼ è¾“è‡³Githubï¼š <a href="https://github.com/ddebby/machine_learning_cousera.git" target="_blank" rel="noopener">https://github.com/ddebby/machine_learning_cousera.git</a></li>
</ul>
<h2 id="Lab1-çº¿æ€§å›å½’"><a href="#Lab1-çº¿æ€§å›å½’" class="headerlink" title="Lab1: çº¿æ€§å›å½’"></a>Lab1: çº¿æ€§å›å½’</h2><h3 id="1-ç®€å•çº¿æ€§å›å½’"><a href="#1-ç®€å•çº¿æ€§å›å½’" class="headerlink" title="1. ç®€å•çº¿æ€§å›å½’"></a>1. ç®€å•çº¿æ€§å›å½’</h3><p>åœ¨ç¬¬ä¸€ä¸ªå®éªŒä¸­æä¾›äº†å•å˜é‡çº¿æ€§å›å½’çš„æ•°æ®ç”¨æ¥é¢„æµ‹å¿«é¤è½¦çš„ç›ˆåˆ©æƒ…å†µï¼Œå…¶ä¸­è¾“å…¥ä¸ºåŸå¸‚ä¸­çš„äººå£ä¿¡æ¯ï¼Œè¾“å‡ºä¸ºè¯¥åŸå¸‚å¿«é¤è½¦çš„ç›ˆåˆ©æƒ…å†µï¼Œæ•°æ®åˆ†å¸ƒæƒ…å†µè¯¦è§ä¸‹å›¾ï¼š</p>
<p><img src="/2018/04/26/machinelearning-labs/../../../../../OneDrive%20-%20%E5%BE%90%E6%B1%87%E5%8C%BA%E4%BA%BA%E6%B0%91%E6%94%BF%E5%BA%9C%E6%BC%95%E6%B2%B3%E6%B3%BE%E5%BC%80%E5%8F%91%E5%8C%BA%E5%90%88%E4%BD%9C%E7%BB%BC%E5%90%88%E5%8D%8F%E8%B0%83%E5%8A%9E%E5%85%AC%E5%AE%A4/Ebby/blog/qnsource/images/2018-04-25-machine-learning-notes/linear_regression_01.jpg" alt="linear_regression_01"></p>
<h4 id="ä»£ä»·å‡½æ•°å’Œæ¢¯åº¦æ›´æ–°å®ç°"><a href="#ä»£ä»·å‡½æ•°å’Œæ¢¯åº¦æ›´æ–°å®ç°" class="headerlink" title="ä»£ä»·å‡½æ•°å’Œæ¢¯åº¦æ›´æ–°å®ç°"></a>ä»£ä»·å‡½æ•°å’Œæ¢¯åº¦æ›´æ–°å®ç°</h4><p>è®¡ç®—ä»£ä»·å‡½æ•° <code>computeCost.m</code> </p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">J</span> = <span class="title">computeCost</span><span class="params">(X, y, theta)</span></span></span><br><span class="line"><span class="comment">%COMPUTECOST Compute cost for linear regression</span></span><br><span class="line"><span class="comment">%   J = COMPUTECOST(X, y, theta) computes the cost of using theta as the</span></span><br><span class="line"><span class="comment">%   parameter for linear regression to fit the data points in X and y</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Initialize some useful values</span></span><br><span class="line">m = <span class="built_in">length</span>(y); <span class="comment">% number of training examples</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% You need to return the following variables correctly </span></span><br><span class="line">J = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% ====================== YOUR CODE HERE ======================</span></span><br><span class="line"><span class="comment">% Instructions: Compute the cost of a particular choice of theta</span></span><br><span class="line"><span class="comment">%               You should set J to the cost.</span></span><br><span class="line">J = <span class="number">1</span>/(<span class="number">2</span>*m) * (X*theta - y)'*(X*theta -y)</span><br><span class="line"><span class="comment">% =========================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>æ¢¯åº¦æ›´æ–° <code>gradientDescent.m</code></p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[theta, J_history]</span> = <span class="title">gradientDescent</span><span class="params">(X, y, theta, alpha, num_iters)</span></span></span><br><span class="line"><span class="comment">%GRADIENTDESCENT Performs gradient descent to learn theta</span></span><br><span class="line"><span class="comment">%   theta = GRADIENTDESCENT(X, y, theta, alpha, num_iters) updates theta by </span></span><br><span class="line"><span class="comment">%   taking num_iters gradient steps with learning rate alpha</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Initialize some useful values</span></span><br><span class="line">m = <span class="built_in">length</span>(y); <span class="comment">% number of training examples</span></span><br><span class="line">J_history = <span class="built_in">zeros</span>(num_iters, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> iter = <span class="number">1</span>:num_iters</span><br><span class="line"></span><br><span class="line">    <span class="comment">% ====================== YOUR CODE HERE ======================</span></span><br><span class="line">    <span class="comment">% Instructions: Perform a single gradient step on the parameter vector</span></span><br><span class="line">    <span class="comment">%               theta. </span></span><br><span class="line">    <span class="comment">%</span></span><br><span class="line">    <span class="comment">% Hint: While debugging, it can be useful to print out the values</span></span><br><span class="line">    <span class="comment">%       of the cost function (computeCost) and gradient here.</span></span><br><span class="line">    <span class="comment">%</span></span><br><span class="line"></span><br><span class="line">    theta = theta - alpha/m * X'*(X*theta - y);</span><br><span class="line"></span><br><span class="line">    <span class="comment">% ============================================================</span></span><br><span class="line">    <span class="comment">% Save the cost J in every iteration    </span></span><br><span class="line">    J_history(iter) = computeCost(X, y, theta);</span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>å®ç°å¹¶æµ‹è¯•ï¼š</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">data = load(<span class="string">'ex1data1.txt'</span>);</span><br><span class="line">X = data(:, <span class="number">1</span>); y = data(:, <span class="number">2</span>);</span><br><span class="line">m = <span class="built_in">length</span>(y); <span class="comment">% number of training examples</span></span><br><span class="line"></span><br><span class="line">X = [ones(m, <span class="number">1</span>), data(:,<span class="number">1</span>)]; <span class="comment">% Add a column of ones to x</span></span><br><span class="line">theta = <span class="built_in">zeros</span>(<span class="number">2</span>, <span class="number">1</span>); <span class="comment">% initialize fitting parameters</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Some gradient descent settings</span></span><br><span class="line">iterations = <span class="number">1500</span>;</span><br><span class="line">alpha = <span class="number">0.01</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% compute and display initial cost</span></span><br><span class="line">J = computeCost(X, y, theta);</span><br><span class="line"></span><br><span class="line"><span class="comment">% further testing of the cost function</span></span><br><span class="line">J = computeCost(X, y, [<span class="number">-1</span> ; <span class="number">2</span>]);</span><br><span class="line"></span><br><span class="line"><span class="comment">% run gradient descent</span></span><br><span class="line">theta = gradientDescent(X, y, theta, alpha, iterations);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Plot the linear fit</span></span><br><span class="line">hold on; <span class="comment">% keep previous plot visible</span></span><br><span class="line">plot(X(:,<span class="number">2</span>), X*theta, <span class="string">'-'</span>)</span><br><span class="line">legend(<span class="string">'Training data'</span>, <span class="string">'Linear regression'</span>)</span><br><span class="line">hold off <span class="comment">% don't overlay any more plots on this figure</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Predict values for population sizes of 35,000 and 70,000</span></span><br><span class="line">predict1 = [<span class="number">1</span>, <span class="number">3.5</span>] *theta;</span><br><span class="line">fprintf(<span class="string">'For population = 35,000, we predict a profit of %f\n'</span>,...</span><br><span class="line">    predict1*<span class="number">10000</span>);</span><br><span class="line">predict2 = [<span class="number">1</span>, <span class="number">7</span>] * theta;</span><br><span class="line">fprintf(<span class="string">'For population = 70,000, we predict a profit of %f\n'</span>,...</span><br><span class="line">    predict2*<span class="number">10000</span>);</span><br></pre></td></tr></table></figure>
<p><img src="/2018/04/26/machinelearning-labs/../../../../../OneDrive%20-%20%E5%BE%90%E6%B1%87%E5%8C%BA%E4%BA%BA%E6%B0%91%E6%94%BF%E5%BA%9C%E6%BC%95%E6%B2%B3%E6%B3%BE%E5%BC%80%E5%8F%91%E5%8C%BA%E5%90%88%E4%BD%9C%E7%BB%BC%E5%90%88%E5%8D%8F%E8%B0%83%E5%8A%9E%E5%85%AC%E5%AE%A4/Ebby/blog/qnsource/images/2018-04-25-machine-learning-notes/linear_regression_02.jpg" alt="linear_regression_02"></p>
<h4 id="J-theta-çš„å¯è§†åŒ–"><a href="#J-theta-çš„å¯è§†åŒ–" class="headerlink" title="$J(\theta)$ çš„å¯è§†åŒ–"></a>$J(\theta)$ çš„å¯è§†åŒ–</h4><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% ============= Part 4: Visualizing J(theta_0, theta_1) =============</span></span><br><span class="line">fprintf(<span class="string">'Visualizing J(theta_0, theta_1) ...\n'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">% Grid over which we will calculate J</span></span><br><span class="line">theta0_vals = <span class="built_in">linspace</span>(<span class="number">-10</span>, <span class="number">10</span>, <span class="number">100</span>);</span><br><span class="line">theta1_vals = <span class="built_in">linspace</span>(<span class="number">-1</span>, <span class="number">4</span>, <span class="number">100</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% initialize J_vals to a matrix of 0's</span></span><br><span class="line">J_vals = <span class="built_in">zeros</span>(<span class="built_in">length</span>(theta0_vals), <span class="built_in">length</span>(theta1_vals));</span><br><span class="line"></span><br><span class="line"><span class="comment">% Fill out J_vals</span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:<span class="built_in">length</span>(theta0_vals)</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">1</span>:<span class="built_in">length</span>(theta1_vals)</span><br><span class="line">	  t = [theta0_vals(i); theta1_vals(j)];</span><br><span class="line">	  J_vals(<span class="built_in">i</span>,<span class="built_in">j</span>) = computeCost(X, y, t);</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Because of the way meshgrids work in the surf command, we need to</span></span><br><span class="line"><span class="comment">% transpose J_vals before calling surf, or else the axes will be flipped</span></span><br><span class="line">J_vals = J_vals';</span><br><span class="line"><span class="comment">% Surface plot</span></span><br><span class="line">figure;</span><br><span class="line">surf(theta0_vals, theta1_vals, J_vals)</span><br><span class="line">xlabel(<span class="string">'\theta_0'</span>); ylabel(<span class="string">'\theta_1'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Contour plot</span></span><br><span class="line">figure;</span><br><span class="line"><span class="comment">% Plot J_vals as 15 contours spaced logarithmically between 0.01 and 100</span></span><br><span class="line">contour(theta0_vals, theta1_vals, J_vals, <span class="built_in">logspace</span>(<span class="number">-2</span>, <span class="number">3</span>, <span class="number">20</span>))</span><br><span class="line">xlabel(<span class="string">'\theta_0'</span>); ylabel(<span class="string">'\theta_1'</span>);</span><br><span class="line">hold on;</span><br><span class="line">plot(theta(<span class="number">1</span>), theta(<span class="number">2</span>), <span class="string">'rx'</span>, <span class="string">'MarkerSize'</span>, <span class="number">10</span>, <span class="string">'LineWidth'</span>, <span class="number">2</span>);</span><br></pre></td></tr></table></figure>
<p><img src="/2018/04/26/machinelearning-labs/../../../../../OneDrive%20-%20%E5%BE%90%E6%B1%87%E5%8C%BA%E4%BA%BA%E6%B0%91%E6%94%BF%E5%BA%9C%E6%BC%95%E6%B2%B3%E6%B3%BE%E5%BC%80%E5%8F%91%E5%8C%BA%E5%90%88%E4%BD%9C%E7%BB%BC%E5%90%88%E5%8D%8F%E8%B0%83%E5%8A%9E%E5%85%AC%E5%AE%A4/Ebby/blog/qnsource/images/2018-04-25-machine-learning-notes/linear_regression_03.jpg" alt="linear_regression_03"></p>
<p><img src="/2018/04/26/machinelearning-labs/../../../../../OneDrive%20-%20%E5%BE%90%E6%B1%87%E5%8C%BA%E4%BA%BA%E6%B0%91%E6%94%BF%E5%BA%9C%E6%BC%95%E6%B2%B3%E6%B3%BE%E5%BC%80%E5%8F%91%E5%8C%BA%E5%90%88%E4%BD%9C%E7%BB%BC%E5%90%88%E5%8D%8F%E8%B0%83%E5%8A%9E%E5%85%AC%E5%AE%A4/Ebby/blog/qnsource/images/2018-04-25-machine-learning-notes/linear_regression_04.jpg" alt="linear_regression_04"></p>
<h3 id="2-å¤šå…ƒçº¿æ€§å›å½’"><a href="#2-å¤šå…ƒçº¿æ€§å›å½’" class="headerlink" title="2. å¤šå…ƒçº¿æ€§å›å½’"></a>2. å¤šå…ƒçº¿æ€§å›å½’</h3><p>åˆ©ç”¨å¤šå…ƒçº¿æ€§å›å½’é¢„æµ‹æˆ¿ä»·ï¼Œè¾“å…¥çš„ç‰¹å¾åŒ…æ‹¬æˆ¿å­å¤§å°ã€æˆ¿é—´æ•°ç›®ï¼Œè¾“å‡ºä¸ºæˆ¿å­ä»·æ ¼ã€‚</p>
<h3 id="2-1-ç‰¹å¾å½’ä¸€åŒ–"><a href="#2-1-ç‰¹å¾å½’ä¸€åŒ–" class="headerlink" title="2.1 ç‰¹å¾å½’ä¸€åŒ–"></a>2.1 ç‰¹å¾å½’ä¸€åŒ–</h3><p><code>featureNormalize.m</code></p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[X_norm, mu, sigma]</span> = <span class="title">featureNormalize</span><span class="params">(X)</span></span></span><br><span class="line"><span class="comment">%FEATURENORMALIZE Normalizes the features in X </span></span><br><span class="line"><span class="comment">%   FEATURENORMALIZE(X) returns a normalized version of X where</span></span><br><span class="line"><span class="comment">%   the mean value of each feature is 0 and the standard deviation</span></span><br><span class="line"><span class="comment">%   is 1. This is often a good preprocessing step to do when</span></span><br><span class="line"><span class="comment">%   working with learning algorithms.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% You need to set these values correctly</span></span><br><span class="line">X_norm = X;</span><br><span class="line">mu = <span class="built_in">zeros</span>(<span class="number">1</span>, <span class="built_in">size</span>(X, <span class="number">2</span>));</span><br><span class="line">sigma = <span class="built_in">zeros</span>(<span class="number">1</span>, <span class="built_in">size</span>(X, <span class="number">2</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">% ====================== YOUR CODE HERE ======================</span></span><br><span class="line"><span class="comment">%       </span></span><br><span class="line">mu = mean(X,<span class="number">1</span>);</span><br><span class="line">sigma = std(X,<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">X_norm = (X - mu)./sigma;</span><br><span class="line"><span class="comment">% ============================================================</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<ul>
<li>The <code>bsxfun</code> is helpful for applying a function (limited to two arguments) in an element-wise fashion to rows of a matrix using a vector of source values. This is useful for feature normalization. An example you can enter at the octave command line:</li>
</ul>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Z=[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span>; <span class="number">2</span> <span class="number">2</span> <span class="number">2</span>;];</span><br><span class="line"></span><br><span class="line">v=[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span>];</span><br><span class="line"></span><br><span class="line"><span class="built_in">bsxfun</span>(@minus,Z,v);</span><br><span class="line"></span><br><span class="line"><span class="built_in">ans</span> =</span><br><span class="line"></span><br><span class="line">    <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="number">1</span>   <span class="number">1</span>   <span class="number">1</span></span><br></pre></td></tr></table></figure>
<ul>
<li>In this case, the corresponding elements of v are subtracted from each row of Z. The minus(a,b) function is equivalent to computing (a-b).</li>
</ul>
<ul>
<li>ä»£ä»·å‡½æ•°å’Œæ¢¯åº¦æ›´æ–°ä¸ç®€å•çº¿æ€§å›å½’ç›¸åŒï¼›</li>
</ul>
<h3 id="2-2-è®¡ç®—-theta-çš„æ•°å€¼è§£"><a href="#2-2-è®¡ç®—-theta-çš„æ•°å€¼è§£" class="headerlink" title="2.2 è®¡ç®— $\theta$ çš„æ•°å€¼è§£"></a>2.2 è®¡ç®— $\theta$ çš„æ•°å€¼è§£</h3><p><code>normalEqn.m</code></p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[theta]</span> = <span class="title">normalEqn</span><span class="params">(X, y)</span></span></span><br><span class="line"><span class="comment">%NORMALEQN Computes the closed-form solution to linear regression </span></span><br><span class="line"><span class="comment">%   NORMALEQN(X,y) computes the closed-form solution to linear </span></span><br><span class="line"><span class="comment">%   regression using the normal equations.</span></span><br><span class="line"></span><br><span class="line">theta = <span class="built_in">zeros</span>(<span class="built_in">size</span>(X, <span class="number">2</span>), <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% ====================== YOUR CODE HERE ======================</span></span><br><span class="line"><span class="comment">% Instructions: Complete the code to compute the closed form solution</span></span><br><span class="line"><span class="comment">%               to linear regression and put the result in theta.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% ---------------------- Sample Solution ----------------------</span></span><br><span class="line">theta = pinv(X'*X)*X'*y;</span><br><span class="line"></span><br><span class="line"><span class="comment">% -------------------------------------------------------------</span></span><br><span class="line"><span class="comment">% ============================================================</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h2 id="Lab-2-Lab-5"><a href="#Lab-2-Lab-5" class="headerlink" title="Lab 2 - Lab 5:"></a>Lab 2 - Lab 5:</h2><blockquote>
<p>ç•™ä½œåç»­æ›´æ–° â€¦</p>
</blockquote>
<h2 id="Lab-6-SVM"><a href="#Lab-6-SVM" class="headerlink" title="Lab 6: SVM"></a>Lab 6: SVM</h2><p>æœ¬å®éªŒåˆ©ç”¨SVMå®ç°éçº¿æ€§åˆ†ç±»å™¨ï¼Œæ ¸å‡½æ•°é€‰æ‹©é«˜æ–¯æ ¸å‡½æ•°ï¼Œé«˜æ–¯æ ¸å‡½æ•°çš„å®šä¹‰å¦‚ä¸‹ï¼š</p>
<script type="math/tex; mode=display">
K_{gaussian}(x^{(i)},x^{(j)}) = exp(-\frac{||x^{(i)}-x^{(j)}||^2}{2\sigma^2})</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% ========== Part 5: Training SVM with RBF Kernel (Dataset 2) ==========</span></span><br><span class="line"><span class="comment">%  After you have implemented the kernel, we can now use it to train the </span></span><br><span class="line"><span class="comment">%  SVM classifier.</span></span><br><span class="line"><span class="comment">% </span></span><br><span class="line">load(<span class="string">'ex6data2.mat'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% SVM Parameters</span></span><br><span class="line">C = <span class="number">1</span>; sigma = <span class="number">0.1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% We set the tolerance and max_passes lower here so that the code will run</span></span><br><span class="line"><span class="comment">% faster. However, in practice, you will want to run the training to</span></span><br><span class="line"><span class="comment">% convergence.</span></span><br><span class="line">model= svmTrain(X, y, C, @(x1, x2) gaussianKernel(x1, x2, sigma)); </span><br><span class="line">visualizeBoundary(X, y, model);</span><br></pre></td></tr></table></figure>
<blockquote>
<p>ç”±äºç›®å‰scikit-learnåº“å¯¹å„ç§SVMç®—æ³•éƒ½æœ‰æ¯”è¾ƒå¥½çš„å°è£…ï¼Œæ‰€ä»¥ä¹Ÿä¸åœ¨è¿›ä¸€æ­¥æ·±ç©¶matlabçš„å®ç°äº†ã€‚</p>
</blockquote>
<h2 id="Lab-7-1-K-Means"><a href="#Lab-7-1-K-Means" class="headerlink" title="Lab 7.1: K-Means"></a>Lab 7.1: K-Means</h2><p>æœ¬å®éªŒä½¿ç”¨K-Meansè¿›è¡Œå›¾åƒå‹ç¼©ï¼ŒK-Meansç®—æ³•çš„åŸºæœ¬å®ç°ï¼š</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% Initialize centroids</span></span><br><span class="line">centroids = kMeansInitCentroids(X, K);</span><br><span class="line"><span class="keyword">for</span> iter = <span class="number">1</span>:iterations</span><br><span class="line">    <span class="comment">% Cluster assignment step: Assign each data point to the</span></span><br><span class="line">    <span class="comment">% closest centroid. idx(i) corresponds to cË†(i), the index</span></span><br><span class="line">    <span class="comment">% of the centroid assigned to example i</span></span><br><span class="line">    idx = findClosestCentroids(X, centroids);</span><br><span class="line">    <span class="comment">% Move centroid step: Compute means based on centroid</span></span><br><span class="line">    <span class="comment">% assignments</span></span><br><span class="line">    centroids = computeMeans(X, idx, K);</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>åœ¨å¾ªç¯ä¸­å…³é”®å®ç°ä¸¤ä¸ªæ­¥éª¤ï¼š1ï¼‰é‡æ–°åˆ’åˆ†èšç±»ï¼›2ï¼‰è®¡ç®—æ–°çš„å‡å€¼åŠä¸­å¿ƒç‚¹</p>
<ol>
<li>å¯»æ‰¾æœ€è¿‘çš„èšç±»ä¸­å¿ƒç‚¹ï¼Œå¹¶èšç±»<script type="math/tex; mode=display">
c^{(i)}:=j \ that \ minimizes \ ||x^{(i)} - \mu_j ||^2</script></li>
</ol>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">idx</span> = <span class="title">findClosestCentroids</span><span class="params">(X, centroids)</span></span></span><br><span class="line"><span class="comment">%FINDCLOSESTCENTROIDS computes the centroid memberships for every example</span></span><br><span class="line"><span class="comment">%   idx = FINDCLOSESTCENTROIDS (X, centroids) returns the closest centroids</span></span><br><span class="line"><span class="comment">%   in idx for a dataset X where each row is a single example. idx = m x 1 </span></span><br><span class="line"><span class="comment">%   vector of centroid assignments (i.e. each entry in range [1..K])</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Set K</span></span><br><span class="line">K = <span class="built_in">size</span>(centroids, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% You need to return the following variables correctly.</span></span><br><span class="line">idx = <span class="built_in">zeros</span>(<span class="built_in">size</span>(X,<span class="number">1</span>), <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Instructions: Go over every example, find its closest centroid, and store</span></span><br><span class="line"><span class="comment">%               the index inside idx at the appropriate location.</span></span><br><span class="line"><span class="comment">%               Concretely, idx(i) should contain the index of the centroid</span></span><br><span class="line"><span class="comment">%               closest to example i. Hence, it should be a value in the </span></span><br><span class="line"><span class="comment">%               range 1..K</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% Note: You can use a for-loop over the examples to compute this.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="built_in">size</span>(X,<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">1</span>: <span class="built_in">size</span>(centroids,<span class="number">1</span>)</span><br><span class="line">         dis(<span class="built_in">j</span>) = sum((centroids(<span class="built_in">j</span>, :) - X(<span class="built_in">i</span>, :)) .^ <span class="number">2</span>, <span class="number">2</span>);  </span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    [t,idx(i)] = min(dis);</span><br><span class="line"><span class="keyword">end</span>  </span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<ol>
<li>æ›´æ–°èšç±»ä¸­å¿ƒç‚¹ä½ç½®</li>
</ol>
<script type="math/tex; mode=display">
\mu_k = \frac{1}{|C_k|} \sum_{i \in C_k} x^{(i)}</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">centroids</span> = <span class="title">computeCentroids</span><span class="params">(X, idx, K)</span></span></span><br><span class="line"><span class="comment">%COMPUTECENTROIDS returns the new centroids by computing the means of the </span></span><br><span class="line"><span class="comment">%data points assigned to each centroid.</span></span><br><span class="line"><span class="comment">%   centroids = COMPUTECENTROIDS(X, idx, K) returns the new centroids by </span></span><br><span class="line"><span class="comment">%   computing the means of the data points assigned to each centroid. It is</span></span><br><span class="line"><span class="comment">%   given a dataset X where each row is a single data point, a vector</span></span><br><span class="line"><span class="comment">%   idx of centroid assignments (i.e. each entry in range [1..K]) for each</span></span><br><span class="line"><span class="comment">%   example, and K, the number of centroids. You should return a matrix</span></span><br><span class="line"><span class="comment">%   centroids, where each row of centroids is the mean of the data points</span></span><br><span class="line"><span class="comment">%   assigned to it.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Useful variables</span></span><br><span class="line">[m n] = <span class="built_in">size</span>(X);</span><br><span class="line"></span><br><span class="line"><span class="comment">% You need to return the following variables correctly.</span></span><br><span class="line">centroids = <span class="built_in">zeros</span>(K, n);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:K</span><br><span class="line">    centroids(<span class="built_in">i</span>,:) = mean(X(<span class="built_in">find</span>(idx==<span class="built_in">i</span>),:));</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p><img src="/2018/04/26/machinelearning-labs/../../qnsource/images/2018-04-26-machinelearning-labs/lab7_01.png" alt="lab7_01"></p>
<p>3.åˆå§‹èµ·ç‚¹çš„éšæœºé€‰å–</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% Randomly reorder the indices of examples </span></span><br><span class="line">randidx = randperm(<span class="built_in">size</span>(X, <span class="number">1</span>)); </span><br><span class="line"><span class="comment">% Take the first K examples as centroids </span></span><br><span class="line">centroids = X(randidx(<span class="number">1</span>:K), :);</span><br></pre></td></tr></table></figure>
<ol>
<li>ä½¿ç”¨K-Meanså‹ç¼©å›¾ç‰‡</li>
</ol>
<p>æˆ‘ä»¬å°†ä¸€å¼ 24bitçš„ç…§ç‰‡ï¼Œå‹ç¼©ä¸º4-bitï¼ˆ16ä¸ªè‰²å½©ï¼‰ï¼›å¯¹äºæ¯ä¸ªåƒç´ ç‚¹ï¼Œå°†é€‰æ‹©æœ€è¿‘çš„ç±»ç°‡è¿›è¡Œé¢œè‰²è¡¨ç¤ºã€‚é€šè¿‡å‹ç¼©å°†128x128x24=393,216bitsçš„å›¾åƒå‹ç¼©ä¸º16x24 + 128x128x4=65,920bitsï¼ˆå…¶ä¸­éœ€è¦é¢å¤–æ¯ç§é¢œè‰²éœ€è¦ä¸€ä¸ª24bitç©ºé—´å­˜å‚¨å„ä¸ªé¢œè‰²å­—å…¸ï¼‰ã€‚</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% ============= Part 4: K-Means Clustering on Pixels ===============</span></span><br><span class="line"><span class="comment">%  In this exercise, you will use K-Means to compress an image. To do this,</span></span><br><span class="line"><span class="comment">%  you will first run K-Means on the colors of the pixels in the image and</span></span><br><span class="line"><span class="comment">%  then you will map each pixel onto its closest centroid.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%  Load an image of a bird</span></span><br><span class="line">A = double(imread(<span class="string">'bird_small.png'</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">% If imread does not work for you, you can try instead</span></span><br><span class="line"><span class="comment">%   load ('bird_small.mat');</span></span><br><span class="line"></span><br><span class="line">A = A / <span class="number">255</span>; <span class="comment">% Divide by 255 so that all values are in the range 0 - 1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Size of the image</span></span><br><span class="line">img_size = <span class="built_in">size</span>(A);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Reshape the image into an Nx3 matrix where N = number of pixels.</span></span><br><span class="line"><span class="comment">% Each row will contain the Red, Green and Blue pixel values</span></span><br><span class="line"><span class="comment">% This gives us our dataset matrix X that we will use K-Means on.</span></span><br><span class="line">X = <span class="built_in">reshape</span>(A, img_size(<span class="number">1</span>) * img_size(<span class="number">2</span>), <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Run your K-Means algorithm on this data</span></span><br><span class="line"><span class="comment">% You should try different values of K and max_iters here</span></span><br><span class="line">K = <span class="number">16</span>; </span><br><span class="line">max_iters = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% When using K-Means, it is important the initialize the centroids</span></span><br><span class="line"><span class="comment">% randomly. </span></span><br><span class="line"><span class="comment">% You should complete the code in kMeansInitCentroids.m before proceeding</span></span><br><span class="line">initial_centroids = kMeansInitCentroids(X, K);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Run K-Means</span></span><br><span class="line">[centroids, idx] = runkMeans(X, initial_centroids, max_iters);</span><br><span class="line"></span><br><span class="line"><span class="comment">%% ================= Part 5: Image Compression ======================</span></span><br><span class="line"><span class="comment">%  In this part of the exercise, you will use the clusters of K-Means to</span></span><br><span class="line"><span class="comment">%  compress an image. To do this, we first find the closest clusters for</span></span><br><span class="line"><span class="comment">%  each example. After that, we </span></span><br><span class="line"><span class="comment">% Find closest cluster members</span></span><br><span class="line">idx = findClosestCentroids(X, centroids);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Essentially, now we have represented the image X as in terms of the</span></span><br><span class="line"><span class="comment">% indices in idx. </span></span><br><span class="line"></span><br><span class="line"><span class="comment">% We can now recover the image from the indices (idx) by mapping each pixel</span></span><br><span class="line"><span class="comment">% (specified by its index in idx) to the centroid value</span></span><br><span class="line">X_recovered = centroids(idx,:);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Reshape the recovered image into proper dimensions</span></span><br><span class="line">X_recovered = <span class="built_in">reshape</span>(X_recovered, img_size(<span class="number">1</span>), img_size(<span class="number">2</span>), <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Display the original image </span></span><br><span class="line">subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>);</span><br><span class="line">imagesc(A); </span><br><span class="line">title(<span class="string">'Original'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Display compressed image side by side</span></span><br><span class="line">subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>);</span><br><span class="line">imagesc(X_recovered)</span><br><span class="line">title(sprintf(<span class="string">'Compressed, with %d colors.'</span>, K));</span><br></pre></td></tr></table></figure>
<p><img src="/2018/04/26/machinelearning-labs/../../qnsource/images/2018-04-26-machinelearning-labs/lab7_02.png" alt="lab7_02"></p>
<h2 id="Lab-7-2ï¼š-PCA"><a href="#Lab-7-2ï¼š-PCA" class="headerlink" title="Lab 7.2ï¼š PCA"></a>Lab 7.2ï¼š PCA</h2><p>æœ¬å®éªŒåˆ©ç”¨PCAå®ç°æ•°æ®é™ç»´åŠå¯è§†åŒ–ã€‚</p>
<p><img src="/2018/04/26/machinelearning-labs/../../qnsource/images/2018-04-26-machinelearning-labs/lab7_03.png" alt="lab7_03"></p>
<ol>
<li>æ•°æ®å½’ä¸€åŒ–</li>
<li>è®¡ç®—åæ–¹å·®å’Œå¥‡å¼‚å€¼åˆ†è§£</li>
</ol>
<script type="math/tex; mode=display">
\Sigma =\frac{1}{m}X^TX</script><script type="math/tex; mode=display">
[U, S, V] = svd(\Sigma)</script><p><img src="/2018/04/26/machinelearning-labs/../../qnsource/images/2018-04-26-machinelearning-labs/lab7_04.png" alt="lab7_04"></p>
<ol>
<li>é™ç»´</li>
</ol>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Z = X * U(:,<span class="number">1</span>:K);</span><br></pre></td></tr></table></figure>
<ol>
<li>æ•°æ®æ¢å¤</li>
</ol>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_rec = Z * U(:,<span class="number">1</span>:K)';</span><br></pre></td></tr></table></figure>
<p><img src="/2018/04/26/machinelearning-labs/../../qnsource/images/2018-04-26-machinelearning-labs/lab7_05.png" alt="lab7_05"></p>
<h3 id="æ•°æ®å¯è§†åŒ–çš„é™ç»´æ˜¾ç¤º"><a href="#æ•°æ®å¯è§†åŒ–çš„é™ç»´æ˜¾ç¤º" class="headerlink" title="æ•°æ®å¯è§†åŒ–çš„é™ç»´æ˜¾ç¤º"></a>æ•°æ®å¯è§†åŒ–çš„é™ç»´æ˜¾ç¤º</h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% Use PCA to project this cloud to 2D for visualization</span></span><br><span class="line"><span class="comment">% X (16383,3)</span></span><br><span class="line"><span class="comment">% Subtract the mean to use PCA</span></span><br><span class="line">[X_norm, mu, sigma] = featureNormalize(X);</span><br><span class="line"></span><br><span class="line"><span class="comment">% PCA and project the data to 2D</span></span><br><span class="line">[U, S] = pca(X_norm);</span><br><span class="line">Z = projectData(X_norm, U, <span class="number">2</span>);</span><br></pre></td></tr></table></figure>
<p><img src="/2018/04/26/machinelearning-labs/../../qnsource/images/2018-04-26-machinelearning-labs/lab7_10.png" alt="lab7_10"></p>
<p><img src="/2018/04/26/machinelearning-labs/../../qnsource/images/2018-04-26-machinelearning-labs/lab7_09.png" alt="lab7_09"></p>
<h2 id="Lab-8-1-å¼‚å¸¸æ£€æµ‹"><a href="#Lab-8-1-å¼‚å¸¸æ£€æµ‹" class="headerlink" title="Lab 8.1: å¼‚å¸¸æ£€æµ‹"></a>Lab 8.1: å¼‚å¸¸æ£€æµ‹</h2><p>æœ¬å®éªŒæ­å»ºä¸€ä¸ªå¼‚å¸¸æ£€æµ‹ç³»ç»Ÿï¼Œç”¨æ¥æ£€æµ‹æœåŠ¡å™¨çš„å¼‚å¸¸ä¿¡æ¯ï¼Œè¾“å…¥ä¸ºæ¯å°æœåŠ¡å™¨çš„æ¯åˆ†é’Ÿåå(mb/s)å’Œå“åº”å»¶æ—¶ï¼ˆmsï¼‰ï¼Œæ•°æ®æä¾›äº†m=307ç»„æ ·æœ¬æ•°æ®ã€‚æœŸæœ›é€šè¿‡éç›‘ç£å­¦ä¹ çš„æ‰‹æ®µæ¥æ£€æµ‹å¼‚å¸¸ã€‚</p>
<p><img src="/2018/04/26/machinelearning-labs/../../qnsource/images/2018-04-26-machinelearning-labs/lab8_01.png" alt="lab8_01"></p>
<p>ä¸ºäº†å¯¹æ•°æ®å¼‚å¸¸è¿›è¡Œæ£€æµ‹ï¼Œé¦–å…ˆéœ€è¦å°†åŸå§‹æ•°æ®æ‹Ÿåˆåˆ°ä¸€ä¸ªåˆ†å¸ƒæ¨¡å‹é‡Œï¼Œæˆ‘ä»¬é€‰æ‹©ä½¿ç”¨å¤šå…ƒé«˜æ–¯æ¨¡å‹è¿›è¡Œæ•°æ®æ‹Ÿåˆ:</p>
<script type="math/tex; mode=display">
p(x;\mu,\Sigma) = \dfrac{1}{(2\pi)^{n/2} |\Sigma|^{1/2}} exp(-1/2(x-\mu)^T\Sigma^{-1}(x-\mu))</script><ol>
<li>é¦–å…ˆéœ€è¦å¯¹å‚æ•°$\mu$ ,$\sigma$ è¿›è¡Œä¼°è®¡ï¼Œå‚è§å¦‚ä¸‹ä»£ç ï¼š</li>
</ol>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mu = mean(X, <span class="number">1</span>);</span><br><span class="line">sigma2 = var(X, <span class="number">1</span>);</span><br><span class="line">p = multivariateGaussian(X, mu, sigma2);</span><br><span class="line"><span class="comment">%  Visualize the fit</span></span><br><span class="line">visualizeFit(X,  mu, sigma2);</span><br></pre></td></tr></table></figure>
<p>æ‹Ÿåˆé«˜æ–¯åˆ†å¸ƒçš„è½®å»“å›¾å¦‚ä¸‹ï¼š</p>
<p><img src="/2018/04/26/machinelearning-labs/../../qnsource/images/2018-04-26-machinelearning-labs/lab8_02.png" alt="lab8_02"></p>
<p>å¤šå…ƒé«˜æ–¯åˆ†å¸ƒå‡½æ•°<code>multivariateGaussian()</code>çš„å®šä¹‰å¦‚ä¸‹ï¼š</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">p</span> = <span class="title">multivariateGaussian</span><span class="params">(X, mu, Sigma2)</span></span></span><br><span class="line"><span class="comment">%MULTIVARIATEGAUSSIAN Computes the probability density function of the</span></span><br><span class="line"><span class="comment">%multivariate gaussian distribution.</span></span><br><span class="line"><span class="comment">%    p = MULTIVARIATEGAUSSIAN(X, mu, Sigma2) Computes the probability </span></span><br><span class="line"><span class="comment">%    density function of the examples X under the multivariate gaussian </span></span><br><span class="line"><span class="comment">%    distribution with parameters mu and Sigma2. If Sigma2 is a matrix, it is</span></span><br><span class="line"><span class="comment">%    treated as the covariance matrix. If Sigma2 is a vector, it is treated</span></span><br><span class="line"><span class="comment">%    as the \sigma^2 values of the variances in each dimension (a diagonal</span></span><br><span class="line"><span class="comment">%    covariance matrix)</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line">k = <span class="built_in">length</span>(mu);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">size</span>(Sigma2, <span class="number">2</span>) == <span class="number">1</span>) || (<span class="built_in">size</span>(Sigma2, <span class="number">1</span>) == <span class="number">1</span>)</span><br><span class="line">    Sigma2 = <span class="built_in">diag</span>(Sigma2);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">X = <span class="built_in">bsxfun</span>(@minus, X, mu(:)');</span><br><span class="line">p = (<span class="number">2</span> * <span class="built_in">pi</span>) ^ (- k / <span class="number">2</span>) * det(Sigma2) ^ (<span class="number">-0.5</span>) * ...</span><br><span class="line">    <span class="built_in">exp</span>(<span class="number">-0.5</span> * sum(<span class="built_in">bsxfun</span>(@times, X * pinv(Sigma2), X), <span class="number">2</span>));</span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<ol>
<li>é˜ˆå€¼$\epsilon$ çš„é€‰æ‹©ï¼Œé€šè¿‡è®¡ç®—æ¯ä¸ªé˜ˆå€¼çš„F1å¾—åˆ†æ¥è¯„ä»·éªŒè¯é›†æ•°æ®ï¼Œé€‰æ‹©æœ€ä¼˜å¾—åˆ†çš„é˜ˆå€¼ï¼š</li>
</ol>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[bestEpsilon bestF1]</span> = <span class="title">selectThreshold</span><span class="params">(yval, pval)</span></span></span><br><span class="line"><span class="comment">%SELECTTHRESHOLD Find the best threshold (epsilon) to use for selecting</span></span><br><span class="line"><span class="comment">%outliers</span></span><br><span class="line"><span class="comment">%   [bestEpsilon bestF1] = SELECTTHRESHOLD(yval, pval) finds the best</span></span><br><span class="line"><span class="comment">%   threshold to use for selecting outliers based on the results from a</span></span><br><span class="line"><span class="comment">%   validation set (pval) and the ground truth (yval).</span></span><br><span class="line"></span><br><span class="line">bestEpsilon = <span class="number">0</span>;</span><br><span class="line">bestF1 = <span class="number">0</span>;</span><br><span class="line">F1 = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">stepsize = (max(pval) - min(pval)) / <span class="number">1000</span>;</span><br><span class="line"><span class="keyword">for</span> epsilon = min(pval):stepsize:max(pval)</span><br><span class="line">    <span class="comment">% Instructions: Compute the F1 score of choosing epsilon as the</span></span><br><span class="line">    <span class="comment">%               threshold and place the value in F1. The code at the</span></span><br><span class="line">    <span class="comment">%               end of the loop will compare the F1 score for this</span></span><br><span class="line">    <span class="comment">%               choice of epsilon and set it to be the best epsilon if</span></span><br><span class="line">    <span class="comment">%               it is better than the current choice of epsilon.</span></span><br><span class="line">    <span class="comment">%               </span></span><br><span class="line">    <span class="comment">% Note: You can use predictions = (pval &lt; epsilon) to get a binary vector</span></span><br><span class="line">    <span class="comment">%       of 0's and 1's of the outlier predictions</span></span><br><span class="line">    cvPredictions = (pval &lt; epsilon);</span><br><span class="line">    fp = sum((cvPredictions == <span class="number">1</span>)&amp; (yval == <span class="number">0</span>));</span><br><span class="line">    tp = sum((cvPredictions == <span class="number">1</span>)&amp;(yval == <span class="number">1</span>));</span><br><span class="line">    fn = sum((cvPredictions == <span class="number">0</span>)&amp;(yval == <span class="number">1</span>));</span><br><span class="line">    </span><br><span class="line">    prec = tp/(tp + fp);</span><br><span class="line">    rec = tp/(tp + fn);</span><br><span class="line"></span><br><span class="line">    F1 = <span class="number">2</span>*prec*rec/(prec + rec);</span><br><span class="line">    <span class="keyword">if</span> F1 &gt; bestF1</span><br><span class="line">       bestF1 = F1;</span><br><span class="line">       bestEpsilon = epsilon;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">pval = multivariateGaussian(Xval, mu, sigma2);</span><br><span class="line">[epsilon F1] = selectThreshold(yval, pval);</span><br></pre></td></tr></table></figure>
<p><img src="/2018/04/26/machinelearning-labs/../../qnsource/images/2018-04-26-machinelearning-labs/lab8_03.png" alt="lab8_03"></p>
<ol>
<li>åœ¨æ›´å¤æ‚åœºæ™¯ä¸‹çš„åº”ç”¨ï¼Œç¤ºä¾‹æä¾›äº†ä¸ªè¾“å…¥ä¸º11ç»´ç‰¹å¾çš„æ•°æ®ï¼Œå¯¹å…¶å¼‚å¸¸æ•°æ®è¿›è¡Œé¢„æµ‹ï¼Œä»£ç ç‰‡æ®µå¦‚ä¸‹ï¼š</li>
</ol>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%  Apply the same steps to the larger dataset</span></span><br><span class="line">[mu sigma2] = estimateGaussian(X);</span><br><span class="line"></span><br><span class="line"><span class="comment">%  Training set </span></span><br><span class="line">p = multivariateGaussian(X, mu, sigma2);</span><br><span class="line"></span><br><span class="line"><span class="comment">%  Cross-validation set</span></span><br><span class="line">pval = multivariateGaussian(Xval, mu, sigma2);</span><br><span class="line"></span><br><span class="line"><span class="comment">%  Find the best threshold</span></span><br><span class="line">[epsilon F1] = selectThreshold(yval, pval);</span><br><span class="line"></span><br><span class="line">fprintf(<span class="string">'Best epsilon found using cross-validation: %e\n'</span>, epsilon);</span><br><span class="line">fprintf(<span class="string">'Best F1 on Cross Validation Set:  %f\n'</span>, F1);</span><br><span class="line">fprintf(<span class="string">'# Outliers found: %d\n\n'</span>, sum(p &lt; epsilon));</span><br></pre></td></tr></table></figure>
<p>â€‹</p>
<h2 id="Lab-8-2ï¼šæ¨èç³»ç»Ÿ"><a href="#Lab-8-2ï¼šæ¨èç³»ç»Ÿ" class="headerlink" title="Lab 8.2ï¼šæ¨èç³»ç»Ÿ"></a>Lab 8.2ï¼šæ¨èç³»ç»Ÿ</h2><p>æœ¬å®éªŒå°†å®ç°ååŒè¿‡æ»¤ç®—æ³•ï¼Œå¹¶åº”ç”¨åˆ°ç”µå½±æ¨èä¹‹ä¸­ã€‚æ•°æ®é›†æ¥è‡ª943ä¸ªç”¨æˆ·çš„1682éƒ¨ç”µå½±çš„è¯„åˆ†æ•°æ®ï¼Œæ¯ä¸ªè¯„åˆ†èŒƒå›´ä¸º1-5ï¼Œå¯ä»¥å­˜åœ¨å¤šä¸ªæœªè¯„åˆ†æ•°æ®ã€‚</p>
<ul>
<li>$X$ ä¸ºnum_movies x num_featuresï¼Œæ˜¯ç”µå½±çš„ç‰¹å¾çŸ©é˜µ</li>
<li>$Y$ ä¸ºnum_movies x num_userçŸ©é˜µï¼Œæè¿°äº†æ¯ä¸ªè¯„åˆ†å€¼$y^{(i,j)}$</li>
<li>$R$ ä¸ºä¸$Y$ åŒç»´åº¦çš„äºŒå€¼çŸ©é˜µï¼Œ$R(i,j)=1$ ä»£è¡¨ç”¨æˆ·$j$ å¯¹ç”µå½±$i$ è¿›è¡Œäº†è¯„åˆ†</li>
</ul>
<ol>
<li>ä»£ä»·å‡½æ•°çš„å®šä¹‰</li>
</ol>
<script type="math/tex; mode=display">
J(x,\theta) = \dfrac{1}{2} \displaystyle \sum_{(i,j):r(i,j)=1}((\theta^{(j)})^Tx^{(i)} - y^{(i,j)})^2 + \dfrac{\lambda}{2}\sum_{i=1}^{n_m} \sum_{k=1}^{n} (x_k^{(i)})^2 + \dfrac{\lambda}{2}\sum_{j=1}^{n_u} \sum_{k=1}^{n} (\theta_k^{(j)})^2</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[J, grad]</span> = <span class="title">cofiCostFunc</span><span class="params">(params, Y, R, num_users, num_movies, ...</span></span></span><br><span class="line"><span class="function"><span class="params">                                  num_features, lambda)</span></span></span><br><span class="line"><span class="comment">%COFICOSTFUNC Collaborative filtering cost function</span></span><br><span class="line"><span class="comment">%   [J, grad] = COFICOSTFUNC(params, Y, R, num_users, num_movies, ...</span></span><br><span class="line"><span class="comment">%   num_features, lambda) returns the cost and gradient for the</span></span><br><span class="line"><span class="comment">%   collaborative filtering problem.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Unfold the U and W matrices from params</span></span><br><span class="line">X = <span class="built_in">reshape</span>(params(<span class="number">1</span>:num_movies*num_features), num_movies, num_features);</span><br><span class="line">Theta = <span class="built_in">reshape</span>(params(num_movies*num_features+<span class="number">1</span>:<span class="keyword">end</span>), ...</span><br><span class="line">                num_users, num_features);</span><br><span class="line">            </span><br><span class="line"><span class="comment">% You need to return the following values correctly</span></span><br><span class="line">J = <span class="number">0</span>;</span><br><span class="line">X_grad = <span class="built_in">zeros</span>(<span class="built_in">size</span>(X));</span><br><span class="line">Theta_grad = <span class="built_in">zeros</span>(<span class="built_in">size</span>(Theta));</span><br><span class="line"></span><br><span class="line"><span class="comment">% Instructions: Compute the cost function and gradient for collaborative</span></span><br><span class="line"><span class="comment">%               filtering. </span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% Notes: X - num_movies  x num_features matrix of movie features</span></span><br><span class="line"><span class="comment">%        Theta - num_users  x num_features matrix of user features</span></span><br><span class="line"><span class="comment">%        Y - num_movies x num_users matrix of user ratings of movies</span></span><br><span class="line"><span class="comment">%        R - num_movies x num_users matrix, where R(i, j) = 1 if the </span></span><br><span class="line"><span class="comment">%            i-th movie was rated by the j-th user</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% You should set the following variables correctly:</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">%        X_grad - num_movies x num_features matrix, containing the </span></span><br><span class="line"><span class="comment">%                 partial derivatives w.r.t. to each element of X</span></span><br><span class="line"><span class="comment">%        Theta_grad - num_users x num_features matrix, containing the </span></span><br><span class="line"><span class="comment">%                     partial derivatives w.r.t. to each element of Theta</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line">J = <span class="number">1</span>/<span class="number">2</span> * sum(sum(((X * Theta' - Y).*R).^<span class="number">2</span>));</span><br><span class="line"></span><br><span class="line">X_grad = ((X * Theta' - Y).*R) * Theta;</span><br><span class="line">Theta_grad = ((X*Theta' -Y).*R)' * X;</span><br><span class="line"></span><br><span class="line"><span class="comment">% Regular version</span></span><br><span class="line">J = J + lambda/<span class="number">2</span> * sum(sum(Theta .^<span class="number">2</span>)) + lambda/<span class="number">2</span> * sum(sum(X.^<span class="number">2</span>));</span><br><span class="line"></span><br><span class="line">X_grad = X_grad + lambda * X;</span><br><span class="line">Theta_grad = Theta_grad + lambda * Theta;</span><br><span class="line"></span><br><span class="line">grad = [X_grad(:); Theta_grad(:)];</span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%  Evaluate cost function</span></span><br><span class="line">J = cofiCostFunc([X(:) ; Theta(:)], Y, R, num_users, num_movies, num_features, <span class="number">1.5</span>);</span><br></pre></td></tr></table></figure>
<ol>
<li>å‘èµ·é¢„æµ‹ï¼Œåœ¨æ•°æ®åº“ä¸­åŠ å…¥è‡ªå·±çš„æ•°æ®ï¼Œéšä¾¿å¯¹ä¸€éƒ¨åˆ†ç”µå½±è¿›è¡Œæ‰“åˆ†ï¼š</li>
</ol>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% ============== Part 6: Entering ratings for a new user ===============</span></span><br><span class="line"><span class="comment">%  Before we will train the collaborative filtering model, we will first</span></span><br><span class="line"><span class="comment">%  add ratings that correspond to a new user that we just observed. This</span></span><br><span class="line"><span class="comment">%  part of the code will also allow you to put in your own ratings for the</span></span><br><span class="line"><span class="comment">%  movies in our dataset!</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line">movieList = loadMovieList();</span><br><span class="line"></span><br><span class="line"><span class="comment">%  Initialize my ratings</span></span><br><span class="line">my_ratings = <span class="built_in">zeros</span>(<span class="number">1682</span>, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Check the file movie_idx.txt for id of each movie in our dataset</span></span><br><span class="line"><span class="comment">% For example, Toy Story (1995) has ID 1, so to rate it "4", you can set</span></span><br><span class="line">my_ratings(<span class="number">1</span>) = <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% Or suppose did not enjoy Silence of the Lambs (1991), you can set</span></span><br><span class="line">my_ratings(<span class="number">98</span>) = <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% We have selected a few movies we liked / did not like and the ratings we</span></span><br><span class="line"><span class="comment">% gave are as follows:</span></span><br><span class="line">my_ratings(<span class="number">7</span>) = <span class="number">3</span>;</span><br><span class="line">my_ratings(<span class="number">12</span>)= <span class="number">5</span>;</span><br><span class="line">my_ratings(<span class="number">54</span>) = <span class="number">4</span>;</span><br><span class="line">my_ratings(<span class="number">64</span>)= <span class="number">5</span>;</span><br><span class="line">my_ratings(<span class="number">66</span>)= <span class="number">3</span>;</span><br><span class="line">my_ratings(<span class="number">69</span>) = <span class="number">5</span>;</span><br><span class="line">my_ratings(<span class="number">183</span>) = <span class="number">4</span>;</span><br><span class="line">my_ratings(<span class="number">226</span>) = <span class="number">5</span>;</span><br><span class="line">my_ratings(<span class="number">355</span>)= <span class="number">5</span>;</span><br></pre></td></tr></table></figure>
<p>æˆ‘ä»¬æ‹¥æœ‰äº†ä¸€ä»½æ–°çš„ç”¨æˆ·å¯¹ç”µå½±æ‰“åˆ†çš„æ•°æ®ï¼š</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">New user ratings:</span><br><span class="line">Rated 4 <span class="keyword">for</span> Toy Story (1995)</span><br><span class="line">Rated 3 <span class="keyword">for</span> Twelve Monkeys (1995)</span><br><span class="line">Rated 5 <span class="keyword">for</span> Usual Suspects, The (1995)</span><br><span class="line">Rated 4 <span class="keyword">for</span> Outbreak (1995)</span><br><span class="line">Rated 5 <span class="keyword">for</span> Shawshank Redemption, The (1994)</span><br><span class="line">Rated 3 <span class="keyword">for</span> While You Were Sleeping (1995)</span><br><span class="line">Rated 5 <span class="keyword">for</span> Forrest Gump (1994)</span><br><span class="line">Rated 2 <span class="keyword">for</span> Silence of the Lambs, The (1991)</span><br><span class="line">Rated 4 <span class="keyword">for</span> Alien (1979)</span><br><span class="line">Rated 5 <span class="keyword">for</span> Die Hard 2 (1990)</span><br><span class="line">Rated 5 <span class="keyword">for</span> Sphere (1998)</span><br></pre></td></tr></table></figure>
<ol>
<li>è®­ç»ƒç®—æ³•</li>
</ol>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% ================== Part 7: Learning Movie Ratings ====================</span></span><br><span class="line"><span class="comment">%  Now, you will train the collaborative filtering model on a movie rating </span></span><br><span class="line"><span class="comment">%  dataset of 1682 movies and 943 users</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%  Load data</span></span><br><span class="line">load(<span class="string">'ex8_movies.mat'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">%  Add our own ratings to the data matrix</span></span><br><span class="line">Y = [my_ratings Y];</span><br><span class="line">R = [(my_ratings ~= <span class="number">0</span>) R];</span><br><span class="line"></span><br><span class="line"><span class="comment">%  Normalize Ratings</span></span><br><span class="line">[Ynorm, Ymean] = normalizeRatings(Y, R);</span><br><span class="line"></span><br><span class="line"><span class="comment">%  Useful Values</span></span><br><span class="line">num_users = <span class="built_in">size</span>(Y, <span class="number">2</span>);</span><br><span class="line">num_movies = <span class="built_in">size</span>(Y, <span class="number">1</span>);</span><br><span class="line">num_features = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% Set Initial Parameters (Theta, X)</span></span><br><span class="line">X = <span class="built_in">randn</span>(num_movies, num_features);</span><br><span class="line">Theta = <span class="built_in">randn</span>(num_users, num_features);</span><br><span class="line"></span><br><span class="line">initial_parameters = [X(:); Theta(:)];</span><br><span class="line"></span><br><span class="line"><span class="comment">% Set options for fmincg</span></span><br><span class="line">options = optimset(<span class="string">'GradObj'</span>, <span class="string">'on'</span>, <span class="string">'MaxIter'</span>, <span class="number">100</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Set Regularization</span></span><br><span class="line">lambda = <span class="number">10</span>;</span><br><span class="line">theta = fmincg (@(t)(cofiCostFunc(t, Ynorm, R, num_users, num_movies, ...</span><br><span class="line">                                num_features, lambda)), ...</span><br><span class="line">                initial_parameters, options);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Unfold the returned theta back into U and W</span></span><br><span class="line">X = <span class="built_in">reshape</span>(theta(<span class="number">1</span>:num_movies*num_features), num_movies, num_features);</span><br><span class="line">Theta = <span class="built_in">reshape</span>(theta(num_movies*num_features+<span class="number">1</span>:<span class="keyword">end</span>), ...</span><br><span class="line">                num_users, num_features);</span><br><span class="line"></span><br><span class="line">fprintf(<span class="string">'Recommender system learning completed.\n'</span>);</span><br><span class="line"></span><br><span class="line">fprintf(<span class="string">'\nProgram paused. Press enter to continue.\n'</span>);</span><br><span class="line">pause;</span><br></pre></td></tr></table></figure>
<p>å…¶ä¸­ï¼Œå‡½æ•°<code>normalizeRatings</code> ç”¨äºå¯¹æ•°æ®è¿›è¡Œå½’ä¸€åŒ–ï¼Œå‡å»å‡å€¼ï¼›å‡½æ•°<code>fmincg</code>ä¸ºMATLABè‡ªå¸¦çš„ä¼˜åŒ–å‡½æ•°ï¼›</p>
<ol>
<li>åˆ©ç”¨ç®—æ³•è¿›è¡Œæ¨è</li>
</ol>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% ================== Part 8: Recommendation for you ====================</span></span><br><span class="line"><span class="comment">%  After training the model, you can now make recommendations by computing</span></span><br><span class="line"><span class="comment">%  the predictions matrix.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line">p = X * Theta';</span><br><span class="line">my_predictions = p(:,<span class="number">1</span>) + Ymean;</span><br><span class="line"></span><br><span class="line">movieList = loadMovieList();</span><br><span class="line"></span><br><span class="line">[r, ix] = sort(my_predictions, <span class="string">'descend'</span>);</span><br><span class="line">fprintf(<span class="string">'\nTop recommendations for you:\n'</span>);</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="number">10</span></span><br><span class="line">    <span class="built_in">j</span> = ix(<span class="built_in">i</span>);</span><br><span class="line">    fprintf(<span class="string">'Predicting rating %.1f for movie %s\n'</span>, my_predictions(<span class="built_in">j</span>), ...</span><br><span class="line">            movieList&#123;j&#125;);</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>è¾“å‡ºç»“æœï¼š</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Top recommendations <span class="keyword">for</span> you:</span><br><span class="line">Predicting rating 5.0 <span class="keyword">for</span> movie Someone Else<span class="string">'s America (1995)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Aiqing wansui (1994)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Great Day in Harlem, A (1994)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Prefontaine (1997)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie They Made Me a Criminal (1939)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Entertaining Angels: The Dorothy Day Story (1996)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Saint of Fort Washington, The (1993)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Santa with Muscles (1996)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Star Kid (1997)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Marlene Dietrich: Shadow and Light (1996)</span></span><br></pre></td></tr></table></figure>
<h2 id="å‚è€ƒ"><a href="#å‚è€ƒ" class="headerlink" title="å‚è€ƒ"></a>å‚è€ƒ</h2><ol>
<li>â€‹</li>
</ol>

      
    </div>
    <footer class="article-footer">

      
        <div id="donation_div"></div>

<script src="/js/vdonate.js"></script>
<script>
var a = new Donate({
  title: 'å¦‚æœè§‰å¾—æˆ‘çš„æ–‡ç« å¯¹æ‚¨æœ‰ç”¨ï¼Œè¯·éšæ„æ‰“èµã€‚æ‚¨çš„æ”¯æŒå°†é¼“åŠ±æˆ‘ç»§ç»­åˆ›ä½œ!', // å¯é€‰å‚æ•°ï¼Œæ‰“èµæ ‡é¢˜
  btnText: 'æ‰“èµæ”¯æŒ', // å¯é€‰å‚æ•°ï¼Œæ‰“èµæŒ‰é’®æ–‡å­—
  el: document.getElementById('donation_div'),
  wechatImage: '/qnsource/site/weixin.png',
  alipayImage: '/qnsource/site/alipay.jpg'
});
</script>
      
      
      <div>
        <ul class="post-copyright">
          <li class="post-copyright-author">
          <strong>æœ¬æ–‡ä½œè€…:  </strong>Ebby DD</a>
          </li>
          <li class="post-copyright-link">
          <strong>æœ¬æ–‡é“¾æ¥:  </strong>
          <a href="/2018/04/26/machinelearning-labs/" target="_blank" title="ã€Šæœºå™¨å­¦ä¹ ã€‹è¯¾ç¨‹å®éªŒå›é¡¾">http://blog.a-stack.com/2018/04/26/machinelearning-labs/</a>
          </li>
          <li class="post-copyright-license">
            <strong>ç‰ˆæƒå£°æ˜:   </strong>
            æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">CC BY-NC-ND 4.0</a>
            è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜å‡ºå¤„
          </li>
         
        </ul>
<div>

      

      
      <!--  -->

      <!--  -->
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/å…¬å¼€è¯¾/">å…¬å¼€è¯¾</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/å®éªŒ/">å®éªŒ</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/æœºå™¨å­¦ä¹ /">æœºå™¨å­¦ä¹ </a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/çº¿æ€§å›å½’/">çº¿æ€§å›å½’</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/é€»è¾‘å›å½’/">é€»è¾‘å›å½’</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/04/29/Everything-About-SVM/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">ä¸Šä¸€ç¯‡</strong>
      <div class="article-nav-title">
        
          Everything-About-SVM
        
      </div>
    </a>
  
  
    <a href="/2018/04/26/machinelearning-notes/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">ä¸‹ä¸€ç¯‡</strong>
      <div class="article-nav-title">Machine Learning Notes</div>
    </a>
  
</nav>

  
</article>

<!-- Table of Contents -->

  <aside id="toc-sidebar">
    <div id="toc" class="toc-article">
    <strong class="toc-title">æ–‡ç« ç›®å½•</strong>
    
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#æ¦‚è¦"><span class="nav-number">1.</span> <span class="nav-text">æ¦‚è¦</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Lab1-çº¿æ€§å›å½’"><span class="nav-number">2.</span> <span class="nav-text">Lab1: çº¿æ€§å›å½’</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-ç®€å•çº¿æ€§å›å½’"><span class="nav-number">2.1.</span> <span class="nav-text">1. ç®€å•çº¿æ€§å›å½’</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#ä»£ä»·å‡½æ•°å’Œæ¢¯åº¦æ›´æ–°å®ç°"><span class="nav-number">2.1.1.</span> <span class="nav-text">ä»£ä»·å‡½æ•°å’Œæ¢¯åº¦æ›´æ–°å®ç°</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#J-theta-çš„å¯è§†åŒ–"><span class="nav-number">2.1.2.</span> <span class="nav-text">$J(\theta)$ çš„å¯è§†åŒ–</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-å¤šå…ƒçº¿æ€§å›å½’"><span class="nav-number">2.2.</span> <span class="nav-text">2. å¤šå…ƒçº¿æ€§å›å½’</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-ç‰¹å¾å½’ä¸€åŒ–"><span class="nav-number">2.3.</span> <span class="nav-text">2.1 ç‰¹å¾å½’ä¸€åŒ–</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-è®¡ç®—-theta-çš„æ•°å€¼è§£"><span class="nav-number">2.4.</span> <span class="nav-text">2.2 è®¡ç®— $\theta$ çš„æ•°å€¼è§£</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Lab-2-Lab-5"><span class="nav-number">3.</span> <span class="nav-text">Lab 2 - Lab 5:</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Lab-6-SVM"><span class="nav-number">4.</span> <span class="nav-text">Lab 6: SVM</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Lab-7-1-K-Means"><span class="nav-number">5.</span> <span class="nav-text">Lab 7.1: K-Means</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Lab-7-2ï¼š-PCA"><span class="nav-number">6.</span> <span class="nav-text">Lab 7.2ï¼š PCA</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#æ•°æ®å¯è§†åŒ–çš„é™ç»´æ˜¾ç¤º"><span class="nav-number">6.1.</span> <span class="nav-text">æ•°æ®å¯è§†åŒ–çš„é™ç»´æ˜¾ç¤º</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Lab-8-1-å¼‚å¸¸æ£€æµ‹"><span class="nav-number">7.</span> <span class="nav-text">Lab 8.1: å¼‚å¸¸æ£€æµ‹</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Lab-8-2ï¼šæ¨èç³»ç»Ÿ"><span class="nav-number">8.</span> <span class="nav-text">Lab 8.2ï¼šæ¨èç³»ç»Ÿ</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#å‚è€ƒ"><span class="nav-number">9.</span> <span class="nav-text">å‚è€ƒ</span></a></li></ol>
    
    </div>
  </aside>

</section>      
        
      </div>
      <!--  -->
      <footer id="footer">
  

  <div class="container">
      	<div class="row">
	      <p> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/iTimeTraveler/hexo-theme-hiker" target="_blank">Hexo-theme-hiker</a> </p>
	      <p id="copyRightEn">Copyright &copy; 2017 - 2020 Ebby&#39;s Notes All Rights Reserved.</p>
	      
	      
  		   	<p id="copyRightCn">Ebby DD ä¿ç•™æ‰€æœ‰æƒåˆ©</p>
  		   
		</div>

		
  </div>
</footer>


<!-- min height -->

<script>
    var wrapdiv = document.getElementById("wrap");
    var contentdiv = document.getElementById("content");
    var allheader = document.getElementById("allheader");

    wrapdiv.style.minHeight = document.body.offsetHeight + "px";
    if (allheader != null) {
      contentdiv.style.minHeight = document.body.offsetHeight - allheader.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    } else {
      contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    }
</script>
    </div>    
    <!-- <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
    <a href="/reading" class="mobile-nav-link">Reading</a>
  
    <a href="/resources" class="mobile-nav-link">Resources</a>
  
    <a href="/notebooks" class="mobile-nav-link">ğŸ“</a>
  
</nav> -->
    

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">

</script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/scripts.js"></script>




  <script src="/js/dialog.js"></script>











	<script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?684368b6943d7a5b6689dba5e7bf30ad";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  </div>

  <div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true" style="display: none;">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h2 class="modal-title" id="myModalLabel">è®¾ç½®</h2>
      </div>
      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">


      <div class="modal-body">
          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseOne" onclick="javascript:setFontSize();" aria-expanded="true" aria-controls="collapseOne">
              æ­£æ–‡å­—å·å¤§å°
            </a>
          </div>
          <div id="collapseOne" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingOne">
          <div class="panel-body">
            æ‚¨å·²è°ƒæ•´é¡µé¢å­—ä½“å¤§å°
          </div>
        </div>
      


          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseTwo" onclick="javascript:setBackground();" aria-expanded="true" aria-controls="collapseTwo">
              å¤œé—´æŠ¤çœ¼æ¨¡å¼
            </a>
        </div>
          <div id="collapseTwo" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTwo">
          <div class="panel-body">
            å¤œé—´æ¨¡å¼å·²ç»å¼€å¯ï¼Œå†æ¬¡å•å‡»æŒ‰é’®å³å¯å…³é—­ 
          </div>
        </div>

        <div>
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseThree" aria-expanded="true" aria-controls="collapseThree">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;å…³ äº&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
        </div>
         <div id="collapseThree" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingThree">
          <div class="panel-body">
            Ebby&#39;s Notes
          </div>
          <div class="panel-body">
            Copyright Â© 2020 Ebby DD All Rights Reserved.
          </div>
        </div>
      </div>


      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <div class="modal-footer">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
      </div>
    </div>
  </div>
</div>
  
  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
  
    <a id="menu-switch"><i class="fa fa-bars fa-lg"></i></a>
  
</body>
</html>