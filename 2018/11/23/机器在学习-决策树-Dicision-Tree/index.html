<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  <title>机器在学习-决策树(dicision tree) | Ebby&#39;s Notes</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
    <meta name="keywords" content="人工智能,深度学习,技术,算法">
  
  
  
  
  <meta name="description" content="摘要：">
<meta name="keywords" content="人工智能,深度学习,技术,算法">
<meta property="og:type" content="article">
<meta property="og:title" content="机器在学习-决策树(Dicision Tree)">
<meta property="og:url" content="http://blog.a-stack.com/2018/11/23/机器在学习-决策树-Dicision-Tree/index.html">
<meta property="og:site_name" content="Ebby&#39;s Notes">
<meta property="og:description" content="摘要：">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://blog.a-stack.com/qnsource/banner/15.jpg">
<meta property="og:image" content="http://blog.a-stack.com/2018/11/23/机器在学习-决策树-Dicision-Tree/credit_scoring_toy_tree_english.png">
<meta property="og:image" content="http://blog.a-stack.com/2018/11/23/机器在学习-决策树-Dicision-Tree/topic3_credit_scoring_entropy.png">
<meta property="og:image" content="http://blog.a-stack.com/2018/11/23/机器在学习-决策树-Dicision-Tree/Criteria%20of%20quality%20as%20a%20function%20of%20binary%20classification.png">
<meta property="og:image" content="http://blog.a-stack.com/2018/11/23/机器在学习-决策树-Dicision-Tree/tree1.png">
<meta property="og:updated_time" content="2018-11-25T07:22:23.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器在学习-决策树(Dicision Tree)">
<meta name="twitter:description" content="摘要：">
<meta name="twitter:image" content="http://blog.a-stack.com/qnsource/banner/15.jpg">
  
    <link rel="alternate" href="/atom.xml" title="Ebby&#39;s Notes" type="application/atom+xml">
  

  

  <link rel="icon" href="/css/images/logo.png">
  <link rel="apple-touch-icon" href="/css/images/logo.png">
  
    <link href="/qnsource/css/Source+Code+Pro.css" rel="stylesheet" type="text/css">
  
  <link href="/qnsource/css/Open+Sans-Montserrat-700.css" rel="stylesheet" type="text/css">
  <link href="/qnsource/css/Roboto-400-300.css" rel="stylesheet" type="text/css">
  <link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <link rel="stylesheet" href="/css/style.css">

  <script src="/js/jquery-3.1.1.min.js"></script>
  <script src="/js/bootstrap.js"></script>

  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="/css/bootstrap.css">

  
    <link rel="stylesheet" href="/css/dialog.css">
  

  

  
    <link rel="stylesheet" href="/css/header-post.css">
  

  
  
  
    <link rel="stylesheet" href="/css/vdonate.css">
  

</head>
</html>


  <body data-spy="scroll" data-target="#toc" data-offset="50">


  
  <div id="container">
    <div id="wrap">
      
        <header>

    <div id="allheader" class="navbar navbar-default navbar-static-top" role="navigation">
        <div class="navbar-inner">
          
          <div class="container"> 
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>

            
              <a class="brand" style="
                 border-width: 0px;  margin-top: 0px;"  
                href="#" data-toggle="modal" data-target="#myModal" >
                  <img width="200px" height="100px" alt="Hike News" src="/css/images/logo.png">
              </a>
            
            
            <div class="navbar-collapse collapse">
              <ul class="hnav navbar-nav">
                
                  <li> <a class="main-nav-link" href="/">首页</a> </li>
                
                  <li> <a class="main-nav-link" href="/archives">归档</a> </li>
                
                  <li> <a class="main-nav-link" href="/categories">分类</a> </li>
                
                  <li> <a class="main-nav-link" href="/tags">标签</a> </li>
                
                  <li> <a class="main-nav-link" href="/about">关于</a> </li>
                
                  <li> <a class="main-nav-link" href="/reading">读书</a> </li>
                
                  <li> <a class="main-nav-link" href="/resources">资源</a> </li>
                
                  <li> <a class="main-nav-link" href="/notebooks">📝</a> </li>
                
                  <li><div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="请输入关键词..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(无标题)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div></li>
            </div>
          </div>
                
      </div>
    </div>

</header>



      
            
      <div id="content" class="outer">
        
          <section id="main" style="float:none;"><article id="post-机器在学习-决策树-Dicision-Tree" style="width: 75%; float:left;" class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" class="article-title" itemprop="name">
      机器在学习-决策树(Dicision Tree)
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2018/11/23/机器在学习-决策树-Dicision-Tree/" class="article-date">
	  <time datetime="2018-11-23T08:50:11.000Z" itemprop="datePublished">2018-11-23</time>
	</a>

      
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>

      
      

    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="/qnsource/banner/15.jpg" alt="Test Picture"></p>
<p><strong>摘要：</strong></p>
<a id="more"></a>
<h2 id="决策树的算法"><a href="#决策树的算法" class="headerlink" title="决策树的算法"></a>决策树的算法</h2><blockquote>
<p>ID3  C4.5  CART</p>
<p>ID3（Iterative Dichotomiser 3）由 Ross Quinlan 在1986年提出。该算法创建一个多路树，找到每个节点（即以贪心的方式）分类特征，这将产生分类目标的最大信息增益。决策树发展到其最大尺寸，然后通常利用剪枝来提高树对未知数据的泛华能力。</p>
<p>C4.5 是 ID3 的后继者，并且通过动态定义将连续属性值分割成一组离散间隔的离散属性（基于数字变量），消除了特征必须被明确分类的限制。C4.5 将训练的树（即，ID3算法的输出）转换成 if-then 规则的集合。然后评估每个规则的这些准确性，以确定应用它们的顺序。如果规则的准确性没有改变，则需要决策树的树枝来解决。</p>
<p>C5.0 是 Quinlan 根据专有许可证发布的最新版本。它使用更少的内存，并建立比 C4.5 更小的规则集，同时更准确。</p>
<p>CART（Classification and Regression Trees （分类和回归树））与 C4.5 非常相似，但它不同之处在于它支持数值目标变量（回归），并且不计算规则集。CART 使用在每个节点产生最大信息增益的特征和阈值来构造二叉树。</p>
<p>scikit-learn 使用 CART 算法的优化版本。</p>
</blockquote>
<p><strong>Decision Trees (DTs)</strong> 是一种用来 <a href="http://sklearn.apachecn.org/cn/0.19.0/modules/tree.html#tree-classification" target="_blank" rel="noopener">classification</a> 和 <a href="http://sklearn.apachecn.org/cn/0.19.0/modules/tree.html#tree-regression" target="_blank" rel="noopener">regression</a> 的无参监督学习方法。其目的是创建一种模型从数据特征中学习简单的决策规则来预测一个目标变量的值。 </p>
<p><img src="/2018/11/23/机器在学习-决策树-Dicision-Tree/credit_scoring_toy_tree_english.png" alt="credit_scoring_toy_tree_english"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build</span><span class="params">(L)</span>:</span></span><br><span class="line">    create node t</span><br><span class="line">    <span class="keyword">if</span> the stopping criterion <span class="keyword">is</span> <span class="keyword">True</span>:</span><br><span class="line">        assign a predictive model to t</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        Find the best binary split L = L_left + L_right</span><br><span class="line">        t.left = build(L_left)</span><br><span class="line">        t.right = build(L_right)</span><br><span class="line">    <span class="keyword">return</span> t</span><br></pre></td></tr></table></figure>
<h3 id="决策树的递归返回"><a href="#决策树的递归返回" class="headerlink" title="决策树的递归返回"></a>决策树的递归返回</h3><ul>
<li>(1) 当前结点包含的样本全属于同一类别，无需划分; </li>
<li>(2) 当前属性集为空，或是所有样本在所有属性上取值相同，无法划分; </li>
<li>(3) 当前结点包含的样本集合为空，不能划分.</li>
</ul>
<h3 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h3><ul>
<li><p>信息熵（香农）： $E(D) = -\sum_k p_klog_2p_k$</p>
</li>
<li><p>增益： $IG(D,a) = E(D) - \sum_v \frac{|D^v|}{|D|}E(D^v)$</p>
<p><img src="/2018/11/23/机器在学习-决策树-Dicision-Tree/topic3_credit_scoring_entropy.png" alt="scoring_entropy"></p>
<blockquote>
<ol>
<li>信息增益可以衡量使用某个属性划分的好坏；</li>
<li>信息增益准则对可能取值数目较多的属性有偏好，为减少这种偏好带来的不利影响，C4.5决策树算法使用增益率来选择最优划分属性。</li>
</ol>
</blockquote>
</li>
<li><p>增益率： $G_r(D,a)=\frac{IG(D,a)}{IV(a)}$</p>
<script type="math/tex; mode=display">
IV(a) =\sum_v \frac{|D^v|}{|D|}log_2\frac{|D^v|}{|D|}</script></li>
</ul>
<h3 id="Gini"><a href="#Gini" class="headerlink" title="Gini"></a>Gini</h3><script type="math/tex; mode=display">
Gini(D)=1-\sum_k p^2_k</script><blockquote>
<p>CART决策树使用的算法,Gini数值约小，数据集D的纯度越高。</p>
</blockquote>
<p><img src="/2018/11/23/机器在学习-决策树-Dicision-Tree/Criteria of quality as a function of binary classification.png" alt="Criteria of quality as a function of binary classification"></p>
<h3 id="剪枝（pruning）"><a href="#剪枝（pruning）" class="headerlink" title="剪枝（pruning）"></a>剪枝（pruning）</h3><ul>
<li><strong>预剪枝：</strong> （自顶向下） 预剪枝是指在决策树生成过程中，对每个结点在划 分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶结点;</li>
<li><strong>后剪枝：</strong>（自底向上）后剪枝则是先从训练集生成一棵完整的决策树， 然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为叶结点.</li>
</ul>
<blockquote>
<p>预剪枝减少了计算量，减少了过拟合，但存在欠拟合的风险；</p>
<p>后剪枝是自底向上的对树中所有非叶节点进行逐一考察，训练开销比预剪枝要大很多。</p>
</blockquote>
<h3 id="一些处理技巧"><a href="#一些处理技巧" class="headerlink" title="一些处理技巧"></a>一些处理技巧</h3><h4 id="处理连续值"><a href="#处理连续值" class="headerlink" title="处理连续值"></a>处理连续值</h4><ul>
<li>连续属性离散化技术（二分法）；</li>
<li>对训练样本值排序，查找最大信息增益的分割点（对结果影响大的点），划分为多个连续区间；</li>
<li>如果训练样本某个属性不同样本值特别多，可以选择top-N增益最大的点作为划分分类的点；</li>
</ul>
<h4 id="处理缺失值"><a href="#处理缺失值" class="headerlink" title="处理缺失值"></a>处理缺失值</h4><ul>
<li>根据缺失值赋权；</li>
</ul>
<h4 id="多变量决策树"><a href="#多变量决策树" class="headerlink" title="多变量决策树"></a>多变量决策树</h4><ul>
<li>组合多个变量，可以形成非与坐标轴平行的分类边界；</li>
</ul>
<h4 id="回归树"><a href="#回归树" class="headerlink" title="回归树"></a>回归树</h4><script type="math/tex; mode=display">
\Large D = \frac{1}{\ell} \sum\limits_{i =1}^{\ell} (y_i - \frac{1}{\ell} \sum\limits_{j=1}^{\ell} y_j)^2</script><p>where $\ell$ is the number of samples in a leaf, $y_i$ is the value of the target variable.</p>
<h2 id="决策树算法的优缺点"><a href="#决策树算法的优缺点" class="headerlink" title="决策树算法的优缺点"></a>决策树算法的优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ol>
<li>可解释性强，决策树的计算原理和人做决策的过程十分类似，是解释性最强的机器学习模型；</li>
<li>可视化方便，计算过程可以在图中直观的反映出来；</li>
<li>训练和预测都十分迅速，计算代价小；</li>
<li>训练需要的数据少。其他机器学习模型通常需要数据规范化，比如构建虚拟变量和移除缺失值,不过请注意，这种模型不支持缺失值。</li>
<li>超参十分少，常用的只有层数、叶子节点中元素个数、最大特征数等少数几个超参；</li>
<li>对于连续变量、离散变量、分类问题和回归问题都可以处理。</li>
</ol>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ol>
<li>对噪声数据敏感，训练数据发生轻微变动，可能导致整个模型参数发生很大变化；</li>
<li>分割界面只能平行或垂直坐标轴方向，处理逻辑太过简单；</li>
<li>需要特别注意过拟合的发生；决策树模型容易产生一个过于复杂的模型,这样的模型对数据的泛化性能会很差。这就是所谓的过拟合.一些策略像剪枝、设置叶节点所需的最小样本数或设置数的最大深度是避免出现 该问题最为有效地方法。</li>
<li>稳定性差；因为数据中的微小变化可能会导致完全不同的树生成。这个问题可以通过决策树的集成来得到缓解 </li>
<li>最优决策树的选择是一个NP-完备问题。需要使用一些启发式算法寻找最优的信息增益，但未必能找到最优值；这个问题可以通过集成学习来训练多棵决策树来缓解,这多棵决策树一般通过对特征和样本有放回的随机采样来生成。 </li>
<li>缺失数据的处理比较麻烦；</li>
<li>数据集没有覆盖的区域，没有区分能力</li>
<li>有些概念很难被决策树学习到,因为决策树很难清楚的表述这些概念。例如XOR，奇偶或者复用器的问题。</li>
</ol>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><blockquote>
<p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html" target="_blank" rel="noopener"><code>sklearn.tree.DecisionTreeClassifier</code></a></p>
<ul>
<li><code>max_depth</code> – the maximum depth of the tree;</li>
<li><code>max_features</code> - the maximum number of features with which to search for the best partition (this is necessary with a large number of features because it would be “expensive” to search for partitions for <em>all</em> features);</li>
<li><code>min_samples_leaf</code> – the minimum number of samples in a leaf. This parameter prevents creating trees where any leaf would have only a few members.</li>
</ul>
<p><a href="http://sklearn.apachecn.org/cn/0.19.0/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor" target="_blank" rel="noopener"><code>DecisionTreeRegressor</code></a> </p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Sklearn</span></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line">clf_tree = DecisionTreeClassifier(criterion=<span class="string">'entropy'</span>, max_depth=<span class="number">3</span>, </span><br><span class="line">                                  random_state=<span class="number">17</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># training the tree</span></span><br><span class="line">clf_tree.fit(train_data, train_labels)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line">tree_pred = tree.predict(X_holdout)</span><br><span class="line">accuracy_score(y_holdout, tree_pred) <span class="comment"># 0.94</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 超参</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV, cross_val_score</span><br><span class="line"></span><br><span class="line">tree_params = &#123;<span class="string">'max_depth'</span>: range(<span class="number">1</span>,<span class="number">11</span>),</span><br><span class="line">               <span class="string">'max_features'</span>: range(<span class="number">4</span>,<span class="number">19</span>)&#125;</span><br><span class="line"></span><br><span class="line">tree_grid = GridSearchCV(tree, tree_params,</span><br><span class="line">                         cv=<span class="number">5</span>, n_jobs=<span class="number">-1</span>, verbose=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">tree_grid.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">accuracy_score(y_holdout, tree_grid.predict(X_holdout)) <span class="comment">#0.946</span></span><br></pre></td></tr></table></figure>
<h3 id="画图"><a href="#画图" class="headerlink" title="画图"></a>画图</h3><p>经过训练，我们可以使用 <a href="http://sklearn.apachecn.org/cn/0.19.0/modules/generated/sklearn.tree.export_graphviz.html#sklearn.tree.export_graphviz" target="_blank" rel="noopener"><code>export_graphviz</code></a> 导出器以 <a href="http://www.graphviz.org/" target="_blank" rel="noopener">Graphviz</a> 格式导出决策树. 如果你是用 <a href="http://conda.io/" target="_blank" rel="noopener">conda</a> 来管理包，那么安装 graphviz 二进制文件和 python 包可以用以下指令安装</p>
<blockquote>
<p>conda install python-graphviz</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pydotplus <span class="comment">#pip install pydotplus</span></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> export_graphviz</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tree_graph_to_png</span><span class="params">(tree, feature_names, png_file_to_save)</span>:</span></span><br><span class="line">    tree_str = export_graphviz(tree, feature_names=feature_names, </span><br><span class="line">                                     filled=<span class="keyword">True</span>, out_file=<span class="keyword">None</span>)</span><br><span class="line">    graph = pydotplus.graph_from_dot_data(tree_str)  </span><br><span class="line">    graph.write_png(png_file_to_save)</span><br><span class="line">    </span><br><span class="line">  tree_graph_to_png(tree=clf_tree, feature_names=[<span class="string">'x1'</span>, <span class="string">'x2'</span>], </span><br><span class="line">                  png_file_to_save=<span class="string">'../../img/topic3_tree1.png'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/2018/11/23/机器在学习-决策树-Dicision-Tree/tree1.png" alt="tree1"></p>
<h3 id="技巧"><a href="#技巧" class="headerlink" title="技巧"></a>技巧</h3><blockquote>
<ul>
<li>对于拥有大量特征的数据决策树会出现过拟合的现象。获得一个合适的样本比例和特征数量十分重要，因为在高维空间中只有少量的样本的树是十分容易过拟合的。</li>
<li>考虑事先进行降维( <a href="http://sklearn.apachecn.org/cn/0.19.0/modules/decomposition.html#pca" target="_blank" rel="noopener">PCA</a> , <a href="http://sklearn.apachecn.org/cn/0.19.0/modules/decomposition.html#ica" target="_blank" rel="noopener">ICA</a> ，使您的树更好地找到具有分辨性的特征。</li>
<li>通过 <code>export</code> 功能可以可视化您的决策树。使用 <code>max_depth=3</code> 作为初始树深度，让决策树知道如何适应您的数据，然后再增加树的深度。</li>
<li>请记住，填充树的样本数量会增加树的每个附加级别。使用 <code>max_depth</code> 来控制输的大小防止过拟合。</li>
<li>通过使用 <code>min_samples_split</code> 和 <code>min_samples_leaf</code> 来控制叶节点上的样本数量。当这个值很小时意味着生成的决策树将会过拟合，然而当这个值很大时将会不利于决策树的对样本的学习。所以尝试 <code>min_samples_leaf=5</code> 作为初始值。如果样本的变化量很大，可以使用浮点数作为这两个参数中的百分比。两者之间的主要区别在于 <code>min_samples_leaf</code> 保证叶结点中最少的采样数，而 <code>min_samples_split</code> 可以创建任意小的叶子，尽管在文献中 <code>min_samples_split</code> 更常见。</li>
<li>在训练之前平衡您的数据集，以防止决策树偏向于主导类.可以通过从每个类中抽取相等数量的样本来进行类平衡，或者优选地通过将每个类的样本权重 (<code>sample_weight</code>) 的和归一化为相同的值。还要注意的是，基于权重的预修剪标准 (<code>min_weight_fraction_leaf</code>) 对于显性类别的偏倚偏小，而不是不了解样本权重的标准，如 <code>min_samples_leaf</code> 。</li>
</ul>
</blockquote>
<ul>
<li>如果样本被加权，则使用基于权重的预修剪标准 <code>min_weight_fraction_leaf</code> 来优化树结构将更容易，这确保叶节点包含样本权重的总和的至少一部分。</li>
<li>所有的决策树内部使用 <code>np.float32</code> 数组 ，如果训练数据不是这种格式，将会复制数据集。</li>
<li>如果输入的矩阵X为稀疏矩阵，建议您在调用fit之前将矩阵X转换为稀疏的<code>csc_matrix</code> ,在调用predict之前将 <code>csr_matrix</code> 稀疏。当特征在大多数样本中具有零值时，与密集矩阵相比，稀疏矩阵输入的训练时间可以快几个数量级。</li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><p>《机器学习》——周志华</p>
</li>
<li><p><a href="https://mlcourse.ai/" target="_blank" rel="noopener">mlcourse.ai</a> – Open Machine Learning Course</p>
</li>
</ol>
<p>3.<a href="http://sklearn.apachecn.org/cn/0.19.0/modules/tree.html#tree" target="_blank" rel="noopener">Sklearn 决策树</a></p>

      
    </div>
    <footer class="article-footer">

      
        <div id="donation_div"></div>

<script src="/js/vdonate.js"></script>
<script>
var a = new Donate({
  title: '如果觉得我的文章对您有用，请随意打赏。您的支持将鼓励我继续创作!', // 可选参数，打赏标题
  btnText: '打赏支持', // 可选参数，打赏按钮文字
  el: document.getElementById('donation_div'),
  wechatImage: '/qnsource/site/weixin.png',
  alipayImage: '/qnsource/site/alipay.jpg'
});
</script>
      
      
      <div>
        <ul class="post-copyright">
          <li class="post-copyright-author">
          <strong>本文作者:  </strong>Ebby DD</a>
          </li>
          <li class="post-copyright-link">
          <strong>本文链接:  </strong>
          <a href="/2018/11/23/机器在学习-决策树-Dicision-Tree/" target="_blank" title="机器在学习-决策树(Dicision Tree)">http://blog.a-stack.com/2018/11/23/机器在学习-决策树-Dicision-Tree/</a>
          </li>
          <li class="post-copyright-license">
            <strong>版权声明:   </strong>
            本博客所有文章除特别声明外，均采用 <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">CC BY-NC-ND 4.0</a>
            许可协议。转载请注明出处
          </li>
         
        </ul>
<div>

      

      
        
 <!-- valine @ebby -->
 <section id="comments" class="comments">
	<style>
		.comments{margin:30px;padding:10px;background:#fff}
		@media screen and (max-width:800px){.comments{margin:auto;padding:10px;background:#fff}}
	</style>
	<div id="vcomment" class="comment"></div>
<script src="//cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script>
<script src="//cdn.jsdelivr.net/npm/leancloud-storage@latest/dist/av-min.js"></script>
<script src='//cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js'></script>
<script>
   var notify = 'false' == true ? true : false;
   var verify = 'false' == true ? true : false;
   new Valine({
            av: AV,
            el: '#vcomment',
            notify: notify,
            verify: verify,
            app_id: "JQMgg0zbFBNWwL0lLnq2s1G7-gzGzoHsz",
            app_key: "m5FMVedFNxGutQCnMsVMAaXM",
            placeholder: "Say Something ...",
            avatar: "wavatar",
            avatar_cdn: "https://sdn.geekzu.org/avatar/",
            pageSize: "15"
    });
</script>
		
</section>



      
      <!--  -->

      <!--  -->
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/人工智能/">人工智能</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/文献/">文献</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/算法/">算法</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/11/23/机器在学习—-KNN/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">上一篇</strong>
      <div class="article-nav-title">
        
          机器在学习-KNN
        
      </div>
    </a>
  
  
    <a href="/2018/11/23/机器在学习-线性回归/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">下一篇</strong>
      <div class="article-nav-title">机器在学习-线性回归与分类</div>
    </a>
  
</nav>

  
</article>

<!-- Table of Contents -->

  <aside id="toc-sidebar">
    <div id="toc" class="toc-article">
    <strong class="toc-title">文章目录</strong>
    
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#决策树的算法"><span class="nav-number">1.</span> <span class="nav-text">决策树的算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#决策树的递归返回"><span class="nav-number">1.1.</span> <span class="nav-text">决策树的递归返回</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#信息增益"><span class="nav-number">1.2.</span> <span class="nav-text">信息增益</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Gini"><span class="nav-number">1.3.</span> <span class="nav-text">Gini</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#剪枝（pruning）"><span class="nav-number">1.4.</span> <span class="nav-text">剪枝（pruning）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#一些处理技巧"><span class="nav-number">1.5.</span> <span class="nav-text">一些处理技巧</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#处理连续值"><span class="nav-number">1.5.1.</span> <span class="nav-text">处理连续值</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#处理缺失值"><span class="nav-number">1.5.2.</span> <span class="nav-text">处理缺失值</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#多变量决策树"><span class="nav-number">1.5.3.</span> <span class="nav-text">多变量决策树</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#回归树"><span class="nav-number">1.5.4.</span> <span class="nav-text">回归树</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#决策树算法的优缺点"><span class="nav-number">2.</span> <span class="nav-text">决策树算法的优缺点</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#优点"><span class="nav-number">2.1.</span> <span class="nav-text">优点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#缺点"><span class="nav-number">2.2.</span> <span class="nav-text">缺点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#实现"><span class="nav-number">3.</span> <span class="nav-text">实现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#画图"><span class="nav-number">3.1.</span> <span class="nav-text">画图</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#技巧"><span class="nav-number">3.2.</span> <span class="nav-text">技巧</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考"><span class="nav-number">4.</span> <span class="nav-text">参考</span></a></li></ol>
    
    </div>
  </aside>

</section>      
        
      </div>
      <!--  -->
      <footer id="footer">
  

  <div class="container">
      	<div class="row">
	      <p> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/iTimeTraveler/hexo-theme-hiker" target="_blank">Hexo-theme-hiker</a> </p>
	      <p id="copyRightEn">Copyright &copy; 2017 - 2020 Ebby&#39;s Notes All Rights Reserved.</p>
	      
	      
  		   	<p id="copyRightCn">Ebby DD 保留所有权利</p>
  		   
		</div>

		
  </div>
</footer>


<!-- min height -->

<script>
    var wrapdiv = document.getElementById("wrap");
    var contentdiv = document.getElementById("content");
    var allheader = document.getElementById("allheader");

    wrapdiv.style.minHeight = document.body.offsetHeight + "px";
    if (allheader != null) {
      contentdiv.style.minHeight = document.body.offsetHeight - allheader.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    } else {
      contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    }
</script>
    </div>    
    <!-- <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
    <a href="/reading" class="mobile-nav-link">Reading</a>
  
    <a href="/resources" class="mobile-nav-link">Resources</a>
  
    <a href="/notebooks" class="mobile-nav-link">📝</a>
  
</nav> -->
    

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">

</script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/scripts.js"></script>




  <script src="/js/dialog.js"></script>











	<script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?684368b6943d7a5b6689dba5e7bf30ad";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  </div>

  <div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true" style="display: none;">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h2 class="modal-title" id="myModalLabel">设置</h2>
      </div>
      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">


      <div class="modal-body">
          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseOne" onclick="javascript:setFontSize();" aria-expanded="true" aria-controls="collapseOne">
              正文字号大小
            </a>
          </div>
          <div id="collapseOne" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingOne">
          <div class="panel-body">
            您已调整页面字体大小
          </div>
        </div>
      


          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseTwo" onclick="javascript:setBackground();" aria-expanded="true" aria-controls="collapseTwo">
              夜间护眼模式
            </a>
        </div>
          <div id="collapseTwo" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTwo">
          <div class="panel-body">
            夜间模式已经开启，再次单击按钮即可关闭 
          </div>
        </div>

        <div>
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseThree" aria-expanded="true" aria-controls="collapseThree">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关 于&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
        </div>
         <div id="collapseThree" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingThree">
          <div class="panel-body">
            Ebby&#39;s Notes
          </div>
          <div class="panel-body">
            Copyright © 2020 Ebby DD All Rights Reserved.
          </div>
        </div>
      </div>


      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <div class="modal-footer">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
      </div>
    </div>
  </div>
</div>
  
  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
  
    <a id="menu-switch"><i class="fa fa-bars fa-lg"></i></a>
  
</body>
</html>