<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>batch-normalization(æ‰¹é‡å½’ä¸€åŒ–) | Ebby&#39;s Notes</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
    <meta name="keywords" content="äººå·¥æ™ºèƒ½,æ·±åº¦å­¦ä¹ ,æŠ€æœ¯,ç®—æ³•" />
  
  
  
  
  <meta name="description" content="æ‘˜è¦ï¼š å€Ÿé‡è¯»è®ºæ–‡çš„æœºä¼šï¼Œé‡æ–°æ•´ç†ä¸€ä¸‹Batch Normalizationçš„å…³é”®æŠ€æœ¯ã€‚">
<meta name="keywords" content="äººå·¥æ™ºèƒ½,æ·±åº¦å­¦ä¹ ,æŠ€æœ¯,ç®—æ³•">
<meta property="og:type" content="article">
<meta property="og:title" content="Batch-Normalization(æ‰¹é‡å½’ä¸€åŒ–)">
<meta property="og:url" content="http://blog.a-stack.com/2019/01/12/Batch-Normalization-æ‰¹é‡å½’ä¸€åŒ–/index.html">
<meta property="og:site_name" content="Ebby&#39;s Notes">
<meta property="og:description" content="æ‘˜è¦ï¼š å€Ÿé‡è¯»è®ºæ–‡çš„æœºä¼šï¼Œé‡æ–°æ•´ç†ä¸€ä¸‹Batch Normalizationçš„å…³é”®æŠ€æœ¯ã€‚">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://blog.a-stack.com/qnsource/banner/07.jpg">
<meta property="og:image" content="http://blog.a-stack.com/2019/01/12/Batch-Normalization-æ‰¹é‡å½’ä¸€åŒ–/BN_Forward.PNG">
<meta property="og:image" content="http://blog.a-stack.com/2019/01/12/Batch-Normalization-æ‰¹é‡å½’ä¸€åŒ–/BN_Backward.PNG">
<meta property="og:image" content="http://blog.a-stack.com/2019/01/12/Batch-Normalization-æ‰¹é‡å½’ä¸€åŒ–/BN_error_with_small_batch_size.png">
<meta property="og:image" content="http://blog.a-stack.com/qnsource/images/2018-04-28-cs231n-notes/normalization_methods.png">
<meta property="og:updated_time" content="2019-01-16T09:43:14.913Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Batch-Normalization(æ‰¹é‡å½’ä¸€åŒ–)">
<meta name="twitter:description" content="æ‘˜è¦ï¼š å€Ÿé‡è¯»è®ºæ–‡çš„æœºä¼šï¼Œé‡æ–°æ•´ç†ä¸€ä¸‹Batch Normalizationçš„å…³é”®æŠ€æœ¯ã€‚">
<meta name="twitter:image" content="http://blog.a-stack.com/qnsource/banner/07.jpg">
  
    <link rel="alternate" href="/atom.xml" title="Ebby&#39;s Notes" type="application/atom+xml">
  

  

  <link rel="icon" href="/css/images/logo.png">
  <link rel="apple-touch-icon" href="/css/images/logo.png">
  
    <link href="/qnsource/css/Source+Code+Pro.css" rel="stylesheet" type="text/css">
  
  <link href="/qnsource/css/Open+Sans-Montserrat-700.css" rel="stylesheet" type="text/css">
  <link href="/qnsource/css/Roboto-400-300.css" rel="stylesheet" type="text/css">
  <link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <link rel="stylesheet" href="/css/style.css">

  <script src="/js/jquery-3.1.1.min.js"></script>
  <script src="/js/bootstrap.js"></script>

  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="/css/bootstrap.css" >

  
    <link rel="stylesheet" href="/css/dialog.css">
  

  

  
    <link rel="stylesheet" href="/css/header-post.css" >
  

  
  
  
    <link rel="stylesheet" href="/css/vdonate.css" >
  

</head>



  <body data-spy="scroll" data-target="#toc" data-offset="50">


  
  <div id="container">
    <div id="wrap">
      
        <header>

    <div id="allheader" class="navbar navbar-default navbar-static-top" role="navigation">
        <div class="navbar-inner">
          
          <div class="container"> 
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>

            
              <a class="brand" style="
                 border-width: 0px;  margin-top: 0px;"  
                href="#" data-toggle="modal" data-target="#myModal" >
                  <img width="200px" height="100px" alt="Hike News" src="/css/images/logo.png">
              </a>
            
            
            <div class="navbar-collapse collapse">
              <ul class="hnav navbar-nav">
                
                  <li> <a class="main-nav-link" href="/">é¦–é¡µ</a> </li>
                
                  <li> <a class="main-nav-link" href="/archives">å½’æ¡£</a> </li>
                
                  <li> <a class="main-nav-link" href="/categories">åˆ†ç±»</a> </li>
                
                  <li> <a class="main-nav-link" href="/tags">æ ‡ç­¾</a> </li>
                
                  <li> <a class="main-nav-link" href="/about">å…³äº</a> </li>
                
                  <li> <a class="main-nav-link" href="/reading">è¯»ä¹¦</a> </li>
                
                  <li> <a class="main-nav-link" href="/resources">èµ„æº</a> </li>
                
                  <li> <a class="main-nav-link" href="/notebooks">ğŸ“</a> </li>
                
                  <li><div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="è¯·è¾“å…¥å…³é”®è¯..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'æ–‡ç« ',
            PAGES: 'é¡µé¢',
            CATEGORIES: 'åˆ†ç±»',
            TAGS: 'æ ‡ç­¾',
            UNTITLED: '(æ— æ ‡é¢˜)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div></li>
            </div>
          </div>
                
      </div>
    </div>

</header>



      
            
      <div id="content" class="outer">
        
          <section id="main" style="float:none;"><article id="post-Batch-Normalization-æ‰¹é‡å½’ä¸€åŒ–" style="width: 75%; float:left;" class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" class="article-title" itemprop="name">
      Batch-Normalization(æ‰¹é‡å½’ä¸€åŒ–)
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2019/01/12/Batch-Normalization-æ‰¹é‡å½’ä¸€åŒ–/" class="article-date">
	  <time datetime="2019-01-12T14:45:29.000Z" itemprop="datePublished">2019-01-12</time>
	</a>

      
    <a class="article-category-link" href="/categories/æ·±åº¦å­¦ä¹ /">æ·±åº¦å­¦ä¹ </a>

      
      

    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="/qnsource/banner/07.jpg" alt="BNä¸å¾—ä¸äº†è§£çš„æ·±åº¦å­¦ä¹ æŠ€æœ¯~"></p>
<p><strong>æ‘˜è¦ï¼š</strong> å€Ÿé‡è¯»è®ºæ–‡çš„æœºä¼šï¼Œé‡æ–°æ•´ç†ä¸€ä¸‹Batch Normalizationçš„å…³é”®æŠ€æœ¯ã€‚</p>
<a id="more"></a>
<blockquote>
<p>è¿‘æœŸåœ¨é‡æ–°åšCS231nä½œä¸šçš„æ—¶å€™ï¼Œå†æ¬¡è¢«Batch Normalizationç»™å›°ä½ï¼Œæ— å¥ˆä»è®ºæ–‡å’Œèµ„æ–™é‡æ–°å¼€å§‹æŸ¥é˜…ï¼Œè¿™æ¬¡å°½é‡æŠŠç›¸å…³æŠ€æœ¯ç ”ç©¶é€ï¼Œæ•´ç†ä»¥å¤‡é€ŸæŸ¥ã€‚</p>
<p>CS231nä¸­å…³äºBatch Normalizationçš„ä½œä¸šå‡ºåœ¨Assignment 2çš„ç¬¬äºŒä¸ªä½œä¸šï¼Œå¯é€šè¿‡è¯¥<a href="https://github.com/ddebby/cs231n/blob/master/assignment2/BatchNormalization.ipynb" target="_blank" rel="noopener">é“¾æ¥</a>è®¿é—®ã€‚</p>
</blockquote>
<h2 id="ä¸ºä»€ä¹ˆéœ€è¦Batch-Normalization"><a href="#ä¸ºä»€ä¹ˆéœ€è¦Batch-Normalization" class="headerlink" title="ä¸ºä»€ä¹ˆéœ€è¦Batch Normalization"></a>ä¸ºä»€ä¹ˆéœ€è¦Batch Normalization</h2><p>BNæ˜¯ç”±Googleäº2015å¹´æå‡ºï¼Œè¿™æ˜¯ä¸€ä¸ªæ·±åº¦ç¥ç»ç½‘ç»œè®­ç»ƒçš„æŠ€å·§ï¼Œå®ƒä¸ä»…å¯ä»¥åŠ å¿«äº†æ¨¡å‹çš„æ”¶æ•›é€Ÿåº¦ï¼Œè€Œä¸”æ›´é‡è¦çš„æ˜¯åœ¨ä¸€å®šç¨‹åº¦ç¼“è§£äº†æ·±å±‚ç½‘ç»œä¸­â€œæ¢¯åº¦å¼¥æ•£â€çš„é—®é¢˜ï¼Œä»è€Œä½¿å¾—è®­ç»ƒæ·±å±‚ç½‘ç»œæ¨¡å‹æ›´åŠ å®¹æ˜“å’Œç¨³å®šã€‚æ‰€ä»¥ç›®å‰BNå·²ç»æˆä¸ºå‡ ä¹æ‰€æœ‰å·ç§¯ç¥ç»ç½‘ç»œçš„æ ‡é…æŠ€å·§äº†ã€‚</p>
<p>åœ¨æœºå™¨å­¦ä¹ ç®—æ³•ä¸­ï¼Œä¸€èˆ¬éƒ½å‡è®¾æ‰€æœ‰è¾“å…¥ç‰¹å¾ç¬¦åˆç‹¬ç«‹åŒåˆ†å¸ƒçš„ç‰¹æ€§ï¼Œæ‰€ä»¥å°†è¾“å…¥æ•°æ®å½’ä¸€åŒ–ä¸ºå•ä½é«˜æ–¯åˆ†å¸ƒæœ‰åˆ©äºæå‡æ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚è¿™ä¹Ÿæ˜¯ç™½åŒ–å¯¹äºæå‡æ¨¡å‹è®­ç»ƒèµ·çš„è‰¯å¥½æ•ˆæœçš„åŸå› ã€‚åœ¨æ·±åº¦ç¥ç»ç½‘ç»œä¸­ï¼Œæˆ‘ä»¬é€šè¿‡å¯¹è¾“å…¥æ•°æ®çš„çº¦æŸï¼Œå·²ç»å¯ä»¥å®ç°åœ¨è¾“å…¥å±‚çš„æ¿€æ´»å¯ä»¥ä¿è¯æ•°æ®çš„ç‹¬ç«‹åŒåˆ†å¸ƒï¼Œä½†éšç€ç½‘ç»œä¼ æ’­è¿‡ç¨‹ï¼Œéçº¿æ€§æ¿€æ´»å‡½æ•°çš„ä½œç”¨ï¼Œå¯¼è‡´æ•°æ®çš„åˆ†å¸ƒä¸æ–­å˜åŒ–ï¼Œæ•°æ®çš„ç‹¬ç«‹æ€§ï¼ˆå±‚çš„æ•°æ®ä¹‹é—´å­˜åœ¨ä¸åŒç¨‹åº¦çš„ç›¸å…³æ€§ï¼‰è¢«ç ´åã€‚æ•°æ®ä¸å†æ˜¯é›¶å‡å€¼æˆ–è€…å•ä½æ–¹å·®ã€‚åŒæ—¶éšç€æ¢¯åº¦çš„æ›´æ–°ï¼Œæ¯å±‚æ•°æ®åˆ†å¸ƒä¹Ÿåœ¨äº§ç”Ÿä¸åŒç¨‹åº¦çš„åç§»ã€‚</p>
<h2 id="Batch-Normalizationçš„æ€æƒ³åŠå®ç°"><a href="#Batch-Normalizationçš„æ€æƒ³åŠå®ç°" class="headerlink" title="Batch Normalizationçš„æ€æƒ³åŠå®ç°"></a>Batch Normalizationçš„æ€æƒ³åŠå®ç°</h2><p>æ¨¡å‹è®­ç»ƒé˜¶æ®µï¼ŒBNå±‚é€šè¿‡ä¼°è®¡mini-batchä¸­æ•°æ®çš„å‡å€¼å’Œæ–¹å·®ï¼Œå°†æ•°æ®è¿›è¡Œå½’ä¸€åŒ–ã€‚åŒæ—¶è¿™äº›ä¼°è®¡ç»“æœçš„æ»‘åŠ¨å‡å€¼è¢«è®°å½•ä¸‹æ¥ï¼Œç”¨äºæ¨ç†é˜¶æ®µã€‚</p>
<p>Batch Normalizationçš„è®¡ç®—</p>
<script type="math/tex; mode=display">
\begin{align}
\mu_i = \frac{1}{m} \sum_{k \in S_i} x_k\\
\sigma_i = \sqrt{\frac{1}{m}\sum_{k\in S_i} (x_k-\mu_i)^2 + \epsilon}\\
\hat x_i = \frac{x_i - \mu_i}{\sigma_i}\\
y_i = \lambda \hat x_i + \beta
\end{align}</script><blockquote>
<p>å…¬å¼ï¼ˆ4ï¼‰æ˜¯ä¸ºäº†ä¿è¯è¢«BNå±‚å¤„ç†ä¹‹åçš„æ•°æ®ä»å…·å¤‡ä¸€å®šçš„éçº¿æ€§ç‰¹å¾è€Œè¿›è¡Œçš„æ¢å¤æ“ä½œï¼Œä¸ç„¶ç½‘ç»œæ‰€æœ‰å±‚éƒ½æ˜¯çº¿æ€§å˜æ¢ï¼Œæ— æ³•è¿›è¡Œæ¨¡å‹å‚æ•°æ›´æ–°ã€‚</p>
</blockquote>
<h3 id="å‰å‘ä¼ æ’­çš„å®ç°"><a href="#å‰å‘ä¼ æ’­çš„å®ç°" class="headerlink" title="å‰å‘ä¼ æ’­çš„å®ç°"></a>å‰å‘ä¼ æ’­çš„å®ç°</h3><p>å‚è€ƒBNä½œè€…è®ºæ–‡çš„æ€è·¯å¦‚ä¸‹ï¼š</p>
<p><img src="/2019/01/12/Batch-Normalization-æ‰¹é‡å½’ä¸€åŒ–/BN_Forward.PNG" alt="BN_Forward"></p>
<p>ä»£ç å®ç°å¦‚ä¸‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batchnorm_forward</span><span class="params">(x, gamma, beta, bn_param)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Forward pass for batch normalization.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    During training the sample mean and (uncorrected) sample variance are</span></span><br><span class="line"><span class="string">    computed from minibatch statistics and used to normalize the incoming data.</span></span><br><span class="line"><span class="string">    During training we also keep an exponentially decaying running mean of the</span></span><br><span class="line"><span class="string">    mean and variance of each feature, and these averages are used to normalize</span></span><br><span class="line"><span class="string">    data at test-time.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    At each timestep we update the running averages for mean and variance using</span></span><br><span class="line"><span class="string">    an exponential decay based on the momentum parameter:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    running_mean = momentum * running_mean + (1 - momentum) * sample_mean</span></span><br><span class="line"><span class="string">    running_var = momentum * running_var + (1 - momentum) * sample_var</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Note that the batch normalization paper suggests a different test-time</span></span><br><span class="line"><span class="string">    behavior: they compute sample mean and variance for each feature using a</span></span><br><span class="line"><span class="string">    large number of training images rather than using a running average. For</span></span><br><span class="line"><span class="string">    this implementation we have chosen to use running averages instead since</span></span><br><span class="line"><span class="string">    they do not require an additional estimation step; the torch7</span></span><br><span class="line"><span class="string">    implementation of batch normalization also uses running averages.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">    - x: Data of shape (N, D)</span></span><br><span class="line"><span class="string">    - gamma: Scale parameter of shape (D,)</span></span><br><span class="line"><span class="string">    - beta: Shift paremeter of shape (D,)</span></span><br><span class="line"><span class="string">    - bn_param: Dictionary with the following keys:</span></span><br><span class="line"><span class="string">      - mode: 'train' or 'test'; required</span></span><br><span class="line"><span class="string">      - eps: Constant for numeric stability</span></span><br><span class="line"><span class="string">      - momentum: Constant for running mean / variance.</span></span><br><span class="line"><span class="string">      - running_mean: Array of shape (D,) giving running mean of features</span></span><br><span class="line"><span class="string">      - running_var Array of shape (D,) giving running variance of features</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - out: of shape (N, D)</span></span><br><span class="line"><span class="string">    - cache: A tuple of values needed in the backward pass</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    mode = bn_param[<span class="string">'mode'</span>]</span><br><span class="line">    eps = bn_param.get(<span class="string">'eps'</span>, <span class="number">1e-5</span>)</span><br><span class="line">    momentum = bn_param.get(<span class="string">'momentum'</span>, <span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line">    N, D = x.shape</span><br><span class="line">    running_mean = bn_param.get(<span class="string">'running_mean'</span>, np.zeros(D, dtype=x.dtype))</span><br><span class="line">    running_var = bn_param.get(<span class="string">'running_var'</span>, np.zeros(D, dtype=x.dtype))</span><br><span class="line"></span><br><span class="line">    out, cache = <span class="keyword">None</span>, <span class="keyword">None</span></span><br><span class="line">    <span class="keyword">if</span> mode == <span class="string">'train'</span>:</span><br><span class="line">        <span class="comment">#######################################################################</span></span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span> Implement the training-time forward pass for batch norm.      #</span></span><br><span class="line">        <span class="comment"># Use minibatch statistics to compute the mean and variance, use      #</span></span><br><span class="line">        <span class="comment"># these statistics to normalize the incoming data, and scale and      #</span></span><br><span class="line">        <span class="comment"># shift the normalized data using gamma and beta.                     #</span></span><br><span class="line">        <span class="comment">#                                                                     #</span></span><br><span class="line">        <span class="comment"># You should store the output in the variable out. Any intermediates  #</span></span><br><span class="line">        <span class="comment"># that you need for the backward pass should be stored in the cache   #</span></span><br><span class="line">        <span class="comment"># variable.                                                           #</span></span><br><span class="line">        <span class="comment">#                                                                     #</span></span><br><span class="line">        <span class="comment"># You should also use your computed sample mean and variance together #</span></span><br><span class="line">        <span class="comment"># with the momentum variable to update the running mean and running   #</span></span><br><span class="line">        <span class="comment"># variance, storing your result in the running_mean and running_var   #</span></span><br><span class="line">        <span class="comment"># variables.                                                          #</span></span><br><span class="line">        <span class="comment">#                                                                     #</span></span><br><span class="line">        <span class="comment"># Note that though you should be keeping track of the running         #</span></span><br><span class="line">        <span class="comment"># variance, you should normalize the data based on the standard       #</span></span><br><span class="line">        <span class="comment"># deviation (square root of variance) instead!                        # </span></span><br><span class="line">        <span class="comment"># Referencing the original paper (https://arxiv.org/abs/1502.03167)   #</span></span><br><span class="line">        <span class="comment"># might prove to be helpful.                                          #</span></span><br><span class="line">        <span class="comment">#######################################################################</span></span><br><span class="line">        <span class="comment">#pass</span></span><br><span class="line">        sample_mean = np.mean(x,axis=<span class="number">0</span>)</span><br><span class="line">        sample_var = np.var(x,axis=<span class="number">0</span>)</span><br><span class="line">        running_mean = momentum * running_mean + (<span class="number">1</span> - momentum) * sample_mean</span><br><span class="line">        running_var = momentum * running_var + (<span class="number">1</span> - momentum) * sample_var</span><br><span class="line">        x_hat = (x - sample_mean)/np.sqrt(sample_var + eps)</span><br><span class="line">        out = gamma * x_hat  + beta</span><br><span class="line"></span><br><span class="line">        cache =(x, x_hat, gamma, beta,eps,sample_mean, sample_var)</span><br><span class="line">        <span class="comment">#######################################################################</span></span><br><span class="line">        <span class="comment">#                           END OF YOUR CODE                          #</span></span><br><span class="line">        <span class="comment">#######################################################################</span></span><br><span class="line">    <span class="keyword">elif</span> mode == <span class="string">'test'</span>:</span><br><span class="line">        <span class="comment">#######################################################################</span></span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span> Implement the test-time forward pass for batch normalization. #</span></span><br><span class="line">        <span class="comment"># Use the running mean and variance to normalize the incoming data,   #</span></span><br><span class="line">        <span class="comment"># then scale and shift the normalized data using gamma and beta.      #</span></span><br><span class="line">        <span class="comment"># Store the result in the out variable.                               #</span></span><br><span class="line">        <span class="comment">#######################################################################</span></span><br><span class="line">        <span class="comment">#pass</span></span><br><span class="line">        x_hat = (x - running_mean)/np.sqrt(running_var + eps)</span><br><span class="line">        out = gamma * x_hat  + beta</span><br><span class="line">        cache =(x,x_hat, gamma, beta, eps, running_mean, running_var)</span><br><span class="line">        <span class="comment">#######################################################################</span></span><br><span class="line">        <span class="comment">#                          END OF YOUR CODE                           #</span></span><br><span class="line">        <span class="comment">#######################################################################</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">'Invalid forward batchnorm mode "%s"'</span> % mode)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Store the updated running means back into bn_param</span></span><br><span class="line">    bn_param[<span class="string">'running_mean'</span>] = running_mean</span><br><span class="line">    bn_param[<span class="string">'running_var'</span>] = running_var</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> out, cache</span><br></pre></td></tr></table></figure>
<h3 id="åå‘ä¼ æ’­çš„å®ç°"><a href="#åå‘ä¼ æ’­çš„å®ç°" class="headerlink" title="åå‘ä¼ æ’­çš„å®ç°"></a>åå‘ä¼ æ’­çš„å®ç°</h3><p><img src="/2019/01/12/Batch-Normalization-æ‰¹é‡å½’ä¸€åŒ–/BN_Backward.PNG" alt="BN_Backward"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batchnorm_backward_alt</span><span class="params">(dout, cache)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Alternative backward pass for batch normalization.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    For this implementation you should work out the derivatives for the batch</span></span><br><span class="line"><span class="string">    normalizaton backward pass on paper and simplify as much as possible. You</span></span><br><span class="line"><span class="string">    should be able to derive a simple expression for the backward pass. </span></span><br><span class="line"><span class="string">    See the jupyter notebook for more hints.</span></span><br><span class="line"><span class="string">     </span></span><br><span class="line"><span class="string">    Note: This implementation should expect to receive the same cache variable</span></span><br><span class="line"><span class="string">    as batchnorm_backward, but might not use all of the values in the cache.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs / outputs: Same as batchnorm_backward</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    dx, dgamma, dbeta = <span class="keyword">None</span>, <span class="keyword">None</span>, <span class="keyword">None</span></span><br><span class="line">    <span class="comment">###########################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> Implement the backward pass for batch normalization. Store the    #</span></span><br><span class="line">    <span class="comment"># results in the dx, dgamma, and dbeta variables.                         #</span></span><br><span class="line">    <span class="comment">#                                                                         #</span></span><br><span class="line">    <span class="comment"># After computing the gradient with respect to the centered inputs, you   #</span></span><br><span class="line">    <span class="comment"># should be able to compute gradients with respect to the inputs in a     #</span></span><br><span class="line">    <span class="comment"># single statement; our implementation fits on a single 80-character line.#</span></span><br><span class="line">    <span class="comment">###########################################################################    </span></span><br><span class="line">    x, x_hat, gamma, beta, eps, mean, var = cache</span><br><span class="line"></span><br><span class="line">    dgamma = np.sum(dout*x_hat,axis=<span class="number">0</span>)</span><br><span class="line">    dbeta = np.sum(dout, axis=<span class="number">0</span>)</span><br><span class="line">    dx_hat = dout * gamma</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># temp vars</span></span><br><span class="line">    xmu = x - mean</span><br><span class="line">    istd = <span class="number">1</span>/np.sqrt(var + eps)</span><br><span class="line">    m = x.shape[<span class="number">0</span>]   </span><br><span class="line">    </span><br><span class="line">    dvar = np.sum(dx_hat*xmu*(<span class="number">-0.5</span>)*np.power((var+eps),<span class="number">-1.5</span>),axis=<span class="number">0</span>)</span><br><span class="line">    dmean = np.sum(dx_hat*(<span class="number">-1</span>)*istd,axis=<span class="number">0</span>) + np.sum(<span class="number">-2</span>*xmu*dvar,axis=<span class="number">0</span>)/m</span><br><span class="line">    dx = dx_hat*istd + dvar*<span class="number">2</span>*xmu/m + dmean/m    </span><br><span class="line"></span><br><span class="line">    <span class="comment">###########################################################################</span></span><br><span class="line">    <span class="comment">#                             END OF YOUR CODE                            #</span></span><br><span class="line">    <span class="comment">###########################################################################</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dx, dgamma, dbeta</span><br></pre></td></tr></table></figure>
<h3 id="BNå±‚å‚æ•°çš„å­¦ä¹ è¿‡ç¨‹ä¸­"><a href="#BNå±‚å‚æ•°çš„å­¦ä¹ è¿‡ç¨‹ä¸­" class="headerlink" title="BNå±‚å‚æ•°çš„å­¦ä¹ è¿‡ç¨‹ä¸­"></a>BNå±‚å‚æ•°çš„å­¦ä¹ è¿‡ç¨‹ä¸­</h3><p>åœ¨æ¯ä¸ªBNå±‚ï¼Œé™¤äº†wå’Œbä¹‹å¤–ï¼Œè¿˜éœ€è¦å­¦ä¹ <code>gamma</code>å’Œ<code>beta</code>ä¸¤ä¸ªé¢å¤–çš„å‚æ•°ã€‚</p>
<h2 id="Batch-Normalizationå¸¦æ¥çš„å¥½å¤„"><a href="#Batch-Normalizationå¸¦æ¥çš„å¥½å¤„" class="headerlink" title="Batch Normalizationå¸¦æ¥çš„å¥½å¤„"></a>Batch Normalizationå¸¦æ¥çš„å¥½å¤„</h2><ol>
<li>ä¸ä»…æå¤§çš„æå‡äº†è®­ç»ƒé€Ÿåº¦ï¼Œæ”¶æ•›è¿‡ç¨‹ä¹Ÿå¤§å¤§çš„åŠ å¿«äº†ï¼›</li>
<li>å¢å¼ºåˆ†ç±»æ•ˆæœï¼Œä¸€ç§è§£é‡Šæ˜¯è¿™æ˜¯ç±»ä¼¼äºDropoutçš„ä¸€ç§é˜²æ­¢è¿‡æ‹Ÿåˆçš„æ­£åˆ™åŒ–è¡¨è¾¾æ–¹å¼ï¼Œæ‰€ä»¥ä¸ç”¨Dropoutä¹Ÿèƒ½è¾¾åˆ°ç›¸å½“çš„æ•ˆæœï¼›</li>
<li>ä½¿ç”¨äº†BNå±‚ä¹‹åï¼Œè¿›ä¸€æ­¥å‡å°‘äº†åœ¨å¤„ç†è¿‡æ‹Ÿåˆè¿‡ç¨‹ä¸­å¯¹Dropoutçš„ä¾èµ–ï¼›</li>
<li>å¯¹äºç½‘ç»œçš„å‚æ•°åˆå§‹åŒ–è¦æ±‚é™ä½ï¼Œä¸å†æ‹…å¿ƒç½‘ç»œåˆå§‹åŒ–æ²¡æ§åˆ¶å¥½å¯¼è‡´ç½‘ç»œéš¾ä»¥è®­ç»ƒçš„é—®é¢˜ï¼ˆå°¤å…¶æ˜¯æ·±å±‚æ¬¡ç½‘ç»œï¼‰</li>
</ol>
<h2 id="å…¶å®ƒçš„å½’ä¸€åŒ–æ–¹æ³•"><a href="#å…¶å®ƒçš„å½’ä¸€åŒ–æ–¹æ³•" class="headerlink" title="å…¶å®ƒçš„å½’ä¸€åŒ–æ–¹æ³•"></a>å…¶å®ƒçš„å½’ä¸€åŒ–æ–¹æ³•</h2><p>ç”±äºBNä¼šå—åˆ°batch sizeå¤§å°çš„å½±å“ï¼Œå¦‚æœbatch sizeå¤ªå°ï¼Œç®—å‡ºçš„å‡å€¼å’Œæ–¹å·®å°±ä¼šä¸å‡†ç¡®ï¼Œå¤ªå¤§å­˜å‚¨å¯èƒ½ä¸å¤Ÿç”¨ã€‚æ‰€ä»¥è¡ç”Ÿå‡ºäº†å‡ ç§ä¼˜åŒ–è¡¨è¾¾ã€‚</p>
<p><img src="/2019/01/12/Batch-Normalization-æ‰¹é‡å½’ä¸€åŒ–/BN_error_with_small_batch_size.png" alt="BN_error_with_small_batch_size"></p>
<p><img src="/qnsource/images/2018-04-28-cs231n-notes/normalization_methods.png" alt="normalization_methods"></p>
<ul>
<li>BatchNormï¼š batchæ–¹å‘åšå½’ä¸€åŒ–ï¼Œè®¡ç®— <code>H*W*C</code> çš„å‡å€¼ï¼›</li>
<li>LayerNormï¼š channelæ–¹å‘åšå½’ä¸€åŒ–ï¼Œè®¡ç®—<code>N*H*W</code> çš„å‡å€¼ï¼›</li>
<li>InstanceNormï¼š ä¸€ä¸ªchannelå†…åšå½’ä¸€åŒ–ï¼Œè®¡ç®—<code>H*W</code>çš„å‡å€¼ï¼›</li>
<li>GroupNormï¼š å°†Channelæ–¹å‘åˆ†ä¸ºGroupï¼Œç„¶åæ¯ä¸ªGroupå†…åšå½’ä¸€åŒ–ï¼Œè®¡ç®—<code>(C//G)*H*W</code>çš„å‡å€¼</li>
</ul>
<blockquote>
<p>å½“G=Cæ—¶ï¼ŒGroupNormä¸ºLayerNormï¼Œå½“G=1æ—¶ï¼ŒGroupNormä¸ºInstanceNorm</p>
</blockquote>
<p>å…¶ä¸­ï¼ŒGourpNormçš„å¯å‘æ¥æºäºå›¾åƒçš„æ‰‹å·¥ç‰¹å¾æå–å™¨ï¼ˆæ¯”å¦‚HOGï¼ŒSIFTï¼‰å‘ç°å¾ˆå¤šä¸åŒç±»å‹çš„ç‰¹å¾éƒ½æ˜¯æˆç»„å‡ºç°çš„ï¼Œåˆ©ç”¨æˆç»„å°è£…çš„æ–¹å¼è¿›è¡Œç‰¹å¾å‡å€¼ã€æ–¹å·®æå–å¯èƒ½æ›´èƒ½åæ˜ ç‰¹å¾çš„çœŸå®æƒ…å†µï¼Œå°¤å…¶åœ¨å°æ‰¹é‡BNæ•ˆæœä¸‹é™çš„æƒ…å†µä¸‹ä½œä¸ºBNçš„ä¸€ä¸ªæ›¿ä»£å“ã€‚</p>
<p>ä½†å®é™…ä¸Šï¼Œåœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­è¿˜æ˜¯ä¼˜å…ˆé€‰ç”¨BNï¼Œåªæœ‰åœ¨æ‰¹é‡å®åœ¨å¾ˆå°ï¼Œå¦‚è§†é¢‘åˆ†æã€å›¾åƒåˆ†å‰²ç­‰åœºæ™¯ï¼Œæ¯ä¸ªæ‰¹æ¬¡åªæœ‰ä¸€ä¸¤å¼ å›¾åƒçš„æƒ…å†µä¸‹ï¼Œé€‰ç”¨GroupNormä½œä¸ºæ›¿ä»£ã€‚</p>
<h2 id="å‚è€ƒ"><a href="#å‚è€ƒ" class="headerlink" title="å‚è€ƒ"></a>å‚è€ƒ</h2><ol>
<li><a href="https://arxiv.org/abs/1502.03167" target="_blank" rel="noopener">Sergey Ioffe and Christian Szegedy, â€œBatch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shiftâ€, ICML 2015.</a></li>
<li><a href="https://arxiv.org/abs/1803.08494" target="_blank" rel="noopener">Wu, Yuxin, and Kaiming He. â€œGroup Normalization.â€ arXiv preprint arXiv:1803.08494 (2018).</a></li>
</ol>

      
    </div>
    <footer class="article-footer">

      
        <div id="donation_div"></div>

<script src="/js/vdonate.js"></script>
<script>
var a = new Donate({
  title: 'å¦‚æœè§‰å¾—æˆ‘çš„æ–‡ç« å¯¹æ‚¨æœ‰ç”¨ï¼Œè¯·éšæ„æ‰“èµã€‚æ‚¨çš„æ”¯æŒå°†é¼“åŠ±æˆ‘ç»§ç»­åˆ›ä½œ!', // å¯é€‰å‚æ•°ï¼Œæ‰“èµæ ‡é¢˜
  btnText: 'æ‰“èµæ”¯æŒ', // å¯é€‰å‚æ•°ï¼Œæ‰“èµæŒ‰é’®æ–‡å­—
  el: document.getElementById('donation_div'),
  wechatImage: '/qnsource/site/weixin.png',
  alipayImage: '/qnsource/site/alipay.jpg'
});
</script>
      
      
      <div>
        <ul class="post-copyright">
          <li class="post-copyright-author">
          <strong>æœ¬æ–‡ä½œè€…:  </strong>Ebby DD</a>
          </li>
          <li class="post-copyright-link">
          <strong>æœ¬æ–‡é“¾æ¥:  </strong>
          <a href="/2019/01/12/Batch-Normalization-æ‰¹é‡å½’ä¸€åŒ–/" target="_blank" title="Batch-Normalization(æ‰¹é‡å½’ä¸€åŒ–)">http://blog.a-stack.com/2019/01/12/Batch-Normalization-æ‰¹é‡å½’ä¸€åŒ–/</a>
          </li>
          <li class="post-copyright-license">
            <strong>ç‰ˆæƒå£°æ˜:   </strong>
            æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">CC BY-NC-ND 4.0</a>
            è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜å‡ºå¤„
          </li>
         
        </ul>
<div>

      

      
        
 <!-- valine @ebby -->
 <section id="comments" class="comments">
	<style>
		.comments{margin:30px;padding:10px;background:#fff}
		@media screen and (max-width:800px){.comments{margin:auto;padding:10px;background:#fff}}
	</style>
	<div id="vcomment" class="comment"></div>
<script src="//cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script>
<script src="//cdn.jsdelivr.net/npm/leancloud-storage@latest/dist/av-min.js"></script>
<script src='//cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js'></script>
<script>
   var notify = 'false' == true ? true : false;
   var verify = 'false' == true ? true : false;
   new Valine({
            av: AV,
            el: '#vcomment',
            notify: notify,
            verify: verify,
            app_id: "JQMgg0zbFBNWwL0lLnq2s1G7-gzGzoHsz",
            app_key: "m5FMVedFNxGutQCnMsVMAaXM",
            placeholder: "Say Something ...",
            avatar: "wavatar",
            avatar_cdn: "https://sdn.geekzu.org/avatar/",
            pageSize: "15"
    });
</script>
		
</section>



      
      <!--  -->

      <!--  -->
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/äººå·¥æ™ºèƒ½/">äººå·¥æ™ºèƒ½</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/æ–‡çŒ®/">æ–‡çŒ®</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ç®—æ³•/">ç®—æ³•</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/01/24/2018å¹´æ€»ç»“ï¼šæ¥è‡ª18å¹´çš„å·¥ä½œæ„Ÿæ‚Ÿ/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">ä¸Šä¸€ç¯‡</strong>
      <div class="article-nav-title">
        
          2018å¹´æ€»ç»“ï¼šæ¥è‡ª18å¹´çš„å·¥ä½œæ„Ÿæ‚Ÿ
        
      </div>
    </a>
  
  
    <a href="/2019/01/02/æ•°æ®ç§‘å­¦å·¥å…·â€”â€”Pandas/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">ä¸‹ä¸€ç¯‡</strong>
      <div class="article-nav-title">æ•°æ®ç§‘å­¦å·¥å…·â€”â€”Pandas</div>
    </a>
  
</nav>

  
</article>

<!-- Table of Contents -->

  <aside id="toc-sidebar">
    <div id="toc" class="toc-article">
    <strong class="toc-title">æ–‡ç« ç›®å½•</strong>
    
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#ä¸ºä»€ä¹ˆéœ€è¦Batch-Normalization"><span class="nav-number">1.</span> <span class="nav-text">ä¸ºä»€ä¹ˆéœ€è¦Batch Normalization</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Batch-Normalizationçš„æ€æƒ³åŠå®ç°"><span class="nav-number">2.</span> <span class="nav-text">Batch Normalizationçš„æ€æƒ³åŠå®ç°</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#å‰å‘ä¼ æ’­çš„å®ç°"><span class="nav-number">2.1.</span> <span class="nav-text">å‰å‘ä¼ æ’­çš„å®ç°</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#åå‘ä¼ æ’­çš„å®ç°"><span class="nav-number">2.2.</span> <span class="nav-text">åå‘ä¼ æ’­çš„å®ç°</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#BNå±‚å‚æ•°çš„å­¦ä¹ è¿‡ç¨‹ä¸­"><span class="nav-number">2.3.</span> <span class="nav-text">BNå±‚å‚æ•°çš„å­¦ä¹ è¿‡ç¨‹ä¸­</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Batch-Normalizationå¸¦æ¥çš„å¥½å¤„"><span class="nav-number">3.</span> <span class="nav-text">Batch Normalizationå¸¦æ¥çš„å¥½å¤„</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#å…¶å®ƒçš„å½’ä¸€åŒ–æ–¹æ³•"><span class="nav-number">4.</span> <span class="nav-text">å…¶å®ƒçš„å½’ä¸€åŒ–æ–¹æ³•</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#å‚è€ƒ"><span class="nav-number">5.</span> <span class="nav-text">å‚è€ƒ</span></a></li></ol>
    
    </div>
  </aside>

</section>      
        
      </div>
      <!--  -->
      <footer id="footer">
  

  <div class="container">
      	<div class="row">
	      <p> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/iTimeTraveler/hexo-theme-hiker" target="_blank">Hexo-theme-hiker</a> </p>
	      <p id="copyRightEn">Copyright &copy; 2017 - 2019 Ebby&#39;s Notes All Rights Reserved.</p>
	      
	      
  		   	<p id="copyRightCn">Ebby DD ä¿ç•™æ‰€æœ‰æƒåˆ©</p>
  		   
		</div>

		
  </div>
</footer>


<!-- min height -->

<script>
    var wrapdiv = document.getElementById("wrap");
    var contentdiv = document.getElementById("content");
    var allheader = document.getElementById("allheader");

    wrapdiv.style.minHeight = document.body.offsetHeight + "px";
    if (allheader != null) {
      contentdiv.style.minHeight = document.body.offsetHeight - allheader.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    } else {
      contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    }
</script>
    </div>    
    <!-- <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
    <a href="/reading" class="mobile-nav-link">Reading</a>
  
    <a href="/resources" class="mobile-nav-link">Resources</a>
  
    <a href="/notebooks" class="mobile-nav-link">ğŸ“</a>
  
</nav> -->
    

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">

</script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/scripts.js"></script>




  <script src="/js/dialog.js"></script>











	<script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?684368b6943d7a5b6689dba5e7bf30ad";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  </div>

  <div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true" style="display: none;">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h2 class="modal-title" id="myModalLabel">è®¾ç½®</h2>
      </div>
      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">


      <div class="modal-body">
          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseOne" onclick="javascript:setFontSize();" aria-expanded="true" aria-controls="collapseOne">
              æ­£æ–‡å­—å·å¤§å°
            </a>
          </div>
          <div id="collapseOne" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingOne">
          <div class="panel-body">
            æ‚¨å·²è°ƒæ•´é¡µé¢å­—ä½“å¤§å°
          </div>
        </div>
      


          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseTwo" onclick="javascript:setBackground();" aria-expanded="true" aria-controls="collapseTwo">
              å¤œé—´æŠ¤çœ¼æ¨¡å¼
            </a>
        </div>
          <div id="collapseTwo" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTwo">
          <div class="panel-body">
            å¤œé—´æ¨¡å¼å·²ç»å¼€å¯ï¼Œå†æ¬¡å•å‡»æŒ‰é’®å³å¯å…³é—­ 
          </div>
        </div>

        <div>
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseThree" aria-expanded="true" aria-controls="collapseThree">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;å…³ äº&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
        </div>
         <div id="collapseThree" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingThree">
          <div class="panel-body">
            Ebby&#39;s Notes
          </div>
          <div class="panel-body">
            Copyright Â© 2019 Ebby DD All Rights Reserved.
          </div>
        </div>
      </div>


      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <div class="modal-footer">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
      </div>
    </div>
  </div>
</div>
  
  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
  
    <a id="menu-switch"><i class="fa fa-bars fa-lg"></i></a>
  
</body>
</html>