{"meta":{"title":"Ebby's Notes","subtitle":"=Blog for AI Learning=","description":"è®°å½•äººå·¥æ™ºèƒ½å­¦ä¹ è·¯å¾„","author":"Ebby DD","url":"http://blog.a-stack.com"},"pages":[{"title":"404-æ‰¾ä¸åˆ°é¡µé¢","date":"2016-09-03T09:17:18.000Z","updated":"2018-05-15T14:59:56.082Z","comments":false,"path":"404.html","permalink":"http://blog.a-stack.com/404.html","excerpt":"","text":"404 Not Foundå¯¹ä¸èµ·ï¼Œæ‚¨æ‰€è®¿é—®çš„é¡µé¢ä¸å­˜åœ¨æˆ–è€…å·²åˆ é™¤ ä½ å¯ä»¥ç‚¹å‡»æ­¤å¤„è¿”å›é¦–é¡µ.æˆ‘çš„Githubï¼šhttps://github.com/ddebbyæˆ–è€…ç»™æˆ‘å‘é‚®ä»¶ï¼šebby.dd@gmail.com â€‹ å› ä¸ºæœŸå¾…å¾—å¤ªè‹¦ï¼Œä¼šå¯¼è‡´å¾—åˆ°çš„æ—¶å€™åˆ†å¤–ç”œ"},{"title":"","date":"2018-07-21T05:43:22.569Z","updated":"2018-07-20T09:10:32.266Z","comments":true,"path":"about/index.html","permalink":"http://blog.a-stack.com/about/index.html","excerpt":"","text":"ProfileStay hungryï¼Œstay foolish. â€”â€” Steve Jobs å…³äºæœ¬ç«™ ä¸ºäº†è®°å½•äººå·¥æ™ºèƒ½æŠ€æœ¯å­¦ä¹ è·¯å¾„å’Œåˆ†äº«çŸ¥è¯†åœ¨2018å¹´3æœˆå¼€å§‹å°è¯•å»ºç«‹å…³äºäººå·¥æ™ºèƒ½çš„åšå®¢ï¼Œè¿ç»­æ›´æ¢å¤šä¸ªHexoçš„ä¸»é¢˜ï¼Œä¸ºäº†æŠ˜è…¾æ›´ç¬¦åˆæ–‡å­—ç‰¹è´¨çš„å†…å®¹å‘ˆç°æ–¹å¼ã€‚ å¦‚æœå¯¹æ··åˆäº‘æŠ€æœ¯æ„Ÿå…´è¶£ï¼Œå¯ä»¥å‰å¾€2017å¹´åˆ›ç«‹çš„æ··åˆäº‘åšå®¢: ã€Azure Stackâ€™s Notesã€ å…³äºæˆ‘ æˆ‘æ˜¯ã€Ebbyã€ï¼Œäº‘æ¶æ„å¸ˆï¼Œäººå·¥æ™ºèƒ½å…¥é—¨çº§ç§‘å­¦å®¶ æœ€è¿‘è¿·æ‹æ·±åº¦å­¦ä¹ æŠ€æœ¯"},{"title":"","date":"2018-07-21T05:43:22.569Z","updated":"2018-07-20T09:16:27.166Z","comments":true,"path":"reading/books.css","permalink":"http://blog.a-stack.com/reading/books.css","excerpt":"","text":".clear { clear: both } #main { /*padding-left: 105px; padding-top: 47px; padding-bottom: 30px;*/ clear: both; /* background: url(images/paper.jpg) left top #F2EDB4;*/ position: relative; /* z-index: 11;*/ box-shadow: 5px 5px 8px #888; margin-top: 50px; margin-bottom: 50px; } /* #main h2 { line-height: 30px; font-size: 17px; margin-bottom: 10px; position: relative; } #main h2 em { font-size: 14px; margin-left: 20px; } #main h2 em span,#main h2 em img { vertical-align: text-bottom; } #main h2 em a { color: #000 } #main h2 em a:hover { color: #1C5F8C; text-decoration: underline } #main h2 span.ad { position: absolute; top: -22px; left: 250px }*/ #main .tag { margin-bottom: 20px; height: 30px; line-height: 30px; font-size: 15px } #main .tag a { padding: 4px 12px } #book { /* margin: -47px 0 -30px -105px;*/ display: table; width: 100%; /*background: #F5F0B6*/ } #book h2 { height: 16px; margin: 0; /*padding: 45px 0 0 105px;*/ background: url(images/bookshelftop.jpg) no-repeat left top; color: #000!important; background-size: cover; } #book ul { float: left; height: auto; background: url(images/bookshelfmiddle.jpg) repeat-y left top; margin-bottom: 0; background-size: 100% 196px; -webkit-margin-before: 0em; -webkit-margin-after: 0em; -webkit-padding-start: 0em; padding: 0 5%; width: 90%; } #book ul li { list-style-type: none; /* height: 160px;*/ /* line-height: 160px;*/ vertical-align: bottom; width: 110px; float: left; margin: 17px 14px 0; padding-bottom: 19px; } #book ul li a { display: block; height: 160px; line-height: 160px; position: relative; } #book ul li img { width: 110px; vertical-align: bottom; box-shadow: 5px 0 6px #512301; position: absolute; bottom: 0; -webkit-transition: all .2s linear; transition: all .2s linear; } #book ul li img:hover { -webkit-box-shadow: 0 15px 30px rgba(0,0,0,0.1); box-shadow: 5px 15px 30px rgba(0,0,0,0.4); -webkit-transform: translate3d(0, -2px, 0); transform: translate3d(0, -2px, 0); }"},{"title":"","date":"2018-07-21T05:43:22.569Z","updated":"2018-07-18T12:43:04.356Z","comments":false,"path":"categories/index.html","permalink":"http://blog.a-stack.com/categories/index.html","excerpt":"","text":""},{"title":"","date":"2018-07-21T05:43:22.570Z","updated":"2018-07-20T09:36:03.611Z","comments":true,"path":"reading/library.html","permalink":"http://blog.a-stack.com/reading/library.html","excerpt":"","text":"æˆ‘çš„ä¹¦æ¶"},{"title":"ä¹¦å•","date":"2018-07-02T03:30:53.000Z","updated":"2018-07-20T09:34:17.743Z","comments":true,"path":"reading/index.html","permalink":"http://blog.a-stack.com/reading/index.html","excerpt":"","text":"function setIframeHeight(iframe) { if (iframe) { var iframeWin = iframe.contentWindow || iframe.contentDocument.parentWindow; if (iframeWin.document.body) { iframe.height = iframeWin.document.documentElement.scrollHeight || iframeWin.document.body.scrollHeight; } } }; setIframeHeight(document.getElementsByTagName('iframe')[0]); window.onload = function () { setIframeHeight(document.getElementsByTagName('iframe')[0]); };"},{"title":"å¸¸ç”¨èµ„æº","date":"2018-07-18T12:10:27.000Z","updated":"2018-07-18T13:09:09.498Z","comments":true,"path":"resources/bak-index.html","permalink":"http://blog.a-stack.com/resources/bak-index.html","excerpt":"","text":"@column-3{ @card{ Website Log History Architecture Dependency } @card{ Resources äººå·¥æ™ºèƒ½å­¦ä¹ èµ„æºæ±‡æ€» Pandas Numpy Scikit-learnç®—æ³• } @card{ Reading Planè®°å½•è¯»ä¹¦è§„åˆ’ï¼ŒæŠ“ä½æ—¶é—´ï¼Œæå‡æ•ˆç‡ï¼ } } Reading Plan@card{ è®°å½•è¯»ä¹¦è§„åˆ’ï¼ŒæŠ“ä½æ—¶é—´ï¼Œæå‡æ•ˆç‡ï¼ } Photography Collection@card{ ä¸ªäººæ›¾ç»çš„æ‘„å½±ä½œå“é›†åˆï¼Œæ¬¢è¿æ¬£èµ~ }"},{"title":"èµ„æºå¯¼èˆª","date":"2018-07-21T05:43:22.570Z","updated":"2018-07-20T09:43:39.321Z","comments":false,"path":"resources/index.html","permalink":"http://blog.a-stack.com/resources/index.html","excerpt":"","text":"Website Log History Architecture Dependency Resources äººå·¥æ™ºèƒ½å­¦ä¹ èµ„æºæ±‡æ€» Pandas Numpy Scikit-learnç®—æ³• Reading Planè®°å½•è¯»ä¹¦è§„åˆ’ï¼ŒæŠ“ä½æ—¶é—´ï¼Œæå‡æ•ˆç‡ï¼ Photography Collectionä¸ªäººæ›¾ç»çš„æ‘„å½±ä½œå“é›†åˆï¼Œæ¬¢è¿æ¬£èµ~"},{"title":"","date":"2018-07-21T05:43:22.576Z","updated":"2018-07-18T12:42:51.313Z","comments":false,"path":"tags/index.html","permalink":"http://blog.a-stack.com/tags/index.html","excerpt":"","text":""},{"title":"NumPy","date":"2018-02-22T15:53:23.000Z","updated":"2018-04-13T04:44:09.000Z","comments":true,"path":"resources/numpy/index.html","permalink":"http://blog.a-stack.com/resources/numpy/index.html","excerpt":"","text":"NumPy: NumPyç³»ç»Ÿæ˜¯Pythonçš„ä¸€ç§å¼€æºçš„æ•°å€¼è®¡ç®—æ‰©å±•ã€‚è¿™ç§å·¥å…·å¯ç”¨æ¥å­˜å‚¨å’Œå¤„ç†å¤§å‹çŸ©é˜µï¼Œæ¯”Pythonè‡ªèº«çš„åµŒå¥—åˆ—è¡¨ï¼ˆnested list structure)ç»“æ„è¦é«˜æ•ˆçš„å¤šã€‚ æ›´å¤šä¿¡æ¯ NumPy Tutorial NumPy Cheat Sheet: Data Analysis in Python"},{"title":"Pandas","date":"2018-02-22T15:53:23.000Z","updated":"2018-04-13T04:44:09.000Z","comments":true,"path":"resources/pandas/index.html","permalink":"http://blog.a-stack.com/resources/pandas/index.html","excerpt":"","text":"Pandasï¼šPythonç»“æ„åŒ–æ•°æ®åˆ†æåˆ©å™¨ â€¦ æ›´å¤šä¿¡æ¯ Python Data Analysis Library Pandas Cheat Sheet: Data Wrangling in Python â€‹"},{"title":"Architecture","date":"2018-07-21T05:43:22.982Z","updated":"2018-04-13T04:44:09.000Z","comments":false,"path":"resources/architecture/index.html","permalink":"http://blog.a-stack.com/resources/architecture/index.html","excerpt":"","text":"æœ¬æ–‡å°†ç”¨äºæ›´æ–°æœ¬ç½‘ç«™çš„åŸºç¡€æ¶æ„åŠå…¶ä½¿ç”¨çš„æŠ€æœ¯ã€‚ æ¦‚è¦ ä½¿ç”¨ä¸»è¦æŠ€æœ¯ æŠ€æœ¯ ç”¨é€” Hexo Hexo is a fast, simple &amp; powerful blog framework powered by Node.js. GitHub å›½å¤–æœåŠ¡æ‰˜ç®¡ Coding.net å›½å†…æœåŠ¡æ‰˜ç®¡ + æºä»£ç æ‰˜ç®¡ ä¸‡ç½‘ åŸŸåæ‰˜ç®¡ Icons LICENSE Hexo Site CC BY 4.0 GitHub Site Wercker Site"},{"title":"äººå·¥æ™ºèƒ½ç›¸å…³èµ„æºæ±‡æ€»","date":"2018-04-14T16:00:00.000Z","updated":"2018-05-19T14:47:55.693Z","comments":true,"path":"resources/resources/index.html","permalink":"http://blog.a-stack.com/resources/resources/index.html","excerpt":"","text":"Every Day Readpyimagesearch blog æœºå™¨è§†è§‰ã€äººå·¥æ™ºèƒ½é¢†åŸŸç›¸å…³åšå®¢ï¼ŒåŠ¨æ‰‹å®è·µæ€§å¼ºï¼Œä¹Ÿæ˜¯ã€ŠDeep Learning for Computer Vision with Pythonã€‹ä½œè€…æ’°å†™çš„åšå®¢ Reddit-DeepLearning || Reddit-MachineLearning è·Ÿè¸ªæœ€æ–°çš„Deep Learningæ–°é—»å’¨è¯¢ Arxiv Sanity Preserver æœ€æ–°æ·±åº¦å­¦ä¹ é¢†åŸŸçš„æ–‡ç«  THE WILD WEEK IN AI NEWSLETTER The Wild Week in AI is a weekly newsletter with hand-curated stories in Deep Learning and Artificial Intelligence. It highlights interesting articles, code projects and research papers. Itâ€™s sent out every Monday. Distill Distill is dedicated to clear explanations of machine learning CoursesCS231n: Convolutional Neural Networks for Visual Recognition Stanford Cs231n,è¯¾ç¨‹å¤§çº²è¯¦è§ ç¬”è®°ï¼šLecture 2 | Lecture 3 | Lecture 4 | Lecture 5 | Machine Learning Coursera Course ä½œä¸šè§£æåŠæ€»ç»“ ç¬”è®° | å®éªŒç¬”è®° BooksDeep Learning: An MIT Press book æ·±åº¦å­¦ä¹ ç†è®ºå­¦ä¹ åœ£ç» å¸¸ç”¨å·¥å…·åŠæŠ€æœ¯ â€‹"},{"title":"è¯»ä¹¦è®¡åˆ’","date":"2018-07-21T05:43:22.983Z","updated":"2018-05-25T07:45:33.186Z","comments":false,"path":"resources/reading/index.html","permalink":"http://blog.a-stack.com/resources/reading/index.html","excerpt":"","text":"æ­£åœ¨è¯» ã€ŠMachine Learningï¼šA Pobabilistic Perspectiveã€‹ MLAPP, æœºå™¨å­¦ä¹ ç»å…¸ç†è®ºæ•™ç¨‹ã€‚ Start Reading Dateï¼š 2018-05-25 å…³æ³¨èµ„æº(2018) å¼€æºä¹¦å• æœºå™¨å­¦ä¹ å…¥é—¨åˆ°è¿›é˜¶ å·¥å…· Pandas 10 Minutes to pandas Pandas Cookbook Learn Pandas Matplotlibç”¨æˆ·æŒ‡å— scikit-learn ä¸­è¯‘ Markdown-ç®€å•çš„ä¸–ç•Œ Keras [Python] A Byte of Python | ä¸­è¯‘ Think Python Version 2 | ä¸­è¯‘ Python æ•°æ®ç§‘å­¦å…¥é—¨ | ä¸­è¯‘ ğŸ’–[Machine Learning] ğŸ’–[Data Analysis with Pandas] ğŸ’–[Data Visualization] ğŸ•™Image and Video Analysis äººå·¥æ™ºèƒ½ âœ…Neural Networks and Deep Learning, Michael Nielsen | ä¸­è¯‘ é¢å‘ç¨‹åºå‘˜çš„æ•°æ®æŒ–æ˜æŒ‡å— âœ…Machine learning for humans | ä¸­è¯‘ âœ…æœºå™¨å­¦ä¹ åŸæ¥è¿™ä¹ˆæœ‰è¶£ | ä¸­è¯‘ ğŸ•™Pattern Recognization and Maching Learning | ä¸­è¯‘ï¼šæ¨¡å¼è¯†åˆ«ä¸æœºå™¨å­¦ä¹  ç®—æ³• ğŸ’–åå¤§ç»å…¸æ’åºç®—æ³• å…¶å®ƒ GitHub Aesome ç³»åˆ— Awesome Machine Learning â­32778 | ä¸­è¯‘ ã€ŠæŒ‡æ•°åŸºé‡‘æŠ•èµ„æŒ‡å—2017ç‰ˆã€‹ 2018å¹´è¯»çš„ä¹¦ Deep Learning for Computer Vision with Python Hands On Machine Learning with Scikit Learn and TensorFlow Deep Learning with Keras Deep Learning with Python Neural Network and Deep Learningâ€”â€”Michale Neilsen æ™ºèƒ½æ—¶ä»£â€”â€”å´å†› æœºå™¨å­¦ä¹ â€”â€”å‘¨å¿—å ç»Ÿè®¡å­¦æ–¹æ³•â€”â€”â€”æèˆª | è¯»ä¹¦ç¬”è®° Considering TensorFlow for the Enterprise 2018çš„è®ºæ–‡ç ”è¯»è®¡åˆ’2017å¹´è¯»ä¹¦è®¡åˆ’æ­£åœ¨è¯» [x] è…¾è®¯ä¼ 1998-2016ï¼šä¸­å›½äº’è”ç½‘å…¬å¸è¿›åŒ–è®º-å´æ™“æ³¢ | ä¹¦è¯„ [x] Pro Git - Cott Chacon,Ben Straub | ä¹¦è¯„ [x] ç¡…è°·ä¹‹è°œ-å´å†› å‡†å¤‡è¯» [ ] SREï¼šGoogleè¿ç»´è§£å¯† [x] è…¾è®¯ä¼ 1998-2016ï¼šä¸­å›½äº’è”ç½‘å…¬å¸è¿›åŒ–è®º-å´æ™“æ³¢ [x] å¤±æ§ : å…¨äººç±»çš„æœ€ç»ˆå‘½è¿å’Œç»“å±€ [x] é»‘å®¢ä¸ç”»å®¶ : ç¡…è°·åˆ›ä¸šä¹‹çˆ¶Paul Grahamæ–‡é›† [ ] åˆ›ä¸šç»´è‰° : å¦‚ä½•å®Œæˆæ¯”éš¾æ›´éš¾çš„äº‹ [ ] é‡æ–°å®šä¹‰å…¬å¸ : è°·æ­Œæ˜¯å¦‚ä½•è¿è¥çš„ [ ] åˆ›ä¸šæ—¶, æˆ‘ä»¬åœ¨çŸ¥ä¹èŠä»€ä¹ˆ? [ ] SDN and openflow"},{"title":"NumPy","date":"2018-02-22T15:53:23.000Z","updated":"2018-05-15T13:50:39.304Z","comments":true,"path":"resources/scikit-learn/index.html","permalink":"http://blog.a-stack.com/resources/scikit-learn/index.html","excerpt":"","text":"Scikit-learnæ˜¯åŸºäºPythonçš„åŠŸèƒ½å¼ºå¤§çš„å¼€æºç§‘å­¦è®¡ç®—å·¥å…·åŒ…ï¼Œå†…å«åˆ†ç±»ã€å›å½’ã€èšç±»ã€æ”¯æŒå‘é‡æœºã€éšæœºæ£®æ—ä¸Gradient Boostingç­‰ç®—æ³•ã€‚ æ›´å¤šä¿¡æ¯ Scikit-Learn å®˜ç½‘ Scikit-Learn Cheat Sheet: Python Machine Learning"},{"title":"å»ºç«™æ—¥å¿—","date":"2018-02-19T15:53:23.000Z","updated":"2018-07-21T04:27:32.797Z","comments":true,"path":"resources/weblog/index.html","permalink":"http://blog.a-stack.com/resources/weblog/index.html","excerpt":"","text":"2018å¹´2æœˆé‡å¯hexoåšå®¢ï¼Œç”¨äºè®°å½•äººå·¥æ™ºèƒ½çš„å­¦ä¹ è¿‡ç¨‹ â€¦ 2018å¹´7æœˆ20æ—¥ï¼Œå†æ¬¡æ›´æ¢ä¸»é¢˜ï¼šhexo-theme-hiker å®‰è£…æ‰‹å†Œè¯¦è§ï¼š https://github.com/iTimeTraveler/hexo-theme-hiker/blob/master/README.cn.md é•œåƒåšå®¢è¯¦è§ï¼š https://itimetraveler.github.io/ é•œåƒåšå®¢é…ç½®è¯¦è§ï¼š https://github.com/iTimeTraveler/iTimeTraveler.github.io/tree/site 2018å¹´7æœˆï¼Œå†æ¬¡æ›´æ¢ä¸»é¢˜hexo-theme-indigo å®‰è£…æ‰‹å†Œè¯¦è§ï¼š https://github.com/yscoder/hexo-theme-indigo/wiki/%E5%AE%89%E8%A3%85 2018å¹´5æœˆï¼Œé€‰æ‹©ä½¿ç”¨ä¸»é¢˜hexo-theme-hueman 2018å¹´4æœˆï¼Œå‘ç°hexoä¸»é¢˜Tranquilpeakæ›´æ–°åˆ°2.0ç‰ˆæœ¬äº†ï¼Œå°è¯•åˆ‡æ¢ã€‚ å‚è€ƒï¼šhttp://www.istarx.cc/ å‚è€ƒæ–‡æ¡£ï¼š https://github.com/cherlas/hexo-theme-tranquilpeak/blob/master/docs/user.md hikerä¸»é¢˜çš„ä¸ªæ€§åŒ–ä¿®æ”¹æ¸…å•[2018-07]1. å¢åŠ è¯„è®ºç³»ç»Ÿvaline å‚è€ƒï¼š https://valine.js.org/quickstart.html æ³¨å†ŒLeancloudè´¦å· æˆ‘ä»¬çš„è¯„è®ºç³»ç»Ÿå…¶å®æ˜¯æ”¾åœ¨Leancloudä¸Šçš„ï¼Œå› æ­¤é¦–å…ˆéœ€è¦å»æ³¨å†Œä¸€ä¸ªè´¦å· Leancloudå®˜ç½‘ï¼Œç‚¹æˆ‘æ³¨å†Œ æ³¨å†Œå®Œä»¥åéœ€è¦åˆ›å»ºä¸€ä¸ªåº”ç”¨ï¼Œåå­—å¯ä»¥éšä¾¿èµ·ï¼Œç„¶å è¿›å…¥åº”ç”¨-&gt;è®¾ç½®-&gt;åº”ç”¨key è·å–ä½ çš„appid å’Œ appkey åŒæ—¶è®°å¾—åœ¨Leancloud -&gt; è®¾ç½® -&gt; å®‰å…¨ä¸­å¿ƒ -&gt; Web å®‰å…¨åŸŸå æŠŠä½ çš„åŸŸååŠ è¿›å»,å¦‚æœæœ¬åœ°æµ‹è¯•éœ€è¦å¢åŠ localhoståŸŸå ä¸»é¢˜é…ç½®æ–‡ä»¶å¢åŠ valineé…ç½®é¡¹ 12345678910#@ebby Valine https://valine.js.orgvaline: appid: =??= appkey: =??= verify: false #éªŒè¯ç  notify: false #è¯„è®ºå›å¤æé†’ avatar: '' #è¯„è®ºåˆ—è¡¨å¤´åƒæ ·å¼ï¼š''/mm/identicon/monsterid/wavatar/retro/hide avatar_cdn: 'https://sdn.geekzu.org/avatar/' #å¤´åƒCDN placeholder: 'çç™½è¯' #è¯„è®ºæ¡†å ä½ç¬¦ pageSize: 15 #è¯„è®ºåˆ†é¡µ åœ¨layoout/_partial/comment.ejsä¸­å¢åŠ å¦‚ä¸‹å†…å®¹ï¼š 12345678910111213141516171819202122--- a/layout/_partial/comment.ejs+++ b/layout/_partial/comment.ejs@@ -105,4 +105,19 @@ &lt;!-- Cityç‰ˆå®‰è£…ä»£ç å·²å®Œæˆ --&gt; &lt;/div&gt;+&lt;% &#125; else if (theme.valine &amp;&amp; theme.valine.appid &amp;&amp; theme.valine.appkey) &#123;%&gt;+ &lt;!-- valine @ebby --&gt;+ &lt;section id=\"comments\" class=\"comments\"&gt;+ &lt;style&gt;+ .comments&#123;margin:30px;padding:10px;background:#fff&#125;+ @media screen and (max-width:800px)&#123;.comments&#123;margin:auto;padding:10px;background:#fff&#125;&#125;+ &lt;/style&gt;+ &lt;%- partial('post/valine', &#123;+ key: post.slug,+ title: post.title,+ url: config.url+url_for(post.path)+ &#125;) %&gt;++&lt;/section&gt; &lt;% &#125; %&gt;+ åœ¨layout/_partial/postç›®å½•ä¸‹æ–°å¢valine.ejsæ–‡ä»¶ï¼š 1234567891011121314151617181920&lt;div id=&quot;vcomment&quot; class=&quot;comment&quot;&gt;&lt;/div&gt;&lt;script src=&quot;//cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;//cdn.jsdelivr.net/npm/leancloud-storage@latest/dist/av-min.js&quot;&gt;&lt;/script&gt;&lt;script src=&apos;//cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js&apos;&gt;&lt;/script&gt;&lt;script&gt; var notify = &apos;&lt;%= theme.valine.notify %&gt;&apos; == true ? true : false; var verify = &apos;&lt;%= theme.valine.verify %&gt;&apos; == true ? true : false; new Valine(&#123; av: AV, el: &apos;#vcomment&apos;, notify: notify, verify: verify, app_id: &quot;&lt;%= theme.valine.appid %&gt;&quot;, app_key: &quot;&lt;%= theme.valine.appkey %&gt;&quot;, placeholder: &quot;&lt;%= theme.valine.placeholder %&gt;&quot;, avatar: &quot;&lt;%= theme.valine.avatar %&gt;&quot;, avatar_cdn: &quot;&lt;%= theme.valine.avatar_cdn %&gt;&quot;, pageSize: &lt;%= theme.valine.pageSize %&gt; &#125;);&lt;/script&gt; åœ¨layout/_partial/article.ejsä¸­åšç®€å•ä¿®æ”¹ 1234567891011--- a/layout/_partial/article.ejs+++ b/layout/_partial/article.ejs@@ -30,7 +30,7 @@ &lt;% if (!index &amp;&amp; theme.copyright.enable)&#123; %&gt; &lt;%- partial('copyright') %&gt; &lt;% &#125; %&gt;- &lt;% if (!index &amp;&amp; post.comments &amp;&amp; (theme.gentie_productKey || theme.duoshuo_shortname || theme.disqus_shortname || theme.uyan_uid || theme.wumii || theme.livere_shortname))&#123; %&gt;+ &lt;% if (!index &amp;&amp; post.comments &amp;&amp; (theme.gentie_productKey || theme.duoshuo_shortname || theme.disqus_shortname || theme.uyan_uid || theme.wumii || theme.livere_shortname ||theme.valine))&#123; %&gt; &lt;%- partial('comment') %&gt; &lt;% &#125; %&gt; &lt;% if (!theme.post_excerpt)&#123; %&gt; å…¶å®ƒé…ç½® å¤´åƒé…ç½® ç›®å‰éè‡ªå®šä¹‰å¤´åƒæœ‰ä»¥ä¸‹7ç§é»˜è®¤å€¼å¯é€‰: å‚æ•°å€¼ è¡¨ç°å½¢å¼ å¤‡æ³¨ ç©ºå­—ç¬¦ä¸²&#39;&#39; Gravatarå®˜æ–¹å›¾å½¢ mp ç¥ç§˜äºº(ä¸€ä¸ªç°ç™½å¤´åƒ) identicon æŠ½è±¡å‡ ä½•å›¾å½¢ monsterid å°æ€ªç‰© wavatar ç”¨ä¸åŒé¢å­”å’ŒèƒŒæ™¯ç»„åˆç”Ÿæˆçš„å¤´åƒ retro å…«ä½åƒç´ å¤å¤å¤´åƒ robohash ä¸€ç§å…·æœ‰ä¸åŒé¢œè‰²ã€é¢éƒ¨ç­‰çš„æœºå™¨äºº hide ä¸æ˜¾ç¤ºå¤´åƒ 2.è‡ªå®šä¹‰çš„ä¿®æ”¹å†…å®¹ é’ˆå¯¹ä¸€äº›fontsæ–‡ä»¶è®¿é—®æ…¢ï¼Œä¸‹è½½å¹¶ä¿®æ”¹ä¸ºCDNå­˜å‚¨ä½ç½®ï¼Œæ¶‰åŠæ–‡ä»¶åŒ…æ‹¬: 123456789101112++ /source/css/vdonate.css- background: url(\"https://ooo.0o0.ooo/2017/03/09/58c158afac35c.png\")- background: url(\"https://ooo.0o0.ooo/2017/03/09/58c1584d5fd9d.png\")- background: url(\"https://ooo.0o0.ooo/2017/03/09/58c16b1f3eaa4.png\") no-repeat+++ b/source/css/bootstrap.css- src: url('../fonts/glyphicons-halflings-regular.eot');- src: url('../fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../fonts/glyphicons-halflings-regular.woff') format('woff'), url('../fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');+++ b/layout/_partial/head.ejs- &lt;link href=\"//fonts.googleapis.com/css?family=Source+Code+Pro\" rel=\"stylesheet\" type=\"text/css\"&gt;- &lt;link href=\"https://fonts.googleapis.com/css?family=Open+Sans|Montserrat:700\" rel=\"stylesheet\" type=\"text/css\"&gt;- &lt;link href=\"https://fonts.googleapis.com/css?family=Roboto:400,300,300italic,400italic\" rel=\"stylesheet\" type=\"text/css\"&gt; Mathjax CDNçš„ä¿®æ”¹ 12345678--- a/layout/_partial/post/mathjax.ejs+++ b/layout/_partial/post/mathjax.ejs@@ -26,5 +26,5 @@ &#125;); &lt;/script&gt;-&lt;script type=\"text/javascript\" src=\"https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\"&gt;+&lt;script type=\"text/javascript\" src=\"http://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML\"&gt; ä¿®æ”¹ä¸€äº›å­—ä½“å¤§å° 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061--- a/source/css/_partial/article.styl+++ b/source/css/_partial/article.styl@@ -180,7 +180,7 @@ blockquote padding: 0.1px 20px; font-family: font-normal- font-size: 1.1em+ font-size: 1.0em color: rgba(44, 44, 44, .6) margin: 1.4em 0px border-left: 2px solid color-theme @@ -137,7 +137,7 @@ .article-entry @extend $base-style clearfix()- color: color-default+ color: rgba(44, 44, 44, .6) margin: 0 article-padding @media mq-mobile margin: 0 @@ -271,7 +271,7 @@ .article-footer clearfix()- font-size: 0.85em+ font-size: 0.90em line-height: line-height border-top: 1px solid rgba(208,211,248,0.25) padding-top: line-heightdiff --git a/source/css/_partial/highlight.styl b/source/css/_partial/highlight.stylindex a198072..007eec0 100644--- a/source/css/_partial/highlight.styl+++ b/source/css/_partial/highlight.styl@@ -101,12 +101,12 @@ $code-block border-width: 1px 0 overflow: auto color: $highlight-foreground- font-size: 0.9em;- line-height: 1em+ font-size: 0.95em;+ line-height: 1.1em $line-numbers color: #666- font-size: 0.85em+ font-size: 0.95emgdiff --git a/source/css/_variables.styl b/source/css/_variables.stylindex 6b9d0a1..83908c8 100644--- a/source/css/_variables.styl+++ b/source/css/_variables.styl@@ -73,7 +73,7 @@ font-icon = FontAwesome font-icon-path = \"fonts/fontawesome-webfont\" font-icon-version = \"4.0.3\" font-size = 14px-line-height = 1.6em+line-height = 1.8em line-height-title = 1em â€‹ æ–°ä¸»é¢˜ä¼˜åŒ–å†…å®¹æ¸…å•[2018-05] å¢åŠ æ–°çš„è¾¹æ ç›®å½• æ›´æ–°mathjax CDN å¢åŠ ä¸ƒç‰›å›¾åºŠåŒæ­¥ å¢åŠ å›¾åƒåœ°å€è½¬ç§» ä¿®å¤mathjaxçš„bug 12npm uninstall hexo-renderer-marked --savenpm install hexo-renderer-kramed --save ä¿®æ”¹Hexoæ¸²æŸ“æºç  è¿™ä¸ªæ–¹æ³•æ˜¯æˆ‘ç›®å‰ä½¿ç”¨çš„ï¼Œç›¸å¯¹æ¥è¯´ï¼Œé€šç”¨æ€§è¾ƒé«˜çš„ä¸€ç§æ–¹å¼ã€‚æ€è·¯å°±æ˜¯ä¿®æ”¹hexoçš„æ¸²æŸ“æºç : nodes_modules/lib/marked/lib/marked.js: å»æ‰\\çš„é¢å¤–è½¬ä¹‰ å°†emæ ‡ç­¾å¯¹åº”çš„ç¬¦å·ä¸­ï¼Œå»æ‰_,å› ä¸ºmarkdownä¸­æœ‰*å¯ä»¥è¡¨ç¤ºæ–œä½“ï¼Œâ€”å°±å»æ‰äº†ã€‚ å…·ä½“æ€è·¯å‚è€ƒäº†ä½¿Marked.jsä¸MathJaxå…±å­˜, æ‰“å¼€nodes_modules/marked/lib/marked.js:ç¬¬ä¸€æ­¥: æ‰¾åˆ°ä¸‹é¢çš„ä»£ç : 1escape: /^\\\\([\\\\`*&#123;&#125;\\[\\]()# +\\-.!_&gt;])/, æ”¹ä¸º: 1escape: /^\\\\([`*&#123;&#125;\\[\\]()# +\\-.!_&gt;])/, è¿™æ ·å°±ä¼šå»æ‰\\çš„è½¬ä¹‰äº†ã€‚ç¬¬äºŒæ­¥: æ‰¾åˆ°emçš„ç¬¦å·: 1em: /^\\b_((?:[^_]|__)+?)_\\b|^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/, æ”¹ä¸º: 1em:/^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/, å»æ‰_çš„æ–œä½“å«ä¹‰,è¿™æ ·å°±è§£å†³äº†ã€‚ æ›´å¤šå‚è€ƒï¼š http://visugar.com/2017/08/01/20170801HexoPlugins/ TO DO List[x] slides over reveal.js hexo-sliding-spoiler æŠ˜å ä»£ç å’Œæ˜¾ç¤ºå†…å®¹ ç›®å½•æ˜¾ç¤ºå®‰è£…hexoæ’ä»¶ 12\"hexo-renderer-markdown-it-plus\": \"^1.0.3\",\"markdown-it-toc-and-anchor\": \"^4.1.2\" åœ¨hexoé…ç½®æ–‡ä»¶_config.ymlä¸­å¢åŠ å¦‚ä¸‹é…ç½®ä¿¡æ¯ï¼š 12345678910111213141516markdown_it_plus: highlight: true html: true xhtmlOut: true breaks: true langPrefix: linkify: true typographer: quotes: â€œâ€â€˜â€™ plugins: - plugin: name: markdown-it-toc-and-anchor enable: true options: tocClassName: 'toc js-fixedContent' anchorClassName: 'anchor' å¤šä¸ªæ¨¡ç»„çš„ä»£ç ç®¡ç† æ·»åŠ æ–°çš„submodule 12$ cd blog-hexo$ git submodule add https://github.com/ddebby/hexo-theme-tranquilpeak.git themes/tranq å¢åŠ è¿œç¨‹æ›´æ–°æº 12345git remote -v git remote add upstream git@github.com:xxx/xxx.gitgit fetch upstreamgit merge upstream/mastergit push å®‰è£…tips ä¸­å›½ç¯å¢ƒå®‰è£…node-sassæœ‰å‘ï¼Œä¸»è¦æ˜¯grunt-sassç‰ˆæœ¬ä½ï¼Œå¯ä»¥å‡çº§grunt-sassç‰ˆæœ¬ç»§ç»­å®‰è£…ã€‚"}],"posts":[{"title":"ç»å…¸ç½‘ç»œå¤ç°ä¹‹SqueezeNet","slug":"ç»å…¸ç½‘ç»œå¤ç°ä¹‹SqueezeNet","date":"2018-07-12T05:58:12.000Z","updated":"2018-07-20T15:52:08.839Z","comments":true,"path":"2018/07/12/ç»å…¸ç½‘ç»œå¤ç°ä¹‹SqueezeNet/","link":"","permalink":"http://blog.a-stack.com/2018/07/12/ç»å…¸ç½‘ç»œå¤ç°ä¹‹SqueezeNet/","excerpt":"æ‘˜è¦ï¼š æœ¬æ–‡è®°å½•åˆ©ç”¨ImageNetæ•°æ®é›†å¤ç°ç»å…¸ç½‘ç»œSqueezeNetçš„è¿‡ç¨‹ï¼Œå¹¶è®°å½•åœ¨å¤§å‹æ•°æ®é›†è®­ç»ƒè¿‡ç¨‹ä¸­éœ€è¦è€ƒè™‘çš„é—®é¢˜ã€‚","text":"æ‘˜è¦ï¼š æœ¬æ–‡è®°å½•åˆ©ç”¨ImageNetæ•°æ®é›†å¤ç°ç»å…¸ç½‘ç»œSqueezeNetçš„è¿‡ç¨‹ï¼Œå¹¶è®°å½•åœ¨å¤§å‹æ•°æ®é›†è®­ç»ƒè¿‡ç¨‹ä¸­éœ€è¦è€ƒè™‘çš„é—®é¢˜ã€‚ ä¸ºäº†å¢å¼ºå¯¹state of the artæ·±åº¦ç¥ç»ç½‘ç»œæ¨¡å‹çš„è®¤çŸ¥ï¼Œå‡†å¤‡è¿›è¡Œä¸€ç³»åˆ—æ¨¡å‹çš„å¤ç°å·¥ä½œï¼Œä½¿ç”¨ImageNetçš„å¤§è§„æ¨¡å›¾åƒåˆ†ç±»æ•°æ®é›†ï¼Œä»å¤´è®­ç»ƒå„ä¸ªç»å…¸çš„ç¥ç»ç½‘ç»œæ¨¡å‹ï¼ŒåŒæ—¶ç»“åˆä½œè€…è®ºæ–‡å¯¹è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŠ€å·§è¿›è¡Œå½’çº³æ€»ç»“ï¼Œä¸»è¦å®‰æ’å¦‚ä¸‹å‡ éƒ¨åˆ†å†…å®¹ï¼š ImageNetæ•°æ®é›†åŠæ•°æ®å‡†å¤‡ AlexNetç½‘ç»œ VGGç½‘ç»œ GoogLeNetç½‘ç»œ ResNetç½‘ç»œ SqueezeNetç½‘ç»œ æ¦‚è¿°SqueezeNetæ­£å¦‚ä½œè€…åœ¨è®ºæ–‡é¢˜ç›®ä¸­ç‰¹åˆ«å¼ºè°ƒçš„é‚£æ ·ï¼Œä¸»è¦é’ˆå¯¹æ¨¡å‹å¤§å°è¿›è¡Œäº†æ·±åº¦ä¼˜åŒ–ï¼Œåœ¨ä¿è¯æ¨¡å‹ç²¾åº¦æ²¡æœ‰å¤ªå¤šæŸå¤±çš„æƒ…å†µä¸‹ï¼Œæå¤§çš„ç¼©å°äº†æ‰€éœ€æ¨¡å‹çš„å°ºå¯¸ï¼Œä¸ºåœ¨åµŒå…¥å¼è®¾å¤‡éƒ¨ç½²æä¾›äº†å¼ºåŠ›æ”¯æ’‘ã€‚SqueezeNetä¸ºæˆ‘ä»¬è£å‰ªæ¨¡å‹å’Œè®¾è®¡å¯åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šè¿è¡Œçš„é«˜æ€§èƒ½æ¨¡å‹æä¾›äº†æŒ‡å¯¼ï¼Œç‰¹åˆ«æ˜¯Fire Moduleçš„è®¾è®¡åŸç†å€¼å¾—æ€è€ƒã€‚ è®ºæ–‡ï¼šSqueezeNet: AlexNet-level accuracy with 50x fewer parameters and &lt;0.5MB model sizeï¼Œ2016. URL: https://arxiv.org/abs/1602.07360 ä»£ç é“¾æ¥ï¼šhttps://github.com/DeepScale/SqueezeNet æ•°æ®é›†ï¼š ImageNet 2012 ILSRVCæ•°æ®é›†ï¼ˆæ•°æ®é›†çš„è·å–åŠå‡†å¤‡è¯¦è§ImageNet-DataSetï¼‰ è®¡ç®—æ¡†æ¶ï¼š MxNet ç®—åŠ›èµ„æºï¼šAWSäº‘ä¸»æœºp2.8xlargeï¼š8ä¸ªTesla K80 GPU ($7.20/hour) æ€»è®¡è®­ç»ƒæ—¶é—´1å¤©å·¦å³ æ¯è½®è¿­ä»£æ—¶é—´ï¼š~1060ç§’ åœ¨ImageNetæ•°æ®é›†ä¸Šçš„æ•ˆæœï¼š SqueezeNet microarchitecture and macro architecture åœ¨è®¾è®¡æ·±åº¦ç½‘ç»œæ¶æ„çš„è¿‡ç¨‹ä¸­ï¼Œå¦‚æœæ‰‹åŠ¨é€‰æ‹©æ¯ä¸€å±‚çš„æ»¤æ³¢å™¨æ˜¾å¾—è¿‡äºç¹å¤ã€‚é€šå¸¸å…ˆæ„å»ºç”±å‡ ä¸ªå·ç§¯å±‚ç»„æˆçš„å°æ¨¡å—ï¼Œå†å°†æ¨¡å—å †å å½¢æˆå®Œæ•´çš„ç½‘ç»œã€‚å®šä¹‰è¿™ç§æ¨¡å—çš„ç½‘ç»œä¸ºCNN microarchitectureã€‚ ä¸æ¨¡å—ç›¸å¯¹åº”ï¼Œå®šä¹‰å®Œæ•´çš„ç½‘ç»œæ¶æ„ä¸ºCNN macroarchitectureã€‚åœ¨å®Œæ•´çš„ç½‘ç»œæ¶æ„ä¸­ï¼Œæ·±åº¦æ˜¯ä¸€ä¸ªé‡è¦çš„å‚æ•°ã€‚ æ¯”å¦‚FPGAä¸­åªæœ‰10MBçš„ç‰‡ä¸Šå†…å­˜ç©ºé—´ï¼Œæ²¡æœ‰ç‰‡ä¸‹å­˜å‚¨ï¼Œå¯¹æ¨¡å‹å¤§å°è¦æ±‚è¾ƒé«˜ï¼›ASICsä¹Ÿä¼šæœ‰ç›¸åŒçš„éœ€æ±‚ï¼› â€‹ è®¾è®¡åŸåˆ™ä½œè€…åœ¨è®ºæ–‡ä¸­ç»™å‡ºSqueezeNetçš„ä¸‰æ¡è®¾è®¡åŸåˆ™ï¼š å°½é‡ç”¨1x1å·ç§¯æ›¿ä»£3x3å·ç§¯ï¼Œç›®çš„è‡ªç„¶æ˜¯é™ä½å‚æ•°é‡ï¼› é™ä½è¾“å…¥åˆ°3x3å·ç§¯å¯¹è±¡çš„channelæ•°ç›®ï¼Œåœ¨SqueezeNetä¸­æ˜¯ä½¿ç”¨squeezeæ¨¡å—æ¥å®ç°çš„ï¼› å°½é‡åœ¨ç½‘ç»œåé¢å±‚æ¬¡ä¸­è¿›è¡Œé™é‡‡æ ·ï¼Œè¿™æ ·å¯ä»¥æ˜¯å·ç§¯å±‚è·å¾—æ›´å¤§çš„æ¿€æ´»åœ°å›¾ï¼Œä»è€Œè·å¾—æ›´é«˜çš„ç²¾åº¦ï¼› Fire Module Fire Moduleæ˜¯æœ¬æ–‡çš„æ ¸å¿ƒæ„ä»¶ï¼Œæ€æƒ³éå¸¸ç®€å•ï¼Œå°±æ˜¯å°†åŸæ¥ç®€å•çš„ä¸€å±‚convå±‚å˜æˆä¸¤å±‚ï¼šsqueezeå±‚+expandå±‚ï¼Œå„è‡ªå¸¦ä¸ŠReluæ¿€æ´»å±‚ã€‚Fire Moduelä¸»è¦åŒ…æ‹¬squeezeæ¨¡å—å’Œexpandæ¨¡å—ï¼Œå…¶ä¸­squeezeæ¨¡å—å…¨éƒ¨ç”±1x1å·ç§¯ç»„æˆï¼Œè€Œexpandæ¨¡å—ç”±1x1å·ç§¯å’Œ3x3å·ç§¯ç»„æˆï¼š squeezeæ¨¡å—ä¸­å·ç§¯æ ¸ä¸ªæ•°ä¸€å®šè¦å°äºexpandæ¨¡å—ä¸­å·ç§¯æ ¸çš„ä¸ªæ•°ï¼Œåªæœ‰è¿™æ ·æ‰èƒ½è¾¾åˆ°é™å‚å’Œå‹ç¼©çš„ç›®çš„ï¼› squeezeä¸­çš„1x1å·ç§¯èµ·åˆ°äº†é™ç»´çš„æ•ˆæœï¼› ä¸ºäº†å®ç°expandæ¨¡å—ä¸­1x1å·ç§¯å’Œ3x3å·ç§¯ä¹‹åçš„æ•°æ®èƒ½å¤Ÿconcatenateåœ¨ä¸€èµ·ï¼Œå¯¹äºè¾“å…¥3x3çš„å¯¹è±¡éœ€è¦å¢åŠ 1çš„zero-paddingæ“ä½œï¼› åœ¨squeezeæ¨¡å—å’Œexpandæ¨¡å—ä¹‹åé€šè¿‡ReLUè¿›è¡Œæ¿€æ´»ï¼› æ¨¡å‹æ¶æ„åŠå‚æ•° å¦‚å›¾æ‰€ç¤ºï¼Œ SqueezeNetä¸­å½»åº•æ”¾å¼ƒäº†å…¨è¿æ¥ç½‘ç»œï¼› ä½œè€…è®ºæ–‡ä¸­åˆå§‹å­¦ä¹ ç‡å¾ˆå¤§ï¼Œä¸º0.04ï¼Œå®é™…å®éªŒä¸­ï¼Œå‘ç°è¿™ä¹ˆå¤§çš„å­¦ä¹ ç‡éœ‡è¡å¤ªå‰å®³ï¼Œé™ä¸º0.01ï¼› é™ç»´çš„æ“ä½œå°½é‡æ”¾åœ¨äº†æ¨¡å‹ååŠæ®µï¼Œä¸ºäº†æ»¡è¶³ç¬¬ä¸‰æ¡è®¾è®¡åŸåˆ™ï¼› å‚æ•°æ–¹é¢ï¼šä½¿ç”¨äº†8ä¸ªFire Moduleï¼Œæ¯ä¸ªFire Moduleä¸­ï¼Œsqueezeçš„å·ç§¯æ ¸æ•°ç›®æ˜¯expandçš„1/8ï¼› fire9ä¹‹åé‡‡ç”¨äº†dropoutï¼Œå…¶ä¸­keep_prob=0.5; åˆ†æç»“æœ å¦‚å›¾æ‰€ç¤ºï¼ŒSqueezeNetæ¨¡å‹æœ¬èº«æ˜¯AlexNetçš„1/50ï¼Œå´å¯ä»¥è·å¾—ç›¸è¿‘çš„å‡†ç¡®ç‡ï¼Œé€šè¿‡åˆ©ç”¨Deep CompressionæŠ€æœ¯å¯ä»¥è¿›ä¸€æ­¥å‹ç¼©æ¨¡å‹ï¼Œå®ç°1/510æ¨¡å‹å¤§å°æƒ…å†µä¸‹çš„ç›¸åŒæ€§èƒ½ï¼ˆå½“ç„¶å®é™…ä¸­ï¼Œç”±äºDeep Compressioné‡‡å–äº†ç¼–ç ç­–ç•¥ï¼Œéœ€è¦ç¼–ç æœ¬ï¼Œä¼šå¸¦æ¥ä¸€å®šçš„é¢å¤–å¼€é”€ï¼‰ã€‚ [æ‰©å±•é˜…è¯»]Deep Compression Deep compression: Compressing DNNs with pruning, trained quantization and huffman codingï¼Œ 2015 å¸¸è§çš„æ¨¡å‹å‹ç¼©æŠ€æœ¯ å¥‡å¼‚å€¼åˆ†è§£(singular value decomposition (SVD))1 ç½‘ç»œå‰ªæï¼ˆNetwork Pruningï¼‰2ï¼šä½¿ç”¨ç½‘ç»œå‰ªæå’Œç¨€ç–çŸ©é˜µ æ·±åº¦å‹ç¼©ï¼ˆDeep compressionï¼‰3ï¼šä½¿ç”¨ç½‘ç»œå‰ªæï¼Œæ•°å­—åŒ–å’Œhuffmanç¼–ç  ç¡¬ä»¶åŠ é€Ÿå™¨ï¼ˆhardware acceleratorï¼‰4 é‡å¤´è®­ç»ƒä¸€ä¸ªSqueezeNet ä½¿ç”¨MxNetæ„å»ºAlexNetä»£ç  123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990# import the necessary packagesimport mxnet as mxclass MxSqueezeNet: @staticmethod def squeeze(input, numFilter): # the first part of a FIRE module consists of a number of 1x1 # filter squeezes on the input data followed by an activation squeeze_1x1 = mx.sym.Convolution(data=input, kernel=(1, 1), stride=(1, 1), num_filter=numFilter) act_1x1 = mx.sym.LeakyReLU(data=squeeze_1x1, act_type=\"elu\") # return the activation for the squeeze return act_1x1 @staticmethod def fire(input, numSqueezeFilter, numExpandFilter): # construct the 1x1 squeeze followed by the 1x1 expand squeeze_1x1 = MxSqueezeNet.squeeze(input, numSqueezeFilter) expand_1x1 = mx.sym.Convolution(data=squeeze_1x1, kernel=(1, 1), stride=(1, 1), num_filter=numExpandFilter) relu_expand_1x1 = mx.sym.LeakyReLU(data=expand_1x1, act_type=\"elu\") # construct the 3x3 expand expand_3x3 = mx.sym.Convolution(data=squeeze_1x1, pad=(1, 1), kernel=(3, 3), stride=(1, 1), num_filter=numExpandFilter) relu_expand_3x3 = mx.sym.LeakyReLU(data=expand_3x3, act_type=\"elu\") # the output of the FIRE module is the concatenation of the # activation for the 1x1 and 3x3 expands along the channel # dimension output = mx.sym.Concat(relu_expand_1x1, relu_expand_3x3, dim=1) # return the output of the FIRE module return output @staticmethod def build(classes): # data input data = mx.sym.Variable(\"data\") # Block #1: CONV =&gt; RELU =&gt; POOL conv_1 = mx.sym.Convolution(data=data, kernel=(7, 7), stride=(2, 2), num_filter=96) relu_1 = mx.sym.LeakyReLU(data=conv_1, act_type=\"elu\") pool_1 = mx.sym.Pooling(data=relu_1, kernel=(3, 3), stride=(2, 2), pool_type=\"max\") # Block #2-4: (FIRE * 3) =&gt; POOL fire_2 = MxSqueezeNet.fire(pool_1, numSqueezeFilter=16, numExpandFilter=64) fire_3 = MxSqueezeNet.fire(fire_2, numSqueezeFilter=16, numExpandFilter=64) fire_4 = MxSqueezeNet.fire(fire_3, numSqueezeFilter=32, numExpandFilter=128) pool_4 = mx.sym.Pooling(data=fire_4, kernel=(3, 3), stride=(2, 2), pool_type=\"max\") # Block #5-8: (FIRE * 4) =&gt; POOL fire_5 = MxSqueezeNet.fire(pool_4, numSqueezeFilter=32, numExpandFilter=128) fire_6 = MxSqueezeNet.fire(fire_5, numSqueezeFilter=48, numExpandFilter=192) fire_7 = MxSqueezeNet.fire(fire_6, numSqueezeFilter=48, numExpandFilter=192) fire_8 = MxSqueezeNet.fire(fire_7, numSqueezeFilter=64, numExpandFilter=256) pool_8 = mx.sym.Pooling(data=fire_8, kernel=(3, 3), stride=(2, 2), pool_type=\"max\") # Block #9-10: FIRE =&gt; DROPOUT =&gt; CONV =&gt; RELU =&gt; POOL fire_9 = MxSqueezeNet.fire(pool_8, numSqueezeFilter=64, numExpandFilter=256) do_9 = mx.sym.Dropout(data=fire_9, p=0.5) conv_10 = mx.sym.Convolution(data=do_9, num_filter=classes, kernel=(1, 1), stride=(1, 1)) relu_10 = mx.sym.LeakyReLU(data=conv_10, act_type=\"elu\") pool_10 = mx.sym.Pooling(data=relu_10, kernel=(13, 13), pool_type=\"avg\") # softmax classifier flatten = mx.sym.Flatten(data=pool_10) model = mx.sym.SoftmaxOutput(data=flatten, name=\"softmax\") # return the network architecture return model å‡ ç‚¹æ³¨æ„ç‚¹ï¼š ä½¿ç”¨ELUæ›¿ä»£äº†ReLUæ¿€æ´»å‡½æ•°ï¼›åœ¨ImageNetæ•°æ®é›†ä¸­ï¼ŒELUè¡¨ç°æ•ˆæœç”±äºReLUï¼› 3x3 expandä¸­æœ‰ä¸ªpad=ï¼ˆ1ï¼Œ1ï¼‰ æœ€æœ‰ä½¿ç”¨çš„å…¨å±€å¹³å‡æ± åŒ–å±‚ï¼Œkernel=ï¼ˆ13ï¼Œ13ï¼‰ å…¨å±€æ± åŒ–è¾“å‡ºè¢«flattenä¹‹åç›´æ¥ä¸¢ç»™softmax SqueezeNetçš„TensorFLowå®ç°123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960class SqueezeNet(object): def __init__(self, inputs, nb_classes=1000, is_training=True): # conv1 net = tf.layers.conv2d(inputs, 96, [7, 7], strides=[2, 2], padding=\"SAME\", activation=tf.nn.relu, name=\"conv1\") # maxpool1 net = tf.layers.max_pooling2d(net, [3, 3], strides=[2, 2], name=\"maxpool1\") # fire2 net = self._fire(net, 16, 64, \"fire2\") # fire3 net = self._fire(net, 16, 64, \"fire3\") # fire4 net = self._fire(net, 32, 128, \"fire4\") # maxpool4 net = tf.layers.max_pooling2d(net, [3, 3], strides=[2, 2], name=\"maxpool4\") # fire5 net = self._fire(net, 32, 128, \"fire5\") # fire6 net = self._fire(net, 48, 192, \"fire6\") # fire7 net = self._fire(net, 48, 192, \"fire7\") # fire8 net = self._fire(net, 64, 256, \"fire8\") # maxpool8 net = tf.layers.max_pooling2d(net, [3, 3], strides=[2, 2], name=\"maxpool8\") # fire9 net = self._fire(net, 64, 256, \"fire9\") # dropout net = tf.layers.dropout(net, 0.5, training=is_training) # conv10 net = tf.layers.conv2d(net, 1000, [1, 1], strides=[1, 1], padding=\"SAME\", activation=tf.nn.relu, name=\"conv10\") # avgpool10 net = tf.layers.average_pooling2d(net, [13, 13], strides=[1, 1], name=\"avgpool10\") # squeeze the axis net = tf.squeeze(net, axis=[1, 2]) self.logits = net self.prediction = tf.nn.softmax(net) def _fire(self, inputs, squeeze_depth, expand_depth, scope): with tf.variable_scope(scope): squeeze = tf.layers.conv2d(inputs, squeeze_depth, [1, 1], strides=[1, 1], padding=\"SAME\", activation=tf.nn.relu, name=\"squeeze\") # squeeze expand_1x1 = tf.layers.conv2d(squeeze, expand_depth, [1, 1], strides=[1, 1], padding=\"SAME\", activation=tf.nn.relu, name=\"expand_1x1\") expand_3x3 = tf.layers.conv2d(squeeze, expand_depth, [3, 3], strides=[1, 1], padding=\"SAME\", activation=tf.nn.relu, name=\"expand_3x3\") return tf.concat([expand_1x1, expand_3x3], axis=3) è®­ç»ƒSqueezeNetè®­ç»ƒç”¨çš„è„šæœ¬å’Œå‰é¢å‡ ä¸ªç½‘ç»œä¸€è‡´ã€‚ å‡ ä¸ªæ³¨æ„ç‚¹ï¼š batchSize = config.BATCH_SIZE * config.NUM_DEVICES; ä½¿ç”¨k80 12GBå…ˆå­˜ï¼Œé€‰æ‹©batchSzie=128ï¼› ä¼˜åŒ–ç®—æ³•ä½¿ç”¨SGDï¼Œåˆå§‹å­¦ä¹ ç‡ä¸º1e-2ï¼ŒåŠ¨é‡0.9ï¼ŒL2æƒé‡æ­£åˆ™åŒ–å‚æ•°0.0002ï¼›rescaleå‚æ•°å°¤ä¸ºå…³é”®ï¼Œæ ¹æ®æ‰¹çš„å¤§å°æ”¾å¤§æ¢¯åº¦ï¼šrescale_grad=1.0 / batchSizeï¼› modelä¸­çš„ctxå‚æ•°ç”¨äºæŒ‡å®šç”¨äºè®­ç»ƒçš„GPUï¼› ä½¿ç”¨äº†Xavierè¿›è¡Œå‚æ•°åˆå§‹åŒ–ï¼Œä¸åŸæ¨¡å‹ç•¥æœ‰ä¸åŒï¼ŒXavieræ˜¯ç›®å‰CNNç½‘ç»œå¸¸é‡‡ç”¨çš„å‚æ•°åˆå§‹åŒ–æ–¹å¼ï¼›initializer=mx.initializer.Xavier()ï¼› In Keras, the ELU activation uses a default Î± value of 1.0. â€¢ But in mxnet, the ELU Î± value defaults to 0.25. å­¦ä¹ ç‡çš„æ§åˆ¶ Epoch å­¦ä¹ ç‡ 1-64 1e-2 65-80 1e-3 81-89 1e-4 90-100 1e-5 æ§åˆ¶æ¯è½®å­¦ä¹ ç‡ä¿®æ”¹çš„è§‚å¯Ÿçª—å£è¦åœ¨10-15ä¸ªepochä¹‹åå†ä¸‹ç»“è®ºï¼Œç¡®å®šè¯¥é˜¶æ®µéªŒè¯é›†å‡†ç¡®ç‡é¥±å’Œäº†å†è¡Œé™ä½å­¦ä¹ ç‡ï¼› è°ƒæ•´å­¦ä¹ ç‡ python train_alexnet.py --checkpoints checkpoints --prefix alexnet \\ --start-epoch 50 åœ¨8ä¸ªGPUä¸Šï¼Œæ¯è½®ç”¨æ—¶1000å¤šç§’ï¼› ç¬¬ä¸€éè®­ç»ƒé‡‡ç”¨1e-2çš„å­¦ä¹ ç‡è®­ç»ƒ75è½®ï¼Œå‘ç°65è½®ä»¥åï¼ŒéªŒè¯é›†å‡†ç¡®ç‡å·²ç»ä¸å†å¢åŠ ï¼›ä¸ºæ­¤åœ¨65è½®ä¹‹åè°ƒæ•´å­¦ä¹ ç‡ä¸º1e-3ï¼› å°†å­¦ä¹ ç‡è°ƒæ•´åˆ°1e-3ä¹‹åï¼ŒéªŒè¯é›†å‡†ç¡®ç‡æœ‰å¤§å¹…æå‡ï¼Œä»£è¡¨è°ƒæ•´æœ‰æ•ˆï¼Œ80è½®ä¹‹åå†åº¦é¥±å’Œï¼Œé™ä½å­¦ä¹ ç‡åˆ°1e-4;åˆ°89è½®éªŒè¯é›†ç»“æœå¦‚ä¸‹ï¼š â€‹ è¿›ä¸€æ­¥é™ä½å­¦ä¹ ç‡åˆ°1e-5ï¼Œå‘ç°æ•´ä¸ªç½‘ç»œæ²¡æœ‰æ€§èƒ½æå‡ï¼Œç»“æŸè¯¥æ‰¹æ¬¡å‚æ•°è®­ç»ƒè¿‡ç¨‹ã€‚ å®éªŒ åˆå§‹å­¦ä¹ ç‡çš„é€‰æ‹© BNçš„æ•ˆæœ åœ¨SqueezeNetä¸­æ²¡æœ‰æ•ˆæœ ReLU vs ELU ï¼Ÿ ç”¨ELUæ›¿ä»£ReLUï¼Œæå‡1-2%çš„æ€§èƒ½ï¼› é€‰å–90è½®çš„è®­ç»ƒç»“æœï¼Œåœ¨æµ‹è¯•é›†æ•°æ®ä¸Šè¿›è¡ŒéªŒè¯ï¼Œç»“æœå¦‚ä¸‹ï¼š 12[INFO] rank-1: 55.44%[INFO] rank-5: 78.10% ç»“è®ºä»Šå¤©ç»ˆäºå®Œæˆäº†æ‰€æœ‰é¢„å®šç¥ç»ç½‘ç»œçš„è®­ç»ƒè¿‡ç¨‹ï¼Œè™½ç„¶æœ‰äº›ç½‘ç»œç”±äºæœ¬èº«å¯¹ç½‘ç»œç»“æ„çš„è®¤çŸ¥æˆ–è€…æ˜¯å®é™…è®­ç»ƒè¿‡ç¨‹ä¸­æ²¡æœ‰å¾ˆå¥½çš„æŠŠæ¡èŠ‚å¥ï¼Œå¯¼è‡´è®­ç»ƒæ•ˆæœä¸æ˜¯ååˆ†ç†æƒ³ï¼Œä½†ä»è¿™æ¬¡çš„è®­ç»ƒè¿‡ç¨‹ä¸­è¿˜æ˜¯å­¦åˆ°äº†å¾ˆå¤šä¸œè¥¿ã€‚æ•´ä¸ªè¿‡ç¨‹å¤§æ¦‚æŒç»­äº†åŠä¸ªæœˆå·¦å³çš„æ—¶é—´ï¼Œå¾—ç›ŠäºAWSä¸Š8 GPUçš„èµ„æºï¼Œä½¿å¾—å¾ˆå¤šç½‘ç»œçš„è®­ç»ƒæ¯”åŸæƒ³è¿›åº¦è¦å¿«å¾ˆå¤šï¼Œä½†è´¹ç”¨ä¹Ÿæ˜¯æƒŠäººï¼Œçœ‹äº†ä¸‹è´¦å•ï¼Œå‘ç”Ÿåœ¨è™šæ‹Ÿæœºä¸Šçš„è´¹ç”¨å¤§æ¦‚æœ‰1ä¸‡3åƒå¤šï¼Œä¸»è¦ç”±äº8 GPUæœåŠ¡å™¨è¦85å…ƒäººæ°‘å¸æ¯ä¸ªå°æ—¶çš„è´¹ç”¨ä¸æ˜¯æ‰€æœ‰äººéƒ½å¯ä»¥æ‰¿å—çš„èµ·çš„ã€‚æ‰€ä»¥æˆ‘ä¸€ç›´è®¤ä¸ºçŸ­æœŸå†…ï¼Œæ·±åº¦å­¦ä¹ è¿˜æ˜¯å¾ˆéš¾çœŸæ­£äº§ä¸šåŒ–çš„ä¸€ä¸ªæ³¡æ²«ï¼Œå¾ˆéš¾æœ‰åº”ç”¨ä¸šåŠ¡å¯ä»¥æŠµæ¶ˆè¿™ä¸ªæ˜‚è´µçš„è®­ç»ƒæˆæœ¬ã€‚æˆ‘è¿™åªæ˜¯å¤ç°ç½‘ç»œï¼ŒçœŸå®è®­ç»ƒä¸€ä¸ªäº§å“çº§çš„ç½‘ç»œã€æ‰€éœ€è¦æµ‹è¯•çš„å‚æ•°åå€ç™¾å€äºæ­¤ã€‚ ä»˜äº†æ˜‚è´µçš„å­¦è´¹ï¼Œå­¦ä¹ çš„åŠ¨åŠ›ä¹Ÿæ›´åŠ å……è¶³ï¼Œå°†å‡ ç§ç½‘ç»œçš„è®­ç»ƒè¿‡ç¨‹è¿›è¡Œä¸€ä¸‹ç®€å•çš„æ¨ªå‘æ¯”è¾ƒï¼ŒåŒæ—¶æ€»ç»“ä¸€ä¸‹å¤§å‹ç½‘ç»œè®­ç»ƒè¿‡ç¨‹ä¸­æ³¨æ„çš„ä¸»è¦å†…å®¹ã€‚ å‡ ç§ç½‘ç»œåœ¨è®­ç»ƒè¿‡ç¨‹çš„ç®€å•æ¯”è¾ƒ ç½‘ç»œåç§° æ¨¡å‹å¤§å° æ¯è½®è®­ç»ƒæ—¶é—´ï¼ˆ8GPU Tesla K80ï¼‰ æ€»è¿­ä»£æ•°+è®­ç»ƒæ—¶é—´ åˆå§‹åŒ–å‚æ•°é€‰æ‹© åˆå§‹å­¦ä¹ ç‡ æ¿€æ´»å‡½æ•° æœ€ç»ˆæµ‹è¯•é›†å‡†ç¡®ç‡ï¼ˆTop-1/Top-5ï¼‰ AlexNet 239MB ~670s ~1.5å¤© Xavier 1e-2,åŠ¨é‡0.9ï¼ŒL2 0.0005 ELU 60.20%/81.99% VGG-16 529MB ~ ~10å¤© MSRA 1e-2,åŠ¨é‡0.9ï¼ŒL2 0.0005 PReLU GoogLeNet 28MB ~1200s ~2å¤© Xavier 1e-3ï¼ŒAdamï¼ŒL2 0.0002 ReLU 69.58%/89.01% ResNet 98MB ~3500s ~3å¤© MSRA 1e-1,åŠ¨é‡0.9ï¼ŒL2 0.0001 ReLU 71.49%/89.96% SqueezeNet 5MB ~1060s ~1.5å¤© Xavier 1e-2ï¼ŒåŠ¨é‡0.9ï¼ŒL2 0.0002 ELU 55.44%/78.10% è®­ç»ƒå¿ƒå¾— è®­ç»ƒä¸€ä¸ªå¤§å‹æ•°æ®é›†çš„æ·±åº¦ç¥ç»ç½‘ç»œæ˜¯ä¸ªè´¹æ—¶è´¹åŠ›çš„æ´»ï¼Œä¸ºäº†è·å¾—æœ€ä¼˜çš„å‚æ•°ï¼Œä¸€èˆ¬éœ€è¦è¿›è¡Œ10-100æ¬¡å‚æ•°å®éªŒï¼Œéœ€è¦æå¤§çš„è€å¿ƒå’Œè®¡ç®—èµ„æºï¼› åŸåˆ™ï¼šè®­ç»ƒæ·±åº¦ç¥ç»ç½‘ç»œçš„ç›®çš„ä¸æ˜¯æ‰¾å¯»å…¨å±€æœ€ä¼˜è§£ï¼Œå› ä¸ºä¸€èˆ¬å¾ˆéš¾æ‰¾åˆ°è¿™ä¸ªè§£ï¼Œæˆ‘ä»¬åªæ˜¯åœ¨æ¢å¯»ä¸€ä¸ªæ¯”ä¸Šæ¬¡æ•ˆæœæ›´å¥½çš„æ¨¡å‹ï¼› ç½‘ç»œå‚æ•°å¦‚ä½•å…¥æ‰‹ï¼Ÿ é€†æœºå™¨å­¦ä¹ æµç¨‹çš„æ€è€ƒï¼šåœ¨æœºå™¨å­¦ä¹ ç®—æ³•çš„åº”ç”¨é€»è¾‘é‡Œï¼Œæˆ‘ä»¬æ€»æ˜¯å¼ºè°ƒè¦å¿«é€Ÿçš„å¼€å§‹æ­å»ºç¬¬ä¸€ä¸ªæ¨¡å‹ï¼Œè®¾å®šæµ‹è¯•çš„åŸºå‡†ï¼Œç„¶åå†è¿­ä»£æ›´æ–°æ¨¡å‹ã€‚è€Œè®­ç»ƒå¤§å‹ç¥ç»ç½‘ç»œï¼Œç”±äºè®­ç»ƒè¿‡ç¨‹å¯¹æ—¶é—´å’Œèµ„æºæ¶ˆè€—ååˆ†å·¨å¤§ï¼Œä¸ºå……åˆ†åˆ©ç”¨èµ„æºï¼Œåˆ‡ä¸å¯ç›²ç›®èµ·æ­¥ï¼› ç”±äºå¯è°ƒå‚æ•°ç»ˆç«¯ï¼Œæ‰€ä»¥å¿…é¡»è¦æƒ³åŠæ³•ç¼©å°å¯è°ƒå‚æ•°èŒƒå›´ï¼Œä¼˜å…ˆé€‰æ‹©é‡è¦å‚æ•°è¿›è¡Œè°ƒè¯•ï¼ŒåŒæ—¶é€šè¿‡æŸ¥é˜…ç›¸ä¼¼æ•°æ®é›†æ–‡çŒ®ä¸­ä½¿ç”¨çš„å‚æ•°æ¥è¿›ä¸€æ­¥ç¼©å°è‡ªå·±è°ƒè¯•å‚æ•°çš„èŒƒå›´ï¼› åˆå§‹å­¦ä¹ ç‡é€‰æ‹©ï¼š å­¦ä¹ ç‡å‚æ•°æ˜¯æ•´ä¸ªå‚æ•°ç©ºé—´ä¸­æœ€é‡è¦çš„ä¸€ä¸ªï¼Œå¦‚æœä½ åªæƒ³è°ƒè¯•ä¸€ä¸ªå‚æ•°ï¼Œé‚£ä¹ˆè¯·é€‰æ‹©å®ƒï¼› åˆå§‹å­¦ä¹ ç‡éœ€è¦æ ¹æ®ç½‘ç»œæ¨¡å‹çš„ç‰¹ç‚¹æ¥å†³å®šï¼Œä¸€èˆ¬è€Œè¨€1e-2å¯èƒ½æ˜¯ä¸€ä¸ªåˆé€‚çš„å­¦ä¹ ç‡ï¼Œä½†ä¸æ˜¯å¯¹æ‰€æœ‰çš„ç½‘ç»œéƒ½æ˜¯æœ€ä½³çš„å­¦ä¹ ç‡ï¼Œæ¯”å¦‚ResNetæ”¯æŒæ›´å¤§çš„å­¦ä¹ ç‡ï¼Œæ¯”å¦‚1e-1,GoogLeNetè€Œè¨€ï¼Œ1e-2æœ‰ç‚¹å¤ªå¤§ï¼ŒéªŒè¯é›†å‡†ç¡®ç‡ä¼šå‘ç”Ÿæ¯”è¾ƒå¤§çš„éœ‡è¡ï¼› å­¦ä¹ ç‡æ§åˆ¶ï¼š åˆå§‹å­¦ä¹ ç‡é€‰æ‹©å¥½ä»¥åï¼Œéœ€è¦åœ¨ç¬¬ä¸€æ¬¡è¿­ä»£ä¸­è®©ç½‘ç»œå¤šè¿è¡Œä¸€æ®µæ—¶é—´ï¼Œè§‚å¯ŸéªŒè¯é›†ä¸Šçš„è¡¨ç°å†³å®šæ˜¯å¦å˜æ›´å­¦ä¹ ç‡ï¼Œä¸€èˆ¬å½“éªŒè¯é›†è¯¯å·®å‡ºç°é˜»å¡æˆ–è€…å‡ºç°æ˜æ˜¾è¿‡æ‹Ÿåˆç°è±¡æ—¶ï¼Œéœ€è¦åœæ­¢è®­ç»ƒï¼Œè°ƒæ•´å­¦ä¹ ç‡ï¼Œä»æ‰“æ–­ä½ç½®æˆ–å‰é¢ä½ç½®ç»§ç»­è®­ç»ƒï¼› å­¦ä¹ ç‡æ‰‹æ®µè¡°å‡ä¸€èˆ¬é‡‡å–å¯¹æ•°è¡°å‡çš„ç­–ç•¥ï¼Œæ¯”å¦‚æ¯æ¬¡è¡°å‡åå€ï¼› ä¼˜åŒ–ç®—æ³•é€‰æ‹©ï¼š å…³äºä¼˜åŒ–ç®—æ³•çš„é€‰æ‹©ï¼Œä¸€èˆ¬å…ˆä»å°è¯•ç»å…¸çš„SGDç®—æ³•ã€é…åˆåŠ¨é‡è®¾ç½®å¼€å§‹è®­ç»ƒçœ‹ç½‘ç»œæ˜¯å¦èƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ å‚æ•°ç©ºé—´ä¿¡æ¯ï¼› è¿›ä¸€æ­¥çš„å¯ä»¥è°ƒæ•´ä¸ºAdamæ¥åŠ å¿«æ¢¯åº¦çš„æ›´æ–°ï¼› åœ¨å¤§å‹ç½‘ç»œè®­ç»ƒä¸­è¿˜ç»å¸¸ä½¿ç”¨æ¢¯åº¦çš„rescaleæ“ä½œï¼Œæ ¹æ®batchsizeå¤§å°ï¼Œæ”¾å¤§æ¢¯åº¦ï¼šrescale_grad=1.0 / batchSizeï¼› æ¿€æ´»å‡½æ•°é€‰æ‹©ï¼šå…ˆä½¿ç”¨ReLUä½œä¸ºæ¿€æ´»å‡½æ•°è·å¾—baselineï¼Œå†é€‰æ‹©æèŠ±ä¸ºELUæ¥è·å¾—æå‡ï¼› åˆå§‹åŒ–å‚æ•°é€‰æ‹©ï¼šè®­ç»ƒæ·±å±‚ç½‘ç»œæ—¶ï¼Œè€ƒè™‘ä½¿ç”¨Xavier,MSRA/HEçš„åˆå§‹åŒ–å‚æ•°ï¼Œå¹¶é…åˆPReLUä¸€èµ·ä½¿ç”¨ï¼Œæ•ˆæœæ›´å¥½ã€‚ è®­ç»ƒè¿‡ç¨‹çš„æ§åˆ¶ï¼š è®­ç»ƒè¿‡ç¨‹è¦åˆ©ç”¨callbackæœºåˆ¶ï¼Œéšæ—¶è®°å½•è®­ç»ƒå‚æ•°ã€checkpointsï¼› é€šè¿‡Tensorboardç­‰å·¥å…·è§‚å¯Ÿè®­ç»ƒè¿‡ç¨‹çš„ç²¾åº¦ã€è¯¯å·®ã€æŸå¤±å‡½æ•°å˜åŒ–æƒ…å†µï¼› æœ‰äº›ç½‘ç»œéœ€è¦é¢„è®­ç»ƒè¿‡ç¨‹ï¼Œé€šè¿‡é¢„è®­ç»ƒå¯ä»¥åŠ é€Ÿç½‘ç»œå­¦ä¹ ï¼› å‚æ•°è°ƒä¼˜çš„å…¶å®ƒæŠ€å·§ï¼š BN DropOut Data Augmentation è®¡ç®—æ¡†æ¶ï¼šTensorFlow or MxNet è®ºæ–‡é˜…è¯»ä¸è®¨è®º â€‹â€¦ å‚è€ƒ ImageNet Classification with Deep Convolutional Neural Networks","categories":[{"name":"åŠ¨æ‰‹å®è·µè¥","slug":"åŠ¨æ‰‹å®è·µè¥","permalink":"http://blog.a-stack.com/categories/åŠ¨æ‰‹å®è·µè¥/"}],"tags":[{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"ç®—æ³•","slug":"ç®—æ³•","permalink":"http://blog.a-stack.com/tags/ç®—æ³•/"},{"name":"æ–‡çŒ®","slug":"æ–‡çŒ®","permalink":"http://blog.a-stack.com/tags/æ–‡çŒ®/"},{"name":"ç½‘ç»œå¤ç°","slug":"ç½‘ç»œå¤ç°","permalink":"http://blog.a-stack.com/tags/ç½‘ç»œå¤ç°/"}]},{"title":"ç»å…¸ç½‘ç»œå¤ç°ä¹‹VGGNet","slug":"2018-07-9-ç»å…¸ç½‘ç»œå¤ç°ä¹‹VGG","date":"2018-07-12T05:58:12.000Z","updated":"2018-07-20T14:53:24.141Z","comments":true,"path":"2018/07/12/2018-07-9-ç»å…¸ç½‘ç»œå¤ç°ä¹‹VGG/","link":"","permalink":"http://blog.a-stack.com/2018/07/12/2018-07-9-ç»å…¸ç½‘ç»œå¤ç°ä¹‹VGG/","excerpt":"æ‘˜è¦ï¼š æœ¬æ–‡è®°å½•åˆ©ç”¨ImageNetæ•°æ®é›†å¤ç°ç»å…¸ç½‘ç»œVGGNetçš„è¿‡ç¨‹ï¼Œå¹¶è®°å½•åœ¨å¤§å‹æ•°æ®é›†è®­ç»ƒè¿‡ç¨‹ä¸­éœ€è¦è€ƒè™‘çš„é—®é¢˜ã€‚","text":"æ‘˜è¦ï¼š æœ¬æ–‡è®°å½•åˆ©ç”¨ImageNetæ•°æ®é›†å¤ç°ç»å…¸ç½‘ç»œVGGNetçš„è¿‡ç¨‹ï¼Œå¹¶è®°å½•åœ¨å¤§å‹æ•°æ®é›†è®­ç»ƒè¿‡ç¨‹ä¸­éœ€è¦è€ƒè™‘çš„é—®é¢˜ã€‚ ä¸ºäº†å¢å¼ºå¯¹state of the artæ·±åº¦ç¥ç»ç½‘ç»œæ¨¡å‹çš„è®¤çŸ¥ï¼Œå‡†å¤‡è¿›è¡Œä¸€ç³»åˆ—æ¨¡å‹çš„å¤ç°å·¥ä½œï¼Œä½¿ç”¨ImageNetçš„å¤§è§„æ¨¡å›¾åƒåˆ†ç±»æ•°æ®é›†ï¼Œä»å¤´è®­ç»ƒå„ä¸ªç»å…¸çš„ç¥ç»ç½‘ç»œæ¨¡å‹ï¼ŒåŒæ—¶ç»“åˆä½œè€…è®ºæ–‡å¯¹è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŠ€å·§è¿›è¡Œå½’çº³æ€»ç»“ï¼Œä¸»è¦å®‰æ’å¦‚ä¸‹å‡ éƒ¨åˆ†å†…å®¹ï¼š ImageNetæ•°æ®é›†åŠæ•°æ®å‡†å¤‡ AlexNetç½‘ç»œ VGGç½‘ç»œ GoogLeNetç½‘ç»œ ResNetç½‘ç»œ SqueezeNetç½‘ç»œ æ¦‚è¿°VGGNetæ˜¯è‹±å›½ç‰›æ´¥å¤§å­¦2014å¹´ImageNet ILSVRCç¬¬äºŒåçš„ç½‘ç»œï¼Œç”±äºå…¶è‰¯å¥½çš„æ³›åŒ–æ€§èƒ½ï¼Œåœ¨è¢«è¿ç§»åˆ°å…¶å®ƒæ·±åº¦å­¦ä¹ ä»»åŠ¡ä¸­ä½“ç°å‡ºæ¥è‰¯å¥½çš„æ•ˆæœï¼Œæ˜¯ç›®å‰è¿ç§»å­¦ä¹ ä¸­ç”¨çš„æœ€å¤šçš„ç½‘ç»œã€‚ä½†ç”±äºç½‘ç»œè§„æ¨¡å’Œå‚æ•°é‡å®åœ¨åºå¤§ï¼Œä»å¤´è®­ç»ƒä¸€ä¸ªç½‘ç»œå……æ»¡éš¾åº¦ã€‚ è®ºæ–‡ï¼š Very Deep Convolutional Networks for Large-Scale Image Recognition æ•°æ®é›†ï¼š ImageNet 2012 ILSRVCæ•°æ®é›†ï¼ˆæ•°æ®é›†çš„è·å–åŠå‡†å¤‡è¯¦è§ImageNet-DataSetï¼‰ è®¡ç®—æ¡†æ¶ï¼š MxNet ç®—åŠ›èµ„æºï¼šAWSäº‘ä¸»æœºp2.8xlargeï¼š8ä¸ªTesla K80 GPU ($7.20/hour) æ€»è®¡è®­ç»ƒæ—¶é—´&gt;10å¤©å·¦å³ é‡å¤´è®­ç»ƒä¸€ä¸ªVGGNet ç”±äºç½‘ç»œæ·±åº¦å¤ªæ·±ã€å‚æ•°å¤ªå¤šï¼Œæ‰€ä»¥ä»å¤´æŒ‰éƒ¨å°±ç­çš„è®­ç»ƒVGGNetæ˜¯å¾ˆæ¼«é•¿çš„è¿‡ç¨‹ï¼Œä¸ºæ­¤VGGçš„ä½œè€…ä½¿ç”¨äº†ä¸€ç§pre-trainingçš„æ–¹å¼ã€‚é€šè¿‡ä¸æ–­è®­ç»ƒå°ä¸€å·çš„ç½‘ç»œæ¶æ„ï¼Œå°†è®­ç»ƒåçš„å‚æ•°ä½œä¸ºåç»­è¾ƒå¤§ç½‘ç»œçš„åˆå§‹å‚æ•°æ¥é€æ­¥é€¼è¿‘å®Œæ•´çš„ç½‘ç»œã€‚æ¯”å¦‚ä¸ºäº†è®­ç»ƒVGG16ï¼Œä½œè€…å…ˆè®­ç»ƒäº†Aç½‘ç»œVGG11ï¼Œç„¶ååˆ©ç”¨Aç½‘ç»œçš„å‚æ•°é€æ­¥è®­ç»ƒB VGG13ï¼Œæœ€åæ‰æ˜¯Dç½‘ç»œ VGG16ã€‚è¿™ç§æ–¹å¼ä½¿ç”¨äº†warmed pre-trained upå±‚å‚æ•°æ¥æ¨è¿›åç»­çš„ç½‘ç»œè®­ç»ƒã€‚ è™½ç„¶ä¸Šè¿°æ–¹æ³•æ˜¯ä¸ªå¾ˆå¥½çš„æŠ€å·§ï¼Œä½†è®­ç»ƒNä¸ªç½‘ç»œæ‰èƒ½è¾¾åˆ°ç›®çš„å®åœ¨æ˜¯ä¸€ä¸ªç—›è‹¦çš„è¿‡ç¨‹ï¼Œéšç€æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å‘å±•ï¼Œå°¤å…¶æ˜¯å‚æ•°åˆå§‹åŒ–æŠ€æœ¯çš„å‘å±•ï¼Œä¸ºè®­ç»ƒVGGæä¾›äº†æ›´åŠ é«˜æ•ˆçš„ç­–ç•¥â€”â€”ä½¿ç”¨é«˜çº§çš„åˆå§‹åŒ–ç­–ç•¥ï¼Œå¦‚Xavieræˆ–MSRAï¼ŒåŒæ—¶é…åˆä½¿ç”¨å‚æ•°åŒ–ReLUå¯ä»¥æŠ›å¼ƒ1ä¸­çš„é¢„è®­ç»ƒæ–¹å¼ã€‚ è®­ç»ƒVGGNetè®­ç»ƒç”¨çš„è„šæœ¬å’Œå‰é¢å‡ ä¸ªç½‘ç»œä¸€è‡´ã€‚ å‡ ä¸ªæ³¨æ„ç‚¹ï¼š batchSize = config.BATCH_SIZE * config.NUM_DEVICES; ä½¿ç”¨k80 12GBå…ˆå­˜ï¼Œé€‰æ‹©batchSzie=32ï¼› åˆå§‹å­¦ä¹ ç‡ä¸º1e-2ï¼ŒåŠ¨é‡0.9ï¼ŒL2æƒé‡æ­£åˆ™åŒ–å‚æ•°0.0005ï¼›rescaleå‚æ•°å°¤ä¸ºå…³é”®ï¼Œæ ¹æ®æ‰¹çš„å¤§å°æ”¾å¤§æ¢¯åº¦ï¼šrescale_grad=1.0 / batchSizeï¼› ä½¿ç”¨äº†MSRAè¿›è¡Œå‚æ•°åˆå§‹åŒ–ï¼Œinitializer=mx.initializer.MSRAPrelu()ï¼› åŒæ—¶ä½¿ç”¨å‚æ•°PReLUä»£æ›¿ReLUä½œä¸ºæ¿€æ´»å‡½æ•°ï¼› å­¦ä¹ ç‡çš„æ§åˆ¶ Epoch å­¦ä¹ ç‡ 1-50 1e-2 51-70 1e-3 71-80 1e-4 æ§åˆ¶æ¯è½®å­¦ä¹ ç‡ä¿®æ”¹çš„è§‚å¯Ÿçª—å£è¦åœ¨10-15ä¸ªepochä¹‹åå†ä¸‹ç»“è®ºï¼Œç¡®å®šè¯¥é˜¶æ®µéªŒè¯é›†å‡†ç¡®ç‡é¥±å’Œäº†å†è¡Œé™ä½å­¦ä¹ ç‡ï¼› è°ƒæ•´å­¦ä¹ ç‡ python train_alexnet.py --checkpoints checkpoints --prefix alexnet \\ --start-epoch 50 å®éªŒ1.é€‰å–40è½®çš„è®­ç»ƒç»“æœï¼Œåœ¨æµ‹è¯•é›†æ•°æ®ä¸Šè¿›è¡ŒéªŒè¯ï¼Œç»“æœå¦‚ä¸‹ï¼š 12[INFO] rank-1: 71.42% [INFO] rank-5: 90.03% ç»“è®º ä¸ºäº†è®­ç»ƒVGGNetï¼Œä¸€å®šè¦ä½¿ç”¨é«˜çº§åˆå§‹åŒ–å‚æ•°æ–¹æ³•ï¼Œå¹¶é…åˆå‚æ•°åŒ–ReLUä½¿ç”¨ï¼› è®­ç»ƒä¸€ä¸ªå¤§å‹æ•°æ®é›†çš„æ·±åº¦ç¥ç»ç½‘ç»œæ˜¯ä¸ªè´¹æ—¶è´¹åŠ›çš„æ´»ï¼Œä¸ºäº†è·å¾—æœ€ä¼˜çš„å‚æ•°ï¼Œä¸€èˆ¬éœ€è¦è¿›è¡Œ10-100æ¬¡å‚æ•°å®éªŒï¼Œéœ€è¦æå¤§çš„è€å¿ƒå’Œè®¡ç®—èµ„æºï¼› è®­ç»ƒæ·±åº¦ç¥ç»ç½‘ç»œçš„ç›®çš„ä¸æ˜¯æ‰¾å¯»å…¨å±€æœ€ä¼˜è§£ï¼Œå› ä¸ºä¸€èˆ¬å¾ˆéš¾æ‰¾åˆ°è¿™ä¸ªè§£ï¼Œæˆ‘ä»¬åªæ˜¯åœ¨æ¢å¯»ä¸€ä¸ªæ¯”ä¸Šæ¬¡æ•ˆæœæ›´å¥½çš„æ¨¡å‹ï¼› å…ˆä½¿ç”¨ReLUä½œä¸ºæ¿€æ´»å‡½æ•°è·å¾—baselineï¼Œå†é€‰æ‹©æèŠ±ä¸ºELUæ¥è·å¾—æå‡ï¼› è®­ç»ƒæ·±å±‚ç½‘ç»œæ—¶ï¼Œè€ƒè™‘ä½¿ç”¨MSRA/HEçš„åˆå§‹åŒ–å‚æ•°ï¼Œå¹¶é…åˆPReLUä¸€èµ·ä½¿ç”¨ï¼Œæ•ˆæœæ›´å¥½ï¼›","categories":[{"name":"åŠ¨æ‰‹å®è·µè¥","slug":"åŠ¨æ‰‹å®è·µè¥","permalink":"http://blog.a-stack.com/categories/åŠ¨æ‰‹å®è·µè¥/"}],"tags":[{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"ç®—æ³•","slug":"ç®—æ³•","permalink":"http://blog.a-stack.com/tags/ç®—æ³•/"},{"name":"æ–‡çŒ®","slug":"æ–‡çŒ®","permalink":"http://blog.a-stack.com/tags/æ–‡çŒ®/"},{"name":"ç½‘ç»œå¤ç°","slug":"ç½‘ç»œå¤ç°","permalink":"http://blog.a-stack.com/tags/ç½‘ç»œå¤ç°/"}]},{"title":"ç»å…¸ç½‘ç»œå¤ç°ä¹‹GoogleNet","slug":"ç»å…¸ç½‘ç»œå¤ç°ä¹‹GoogleNet","date":"2018-07-12T05:58:12.000Z","updated":"2018-07-20T15:52:31.842Z","comments":true,"path":"2018/07/12/ç»å…¸ç½‘ç»œå¤ç°ä¹‹GoogleNet/","link":"","permalink":"http://blog.a-stack.com/2018/07/12/ç»å…¸ç½‘ç»œå¤ç°ä¹‹GoogleNet/","excerpt":"æ‘˜è¦ï¼š æœ¬æ–‡è®°å½•åˆ©ç”¨ImageNetæ•°æ®é›†å¤ç°ç»å…¸ç½‘ç»œGoogLeNetçš„è¿‡ç¨‹ï¼Œå¹¶è®°å½•åœ¨å¤§å‹æ•°æ®é›†è®­ç»ƒè¿‡ç¨‹ä¸­éœ€è¦è€ƒè™‘çš„é—®é¢˜ã€‚","text":"æ‘˜è¦ï¼š æœ¬æ–‡è®°å½•åˆ©ç”¨ImageNetæ•°æ®é›†å¤ç°ç»å…¸ç½‘ç»œGoogLeNetçš„è¿‡ç¨‹ï¼Œå¹¶è®°å½•åœ¨å¤§å‹æ•°æ®é›†è®­ç»ƒè¿‡ç¨‹ä¸­éœ€è¦è€ƒè™‘çš„é—®é¢˜ã€‚ ä¸ºäº†å¢å¼ºå¯¹state of the artæ·±åº¦ç¥ç»ç½‘ç»œæ¨¡å‹çš„è®¤çŸ¥ï¼Œå‡†å¤‡è¿›è¡Œä¸€ç³»åˆ—æ¨¡å‹çš„å¤ç°å·¥ä½œï¼Œä½¿ç”¨ImageNetçš„å¤§è§„æ¨¡å›¾åƒåˆ†ç±»æ•°æ®é›†ï¼Œä»å¤´è®­ç»ƒå„ä¸ªç»å…¸çš„ç¥ç»ç½‘ç»œæ¨¡å‹ï¼ŒåŒæ—¶ç»“åˆä½œè€…è®ºæ–‡å¯¹è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŠ€å·§è¿›è¡Œå½’çº³æ€»ç»“ï¼Œä¸»è¦å®‰æ’å¦‚ä¸‹å‡ éƒ¨åˆ†å†…å®¹ï¼š ImageNetæ•°æ®é›†åŠæ•°æ®å‡†å¤‡ AlexNetç½‘ç»œ VGGç½‘ç»œ GoogLeNetç½‘ç»œ ResNetç½‘ç»œ SqueezeNetç½‘ç»œ æ¦‚è¿°GoogleNetä½œä¸º2012å¹´ILSVRCçš„å† å†›ï¼Œæœ€è¿‘å‡ å¹´åœ¨åŸå…ˆInception v1ç‰ˆæœ¬ä¸Šä¹Ÿåœ¨ä¸æ–­çš„æ¼”åŒ–å‘å±•ï¼Œç›®å‰å·²ç»åˆ°äº†v4ç‰ˆæœ¬ã€‚GoogleNetæ¨¡å‹è®¾è®¡åœ¨ä¿è¯å‡†ç¡®ç‡çš„åŒæ—¶å¤§å¤§é™ä½äº†æ¨¡å‹çš„å¤§å°ï¼Œä¸VGGæ¥è¿‘500MBç›¸æ¯”ï¼Œåªæœ‰28MBå·¦å³çš„æ¨¡å‹å¤§å°ã€‚ è®ºæ–‡ï¼š Christian Szegedy et al. â€œGoing Deeper with Convolutionsâ€. In: Computer Vision and Pattern Recognition (CVPR). 2015. URL: http://arxiv.org/abs/1409.4842 æ•°æ®é›†ï¼š ImageNet 2012 ILSRVCæ•°æ®é›†ï¼ˆæ•°æ®é›†çš„è·å–åŠå‡†å¤‡è¯¦è§ImageNet-DataSetï¼‰ è®¡ç®—æ¡†æ¶ï¼š MxNet ç®—åŠ›èµ„æºï¼šAWSäº‘ä¸»æœºp2.8xlargeï¼š8ä¸ªTesla K80 GPU ($7.20/hour) æ€»è®¡è®­ç»ƒæ—¶é—´2å¤©å·¦å³ æ¯è½®è¿­ä»£æ—¶é—´ï¼š~1200ç§’(~20åˆ†é’Ÿ) GoogleNetGoogleNetçš„ä¸»è¦åˆ›æ–°ç‚¹ä½“ç°åœ¨ï¼š ä¸€ã€æ‰“ç ´äº†å¸¸è§„çš„å·ç§¯å±‚ä¸²è”çš„æ¨¡å¼ï¼Œæå‡ºäº†å°†1x1ï¼Œ3x3ï¼Œ5x5çš„å·ç§¯å±‚å’Œ3x3çš„poolingæ± åŒ–å±‚å¹¶è”ç»„åˆåconcatenateç»„è£…åœ¨ä¸€èµ·çš„è®¾è®¡æ€è·¯ã€‚ äºŒã€InceptionV1é™ä½äº†å‚æ•°é‡ï¼Œç›®çš„æœ‰ä¸¤ä¸ªï¼š1 å‚æ•°è¶Šå¤šæ¨¡å‹è¶Šå¤§ï¼Œéœ€è¦æä¾›æ¨¡å‹å­¦ä¹ çš„æ•°æ®é‡å°±è¶Šå¤§ï¼Œæ•°æ®é‡ä¸å¤§çš„æƒ…å†µä¸‹å®¹æ˜“è¿‡æ‹Ÿåˆï¼›2 å‚æ•°è¶Šå¤šï¼Œè€—è´¹çš„è®¡ç®—èµ„æºä¹Ÿä¼šæ›´å¤§ã€‚ ä¸‰ã€å»é™¤äº†æœ€åçš„å…¨è¿æ¥å±‚ï¼Œç”¨å…¨å±€å¹³å‡æ± åŒ–å±‚æ¥å–ä»£å®ƒã€‚å…¨è¿æ¥å±‚å‡ ä¹å æ®äº†AlexNetæˆ–VGGNetä¸­90%çš„å‚æ•°é‡ï¼Œè€Œä¸”ä¼šå¼•èµ·è¿‡æ‹Ÿåˆï¼Œå»é™¤å…¨è¿æ¥å±‚åæ¨¡å‹è®­ç»ƒæ›´å¿«å¹¶ä¸”å‡è½»äº†è¿‡æ‹Ÿåˆã€‚ç”¨å…¨å±€å¹³å‡æ± åŒ–å±‚å–ä»£å…¨è¿æ¥å±‚çš„åšæ³•å€Ÿé‰´äº†NetworkIn Networkï¼ˆä»¥ä¸‹ç®€ç§°NINï¼‰è®ºæ–‡ã€‚ å››ã€InceptionV1ä¸­ç²¾å¿ƒè®¾è®¡çš„InceptionModuleæé«˜äº†å‚æ•°çš„åˆ©ç”¨æ•ˆç‡ã€‚è¿™ä¸€éƒ¨åˆ†ä¹Ÿå€Ÿé‰´äº†NINçš„æ€æƒ³ï¼Œå½¢è±¡çš„è§£é‡Šå°±æ˜¯InceptionModuleæœ¬èº«å¦‚åŒå¤§ç½‘ç»œä¸­çš„ä¸€ä¸ªå°ç½‘ç»œï¼Œå…¶ç»“æ„å¯ä»¥åå¤å †å åœ¨ä¸€èµ·å½¢æˆå¤§ç½‘ç»œã€‚InceptionV1æ¯”NINæ›´è¿›ä¸€æ­¥çš„æ˜¯å¢åŠ äº†åˆ†æ”¯ç½‘ç»œï¼ŒNINåˆ™ä¸»è¦æ˜¯çº§è”çš„å·ç§¯å±‚å’ŒMLPConvå±‚ã€‚ä¸€èˆ¬æ¥è¯´å·ç§¯å±‚è¦æå‡è¡¨è¾¾èƒ½åŠ›ï¼Œä¸»è¦ä¾é å¢åŠ è¾“å‡ºé€šé“æ•°ï¼Œä½†å‰¯ä½œç”¨æ˜¯è®¡ç®—é‡å¢å¤§å’Œè¿‡æ‹Ÿåˆã€‚æ¯ä¸€ä¸ªè¾“å‡ºé€šé“å¯¹åº”ä¸€ä¸ªæ»¤æ³¢å™¨ï¼ŒåŒä¸€ä¸ªæ»¤æ³¢å™¨å…±äº«å‚æ•°ï¼Œåªèƒ½æå–ä¸€ç±»ç‰¹å¾ï¼Œå› æ­¤ä¸€ä¸ªè¾“å‡ºé€šé“åªèƒ½åšä¸€ç§ç‰¹å¾å¤„ç†ã€‚è€ŒNINä¸­çš„MLPConvåˆ™æ‹¥æœ‰æ›´å¼ºå¤§çš„èƒ½åŠ›ï¼Œå…è®¸åœ¨è¾“å‡ºé€šé“ä¹‹é—´ç»„åˆä¿¡æ¯ï¼Œå› æ­¤æ•ˆæœæ˜æ˜¾ã€‚å¯ä»¥è¯´ï¼ŒMLPConvåŸºæœ¬ç­‰æ•ˆäºæ™®é€šå·ç§¯å±‚åå†è¿æ¥1*1çš„å·ç§¯å’ŒReLUæ¿€æ´»å‡½æ•°ã€‚ é‡å¤´è®­ç»ƒä¸€ä¸ªGoogLeNet ä½¿ç”¨MxNetæ„å»ºGoogleNetä»£ç  123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101import mxnet as mxclass MxGoogLeNet: @staticmethod def conv_module(data, K, kX, kY, pad=(0, 0), stride=(1, 1)): # define the CONV =&gt; BN =&gt; RELU pattern conv = mx.sym.Convolution(data=data, kernel=(kX, kY), num_filter=K, pad=pad, stride=stride) #bn = mx.sym.BatchNorm(data=conv) act = mx.sym.Activation(data=conv, act_type=\"relu\") bn = mx.sym.BatchNorm(data=act) # return the block return bn @staticmethod def inception_module(data, num1x1, num3x3Reduce, num3x3, num5x5Reduce, num5x5, num1x1Proj): # the first branch of the Inception module consists of 1x1 # convolutions conv_1x1 = MxGoogLeNet.conv_module(data, num1x1, 1, 1) # the second branch of the Inception module is a set of 1x1 # convolutions followed by 3x3 convolutions conv_r3x3 = MxGoogLeNet.conv_module(data, num3x3Reduce, 1, 1) conv_3x3 = MxGoogLeNet.conv_module(conv_r3x3, num3x3, 3, 3, pad=(1, 1)) # the third branch of the Inception module is a set of 1x1 # convolutions followed by 5x5 convolutions conv_r5x5 = MxGoogLeNet.conv_module(data, num5x5Reduce, 1, 1) conv_5x5 = MxGoogLeNet.conv_module(conv_r5x5, num5x5, 5, 5, pad=(2, 2)) # the final branch of the Inception module is the POOL + # projection layer set pool = mx.sym.Pooling(data=data, pool_type=\"max\", pad=(1, 1), kernel=(3, 3), stride=(1, 1)) conv_proj = MxGoogLeNet.conv_module(pool, num1x1Proj, 1, 1) # concatenate the filters across the channel dimension concat = mx.sym.Concat(*[conv_1x1, conv_3x3, conv_5x5, conv_proj]) # return the block return concat @staticmethod def build(classes): # data input data = mx.sym.Variable(\"data\") # Block #1: CONV =&gt; POOL =&gt; CONV =&gt; CONV =&gt; POOL conv1_1 = MxGoogLeNet.conv_module(data, 64, 7, 7, pad=(3, 3), stride=(2, 2)) pool1 = mx.sym.Pooling(data=conv1_1, pool_type=\"max\", pad=(1, 1), kernel=(3, 3), stride=(2, 2)) conv1_2 = MxGoogLeNet.conv_module(pool1, 64, 1, 1) conv1_3 = MxGoogLeNet.conv_module(conv1_2, 192, 3, 3, pad=(1, 1)) pool2 = mx.sym.Pooling(data=conv1_3, pool_type=\"max\", pad=(1, 1), kernel=(3, 3), stride=(2, 2)) # Block #3: (INCEP * 2) =&gt; POOL in3a = MxGoogLeNet.inception_module(pool2, 64, 96, 128, 16, 32, 32) in3b = MxGoogLeNet.inception_module(in3a, 128, 128, 192, 32, 96, 64) pool3 = mx.sym.Pooling(data=in3b, pool_type=\"max\", pad=(1, 1), kernel=(3, 3), stride=(2, 2)) # Block #4: (INCEP * 5) =&gt; POOL in4a = MxGoogLeNet.inception_module(pool3, 192, 96, 208, 16, 48, 64) in4b = MxGoogLeNet.inception_module(in4a, 160, 112, 224, 24, 64, 64) in4c = MxGoogLeNet.inception_module(in4b, 128, 128, 256, 24, 64, 64) in4d = MxGoogLeNet.inception_module(in4c, 112, 144, 288, 32, 64, 64) in4e = MxGoogLeNet.inception_module(in4d, 256, 160, 320, 32, 128, 128,) pool4 = mx.sym.Pooling(data=in4e, pool_type=\"max\", pad=(1, 1), kernel=(3, 3), stride=(2, 2)) # Block #5: (INCEP * 2) =&gt; POOL =&gt; DROPOUT in5a = MxGoogLeNet.inception_module(pool4, 256, 160, 320, 32, 128, 128) in5b = MxGoogLeNet.inception_module(in5a, 384, 192, 384, 48, 128, 128) pool5 = mx.sym.Pooling(data=in5b, pool_type=\"avg\", kernel=(7, 7), stride=(1, 1)) do = mx.sym.Dropout(data=pool5, p=0.4) # softmax classifier flatten = mx.sym.Flatten(data=do) fc1 = mx.sym.FullyConnected(data=flatten, num_hidden=classes) model = mx.sym.SoftmaxOutput(data=fc1, name=\"softmax\") # return the network architecture return model å‡ ç‚¹æ³¨æ„ç‚¹ï¼š ä¸åŸç½‘ç»œä¸åŒï¼Œæˆ‘ä»¬å°†BNæ”¾åœ¨äº†activationä¹‹åï¼Œæå‡äº†æ¨¡å‹æ•ˆæœï¼› DropoutåŸç½‘ç»œä½¿ç”¨40%ï¼Œå½“ç„¶ç°åœ¨æ›´å¸¸è§çš„æ˜¯ä½¿ç”¨50%ï¼› â€‹Inception Moduleä¸­å‡ ä¸ªåˆ†æ”¯ç½‘ç»œé€šè¿‡concatè¿æ¥åœ¨ä¸€èµ·ï¼Œè¿™ç‚¹ä¸ResNetçš„æœ¬è´¨åŒºåˆ«ï¼› è®­ç»ƒGoogLeNetè®­ç»ƒç”¨çš„è„šæœ¬å’Œå‰é¢å‡ ä¸ªç½‘ç»œä¸€è‡´ã€‚ å‡ ä¸ªæ³¨æ„ç‚¹ï¼š batchSize = config.BATCH_SIZE * config.NUM_DEVICES; ä½¿ç”¨k80 12GBå…ˆå­˜ï¼Œé€‰æ‹©batchSzie=128ï¼› ä¼˜åŒ–ç®—æ³•ä½¿ç”¨Adamï¼Œåˆå§‹å­¦ä¹ ç‡ä¸º1e-3ï¼ŒL2æƒé‡æ­£åˆ™åŒ–å‚æ•°0.0002ï¼›rescaleå‚æ•°å°¤ä¸ºå…³é”®ï¼Œæ ¹æ®æ‰¹çš„å¤§å°æ”¾å¤§æ¢¯åº¦ï¼šrescale_grad=1.0 / batchSizeï¼›ï¼ˆä½¿ç”¨SGDè®­ç»ƒæ•ˆæœä¸€èˆ¬ï¼‰ ä½¿ç”¨äº†Xavierè¿›è¡Œå‚æ•°åˆå§‹åŒ–ï¼Œinitializer=mx.initializer.Xavier(),ï¼› å­¦ä¹ ç‡çš„æ§åˆ¶ è®­ç»ƒResNetç”±äºåˆå§‹å­¦ä¹ ç‡é«˜ï¼Œæ‰€ä»¥æœ€ç»ˆå®Œæˆè®­ç»ƒæ‰€éœ€çš„è¿­ä»£æ•°ç›®è¦å°å¾ˆå¤šï¼› Epoch å­¦ä¹ ç‡ 1-31 1e-3 32-40 1e-4 41-47 1e-5 æ§åˆ¶æ¯è½®å­¦ä¹ ç‡ä¿®æ”¹çš„è§‚å¯Ÿçª—å£è¦åœ¨10-15ä¸ªepochä¹‹åå†ä¸‹ç»“è®ºï¼Œç¡®å®šè¯¥é˜¶æ®µéªŒè¯é›†å‡†ç¡®ç‡é¥±å’Œäº†å†è¡Œé™ä½å­¦ä¹ ç‡ï¼› è°ƒæ•´å­¦ä¹ ç‡ python train_alexnet.py --checkpoints checkpoints --prefix alexnet \\ --start-epoch 50 åœ¨8ä¸ªGPUä¸Šï¼Œæ¯è½®ç”¨æ—¶1200å¤šç§’ï¼› ç¬¬ä¸€éè®­ç»ƒé‡‡ç”¨1e-3çš„å­¦ä¹ ç‡é…åˆAdamç®—æ³•è®­ç»ƒ31è½®ï¼Œå‘ç°é¥±å’Œç°è±¡ï¼Œé™ä½å­¦ä¹ ç‡åˆ°1e-4ï¼Œç»§ç»­è®­ç»ƒåˆ°42è½®ï¼› â€‹ å‘ç°40è½®ä¹‹åå°±å·²ç»å‡ºç°äº†éªŒè¯å‡†ç¡®ç‡çš„é¥±å’Œç°è±¡ï¼Œåœ¨40è½®ä¹‹åè°ƒæ•´å­¦ä¹ ç‡ä¸º1e-5ç»§ç»­è®­ç»ƒå‡ è½®å®Œæˆï¼š å®éªŒ Adam or SGD å¦‚æœä½¿ç”¨SGD + 1e-2çš„ç»å…¸å¼€å§‹é…åˆï¼Œåœ¨GoogleNetä¸Šæ•ˆæœå¹¶ä¸å¥½ï¼ŒæŠ–åŠ¨å‰§çƒˆï¼Œè™½ç„¶è¿™æ˜¯ä½œè€…æ¨èçš„å‚æ•°ï¼Œå¦‚ä¸‹ï¼š é¦–å…ˆä¿®æ”¹åˆå§‹å­¦ä¹ ç‡ä¸º1e-3ï¼Œå°½ç®¡æŠ–åŠ¨é™ä½äº†ï¼Œä½†å­¦ä¹ å¤ªæ…¢ï¼Œæ•ˆæœä¹Ÿä¸ä½³ï¼Œä¸ºæ­¤è¿›ä¸€æ­¥çš„è°ƒæ•´äº†ä¼˜åŒ–ç®—æ³•ä¸ºAdamç®—æ³•ã€‚ ä½¿ç”¨BNåœ¨æ¿€æ´»å‡½æ•°ä¹‹å å–å¾—äº†1%ä»¥ä¸Šçš„æ€§èƒ½æå‡ é€‰å–40è½®çš„è®­ç»ƒç»“æœï¼Œåœ¨æµ‹è¯•é›†æ•°æ®ä¸Šè¿›è¡ŒéªŒè¯ï¼Œç»“æœå¦‚ä¸‹ï¼š 12[INFO] rank-1: 69.58%[INFO] rank-5: 89.01% ç»“è®º GoogleNetå¾ˆéš¾å¤ç°ä½œè€…çš„æ•ˆæœï¼Œå®é™…ä¸Šè¿˜æ²¡æœ‰VGGçš„æ•ˆæœå¥½ï¼Œå¯èƒ½æ˜¯ä½œè€…è®ºæ–‡ä¸­æŸäº›å‚æ•°æ²¡æœ‰æœ‰æ•ˆæ ‡æ³¨å‡ºæ¥ï¼› è®­ç»ƒä¸€ä¸ªå¤§å‹æ•°æ®é›†çš„æ·±åº¦ç¥ç»ç½‘ç»œæ˜¯ä¸ªè´¹æ—¶è´¹åŠ›çš„æ´»ï¼Œä¸ºäº†è·å¾—æœ€ä¼˜çš„å‚æ•°ï¼Œä¸€èˆ¬éœ€è¦è¿›è¡Œ10-100æ¬¡å‚æ•°å®éªŒï¼Œéœ€è¦æå¤§çš„è€å¿ƒå’Œè®¡ç®—èµ„æºï¼› è®­ç»ƒæ·±åº¦ç¥ç»ç½‘ç»œçš„ç›®çš„ä¸æ˜¯æ‰¾å¯»å…¨å±€æœ€ä¼˜è§£ï¼Œå› ä¸ºä¸€èˆ¬å¾ˆéš¾æ‰¾åˆ°è¿™ä¸ªè§£ï¼Œæˆ‘ä»¬åªæ˜¯åœ¨æ¢å¯»ä¸€ä¸ªæ¯”ä¸Šæ¬¡æ•ˆæœæ›´å¥½çš„æ¨¡å‹ï¼› å…ˆä½¿ç”¨ReLUä½œä¸ºæ¿€æ´»å‡½æ•°è·å¾—baselineï¼Œå†é€‰æ‹©æèŠ±ä¸ºELUæ¥è·å¾—æå‡ï¼› è®­ç»ƒæ·±å±‚ç½‘ç»œæ—¶ï¼Œè€ƒè™‘ä½¿ç”¨MSRA/HEçš„åˆå§‹åŒ–å‚æ•°ï¼Œå¹¶é…åˆPReLUä¸€èµ·ä½¿ç”¨ï¼Œæ•ˆæœæ›´å¥½ï¼› å‚è€ƒ ImageNet Classification with Deep Convolutional Neural Networks","categories":[{"name":"åŠ¨æ‰‹å®è·µè¥","slug":"åŠ¨æ‰‹å®è·µè¥","permalink":"http://blog.a-stack.com/categories/åŠ¨æ‰‹å®è·µè¥/"}],"tags":[{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"ç®—æ³•","slug":"ç®—æ³•","permalink":"http://blog.a-stack.com/tags/ç®—æ³•/"},{"name":"æ–‡çŒ®","slug":"æ–‡çŒ®","permalink":"http://blog.a-stack.com/tags/æ–‡çŒ®/"},{"name":"ç½‘ç»œå¤ç°","slug":"ç½‘ç»œå¤ç°","permalink":"http://blog.a-stack.com/tags/ç½‘ç»œå¤ç°/"}]},{"title":"ç»å…¸ç½‘ç»œå¤ç°ä¹‹ResNet","slug":"ç»å…¸ç½‘ç»œå¤ç°ä¹‹ResNet","date":"2018-07-12T05:58:12.000Z","updated":"2018-07-20T15:52:21.624Z","comments":true,"path":"2018/07/12/ç»å…¸ç½‘ç»œå¤ç°ä¹‹ResNet/","link":"","permalink":"http://blog.a-stack.com/2018/07/12/ç»å…¸ç½‘ç»œå¤ç°ä¹‹ResNet/","excerpt":"æ‘˜è¦ï¼š æœ¬æ–‡è®°å½•åˆ©ç”¨ImageNetæ•°æ®é›†å¤ç°ç»å…¸ç½‘ç»œResNetçš„è¿‡ç¨‹ï¼Œå¹¶è®°å½•åœ¨å¤§å‹æ•°æ®é›†è®­ç»ƒè¿‡ç¨‹ä¸­éœ€è¦è€ƒè™‘çš„é—®é¢˜ã€‚","text":"æ‘˜è¦ï¼š æœ¬æ–‡è®°å½•åˆ©ç”¨ImageNetæ•°æ®é›†å¤ç°ç»å…¸ç½‘ç»œResNetçš„è¿‡ç¨‹ï¼Œå¹¶è®°å½•åœ¨å¤§å‹æ•°æ®é›†è®­ç»ƒè¿‡ç¨‹ä¸­éœ€è¦è€ƒè™‘çš„é—®é¢˜ã€‚ ä¸ºäº†å¢å¼ºå¯¹state of the artæ·±åº¦ç¥ç»ç½‘ç»œæ¨¡å‹çš„è®¤çŸ¥ï¼Œå‡†å¤‡è¿›è¡Œä¸€ç³»åˆ—æ¨¡å‹çš„å¤ç°å·¥ä½œï¼Œä½¿ç”¨ImageNetçš„å¤§è§„æ¨¡å›¾åƒåˆ†ç±»æ•°æ®é›†ï¼Œä»å¤´è®­ç»ƒå„ä¸ªç»å…¸çš„ç¥ç»ç½‘ç»œæ¨¡å‹ï¼ŒåŒæ—¶ç»“åˆä½œè€…è®ºæ–‡å¯¹è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŠ€å·§è¿›è¡Œå½’çº³æ€»ç»“ï¼Œä¸»è¦å®‰æ’å¦‚ä¸‹å‡ éƒ¨åˆ†å†…å®¹ï¼š ImageNetæ•°æ®é›†åŠæ•°æ®å‡†å¤‡ AlexNetç½‘ç»œ VGGç½‘ç»œ GoogLeNetç½‘ç»œ ResNetç½‘ç»œ SqueezeNetç½‘ç»œ æ¦‚è¿°ResNetåœ¨æ•´ä¸ªæ·±åº¦ç¥ç»ç½‘ç»œå‘å±•è¿‡ç¨‹ä¸­å›½èµ·åˆ°äº†é‡Œç¨‹ç¢‘å¼çš„æ„ä¹‰ï¼Œæ®‹å·®æ¨¡å—çš„æå‡ºä¸ºè®­ç»ƒæ•°åƒå±‚çš„ç¥ç»ç½‘ç»œæä¾›äº†æ–¹æ³•ï¼Œåç»­è®¸å¤šç½‘ç»œä¹Ÿçº·çº·åœ¨å…¶ç½‘ç»œæ¶æ„ä¸­å¢åŠ æ®‹å·®æ¨¡å—ï¼ŒåŠ›å›¾æå‡è®­ç»ƒæ•ˆç‡ã€‚ è®ºæ–‡ï¼š Deep Residual Learning for Image Recognition Identity Mappings in Deep Residual Networks æ•°æ®é›†ï¼š ImageNet 2012 ILSRVCæ•°æ®é›†ï¼ˆæ•°æ®é›†çš„è·å–åŠå‡†å¤‡è¯¦è§ImageNet-DataSetï¼‰ è®¡ç®—æ¡†æ¶ï¼š MxNet ç®—åŠ›èµ„æºï¼šAWSäº‘ä¸»æœºp2.8xlargeï¼š8ä¸ªTesla K80 GPU ($7.20/hour) æ€»è®¡è®­ç»ƒæ—¶é—´3å¤©å·¦å³ æ¯è½®è¿­ä»£æ—¶é—´ï¼š~3500ç§’(~1å°æ—¶) ResNetç”±äºä¹‹å‰å‡†å¤‡å†™è¿‡ä¸€ç¯‡åšå®¢æ¥åˆ†æResNetï¼Œå†æ¬¡ä¸å†å±•å¼€è¯´æ˜äº†ï¼Œè¯¦ç»†å†…å®¹å‚è§ï¼šç»å…¸ç½‘ç»œå½’çº³ï¼š ResNet é‡å¤´è®­ç»ƒä¸€ä¸ªResNetæˆ‘ä»¬è®­ç»ƒçš„æ ‡çš„æ˜¯ResNet50ï¼Œå³50å±‚çš„æ®‹å·®ç½‘ç»œï¼Œ50ä»£è¡¨äº†æ•´ä¸ªç½‘ç»œä¸­æ‰€æœ‰å«å‚æ•°å±‚çš„æ•°ç›®ï¼š 1 + ï¼ˆ3x3ï¼‰ + (4x3) + (6x3) + (3x3) + 1 = 50 ç¬¬ä¸€ä¸ªå·ç§¯å±‚ä½¿ç”¨7x7çš„å·ç§¯æ ¸ï¼Œç”¨äºå¿«é€Ÿé™ä½ç½‘ç»œå°ºå¯¸ï¼Œé…åˆç´§æ¥ç€çš„æ± åŒ–å±‚ï¼Œå°†è¾“å…¥224x224çš„å°ºå¯¸é™ä½åˆ°56x56ã€‚ ä½¿ç”¨MxNetæ„å»ºResNetä»£ç  1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495import mxnet as mxclass MxResNet: # uses \"bottleneck\" module with pre-activation (He et al. 2016) @staticmethod def residual_module(data, K, stride, red=False, bnEps=2e-5, bnMom=0.9): # the shortcut branch of the ResNet module should be # initialized as the input (identity) data shortcut = data # the first block of the ResNet module are 1x1 CONVs bn1 = mx.sym.BatchNorm(data=data, fix_gamma=False, eps=bnEps, momentum=bnMom) act1 = mx.sym.Activation(data=bn1, act_type=\"relu\") conv1 = mx.sym.Convolution(data=act1, pad=(0, 0), kernel=(1, 1), stride=(1, 1), num_filter=int(K * 0.25), no_bias=True) # the second block of the ResNet module are 3x3 CONVs bn2 = mx.sym.BatchNorm(data=conv1, fix_gamma=False, eps=bnEps, momentum=bnMom) act2 = mx.sym.Activation(data=bn2, act_type=\"relu\") conv2 = mx.sym.Convolution(data=act2, pad=(1, 1), kernel=(3, 3), stride=stride, num_filter=int(K * 0.25), no_bias=True) # the third block of the ResNet module is another set of 1x1 # CONVs bn3 = mx.sym.BatchNorm(data=conv2, fix_gamma=False, eps=bnEps, momentum=bnMom) act3 = mx.sym.Activation(data=bn3, act_type=\"relu\") conv3 = mx.sym.Convolution(data=act3, pad=(0, 0), kernel=(1, 1), stride=(1, 1), num_filter=K, no_bias=True) # if we are to reduce the spatial size, apply a CONV layer # to the shortcut if red: shortcut = mx.sym.Convolution(data=act1, pad=(0, 0), kernel=(1, 1), stride=stride, num_filter=K, no_bias=True) # add together the shortcut and the final CONV add = conv3 + shortcut # return the addition as the output of the ResNet module return add @staticmethod def build(classes, stages, filters, bnEps=2e-5, bnMom=0.9): # data input data = mx.sym.Variable(\"data\") # Block #1: BN =&gt; CONV =&gt; ACT =&gt; POOL, then initialize the # \"body\" of the network bn1_1 = mx.sym.BatchNorm(data=data, fix_gamma=True, eps=bnEps, momentum=bnMom) conv1_1 = mx.sym.Convolution(data=bn1_1, pad=(3, 3), kernel=(7, 7), stride=(2, 2), num_filter=filters[0], no_bias=True) bn1_2 = mx.sym.BatchNorm(data=conv1_1, fix_gamma=False, eps=bnEps, momentum=bnMom) act1_2 = mx.sym.Activation(data=bn1_2, act_type=\"relu\") pool1 = mx.sym.Pooling(data=act1_2, pool_type=\"max\", pad=(1, 1), kernel=(3, 3), stride=(2, 2)) body = pool1 # loop over the number of stages for i in range(0, len(stages)): # initialize the stride, then apply a residual module # used to reduce the spatial size of the input volume stride = (1, 1) if i == 0 else (2, 2) body = MxResNet.residual_module(body, filters[i + 1], stride, red=True, bnEps=bnEps, bnMom=bnMom) # loop over the number of layers in the stage for j in range(0, stages[i] - 1): # apply a ResNet module body = MxResNet.residual_module(body, filters[i + 1], (1, 1), bnEps=bnEps, bnMom=bnMom) # apply BN =&gt; ACT =&gt; POOL bn2_1 = mx.sym.BatchNorm(data=body, fix_gamma=False, eps=bnEps, momentum=bnMom) act2_1 = mx.sym.Activation(data=bn2_1, act_type=\"relu\") pool2 = mx.sym.Pooling(data=act2_1, pool_type=\"avg\", global_pool=True, kernel=(7, 7)) # softmax classifier flatten = mx.sym.Flatten(data=pool2) fc1 = mx.sym.FullyConnected(data=flatten, num_hidden=classes) model = mx.sym.SoftmaxOutput(data=fc1, name=\"softmax\") # return the network architecture return model å‡ ç‚¹æ³¨æ„ç‚¹ï¼š åœ¨bottleneckç‰ˆæœ¬çš„æ®‹å·®æ¨¡å—ä¸­ï¼Œå‰ä¸¤ä¸ªå·ç§¯æ ¸çš„æ•°ç›®æ˜¯ç¬¬ä¸‰ä¸ªçš„1/4ï¼› æœ¬æ¬¡è¯•éªŒä¸­ä½¿ç”¨äº†é¢„æ¿€æ´»ç‰ˆæœ¬çš„æ®‹å·®å—ï¼› æ•´ä¸ªç½‘ç»œä¸­æ²¡æœ‰ä½¿ç”¨dropoutå±‚ï¼› æ³¨æ„ï¼Œç½‘ç»œç»“æ„ä¸€å¼€å§‹ï¼Œå…ˆä½¿ç”¨ä¸€ä¸ªBNåº”ç”¨åˆ°è¾“å…¥æ•°æ®ï¼Œèµ·åˆ°æ­£åˆ™åŒ–çš„ä½œç”¨ï¼› å…¨å±€æ± åŒ–è¾“å‡ºè¢«flattenä¹‹åæ¥ä¸€ä¸ªFCå±‚ä¸¢ç»™softmax è®­ç»ƒResNetè®­ç»ƒç”¨çš„è„šæœ¬å’Œå‰é¢å‡ ä¸ªç½‘ç»œä¸€è‡´ã€‚ å‡ ä¸ªæ³¨æ„ç‚¹ï¼š batchSize = config.BATCH_SIZE * config.NUM_DEVICES; ä½¿ç”¨k80 12GBå…ˆå­˜ï¼Œé€‰æ‹©batchSzie=32ï¼› ä¼˜åŒ–ç®—æ³•ä½¿ç”¨SGDï¼Œåˆå§‹å­¦ä¹ ç‡ä¸º1e-1ï¼ŒåŠ¨é‡0.9ï¼ŒL2æƒé‡æ­£åˆ™åŒ–å‚æ•°0.0001ï¼›rescaleå‚æ•°å°¤ä¸ºå…³é”®ï¼Œæ ¹æ®æ‰¹çš„å¤§å°æ”¾å¤§æ¢¯åº¦ï¼šrescale_grad=1.0 / batchSizeï¼›ï¼ˆHeè®ºæ–‡çš„å»ºè®®å‚æ•°ï¼‰ ä½¿ç”¨äº†MSRAè¿›è¡Œå‚æ•°åˆå§‹åŒ–ï¼Œinitializer=mx.initializer.MSRAPrelu()ï¼› å­¦ä¹ ç‡çš„æ§åˆ¶ è®­ç»ƒResNetç”±äºåˆå§‹å­¦ä¹ ç‡é«˜ï¼Œæ‰€ä»¥æœ€ç»ˆå®Œæˆè®­ç»ƒæ‰€éœ€çš„è¿­ä»£æ•°ç›®è¦å°å¾ˆå¤šï¼› Epoch å­¦ä¹ ç‡ 1-64 1e-2 65-80 1e-3 81-89 1e-4 90-100 1e-5 æ§åˆ¶æ¯è½®å­¦ä¹ ç‡ä¿®æ”¹çš„è§‚å¯Ÿçª—å£è¦åœ¨10-15ä¸ªepochä¹‹åå†ä¸‹ç»“è®ºï¼Œç¡®å®šè¯¥é˜¶æ®µéªŒè¯é›†å‡†ç¡®ç‡é¥±å’Œäº†å†è¡Œé™ä½å­¦ä¹ ç‡ï¼› è°ƒæ•´å­¦ä¹ ç‡ python train_alexnet.py --checkpoints checkpoints --prefix alexnet \\ --start-epoch 50 åœ¨8ä¸ªGPUä¸Šï¼Œæ¯è½®ç”¨æ—¶1000å¤šç§’ï¼› ç¬¬ä¸€éè®­ç»ƒé‡‡ç”¨1e-1çš„å­¦ä¹ ç‡è®­ç»ƒ16è½®ï¼Œå‘ç°é¥±å’Œç°è±¡ï¼Œè€Œä¸”è®­ç»ƒè¯¯å·®å’Œæµ‹è¯•è¯¯å·®çº¦æ‹‰è¶Šå¤§ï¼› åœ¨ç¬¬10ä¸ªè¿­ä»£è°ƒæ•´å­¦ä¹ ç‡åˆ°1e-2ï¼ŒéªŒè¯é›†å‡†ç¡®ç‡æœ‰å¤§å¹…æå‡ï¼Œä»£è¡¨è°ƒæ•´æœ‰æ•ˆï¼Œä¹‹ååœ¨16è½®è¿­ä»£ä¹‹åå†æ¬¡é™ä½å­¦ä¹ ç‡åˆ°1e-3,25è½®è°ƒæ•´å­¦ä¹ ç‡åˆ°1e-4ï¼Œæœ€ç»ˆtop-5çš„å‡†ç¡®ç‡ä¸º0.884073ï¼Œtop-1å‡†ç¡®ç‡ä¸º0.68338ï¼š å®éªŒ åˆå§‹å­¦ä¹ ç‡çš„é€‰æ‹© åˆå§‹å­¦ä¹ ç‡å¦‚æœé€‰æ‹©1e-2ï¼Œä¸1e-1æ¯”ï¼Œå¾ˆæ—©æ¨¡å‹å°±å‡ºç°è¿‡æ‹Ÿåˆç°è±¡ï¼Œæ— æ³•åˆ°è¾¾æ›´é«˜çš„è®­ç»ƒç²¾åº¦ï¼› æ¯”å¦‚ä½¿ç”¨1e-1ï¼Œåœ¨ç¬¬10è½®è°ƒæ•´å­¦ä¹ ç‡åˆ°1e-2ä¹‹åï¼Œç½‘ç»œå‡†ç¡®ç‡ä¼šå‡ºç°ä¸€ä¸ª10%ä»¥ä¸Šçš„è·³å˜ï¼› å¦‚æœä¸é‡‡ç”¨é¢„æ¿€æ´» 3-5%ç‚¹çš„æ€§èƒ½ä¸‹é™ï¼ŒåŸå› è§ä½œè€…åŸæ–‡åˆ†æï¼› é€‰å–30è½®çš„è®­ç»ƒç»“æœï¼Œåœ¨æµ‹è¯•é›†æ•°æ®ä¸Šè¿›è¡ŒéªŒè¯ï¼Œç»“æœå¦‚ä¸‹ï¼š 12[INFO] rank-1: 71.49%[INFO] rank-5: 89.96% ç»“è®º æ•ˆæœä¸æ˜¯ååˆ†ç†æƒ³ï¼Œä¸»è¦åŸå› åº”è¯¥æ˜¯ç¬¬ä¸€é˜¶æ®µ1e-1å­¦ä¹ ç‡çš„è®­ç»ƒè¿‡ç¨‹è¿‡æ—©çš„è®¤ä¸ºè¿‡æ‹Ÿåˆæ‰“æ–­äº†è®­ç»ƒè¿‡ç¨‹ï¼Œåº”è¯¥è®©è¿™ä¸ªè¿‡ç¨‹å†æŒç»­ä¸€æ®µæ—¶é—´è§‚å¯Ÿæ•ˆæœï¼Œæ— å¥ˆè®­ç»ƒä¸€æ¬¡ResNetå®åœ¨å¤ªä¹…ï¼Œæ”¾å¼ƒç»§ç»­å°è¯•äº†ï¼› è®­ç»ƒä¸€ä¸ªå¤§å‹æ•°æ®é›†çš„æ·±åº¦ç¥ç»ç½‘ç»œæ˜¯ä¸ªè´¹æ—¶è´¹åŠ›çš„æ´»ï¼Œä¸ºäº†è·å¾—æœ€ä¼˜çš„å‚æ•°ï¼Œä¸€èˆ¬éœ€è¦è¿›è¡Œ10-100æ¬¡å‚æ•°å®éªŒï¼Œéœ€è¦æå¤§çš„è€å¿ƒå’Œè®¡ç®—èµ„æºï¼› è®­ç»ƒæ·±åº¦ç¥ç»ç½‘ç»œçš„ç›®çš„ä¸æ˜¯æ‰¾å¯»å…¨å±€æœ€ä¼˜è§£ï¼Œå› ä¸ºä¸€èˆ¬å¾ˆéš¾æ‰¾åˆ°è¿™ä¸ªè§£ï¼Œæˆ‘ä»¬åªæ˜¯åœ¨æ¢å¯»ä¸€ä¸ªæ¯”ä¸Šæ¬¡æ•ˆæœæ›´å¥½çš„æ¨¡å‹ï¼› å…ˆä½¿ç”¨ReLUä½œä¸ºæ¿€æ´»å‡½æ•°è·å¾—baselineï¼Œå†é€‰æ‹©æèŠ±ä¸ºELUæ¥è·å¾—æå‡ï¼› è®­ç»ƒæ·±å±‚ç½‘ç»œæ—¶ï¼Œè€ƒè™‘ä½¿ç”¨MSRA/HEçš„åˆå§‹åŒ–å‚æ•°ï¼Œå¹¶é…åˆPReLUä¸€èµ·ä½¿ç”¨ï¼Œæ•ˆæœæ›´å¥½ï¼› å¯¹äºResNetè¦æƒ³å†è¿›ä¸€æ­¥æå‡æ€§èƒ½ï¼Œéœ€è¦è€ƒè™‘åŠ å¼ºæ­£åˆ™åŒ–ã€æ›´å¤šçš„æ•°æ®æ”¾å¤§ã€åˆç†çš„åº”ç”¨dropoutç­‰æ–¹å¼ã€‚ å‚è€ƒ ImageNet Classification with Deep Convolutional Neural Networks","categories":[{"name":"åŠ¨æ‰‹å®è·µè¥","slug":"åŠ¨æ‰‹å®è·µè¥","permalink":"http://blog.a-stack.com/categories/åŠ¨æ‰‹å®è·µè¥/"}],"tags":[{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"ç®—æ³•","slug":"ç®—æ³•","permalink":"http://blog.a-stack.com/tags/ç®—æ³•/"},{"name":"æ–‡çŒ®","slug":"æ–‡çŒ®","permalink":"http://blog.a-stack.com/tags/æ–‡çŒ®/"},{"name":"ç½‘ç»œå¤ç°","slug":"ç½‘ç»œå¤ç°","permalink":"http://blog.a-stack.com/tags/ç½‘ç»œå¤ç°/"}]},{"title":"ç»å…¸ç½‘ç»œå¤ç°ä¹‹AlexNet","slug":"ç»å…¸ç½‘ç»œå¤ç°ä¹‹AlexNet","date":"2018-07-08T05:58:12.000Z","updated":"2018-07-20T15:52:42.648Z","comments":true,"path":"2018/07/08/ç»å…¸ç½‘ç»œå¤ç°ä¹‹AlexNet/","link":"","permalink":"http://blog.a-stack.com/2018/07/08/ç»å…¸ç½‘ç»œå¤ç°ä¹‹AlexNet/","excerpt":"æ‘˜è¦ï¼š æœ¬æ–‡è®°å½•åˆ©ç”¨ImageNetæ•°æ®é›†å¤ç°ç»å…¸ç½‘ç»œAlexNetçš„è¿‡ç¨‹ï¼Œå¹¶è®°å½•åœ¨å¤§å‹æ•°æ®é›†è®­ç»ƒè¿‡ç¨‹ä¸­éœ€è¦è€ƒè™‘çš„é—®é¢˜ã€‚","text":"æ‘˜è¦ï¼š æœ¬æ–‡è®°å½•åˆ©ç”¨ImageNetæ•°æ®é›†å¤ç°ç»å…¸ç½‘ç»œAlexNetçš„è¿‡ç¨‹ï¼Œå¹¶è®°å½•åœ¨å¤§å‹æ•°æ®é›†è®­ç»ƒè¿‡ç¨‹ä¸­éœ€è¦è€ƒè™‘çš„é—®é¢˜ã€‚ ä¸ºäº†å¢å¼ºå¯¹state of the artæ·±åº¦ç¥ç»ç½‘ç»œæ¨¡å‹çš„è®¤çŸ¥ï¼Œå‡†å¤‡è¿›è¡Œä¸€ç³»åˆ—æ¨¡å‹çš„å¤ç°å·¥ä½œï¼Œä½¿ç”¨ImageNetçš„å¤§è§„æ¨¡å›¾åƒåˆ†ç±»æ•°æ®é›†ï¼Œä»å¤´è®­ç»ƒå„ä¸ªç»å…¸çš„ç¥ç»ç½‘ç»œæ¨¡å‹ï¼ŒåŒæ—¶ç»“åˆä½œè€…è®ºæ–‡å¯¹è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŠ€å·§è¿›è¡Œå½’çº³æ€»ç»“ï¼Œä¸»è¦å®‰æ’å¦‚ä¸‹å‡ éƒ¨åˆ†å†…å®¹ï¼š ImageNetæ•°æ®é›†åŠæ•°æ®å‡†å¤‡ AlexNetç½‘ç»œ VGGç½‘ç»œ GoogLeNetç½‘ç»œ ResNetç½‘ç»œ SqueezeNetç½‘ç»œ æ¦‚è¿°2012å¹´çš„AlexNetæ˜¯é€šç”¨CNNçš„å¼€å±±ä¹‹ä½œï¼ˆæ—©åœ¨1986å¹´ï¼ŒYann LeCunå°±åˆ©ç”¨å·ç§¯ç¥ç»ç½‘ç»œæ„å»ºäº†LeNetå¹¶ç¬¬ä¸€æ¬¡å°†å…¶è¿ç”¨åˆ°äº†ç”Ÿäº§ç¯èŠ‚â€”â€”é‚®æ”¿ç¼–ç è¯†åˆ«ï¼Œè¯¦è§http://yann.lecun.com/exdb/lenet/a35.html ï¼Œä½†ç›¸å…³ç½‘ç»œç»“æ„æœªèƒ½å¾—åˆ°å……åˆ†å¤åˆ¶å’Œå‘å±•ï¼‰ï¼Œä»æ­¤ä»¥åï¼ŒCNNè¢«å¹¿æ³›åº”ç”¨äºå„ç§æœºå™¨è§†è§‰æ¯”èµ›ã€åº”ç”¨ä¹‹ä¸­ï¼Œå¾—åˆ°äº†ç©ºå‰çš„å‘å±•ã€‚æœ¬æ–‡ï¼Œä¸»è¦æ ¹æ®AlexNetè®ºæ–‡å›é¡¾å…¶ç½‘ç»œç»“æ„ã€è®¾è®¡æŠ€å·§ï¼Œå¹¶åˆ©ç”¨ImageNetçš„å›¾åƒåˆ†ç±»æ•°æ®é›†å¤ç°åœ¨2012å¹´ImageNetæŒ‘æˆ˜èµ›ä¸­çš„ç»“æœã€‚ è®ºæ–‡ï¼š Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. â€œImageNet Classification with Deep Convolutional Neural Networksâ€. In: Advances in Neural Information Processing Systems 25. Edited by F. Pereira et al. Curran Associates, Inc., 2012, pages 1097â€“1105. URL: http://papers.nips.cc/paper/4824-imagenet-classification-with-deepconvolutional-neural-networks.pdf æ•°æ®é›†ï¼š ImageNet 2012 ILSRVCæ•°æ®é›†ï¼ˆæ•°æ®é›†çš„è·å–åŠå‡†å¤‡è¯¦è§ImageNet-DataSetï¼‰ è®¡ç®—æ¡†æ¶ï¼š MxNet ç®—åŠ›èµ„æºï¼šAWSäº‘ä¸»æœºp2.8xlargeï¼š8ä¸ªTesla K80 GPU ($7.20/hour) AlexNetAlexNetåœ¨2012å¹´ImageNet ILSVRCæ¯”èµ›ä¸­top-5çš„é”™è¯¯ç‡æœª15.3%ï¼Œé¢†å…ˆç¬¬äºŒå10.9%ä¸ªç™¾åˆ†ç‚¹ï¼Œæ•´ä¸ªç½‘ç»œæ¶æ„æ€»å…±æœ‰8å±‚å‚æ•°ç½‘ç»œå±‚ï¼Œå…¶ä¸­5å±‚å·ç§¯ç½‘ç»œ+3å±‚å…¨è¿æ¥ç½‘ç»œã€‚æœ¬èŠ‚å°†æŒ‰ç…§AlexNetè®ºæ–‡æè¿°çš„å†…å®¹ï¼Œæ•´ç†AlexNetçš„ç‰¹ç‚¹ï¼Œå’Œæå…·å€Ÿé‰´æ€§çš„åˆ›æ–°æˆæœã€‚ ç½‘ç»œæ¶æ„ AlexNetçš„ç½‘ç»œæ¶æ„å¦‚å›¾æ‰€ç¤ºï¼Œè¾“å…¥å›¾åƒå°ºå¯¸ä¸ºï¼ˆ224ï¼Œ224ï¼Œ3ï¼‰ï¼Œç»è¿‡5ä¸ªCNNå±‚ï¼Œ3ä¸ªFCå±‚è¾“å‡º1000ä¸ªåˆ†ç±»ç»“æœï¼Œä¸ºäº†ä¾¿äºä½¿ç½‘ç»œè®­ç»ƒé‡‡ç”¨GPUï¼Œæ‰€ä»¥æ•´ä¸ªç½‘ç»œåˆ†ä¸ºä¸Šä¸‹ä¸¤éƒ¨åˆ†ï¼Œåˆ†åˆ«åœ¨ä¸¤ä¸ªGPUä¸Šè¿›è¡Œè®­ç»ƒï¼Œå…¶ä¸­ç¬¬ä¸€å±‚CNNå’Œ3ä¸ªFCå±‚åœ¨ä¸¤ä¸ªGPUä¸Šè¿›è¡Œäº†å‚æ•°å…±äº«ã€‚ AlexNetç½‘ç»œä¸­æ‹¥æœ‰600ä¸‡ä¸ªå‚æ•°ï¼Œ650 000ä¸ªç¥ç»å…ƒã€‚ GPUçš„ç¬¬ä¸€æ¬¡ä½¿ç”¨AlexNetæ˜¯ç¬¬ä¸€ä¸ªä½¿ç”¨GPUè¿›è¡Œè®­ç»ƒçš„æ·±åº¦ç¥ç»ç½‘ç»œï¼Œå—å½“æ—¶ç¡¬ä»¶æ¡ä»¶é™åˆ¶ï¼Œä½¿ç”¨äº†2å—3GBå†…å­˜çš„GTX 580 GPUï¼ŒåŒæ—¶ç”±äºå…¨éƒ¨çš„ç½‘ç»œå‚æ•°è¶…è¿‡äº†3GBçš„æ˜¾å­˜ç©ºé—´ï¼Œæ‰€ä»¥å°†ç½‘ç»œåˆ†æˆäº†ä¸¤éƒ¨åˆ†ã€‚è®­ç»ƒæ—¶é—´ä¸Šå®é™…æ¯”å•å—GPUæ²¡æœ‰æå‡å¤ªå¤šï¼Œä½†å°†é”™è¯¯ç‡é™ä½äº†1.2ä¸ªç™¾åˆ†ç‚¹ã€‚ æ¿€æ´»å‡½æ•°çš„é€‰æ‹©â€”â€”ä»æ­¤ReLUå‡½æ•°å¾—åˆ°é‡ç”¨AlexNetä¸­ç»è¿‡å®è·µæµ‹è¯•å‘ç°ï¼Œé‡‡ç”¨ReLUä½œä¸ºæ¿€æ´»å‡½æ•°æ¯”tanhè¦å¿«å¾ˆå¤šï¼ˆåœ¨CIFAR-10ä¸Šæµ‹è¯•å‰è€…é€Ÿåº¦æ˜¯åè€…çš„6å€å¤šï¼‰ï¼Œè¿™ä¹Ÿå¥ å®šäº†ReLUç§°ä¸ºåæ¥CNNç½‘ç»œçš„é¦–é€‰ã€‚ è§£å†³è¿‡æ‹Ÿåˆæ•´ä¸ªAlexNetéƒ½æ˜¯å›´ç»•ç€è®¡ç®—æ•ˆç‡æå‡å’Œè§£å†³è¿‡æ‹Ÿåˆè¿›è¡Œä¼˜åŒ–å’Œå°è¯•ã€‚AlexNetä¸­çš„600ä¸‡å‚æ•°å¢å¼ºç½‘ç»œå­¦ä¹ èƒ½åŠ›çš„åŒæ—¶ä¹Ÿå¸¦æ¥äº†æ½œåœ¨çš„è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œå…¶ä¸­å¯¹è§£å†³è¿‡æ‹Ÿåˆçš„è¯¸å¤šå°è¯•åœ¨æœªæ¥çš„ç½‘ç»œå‘å±•ä¸­è¢«åå¤éªŒè¯å’Œä½¿ç”¨ã€‚ 1. æ•°æ®å¢å¼ºAlexNetä¸­æ•°æ®å¢å¼ºä¸»è¦é‡‡ç”¨äº†ä¸¤ç§æ–¹å¼ï¼Œä¸€ç§æ˜¯éšæœºæ‰£å–å’Œæ°´å¹³ç¿»è½¬ï¼Œå¦ä¸€ç§æ˜¯ç™½åŒ–ã€‚ éšæœºæ‰£å–å’Œæ°´å¹³ç¿»è½¬ï¼šAlexNetå°†åŸå§‹å›¾åƒå¤„ç†æˆ256x256å¤§å°çš„ç»Ÿä¸€å›¾åƒï¼Œåœ¨è®­ç»ƒé˜¶æ®µï¼Œéšæœºä»åŸå§‹å›¾åƒä¸­æ‰£å–227x227çš„åƒç´ ï¼Œå¹¶é€šè¿‡æ°´å¹³ç¿»è½¬æ¥æå‡è®­ç»ƒé›†çš„å·®å¼‚æ€§ï¼Œå¢å¼ºç½‘ç»œæ³›åŒ–æ€§èƒ½ï¼›åœ¨æµ‹è¯•é˜¶æ®µï¼Œå¯¹äºè¾“å…¥æµ‹è¯•å›¾åƒåˆ†åˆ«ä»å››ä¸ªé¡¶è§’å’Œä¸­å¿ƒä½ç½®è·å¾—5å¼ å›¾åƒï¼Œå¹¶é€šè¿‡æ°´å¹³ç¿»è½¬å½¢æˆ10å¼ å›¾åƒï¼Œé€šè¿‡è¯„ä»·10å¼ å›¾åƒçš„é¢„æµ‹ç»“æœä½œä¸ºæœ€ç»ˆè¾“å‡ºç»“æœï¼Œå°†ç½‘ç»œæ€§èƒ½æå‡äº†å°†è¿‘1ä¸ªç™¾åˆ†ç‚¹ï¼› ç™½åŒ–ï¼š åˆ©ç”¨PCAè¿›è¡Œä¸»æˆåˆ†æŠ½å– 2. Dropoutè¿™æ˜¯Dropoutçš„ç¬¬ä¸€æ¬¡æ­£å¼ä½¿ç”¨ï¼ŒDropoutæœ¬èº«èµ·åˆ°äº†æ¨¡å‹ç»„åˆçš„ä½œç”¨ï¼ŒåŒæ—¶èµ·åˆ°æ­£åˆ™åŒ–æ•ˆæœï¼Œå¯ä»¥é¿å…è¿‡æ‹Ÿåˆï¼Œæå‡æ•ˆæœã€‚å½“ç„¶ä»£ä»·æ˜¯ç½‘ç»œæ”¶æ•›æ—¶é—´è¢«å»¶é•¿ã€‚ åœ¨å‰ä¸¤ä¸ªFCå±‚ä¹‹åä½¿ç”¨äº†Dropout è®­ç»ƒå‚æ•° ä¼˜åŒ–ç®—æ³•é€‰æ‹©SGDï¼Œ åŠ¨é‡ä¸º0.9ï¼› batch_size = 128 æƒé‡è¡°å‡ä¸º0.0005ï¼Œè¿™ä¸ªå¾ˆå°çš„æƒé‡è¡°å‡å¯¹äºæ¨¡å‹å­¦ä¹ èµ·åˆ°äº†ä¸å¯å¿½è§†çš„ä½œç”¨ï¼› æƒé‡å‚æ•°åˆå§‹åŒ–ä¸ºé›¶å‡å€¼ï¼Œ0.01æ ‡å‡†å·®çš„é«˜æ–¯åˆ†å¸ƒï¼› ä¸ºäº†ä½¿å¾—åˆå§‹å‚æ•°è½åœ¨ReLUçš„æ­£å€¼åŒºåŸŸï¼Œå°†åå·®å‚æ•°åˆå§‹åŒ–ä¸º1ï¼› åˆå§‹å­¦ä¹ ç‡ä¸º0.01ï¼Œå½“éªŒè¯é›†é”™è¯¯ç‡é¥±å’Œæ—¶ä»¥å¯¹æ•°å½¢å¼é™ä½å­¦ä¹ ç‡ï¼Œä¸€å…±é™ä½3æ¬¡ï¼Œå³1e-3,1e-4,1e-5ï¼› è®­ç»ƒäº†90ä¸ªepochï¼Œæ€»å…±ç”¨æ—¶5-6å¤© ç»“æœ ä½¿ç”¨5ä¸ªCNNçš„ç»„åˆï¼Œtop-5é”™è¯¯ç‡ä¸º16.4%â€‹ å…¶å®ƒAlexNetè¿˜ä½¿ç”¨äº†å±€éƒ¨å“åº”å½’ä¸€åŒ–ï¼ˆLocal Response Normalizationï¼‰ã€é‡å æ± åŒ–ç­‰ä¼˜åŒ–ç­–ç•¥ï¼Œä¸è¿‡åœ¨æœªæ¥çš„ç½‘ç»œç»“æ„ä¸­æ²¡æœ‰å¾—åˆ°è‰¯å¥½çš„æ•ˆæœå’Œåº”ç”¨æ™®åŠã€‚ é‡å¤´è®­ç»ƒä¸€ä¸ªAlexNet ImageNetæ•°æ®å‡†å¤‡å‚è§å‰åºåšæ–‡ ç”±äºç°åœ¨GPUç¡¬ä»¶å’Œæ·±åº¦å­¦ä¹ è®¡ç®—æ¡†æ¶çš„å‘å±•ï¼Œæˆ‘ä»¬ä¸éœ€è¦å°†ç½‘ç»œæ‹†æˆä¸¤ä¸ªéƒ¨åˆ†ï¼Œå•ç‹¬è®­ç»ƒäº†ï¼Œæ‰€ä»¥ç½‘ç»œæ¶æ„è¿›è¡Œäº†å¾®è°ƒï¼Œè¯¦è§ä¸‹å›¾ï¼› ä½¿ç”¨MxNetè®­ç»ƒç½‘ç»œæ¯”Keras + TensroFlowè¦å¿«ï¼› ä½¿ç”¨MxNetæ„å»ºAlexNetä»£ç 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162import mxnet as mxclass MxAlexNet: @staticmethod def build(classes): # data input data = mx.sym.Variable(\"data\") # Block #1: first CONV =&gt; RELU =&gt; POOL layer set conv1_1 = mx.sym.Convolution(data=data, kernel=(11, 11), stride=(4, 4), num_filter=96) act1_1 = mx.sym.LeakyReLU(data=conv1_1, act_type=\"elu\") bn1_1 = mx.sym.BatchNorm(data=act1_1) pool1 = mx.sym.Pooling(data=bn1_1, pool_type=\"max\", kernel=(3, 3), stride=(2, 2)) do1 = mx.sym.Dropout(data=pool1, p=0.25) # Block #2: second CONV =&gt; RELU =&gt; POOL layer set conv2_1 = mx.sym.Convolution(data=do1, kernel=(5, 5), pad=(2, 2), num_filter=256) act2_1 = mx.sym.LeakyReLU(data=conv2_1, act_type=\"elu\") bn2_1 = mx.sym.BatchNorm(data=act2_1) pool2 = mx.sym.Pooling(data=bn2_1, pool_type=\"max\", kernel=(3, 3), stride=(2, 2)) do2 = mx.sym.Dropout(data=pool2, p=0.25) # Block #3: (CONV =&gt; RELU) * 3 =&gt; POOL conv3_1 = mx.sym.Convolution(data=do2, kernel=(3, 3), pad=(1, 1), num_filter=384) act3_1 = mx.sym.LeakyReLU(data=conv3_1, act_type=\"elu\") bn3_1 = mx.sym.BatchNorm(data=act3_1) conv3_2 = mx.sym.Convolution(data=bn3_1, kernel=(3, 3), pad=(1, 1), num_filter=384) act3_2 = mx.sym.LeakyReLU(data=conv3_2, act_type=\"elu\") bn3_2 = mx.sym.BatchNorm(data=act3_2) conv3_3 = mx.sym.Convolution(data=bn3_2, kernel=(3, 3), pad=(1, 1), num_filter=256) act3_3 = mx.sym.LeakyReLU(data=conv3_3, act_type=\"elu\") bn3_3 = mx.sym.BatchNorm(data=act3_3) pool3 = mx.sym.Pooling(data=bn3_3, pool_type=\"max\", kernel=(3, 3), stride=(2, 2)) do3 = mx.sym.Dropout(data=pool3, p=0.25) # Block #4: first set of FC =&gt; RELU layers flatten = mx.sym.Flatten(data=do3) fc1 = mx.sym.FullyConnected(data=flatten, num_hidden=4096) act4_1 = mx.sym.LeakyReLU(data=fc1, act_type=\"elu\") bn4_1 = mx.sym.BatchNorm(data=act4_1) do4 = mx.sym.Dropout(data=bn4_1, p=0.5) # Block #5: second set of FC =&gt; RELU layers fc2 = mx.sym.FullyConnected(data=do4, num_hidden=4096) act5_1 = mx.sym.LeakyReLU(data=fc2, act_type=\"elu\") bn5_1 = mx.sym.BatchNorm(data=act5_1) do5 = mx.sym.Dropout(data=bn5_1, p=0.5) # softmax classifier fc3 = mx.sym.FullyConnected(data=do5, num_hidden=classes) model = mx.sym.SoftmaxOutput(data=fc3, name=\"softmax\") # return the network architecture return model å‡ ç‚¹æ³¨æ„ç‚¹ï¼š ä¸»è¦é‡‡ç”¨äº†Caffeä¸­å®ç°çš„AlexNetç‰ˆæœ¬ï¼› ä½¿ç”¨ELUæ›¿ä»£äº†ReLUæ¿€æ´»å‡½æ•°ï¼› æ¯ä¸ªblockéƒ½ä½¿ç”¨äº†dropoutï¼Œè€Œä¸æ˜¯åŸæ–‡åªåœ¨ä¸¤ä¸ªFCå±‚ä½¿ç”¨ï¼›å…¶ä¸­CNNå±‚å‚æ•°ä¸º0.25ï¼ŒFCå±‚ä¸º0.5ï¼› ä½¿ç”¨äº†BNå±‚åŠ é€Ÿç½‘ç»œè®­ç»ƒï¼Œè€Œä¸”BNåœ¨æ¿€æ´»å‡½æ•°ä¹‹åä½¿ç”¨ï¼› è®­ç»ƒAlexNet123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111# USAGE# python train_alexnet.py --checkpoints checkpoints --prefix alexnet# python train_alexnet.py --checkpoints checkpoints --prefix alexnet --start-epoch 25# import the necessary packagesfrom config import imagenet_alexnet_config as configfrom pyimagesearch.nn.mxconv import MxAlexNetimport mxnet as mximport argparseimport loggingimport jsonimport os# construct the argument parse and parse the argumentsap = argparse.ArgumentParser()ap.add_argument(\"-c\", \"--checkpoints\", required=True, help=\"path to output checkpoint directory\")ap.add_argument(\"-p\", \"--prefix\", required=True, help=\"name of model prefix\")ap.add_argument(\"-s\", \"--start-epoch\", type=int, default=0, help=\"epoch to restart training at\")args = vars(ap.parse_args())# set the logging level and output filelogging.basicConfig(level=logging.DEBUG, filename=\"training_&#123;&#125;.log\".format(args[\"start_epoch\"]), filemode=\"w\")# load the RGB means for the training set, then determine the batch# sizemeans = json.loads(open(config.DATASET_MEAN).read())batchSize = config.BATCH_SIZE * config.NUM_DEVICES# construct the training image iteratortrainIter = mx.io.ImageRecordIter( path_imgrec=config.TRAIN_MX_REC, data_shape=(3, 227, 227), batch_size=batchSize, rand_crop=True, rand_mirror=True, rotate=15, max_shear_ratio=0.1, mean_r=means[\"R\"], mean_g=means[\"G\"], mean_b=means[\"B\"], preprocess_threads=config.NUM_DEVICES * 2)# construct the validation image iteratorvalIter = mx.io.ImageRecordIter( path_imgrec=config.VAL_MX_REC, data_shape=(3, 227, 227), batch_size=batchSize, mean_r=means[\"R\"], mean_g=means[\"G\"], mean_b=means[\"B\"])# initialize the optimizeropt = mx.optimizer.SGD(learning_rate=1e-2, momentum=0.9, wd=0.0005, rescale_grad=1.0 / batchSize)# construct the checkpoints path, initialize the model argument and# auxiliary parameterscheckpointsPath = os.path.sep.join([args[\"checkpoints\"], args[\"prefix\"]])argParams = NoneauxParams = None# if there is no specific model starting epoch supplied, then# initialize the networkif args[\"start_epoch\"] &lt;= 0: # build the LeNet architecture print(\"[INFO] building network...\") model = MxAlexNet.build(config.NUM_CLASSES)# otherwise, a specific checkpoint was suppliedelse: # load the checkpoint from disk print(\"[INFO] loading epoch &#123;&#125;...\".format(args[\"start_epoch\"])) model = mx.model.FeedForward.load(checkpointsPath, args[\"start_epoch\"]) # update the model and parameters argParams = model.arg_params auxParams = model.aux_params model = model.symbol# compile the modelmodel = mx.model.FeedForward( ctx=[mx.gpu(0), mx.gpu(1), mx.gpu(2), mx.gpu(3), mx.gpu(4), mx.gpu(5), mx.gpu(6), mx.gpu(7)], symbol=model, initializer=mx.initializer.Xavier(), arg_params=argParams, aux_params=auxParams, optimizer=opt, num_epoch=90, begin_epoch=args[\"start_epoch\"])# initialize the callbacks and evaluation metricsbatchEndCBs = [mx.callback.Speedometer(batchSize, 500)]epochEndCBs = [mx.callback.do_checkpoint(checkpointsPath)]metrics = [mx.metric.Accuracy(), mx.metric.TopKAccuracy(top_k=5), mx.metric.CrossEntropy()]# train the networkprint(\"[INFO] training network...\")model.fit( X=trainIter, eval_data=valIter, eval_metric=metrics, batch_end_callback=batchEndCBs, epoch_end_callback=epochEndCBs) å‡ ä¸ªæ³¨æ„ç‚¹ï¼š batchSize = config.BATCH_SIZE * config.NUM_DEVICES; ä¼˜åŒ–ç®—æ³•ä½¿ç”¨SGDï¼Œåˆå§‹å­¦ä¹ ç‡ä¸º1e-2ï¼ŒåŠ¨é‡0.9ï¼ŒL2æƒé‡æ­£åˆ™åŒ–å‚æ•°0.0005ï¼›rescaleå‚æ•°å°¤ä¸ºå…³é”®ï¼Œæ ¹æ®æ‰¹çš„å¤§å°æ”¾å¤§æ¢¯åº¦ï¼› modelä¸­çš„ctxå‚æ•°ç”¨äºæŒ‡å®šç”¨äºè®­ç»ƒçš„GPUï¼› ä½¿ç”¨äº†Xavierè¿›è¡Œå‚æ•°åˆå§‹åŒ–ï¼Œä¸åŸæ¨¡å‹ç•¥æœ‰ä¸åŒï¼ŒXavieræ˜¯ç›®å‰CNNç½‘ç»œå¸¸é‡‡ç”¨çš„å‚æ•°åˆå§‹åŒ–æ–¹å¼ï¼› å­¦ä¹ ç‡çš„æ§åˆ¶ Epoch å­¦ä¹ ç‡ 1-80 1e-2 81-100 1e-3 86-100 1e-4 æ§åˆ¶æ¯è½®å­¦ä¹ ç‡ä¿®æ”¹çš„è§‚å¯Ÿçª—å£è¦åœ¨10-15ä¸ªepochä¹‹åå†ä¸‹ç»“è®ºï¼Œç¡®å®šè¯¥é˜¶æ®µéªŒè¯é›†å‡†ç¡®ç‡é¥±å’Œäº†å†è¡Œé™ä½å­¦ä¹ ç‡ï¼› è°ƒæ•´å­¦ä¹ ç‡ python train_alexnet.py --checkpoints checkpoints --prefix alexnet \\ --start-epoch 50 åœ¨8ä¸ªGPUä¸Šï¼Œæ¯è½®ç”¨æ—¶600å¤šç§’ï¼ˆå½“ç„¶æˆ‘batch sizeè®¾çš„æ¯”è¾ƒå°ï¼Œè¿™ä¸ªé€Ÿåº¦å¯ä»¥æå‡ä¸€ä¸ªæ•°é‡çº§ï¼‰ï¼› ç¬¬ä¸€éè®­ç»ƒé‡‡ç”¨1e-2çš„å­¦ä¹ ç‡è®­ç»ƒ90è½®ï¼Œå‘ç°80è½®ä»¥åï¼ŒéªŒè¯é›†å‡†ç¡®ç‡å·²ç»ä¸å†å¢åŠ ï¼›ä¸ºæ­¤åœ¨80è½®ä¹‹åè°ƒæ•´å­¦ä¹ ç‡ï¼›80è½®çš„æ€§èƒ½å‚æ•°å¦‚ä¸‹ï¼š INFO:root:Epoch[78] Validation-accuracy=0.517843 INFO:root:Epoch[78] Validation-top_k_accuracy_5=0.759725 INFO:root:Epoch[78] Validation-cross-entropy=2.123822 INFO:root:Saved checkpoint to â€œcheckpoints/1//alexnet01-0080.paramsâ€ å°†å­¦ä¹ ç‡è°ƒæ•´åˆ°1e-3ä¹‹åï¼ŒéªŒè¯é›†å‡†ç¡®ç‡æœ‰å¤§å¹…æå‡ï¼Œä»£è¡¨è°ƒæ•´æœ‰æ•ˆï¼Œ100è½®ä¹‹åå†åº¦é¥±å’Œï¼Œé™ä½å­¦ä¹ ç‡åˆ°1e-4;105è½®éªŒè¯é›†ç»“æœå¦‚ä¸‹ï¼š INFO:root:Epoch[105] Validation-accuracy=0.564901 INFO:root:Epoch[105] Validation-top_k_accuracy_5=0.796509 INFO:root:Epoch[105] Validation-cross-entropy=1.880376 ä¿æŒ1e-4å­¦ä¹ ç‡ï¼Œè®­ç»ƒåˆ°125è½®ï¼Œè¿›ä¸€æ­¥é™ä½å­¦ä¹ ç‡åˆ°1e-5ï¼Œå‘ç°æ•´ä¸ªç½‘ç»œæ²¡æœ‰æ€§èƒ½æå‡ï¼Œç»“æŸè¯¥æ‰¹æ¬¡å‚æ•°è®­ç»ƒè¿‡ç¨‹ã€‚ å®éªŒ BNæ”¾åœ¨æ¿€æ´»ä¹‹å‰è¿˜æ˜¯ä¹‹åï¼Ÿ è°ƒæ•´BNä½ç½®ï¼Œå‡†ç¡®ç‡ä»77.9%â€”&gt; 79.6% ReLU vs ELU ï¼Ÿ ç”¨ELUæ›¿ä»£ReLUï¼Œæå‡1-2%çš„æ€§èƒ½ï¼› é€‰å–125è½®çš„è®­ç»ƒç»“æœï¼Œåœ¨æµ‹è¯•é›†æ•°æ®ä¸Šè¿›è¡ŒéªŒè¯ï¼Œç»“æœå¦‚ä¸‹ï¼š 12[INFO] rank-1: 60.20%[INFO] rank-5: 81.99% â€‹ ç»“è®º è®­ç»ƒä¸€ä¸ªå¤§å‹æ•°æ®é›†çš„æ·±åº¦ç¥ç»ç½‘ç»œæ˜¯ä¸ªè´¹æ—¶è´¹åŠ›çš„æ´»ï¼Œä¸ºäº†è·å¾—æœ€ä¼˜çš„å‚æ•°ï¼Œä¸€èˆ¬éœ€è¦è¿›è¡Œ10-100æ¬¡å‚æ•°å®éªŒï¼Œéœ€è¦æå¤§çš„è€å¿ƒå’Œè®¡ç®—èµ„æºï¼› è®­ç»ƒæ·±åº¦ç¥ç»ç½‘ç»œçš„ç›®çš„ä¸æ˜¯æ‰¾å¯»å…¨å±€æœ€ä¼˜è§£ï¼Œå› ä¸ºä¸€èˆ¬å¾ˆéš¾æ‰¾åˆ°è¿™ä¸ªè§£ï¼Œæˆ‘ä»¬åªæ˜¯åœ¨æ¢å¯»ä¸€ä¸ªæ¯”ä¸Šæ¬¡æ•ˆæœæ›´å¥½çš„æ¨¡å‹ï¼› å‚è€ƒ ImageNet Classification with Deep Convolutional Neural Networks","categories":[{"name":"åŠ¨æ‰‹å®è·µè¥","slug":"åŠ¨æ‰‹å®è·µè¥","permalink":"http://blog.a-stack.com/categories/åŠ¨æ‰‹å®è·µè¥/"}],"tags":[{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"ç®—æ³•","slug":"ç®—æ³•","permalink":"http://blog.a-stack.com/tags/ç®—æ³•/"},{"name":"æ–‡çŒ®","slug":"æ–‡çŒ®","permalink":"http://blog.a-stack.com/tags/æ–‡çŒ®/"},{"name":"ç½‘ç»œå¤ç°","slug":"ç½‘ç»œå¤ç°","permalink":"http://blog.a-stack.com/tags/ç½‘ç»œå¤ç°/"}]},{"title":"ImageNet-DataSet","slug":"ImageNet-DataSet","date":"2018-07-06T08:02:00.000Z","updated":"2018-07-20T15:52:52.732Z","comments":true,"path":"2018/07/06/ImageNet-DataSet/","link":"","permalink":"http://blog.a-stack.com/2018/07/06/ImageNet-DataSet/","excerpt":"æ‘˜è¦ï¼š","text":"æ‘˜è¦ï¼š ImageNetæ•°æ®é›†ImageNetæ•°æ®é›†æ˜¯ä¼´éšç€CNNå’Œæœºå™¨è§†è§‰ä¹ƒè‡³äººå·¥æ™ºèƒ½å‘å±•çš„é‡Œç¨‹ç¢‘å¼çš„æ•°æ®é›†ï¼Œè™½ç„¶åˆ©ç”¨è¯¥æ•°æ®é›†å¤§è§„æ¨¡æœºå™¨è§†è§‰æ¯”èµ›2017å¹´ä»¥ååœæ­¢ä¸¾åŠï¼Œä½†è¯¥æ•°æ®é›†å¯¹æ•´ä¸ªäººå·¥æ™ºèƒ½äº§ä¸šé©å‘½çš„å½±å“å¿…å°†æŒç»­ä¸‹å»ã€‚ ImageNet is an image database organized according to the WordNet hierarchy (currently only the nouns), in which each node of the hierarchy is depicted by hundreds and thousands of images. Currently we have an average of over five hundred images per node. We hope ImageNet will become a useful resource for researchers, educators, students and all of you who share our passion for pictures. 22kåˆ†ç±»ï¼Œ14M ç…§ç‰‡ ç½‘å€ï¼š http://image-net.org/ è¿™äº›æ•°æ®é äººæ¥æ ‡è®°ï¼Œéœ€è¦ä¸€ä¸ªäºº19å¹´æ—¶é—´ï¼› ä½¿ç”¨Amazonçš„ä¼—åŒ…æœåŠ¡ï¼Œè°ƒç”¨äº†167ä¸ªå›½å®¶çš„49000äººæ¬¡åœ¨2007-2010å¹´é—´å®Œæˆæ ‡è®° WordNet ImageNet Large Scale Visual Recognition Challenge(ILSVRC) Models are trained on â‰ˆ 1.2 million training images with another 50,000 images for validation (50 images per synset) and 100,000 images for testing (100 images per synset). åˆ†ç±»éš¾åº¦å¤§ï¼šæ¯”å¦‚ImageNet instead includes 120 different breeds of dogs. ILSVRC2017ä¸»è¦æœ‰ä¸‰é¡¹æŒ‘æˆ˜ï¼š I: Object localization II: Object detection III: Object detection from video å½“ç„¶ï¼Œæ­£æ˜¯ç”±äºImageNetçš„éš¾åº¦å’Œç§ç±»ç¹å¤šç‰¹æ€§ï¼Œä½¿å¾—åœ¨ImageNetè®­ç»ƒçš„æ¨¡å‹å¯ä»¥å¾ˆå®¹æ˜“é€šè¿‡è¿ç§»å­¦ä¹ ç”¨åˆ°å…¶å®ƒé¢†åŸŸçš„å›¾åƒè¯†åˆ«ï¼› æ•°æ®é›†çš„è·å– è®­ç»ƒæ•°æ®å¤§å°138 GB éªŒè¯æ•°æ®6.3 GB æµ‹è¯•æ•°æ® 13GB ä¸‹è½½ImageNetæ•°æ®é›†éœ€è¦ä½¿ç”¨å­¦æ ¡é‚®ç®±æ³¨å†Œä¸€ä¸ªè´¦å·ï¼Œè·å¾—æ•°æ®ä¸‹è½½æƒé™ï¼Œç„¶åå¯ä»¥ç™»é™†æ•°æ®ä¸‹è½½é¡µé¢å¦‚ä¸‹å›¾ä¸‹è½½çº¢è‰²æ ‡è®°éƒ¨åˆ†ã€‚ å…¶ä¸­Development KitåŒ…å«äº†å¯¹æ•°æ®ç»“æ„å’Œåˆ†ç±»çš„æè¿°æ–‡ä»¶ï¼Œä¾¿äºæˆ‘ä»¬é€šè¿‡è„šæœ¬è¯»å–å›¾åƒæ•°æ®ï¼› å¯ä»¥ä½¿ç”¨wgetå‘½ä»¤ä¸‹è½½ 1wget -t 0 -c -i urls -o log å…¶ä¸­-cä»£è¡¨ç«¯ç‚¹ç»­ä¼ ï¼Œ-t 0ä»£è¡¨å¤±è´¥é‡è¯•ï¼Œurlsæ–‡ä»¶ä¸ºæ‰€æœ‰éœ€è¦ä¸‹è½½ç›®å½•åœ°å€ï¼š 12345678www.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_train.tarwww.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_train_t3.tarwww.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_val.tarwww.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_test.tarwww.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_bbox_train_v2.tar.gzwww.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_bbox_train_dogs.tar.gzwww.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_bbox_val_v3.tgzwww.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_bbox_test_dogs.zip å®é™…ä½¿ç”¨è¿‡ç¨‹ä¸­ï¼Œå‘ç°å›½å†…ç½‘ç»œåŸå› ä½¿ç”¨è¿™ç§æ–¹æ³•åªæœ‰50KB-100KB/så·¦å³çš„é€Ÿåº¦ï¼Œæ•´ä¸ªæ•°æ®é›†ä¸‹è½½éœ€è¦12-15å¤©ã€‚ä¸ºäº†å¿«é€Ÿä¸‹è½½ï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹ç£åŠ›é“¾æ¥åœ°å€ï¼š 12magnet:?xt=urn:btih:A306397CCF9C2EAD27155983C254227C0FD938E2magnet:?xt=urn:btih:5D6D0DF7ED81EFD49CA99EA4737E0AE5E3A5F2E5 ImageNetæ•°æ®çš„ä»å±æƒé—®é¢˜ ImageNetä¸­çš„æ¯å¼ å›¾ç‰‡å±äºæä¾›å›¾ç‰‡çš„ä¸ªäºº ImageNetæ•°æ®é›†å¯ä»¥å…è´¹ç”¨äºå­¦æœ¯ç ”ç©¶å’Œéå•†ä¸šç”¨é€” ä½†ä¸èƒ½ç›´æ¥ä½¿ç”¨è¿™äº›æ•°æ®ä½œä¸ºäº§å“çš„ä¸€éƒ¨åˆ† ä½¿ç”¨ImageNetè®­ç»ƒçš„æ¨¡å‹ï¼ˆè‡ªå·±ä»å¤´è®­ç»ƒï¼‰çš„ä»å±æƒé—®é¢˜æ˜¯ä¸€ä¸ªç›®å‰æ²¡æœ‰ç­”æ¡ˆçš„é—®é¢˜ï¼Œç›®å‰ä»å¤´è®­ç»ƒä¸€ä¸ªæ¨¡å‹æ˜¯å¯ä»¥åº”ç”¨åˆ°å•†ä¸šè½¯ä»¶ä¸­çš„ å®˜æ–¹çš„ç»™å‡ºçš„ä»‹ç»æ€§å†…å®¹å¦‚ä¸‹ï¼š Does ImageNet own the images? Can I download the images? No, ImageNet does not own the copyright of the images. ImageNet only provides thumbnails and URLs of images, in a way similar to what image search engines do. In other words, ImageNet compiles an accurate list of web images for each synset of WordNet. For researchers and educators who wish to use the images for non-commercial research and/or educational purposes, we can provide access through our site under certain conditions and terms. æ•°æ®å‡†å¤‡ ä¸‹è½½æ•°æ®é›†ä¸­æ¯ä¸ªæ–‡ä»¶é‡‡ç”¨WordNetIDçš„æ–¹å¼å‘½åï¼Œæ¯”å¦‚n01440764ï¼› æ¯ä¸ªåˆ†ç±»æœ‰732~1300å¼ å›¾ç‰‡ ä½¿ç”¨MXNETçš„.recæ ¼å¼æ–‡ä»¶å­˜å‚¨æ•°æ®ï¼› â€‹ 12345678dir=./for x in `ls *.tar` do filename=`basename $x .tar` mkdir $filename tar -xvf $x -C ./$filenamedone å…³é”®æ–‡ä»¶map_clsloc.txt: è®°å½•äº†WordNet IDåˆ°åˆ†ç±»åç§°çš„æ˜ å°„å…³ç³»ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š 12345678910n02119789 1 kit_foxn02100735 2 English_settern02110185 3 Siberian_huskyn02096294 4 Australian_terriern02102040 5 English_springern02066245 6 grey_whalen02509815 7 lesser_pandan02124075 8 Egyptian_catn02417914 9 ibexn02123394 10 Persian_cat æ„å»ºä¸€ä¸ª.lstæ–‡ä»¶ï¼ŒåŒ…æ‹¬ï¼š [å›¾åƒIDï¼Œ æ ‡ç­¾ï¼Œ å›¾åƒå­˜å‚¨çš„å®Œæ•´åœ°å€] 12345$ wc -l /raid/datasets/imagenet/lists/*.lst 50000 /raid/datasets/imagenet/lists/test.lst 1231167 /raid/datasets/imagenet/lists/train.lst 48238 /raid/datasets/imagenet/lists/val.lst 1329405 total â€‹ å»é™¤é»‘åå•æ•°æ® åˆ›å»º.rec æ–‡ä»¶ mxnetæä¾›ä¸€ä¸ªå·¥å…·im2recæ¥å‡†å¤‡è®­ç»ƒæ•°æ®ï¼Œå·¥å…·åœ°å€å¦‚ä¸‹ï¼š 1anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/tools/im2rec.py å…³äºim2recçš„æ›´å¤šç”¨æ³•: 1) ç”Ÿæˆlistæ–‡ä»¶ 12&gt; python ~/mxnet/tools/im2rec.py â€“list True â€“recursive True â€“train-ratio 0.9 myData /home/xxx/data/&gt; &gt; å‚æ•°ï¼š â€“listï¼šå½“è¦ç”Ÿæˆlistæ–‡ä»¶æ—¶ï¼Œè¿™ä¸ªå‚æ•°ä¸€å®šè¦è®¾ä¸ºTrueï¼Œè¡¨ç¤ºå½“å‰ç”¨æ¥ç”Ÿæˆçš„listæ–‡ä»¶ï¼›é»˜è®¤æ˜¯ç”Ÿæˆrecæ–‡ä»¶ï¼› â€“recursiveï¼šé€’å½’çš„éå†ä½ çš„æ‰€æœ‰æ•°æ®é›†ï¼Œè¦è®¾ä¸ºTrueï¼› â€“train-ratioï¼šç”¨æ¥å°†ä½ çš„å…¨éƒ¨æ•°æ®é›†æ‹†åˆ†æˆä¸¤éƒ¨åˆ†ï¼šè®­ç»ƒé›†ï¼ˆtrainï¼‰å’Œäº¤å‰éªŒè¯é›†ï¼ˆvalï¼‰ï¼Œå…·ä½“å¤šå°‘ä½œä¸ºè®­ç»ƒé›†ï¼Œå¤šå°‘ä½œä¸ºéªŒè¯é›†ï¼Œå°±ç”±è¿™ä¸ªå‚æ•°æ¥ç¡®å®šï¼› â€“test-ratioï¼šåŒä¸Šï¼Œåˆ†æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸¤éƒ¨åˆ†ï¼› â€“extsï¼šè¿™ä¸ªæ˜¯ä½ æ•°æ®çš„åç¼€ï¼ˆæ³¨ï¼Œè¿™é‡Œæˆ‘ä»¬ä¸€èˆ¬è¯´çš„å›¾ç‰‡æ•°æ®ï¼‰ï¼Œç›®å‰çš„MXNetåªæ”¯æŒä¸¤ç§å›¾ç‰‡æ ¼å¼ï¼šjpgå’Œjpeg prefixï¼šè¿™é‡ŒæŒ‡çš„æ˜¯ä½ è¦ç”Ÿæˆlistæ–‡ä»¶çš„å‰ç¼€åï¼Œæˆ‘è¿™é‡Œå‘½åä¸ºmyDataï¼› rootï¼šè¿™é‡ŒæŒ‡çš„æ˜¯ä½ çš„å›¾ç‰‡æ•°æ®å­˜æ”¾çš„è·¯å¾„ï¼› 2ï¼‰ç”Ÿæˆrecæ–‡ä»¶ 12&gt; python ~/mxnet/tools/im2rec.py â€“num-thread 4 â€“pass-through 1 myData /home/xxx/data/&gt; å‚æ•°ï¼š Options for creating database: â€”pass-through whether to skip transformation and save image as is (default: False) â€”resize RESIZE resize the shorter edge of image to the newsize, original images will be packed by default. â€”center-crop specify whether to crop the center image to make it rectangular. (default: False) â€”quality QUALITY JPEG quality for encoding, 1-100; or PNG compression for encoding, 1-9 (default: 95) â€”num-thread NUM_THREAD number of thread to use for encoding. order of images will be different from the input list if &gt;1. the input list will be modified to match the resulting order. (default: 1) â€”color {-1,0,1} specify the color mode of the loaded image. 1: Loads a color image. Any transparency of image will be neglected. It is the default flag. 0: Loads image in grayscale mode. -1:Loads image as such including alpha channel. (default: 1) â€”encoding {.jpg,.png} specify the encoding of the images. (default: .jpg) â€”pack-label Whether to also pack multi dimensional label in the record file (default: False) ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤åˆ†åˆ«å‡†å¤‡è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†æ•°æ®ï¼š 12345python im2rec.py /home/ubuntu/data/imagenet/lists/val.lst \"\" --num-thread 16 --resize 256 --encoding '.jpg' --quality 100 python im2rec.py /home/ubuntu/data/imagenet/lists/train.lst \"\" --num-thread 16 --resize 256 --encoding '.jpg' --quality 100python im2rec.py /home/ubuntu/data/imagenet/lists/test.lst \"\" --num-thread 16 --resize 256 --encoding '.jpg' --quality 100 å…¶å®ƒç›¸å…³å†…å®¹ æé£é£åœ¨ILSVRC2017çš„æŠ¥å‘Š","categories":[{"name":"åŠ¨æ‰‹å®è·µè¥","slug":"åŠ¨æ‰‹å®è·µè¥","permalink":"http://blog.a-stack.com/categories/åŠ¨æ‰‹å®è·µè¥/"},{"name":"æœºå™¨è§†è§‰","slug":"åŠ¨æ‰‹å®è·µè¥/æœºå™¨è§†è§‰","permalink":"http://blog.a-stack.com/categories/åŠ¨æ‰‹å®è·µè¥/æœºå™¨è§†è§‰/"}],"tags":[{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"ç®—æ³•","slug":"ç®—æ³•","permalink":"http://blog.a-stack.com/tags/ç®—æ³•/"},{"name":"æ–‡çŒ®","slug":"æ–‡çŒ®","permalink":"http://blog.a-stack.com/tags/æ–‡çŒ®/"},{"name":"æ•°æ®é›†","slug":"æ•°æ®é›†","permalink":"http://blog.a-stack.com/tags/æ•°æ®é›†/"}]},{"title":"æ·±åº¦å­¦ä¹ å®è·µæ–¹æ³•è®º","slug":"æ·±åº¦å­¦ä¹ å®è·µæ–¹æ³•è®º","date":"2018-07-03T09:34:48.000Z","updated":"2018-07-20T15:53:03.168Z","comments":true,"path":"2018/07/03/æ·±åº¦å­¦ä¹ å®è·µæ–¹æ³•è®º/","link":"","permalink":"http://blog.a-stack.com/2018/07/03/æ·±åº¦å­¦ä¹ å®è·µæ–¹æ³•è®º/","excerpt":"æ‘˜è¦ï¼š æ·±åº¦å­¦ä¹ å®è·µçš„æ–¹æ³•è®ºæ˜¯ä¸€å¥—é ç»éªŒè€Œéç®—æ³•æ€»ç»“çš„è¡Œä¹‹æœ‰æ•ˆçš„æŒ‡å¯¼ï¼Œåç»­éšç€ç ”ç©¶æ·±å…¥å°†ä¸æ–­æ›´æ–°è¡¥å……ç›¸å…³å†…å®¹ã€‚","text":"æ‘˜è¦ï¼š æ·±åº¦å­¦ä¹ å®è·µçš„æ–¹æ³•è®ºæ˜¯ä¸€å¥—é ç»éªŒè€Œéç®—æ³•æ€»ç»“çš„è¡Œä¹‹æœ‰æ•ˆçš„æŒ‡å¯¼ï¼Œåç»­éšç€ç ”ç©¶æ·±å…¥å°†ä¸æ–­æ›´æ–°è¡¥å……ç›¸å…³å†…å®¹ã€‚ æ¦‚è¿°ä»Couseraå­¦ä¹ å´æ©è¾¾çš„æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ç³»åˆ—è¯¾ç¨‹ä¾¿å¼€å§‹å¸Œæœ›èƒ½å¤Ÿæ ¹æ®è¯¾ç¨‹å­¦ä¹ å†…å®¹ï¼Œé€æ­¥æ€»ç»“æ·±åº¦å­¦ä¹ ç®—æ³•åœ¨é¡¹ç›®å®è·µä¸­åº”è¯¥å¦‚ä½•åº”ç”¨ï¼Œæ˜¯å¦èƒ½å¤Ÿæ€»ç»“ä¸€ä»½æœ€ä½³å®è·µæ‰‹å†Œï¼Œå¹¶é€šè¿‡ä¸æ–­çš„æ›´æ–°ç»´æŠ¤ï¼Œæ–¹ä¾¿æ—¥åæŸ¥é˜…å’ŒæŒ‡å¯¼æ·±åº¦å­¦ä¹ å·¥ç¨‹å¸ˆçš„é¡¹ç›®å¼€å‘ã€‚æœ€è¿‘åœ¨çœ‹Goodfellowçš„æ·±åº¦å­¦ä¹ åœ£ç»â€”â€”ã€ŠDeep Learningã€‹ï¼Œç¬¬åä¸€ç« å†æ¬¡è®²åˆ°äº†è¿™ä¸ªé—®é¢˜ï¼Œäºæ˜¯ä¾¿ä»¥ä¹¦ä¸­å†…å®¹ä¸ºåŸºç¡€ï¼Œæ€»ç»“è¿™ç¯‡æ·±åº¦å­¦ä¹ å®è·µçš„åšå®¢ã€‚ æ­£å¦‚ä¹¦ä¸­æ‰€è¯´è¦æˆåŠŸåœ°ä½¿ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œä»…ä»…çŸ¥é“å­˜åœ¨å“ªäº›ç®—æ³•å’Œè§£é‡Šä»–ä»¬ä¸ºä½•æœ‰æ•ˆçš„åŸç†æ˜¯ä¸å¤Ÿçš„ã€‚ä¸€ä¸ªä¼˜ç§€çš„æœºå™¨å­¦ä¹ å®è·µè€…è¿˜éœ€è¦çŸ¥é“å¦‚ä½•é’ˆå¯¹å…·ä½“åº”ç”¨æŒ‘é€‰ä¸€ä¸ªåˆé€‚çš„ç®—æ³•ä»¥åŠå¦‚ä½•ç›‘æ§ï¼Œå¹¶æ ¹æ®å®éªŒåé¦ˆæ”¹è¿›æœºå™¨å­¦ä¹ ç³»ç»Ÿã€‚ä¹¦ä¸­å»ºè®®å‚è€ƒå¦‚ä¸‹å‡ ä¸ªå®è·µè®¾è®¡æµç¨‹ï¼š ç¡®å®šç›®æ ‡â€”â€”ä½¿ç”¨ä»€ä¹ˆæ ·çš„è¯¯å·®åº¦é‡ï¼Œå¹¶ä¸ºæ­¤è¯¯å·®åº¦é‡æŒ‡å®šç›®æ ‡å€¼ã€‚è¿™äº›ç›®æ ‡ å’Œè¯¯å·®åº¦é‡å–å†³äºè¯¥åº”ç”¨æ—¨åœ¨è§£å†³çš„é—®é¢˜ã€‚ å°½å¿«å»ºç«‹ä¸€ä¸ªç«¯åˆ°ç«¯çš„å·¥ä½œæµç¨‹ï¼ŒåŒ…æ‹¬ä¼°è®¡åˆé€‚çš„æ€§èƒ½åº¦é‡ã€‚ æ­å»ºç³»ç»Ÿï¼Œå¹¶ç¡®å®šæ€§èƒ½ç“¶é¢ˆã€‚æ£€æŸ¥å“ªä¸ªéƒ¨åˆ†çš„æ€§èƒ½å·®äºé¢„æœŸï¼Œä»¥åŠæ˜¯å¦æ˜¯å›  ä¸ºè¿‡æ‹Ÿåˆã€æ¬ æ‹Ÿåˆï¼Œæˆ–è€…æ•°æ®æˆ–è½¯ä»¶ç¼ºé™·é€ æˆçš„ã€‚ æ ¹æ®å…·ä½“è§‚å¯Ÿåå¤åœ°è¿›è¡Œå¢é‡å¼çš„æ”¹åŠ¨ï¼Œå¦‚æ”¶é›†æ–°æ•°æ®ã€è°ƒæ•´è¶…å‚æ•°æˆ–æ”¹è¿›ç®— æ³•ã€‚ é—®é¢˜çš„å®šä¹‰å’Œæè¿° é€‰å®šè¯¯å·®åº¦é‡æ ‡å‡†ï¼› ç§‘ç ”ä¸­ï¼Œç›®æ ‡é€šå¸¸æ˜¯åœ¨æŸä¸ªç¡®å®šåŸºå‡†ä¸‹æ¢è®¨å“ªä¸ªç®—æ³•æ›´å¥½ï¼Œä¸€èˆ¬ä¼šå›ºå®šè®­ç»ƒé›†ï¼Œä¸å…è®¸æ”¶é›†æ›´å¤šçš„æ•°æ®ã€‚ æ€§èƒ½æœŸæœ›çš„è®¾è®¡ åº¦é‡ï¼š å‡†ç¡®ç‡ã€é”™è¯¯ç‡ï¼Œå¬å›ç‡ï¼Œç²¾ç¡®ç‡ï¼ŒF1åˆ†æ•°ï¼ŒmAP â€¦ è¦†ç›–ï¼ˆcoverageï¼‰ï¼š æœºå™¨å­¦ä¹ ç³»ç»Ÿèƒ½å¤Ÿäº§ç”Ÿå“åº”çš„æ ·æœ¬æ‰€å çš„æ¯”ç‡ï¼› åŸºå‡†æ¨¡å‹ æ˜ç¡®ä»»åŠ¡çš„åº¦é‡å’Œç›®æ ‡ä¹‹åï¼Œéœ€è¦å¿«é€Ÿçš„è¿­ä»£ç¬¬ä¸€ä¸ªç«¯åˆ°ç«¯çš„ç³»ç»Ÿã€‚ é¡¹ç›®å¼€å§‹æ—¶ï¼Œå¯èƒ½æ— éœ€ä½¿ç”¨æ·±åº¦å­¦ä¹ ï¼Œæ„å»ºä¸€ä¸ªç®€å•çš„ç»Ÿè®¡æ¨¡å‹å¯ä»¥å¿«é€Ÿå®ç°åŸå‹å¼€å‘ï¼Œå½“ç„¶å¦‚æœé—®é¢˜æœ¬èº«å±äºâ€œAI-å®Œå…¨â€çš„ï¼Œå¦‚å¯¹è±¡è¯†åˆ«ã€è¯­éŸ³è¯†åˆ«ã€æœºå™¨ç¿»è¯‘ï¼Œé‚£ä¹ˆå¯ä»¥æ ¹æ®æ•°æ®çš„ç»“æ„é€‰æ‹©ä»ä¸€ä¸ªåŸºæœ¬çš„CNN/RNN/DNNæ¨¡å‹å¼€å§‹ã€‚ ä¼˜åŒ–ç®—æ³•æ–¹é¢ï¼Œå…·æœ‰è¡°å‡å­¦ä¹ ç‡ä»¥åŠåŠ¨é‡çš„SGDæ˜¯ä¼˜åŒ–ç®—æ³•ä¸€ä¸ªåˆç†çš„é€‰æ‹©ï¼ˆæµè¡Œçš„è¡°å‡æ–¹æ³•æœ‰ï¼Œè¡°å‡åˆ°å›ºå®šæœ€ä½å­¦ä¹ ç‡çš„çº¿æ€§è¡°å‡ã€æŒ‡æ•°è¡°å‡ï¼Œæˆ–æ¯æ¬¡å‘ç”ŸéªŒè¯é”™è¯¯åœæ»æ—¶ å°†å­¦ä¹ ç‡é™ä½ 2 âˆ’ 10 å€ï¼Œè¿™äº›è¡°å‡æ–¹æ³•åœ¨ä¸åŒé—®é¢˜ä¸Šå¥½åä¸ä¸€ï¼‰ã€‚ ä¹Ÿå¯ä»¥ç›´æ¥ä½¿ç”¨Adamç®—æ³• æ‰¹æ ‡å‡†åŒ–å¯ä»¥è§†æƒ…å†µé€æ­¥é‡‡ç”¨ï¼› å¦‚æœé¡¹ç›®å†…å®¹å’Œåˆ«äººå·²ç»å®Œæˆçš„æ¨¡å‹ä»»åŠ¡å¾ˆç›¸åƒï¼Œå¤åˆ¶ç°æˆçš„ç½‘ç»œç»“æ„æˆ–åˆ©ç”¨è¿ç§»å­¦ä¹ fine-tuneä¹Ÿæ˜¯è¿™é˜¶æ®µåº”è¯¥è€ƒè™‘çš„ï¼› æ•°æ®æ”¶é›† æ”¶é›†æ›´å¤šæ•°æ®å¯¹äºæ·±åº¦å­¦ä¹ æ¥è¯´æ˜¯æœ€ç›´æ¥æ”¹è§‚æ€§èƒ½çš„æ–¹å¼ï¼Œä½†ä½•æ—¶æ”¶é›†ï¼Œæ˜¯å¦åº”è¯¥æ”¶é›†éœ€è¦è¯„ä¼°æŠ•å…¥-äº§å‡ºæ¯”ï¼› ä¹Ÿè®¸æ­£åˆ™åŒ–å¯ä»¥å¼¥è¡¥æ¨¡å‹çš„è¯¯å·®æœŸæœ›å·®è·ï¼Œæ²¡æœ‰å¿…è¦æŠ•å…¥ä»£ä»·æ›´å¥½çš„æ•°æ®æ”¶é›†å·¥ä½œï¼› å¦‚æœæ”¶é›†æ•°æ®ï¼Œåº”è¯¥æ”¶é›†å¤šå°‘æ•°æ®ï¼Ÿ å¦‚å›¾æ‰€ç¤ºï¼Œç»˜åˆ¶æ›²çº¿æ˜¾ç¤ºè®­ç»ƒé›†è§„æ¨¡å’Œæ³›åŒ–è¯¯å·®ä¹‹é—´çš„å…³ç³»æ˜¯å¾ˆæœ‰å¸®åŠ©çš„ã€‚æ ¹æ®èµ°åŠ¿å»¶ä¼¸æ›²çº¿ï¼Œå¯ä»¥é¢„æµ‹è¿˜éœ€è¦å¤šå°‘è®­ç»ƒæ•°æ®æ¥è¾¾åˆ°ä¸€å®šçš„æ€§èƒ½ã€‚ è¶…å‚é€‰æ‹©å¤§éƒ¨åˆ†æ·±åº¦å­¦ä¹ ç®—æ³•éƒ½æœ‰è®¸å¤šè¶…å‚æ•°æ¥æ§åˆ¶ä¸åŒæ–¹é¢çš„ç®—æ³•è¡¨ç°ã€‚æœ‰äº›è¶…å‚æ•°ä¼šå½±å“ç®—æ³•è¿è¡Œçš„æ—¶é—´å’Œå­˜å‚¨æˆæœ¬ã€‚æœ‰äº›è¶…å‚æ•°ä¼šå½±å“å­¦ä¹ åˆ°çš„æ¨¡å‹è´¨é‡ï¼Œä»¥åŠ åœ¨æ–°è¾“å…¥ä¸Šæ¨æ–­æ­£ç¡®ç»“æœçš„èƒ½åŠ›ã€‚ æœ‰ä¸¤ç§é€‰æ‹©è¶…å‚æ•°çš„åŸºæœ¬æ–¹æ³•ï¼šæ‰‹åŠ¨é€‰æ‹©å’Œè‡ªåŠ¨é€‰æ‹©ã€‚ æ‰‹åŠ¨è°ƒèŠ‚è¶…å‚æ‰‹åŠ¨æœç´¢è¶…å‚æ•°çš„ç›®æ ‡é€šå¸¸æ˜¯æœ€å°åŒ–å—é™äºè¿è¡Œæ—¶é—´å’Œå†…å­˜é¢„ç®—çš„æ³›åŒ–è¯¯å·®ã€‚é€šè¿‡è°ƒæ•´æ¨¡å‹çš„æœ‰æ•ˆå®¹é‡ä»¥åŒ¹é…ä»»åŠ¡çš„å¤æ‚æ€§ã€‚æœ‰æ•ˆå®¹é‡å—é™äºä¸‰ä¸ªå› ç´ ï¼š æ¨¡å‹çš„è¡¨ç¤ºå®¹é‡ å­¦ä¹ ç®—æ³•æˆåŠŸæœ€å°åŒ–è®­ç»ƒæ¨¡å‹ä»£ä»·å‡½æ•°çš„èƒ½åŠ› ä»£ä»·å‡½æ•°å’Œè®­ç»ƒè¿‡ç¨‹æ­£åˆ™åŒ–æ¨¡å‹çš„ç¨‹åº¦ å­¦ä¹ ç‡å¯èƒ½æ˜¯æœ€é‡è¦çš„è¶…å‚æ•°ï¼Œå¦‚æœä½ åªæœ‰æ—¶é—´è°ƒæ•´ä¸€ä¸ªè¶…å‚ï¼Œé‚£å°±è°ƒæ•´å­¦ä¹ ç‡ã€‚ç›¸æ¯”å…¶ä»–è¶…å‚æ•°ï¼Œå®ƒä»¥ä¸€ç§æ›´å¤æ‚çš„æ–¹å¼æ§åˆ¶æ¨¡å‹çš„æœ‰æ•ˆå®¹é‡â€”â€”å½“å­¦ä¹ ç‡é€‚åˆä¼˜åŒ–é—®é¢˜æ—¶ï¼Œæ¨¡å‹çš„æœ‰æ•ˆå®¹é‡æœ€é«˜ï¼Œæ­¤æ—¶å­¦ä¹ ç‡æ˜¯æ­£ç¡®çš„ï¼Œæ—¢ä¸æ˜¯ç‰¹åˆ«å¤§ä¹Ÿä¸æ˜¯ç‰¹åˆ«å°ã€‚å­¦ä¹ ç‡å…³äºè®­ç»ƒè¯¯å·®å…·æœ‰ U å½¢æ›²çº¿ï¼Œå¦‚å›¾æ‰€ç¤ºã€‚å½“å­¦ä¹ ç‡è¿‡å¤§æ—¶ï¼Œæ¢¯åº¦ä¸‹é™å¯èƒ½ä¼šä¸ç»æ„åœ°å¢åŠ è€Œéå‡å°‘è®­ç»ƒè¯¯å·®ã€‚åœ¨ç†æƒ³åŒ–çš„äºŒæ¬¡æƒ…å†µä¸‹ï¼Œå¦‚æœå­¦ä¹ ç‡æ˜¯æœ€ä½³å€¼çš„ä¸¤å€å¤§æ—¶ï¼Œä¼šå‘ç”Ÿè¿™ç§æƒ…å†µ (LeCun et al., 1998b)ã€‚å½“å­¦ä¹ ç‡å¤ªå°ï¼Œè®­ç»ƒä¸ä»…æ…¢ï¼Œè¿˜æœ‰å¯èƒ½æ°¸ä¹…åœç•™åœ¨ä¸€ä¸ªå¾ˆé«˜çš„è®­ç»ƒè¯¯å·®ã€‚ å®è·µä¸­èƒ½å¤Ÿç¡®ä¿å­¦ä¹ æœ‰æ•ˆçš„æš´åŠ›æ–¹æ³•å°±æ˜¯ä¸æ–­æé«˜æ¨¡å‹å®¹é‡å’Œè®­ç»ƒ é›†çš„å¤§å°ï¼Œç›´åˆ°è§£å†³é—®é¢˜ã€‚ è‡ªåŠ¨è¶…å‚ä¼˜åŒ–å¦‚æœæˆ‘ä»¬ä»”ç»†æƒ³æƒ³ä½¿ç”¨è€…æœç´¢å­¦ä¹ ç®—æ³•åˆé€‚è¶…å‚æ•°çš„æ–¹å¼ï¼Œæˆ‘ä»¬ä¼šæ„è¯†åˆ°è¿™å…¶å®æ˜¯ä¸€ç§ä¼˜åŒ–ï¼šæˆ‘ä»¬åœ¨è¯•å›¾å¯»æ‰¾è¶…å‚æ•°æ¥ä¼˜åŒ–ç›®æ ‡å‡½æ•°ï¼Œä¾‹å¦‚éªŒè¯è¯¯å·®ï¼Œæœ‰æ—¶è¿˜ä¼šæœ‰ä¸€äº›çº¦æŸï¼ˆå¦‚è®­ç»ƒæ—¶é—´ï¼Œå†…å­˜æˆ–è¯†åˆ«æ—¶é—´çš„é¢„ç®—ï¼‰ã€‚ ç½‘æ ¼æœç´¢ï¼ˆgrid searchï¼‰æ˜¯è¶…å‚é€‰æ‹©çš„å¸¸ç”¨æ–¹æ³•ï¼Œåˆ©ç”¨å‡ ä¸ªå°çš„æœ‰é™é›†è®­ç»ƒå‚æ•°æ¨¡å‹ï¼Œä»ä¸­æŒ‘é€‰éªŒè¯é›†è¯¯å·®æœ€å°çš„è¶…å‚ã€‚è¶…å‚èŒƒå›´çš„è®¾å®šä¸€èˆ¬é‡‡ç”¨å¯¹æ•°å°ºåº¦å°æŒ‘é€‰åˆé€‚çš„å€¼ã€‚ éšæœºæœç´¢ï¼š ä¸ºæ¯ä¸ªè¶…å‚æ•°å®šä¹‰ä¸€ä¸ªè¾¹ç¼˜åˆ†å¸ƒï¼Œæˆ–è€…å¯¹æ•°å°ºåº¦ä¸Šçš„å‡åŒ€åˆ†å¸ƒã€‚ä¸ç½‘æ ¼æœç´¢ä¸æ‡‚ï¼Œä¸éœ€è¦ç¦»æ•£åŒ–è¶…å‚æ•°çš„å€¼ã€‚å®è·µè¯æ˜ï¼Œéšæœºæœç´¢æ•ˆç‡æ¯”ç½‘æ ¼æœç´¢æ›´é«˜ã€‚ è°ƒæ•´ç­–ç•¥ è°ƒè¯•ç­–ç•¥ å¯è§†åŒ–è®¡ç®—ä¸­æ¨¡å‹çš„è¡Œä¸ºï¼šå½“è®­ç»ƒæ¨¡å‹æ£€æµ‹å›¾åƒä¸­çš„å¯¹è±¡æ—¶ï¼ŒæŸ¥çœ‹ä¸€äº›æ¨¡å‹æ£€æµ‹åˆ°éƒ¨åˆ†é‡å çš„å›¾åƒã€‚åœ¨è®­ç»ƒè¯­éŸ³ç”Ÿæˆæ¨¡å‹æ—¶ï¼Œè¯•å¬ä¸€äº›ç”Ÿæˆçš„è¯­éŸ³æ ·æœ¬ã€‚è¿™ä¼¼ä¹æ˜¯æ˜¾è€Œæ˜“è§çš„ï¼Œä½†åœ¨å®é™…ä¸­å¾ˆå®¹æ˜“åªæ³¨æ„é‡åŒ–æ€§èƒ½åº¦é‡ï¼Œå¦‚å‡†ç¡®ç‡æˆ–å¯¹æ•°ä¼¼ç„¶ã€‚ç›´æ¥è§‚å¯Ÿæœºå™¨å­¦ä¹ æ¨¡å‹è¿è¡Œå…¶ä»»åŠ¡ï¼Œæœ‰åŠ©äºç¡®å®šå…¶è¾¾åˆ°çš„é‡åŒ–æ€§èƒ½æ•°æ®æ˜¯å¦çœ‹ä¸Šå»åˆ ç†ã€‚é”™è¯¯è¯„ä¼°æ¨¡å‹æ€§èƒ½å¯èƒ½æ˜¯æœ€å…·ç ´åæ€§çš„é”™è¯¯ä¹‹ä¸€ï¼Œå› ä¸ºå®ƒä»¬ä¼šä½¿ä½ åœ¨ç³»ç»Ÿå‡ºé—®é¢˜æ—¶è¯¯ä»¥ä¸ºç³»ç»Ÿè¿è¡Œè‰¯å¥½ã€‚ å¯è§†åŒ–æœ€ä¸¥é‡çš„é”™è¯¯ï¼šå¤§å¤šæ•°æ¨¡å‹èƒ½å¤Ÿè¾“å‡ºè¿è¡Œä»»åŠ¡æ—¶çš„æŸç§ç½®ä¿¡åº¦é‡ã€‚ä¾‹å¦‚ï¼ŒåŸºäºsoftmax å‡½æ•°è¾“å‡ºå±‚çš„åˆ†ç±»å™¨ç»™æ¯ä¸ªç±»åˆ†é…ä¸€ä¸ªæ¦‚ç‡ã€‚å› æ­¤ï¼Œåˆ†é…ç»™æœ€æœ‰å¯èƒ½çš„ç±»çš„æ¦‚ç‡ç»™å‡ºäº†æ¨¡å‹åœ¨å…¶åˆ†ç±»å†³å®šä¸Šçš„ç½®ä¿¡ä¼°è®¡å€¼ã€‚é€šå¸¸ï¼Œç›¸æ¯”äºæ­£ç¡®é¢„æµ‹çš„æ¦‚ç‡æœ€å¤§ä¼¼ç„¶è®­ç»ƒä¼šç•¥æœ‰é«˜ä¼°ã€‚ä½†æ˜¯ç”±äºå®é™…ä¸Šæ¨¡å‹çš„è¾ƒå°æ¦‚ç‡ä¸å¤ªå¯èƒ½å¯¹åº”ç€æ­£ç¡® çš„æ ‡ç­¾ï¼Œå› æ­¤å®ƒä»¬åœ¨ä¸€å®šæ„ä¹‰ä¸Šè¿˜æ˜¯æœ‰äº›ç”¨çš„ã€‚é€šè¿‡æŸ¥çœ‹è®­ç»ƒé›†ä¸­å¾ˆéš¾æ­£ç¡®å»ºæ¨¡çš„æ ·æœ¬ï¼Œé€šå¸¸å¯ä»¥å‘ç°è¯¥æ•°æ®é¢„å¤„ç†æˆ–è€…æ ‡è®°æ–¹å¼çš„é—®é¢˜ã€‚ æ ¹æ®è®­ç»ƒå’Œæµ‹è¯•è¯¯å·®æ£€æµ‹è½¯ä»¶ï¼šæˆ‘ä»¬å¾€å¾€å¾ˆéš¾ç¡®å®šåº•å±‚è½¯ä»¶æ˜¯å¦æ˜¯æ­£ç¡®å®ç°ã€‚è®­ç»ƒå’Œæµ‹è¯•è¯¯å·®èƒ½å¤Ÿæä¾›ä¸€äº›çº¿ç´¢ã€‚å¦‚æœè®­ç»ƒè¯¯å·®è¾ƒä½ï¼Œä½†æ˜¯æµ‹è¯•è¯¯å·®è¾ƒé«˜ï¼Œé‚£ä¹ˆå¾ˆæœ‰å¯èƒ½è®­ç»ƒè¿‡ç¨‹æ˜¯åœ¨æ­£å¸¸è¿è¡Œï¼Œä½†æ¨¡å‹ç”±äºç®—æ³•åŸå› è¿‡æ‹Ÿåˆäº†ã€‚å¦ä¸€ç§å¯èƒ½æ˜¯ï¼Œæµ‹è¯•è¯¯å·®æ²¡æœ‰è¢«æ­£ç¡®åœ°åº¦é‡ï¼Œå¯èƒ½æ˜¯ç”±äºè®­ç»ƒåä¿å­˜æ¨¡å‹å†é‡è½½å»åº¦é‡æµ‹è¯•é›†æ—¶å‡ºç° é—®é¢˜ï¼Œæˆ–è€…æ˜¯å› ä¸ºæµ‹è¯•æ•°æ®å’Œè®­ç»ƒæ•°æ®é¢„å¤„ç†çš„æ–¹å¼ä¸åŒã€‚å¦‚æœè®­ç»ƒå’Œæµ‹è¯•è¯¯å·®éƒ½å¾ˆé«˜ï¼Œé‚£ä¹ˆå¾ˆéš¾ç¡®å®šæ˜¯è½¯ä»¶é”™è¯¯ï¼Œè¿˜æ˜¯ç”±äºç®—æ³•åŸå› æ¨¡å‹æ¬ æ‹Ÿåˆã€‚è¿™ç§æƒ…å†µéœ€è¦è¿›ä¸€æ­¥çš„æµ‹è¯•ã€‚ æ‹Ÿåˆæå°çš„æ•°æ®é›†ï¼šå½“è®­ç»ƒé›†ä¸Šæœ‰å¾ˆå¤§çš„è¯¯å·®æ—¶ï¼Œæˆ‘ä»¬éœ€è¦ç¡®å®šé—®é¢˜æ˜¯çœŸæ­£çš„æ¬ æ‹Ÿåˆï¼Œè¿˜æ˜¯è½¯ä»¶é”™è¯¯ã€‚é€šå¸¸ï¼Œå³ä½¿æ˜¯å°æ¨¡å‹ä¹Ÿå¯ä»¥ä¿è¯å¾ˆå¥½åœ°æ‹Ÿåˆä¸€ä¸ªè¶³å¤Ÿå°çš„æ•°æ®é›†ã€‚ä¾‹å¦‚ï¼Œåªæœ‰ä¸€ä¸ªæ ·æœ¬çš„åˆ†ç±»æ•°æ®å¯ä»¥é€šè¿‡æ­£ç¡®è®¾ç½®è¾“å‡ºå±‚çš„åç½®æ¥æ‹Ÿåˆã€‚é€šå¸¸ï¼Œå¦‚æœä¸èƒ½è®­ç»ƒä¸€ä¸ªåˆ†ç±»å™¨æ¥æ­£ç¡®æ ‡æ³¨ä¸€ä¸ªå•ç‹¬çš„æ ·æœ¬ï¼Œæˆ–ä¸èƒ½è®­ç»ƒä¸€ä¸ªè‡ªç¼–ç  å™¨æ¥æˆåŠŸåœ°ç²¾å‡†å†ç°ä¸€ä¸ªå•ç‹¬çš„æ ·æœ¬ï¼Œæˆ–ä¸èƒ½è®­ç»ƒä¸€ä¸ªç”Ÿæˆæ¨¡å‹æ¥ä¸€è‡´åœ°ç”Ÿæˆä¸€ä¸ªå•ç‹¬çš„æ ·æœ¬ï¼Œé‚£ä¹ˆå¾ˆæœ‰å¯èƒ½æ˜¯ç”±äºè½¯ä»¶é”™è¯¯é˜»æ­¢è®­ç»ƒé›†ä¸Šçš„æˆåŠŸä¼˜åŒ–ã€‚æ­¤æµ‹è¯•å¯ä»¥æ‰©å±•åˆ°åªæœ‰å°‘é‡æ ·æœ¬çš„å°æ•°æ®é›†ä¸Šã€‚ æ¯”è¾ƒåå‘ä¼ æ’­å¯¼æ•°å’Œæ•°å€¼å¯¼æ•°ï¼šå¦‚æœè¯»è€…æ­£åœ¨ä½¿ç”¨ä¸€ä¸ªéœ€è¦å®ç°æ¢¯åº¦è®¡ç®—çš„è½¯ä»¶æ¡†æ¶ï¼Œæˆ–è€…åœ¨æ·»åŠ ä¸€ä¸ªæ–°æ“ä½œåˆ°æ±‚å¯¼åº“ä¸­ï¼Œå¿…é¡»å®šä¹‰å®ƒçš„ bprop æ–¹æ³•ï¼Œé‚£ä¹ˆå¸¸è§çš„é”™è¯¯åŸå› æ˜¯æ²¡èƒ½æ­£ç¡®åœ°å®ç°æ¢¯åº¦è¡¨è¾¾ã€‚éªŒè¯è¿™äº›æ±‚å¯¼æ­£ç¡®æ€§çš„ä¸€ç§æ–¹æ³•æ˜¯æ¯”è¾ƒå®ç°çš„è‡ªåŠ¨æ±‚å¯¼å’Œé€šè¿‡æœ‰é™å·®åˆ†ï¼ˆfinite differenceï¼‰è®¡ç®—çš„å¯¼æ•°ã€‚ ç›‘æ§æ¿€æ´»å‡½æ•°å€¼å’Œæ¢¯åº¦çš„ç›´æ–¹å›¾ï¼šå¯è§†åŒ–ç¥ç»ç½‘ç»œåœ¨å¤§é‡è®­ç»ƒè¿­ä»£åï¼ˆä¹Ÿè®¸æ˜¯ä¸€ä¸ªè½®ï¼‰æ”¶é›†åˆ°çš„æ¿€æ´»å‡½æ•°å€¼å’Œæ¢¯åº¦çš„ç»Ÿè®¡é‡å¾€å¾€æ˜¯æœ‰ç”¨çš„ã€‚éšè—å•å…ƒçš„é¢„æ¿€æ´»å€¼å¯ä»¥å‘Šè¯‰æˆ‘ä»¬è¯¥å•å…ƒæ˜¯å¦é¥±å’Œï¼Œæˆ–è€…å®ƒä»¬é¥±å’Œçš„é¢‘ç‡å¦‚ä½•ã€‚ä¾‹å¦‚ï¼Œå¯¹äºæ•´æµå™¨ï¼Œå®ƒä»¬å¤šä¹…å…³ä¸€æ¬¡ï¼Ÿæ˜¯å¦æœ‰å•å…ƒä¸€ç›´å…³é—­ï¼Ÿå¯¹äºåŒæ›²æ­£åˆ‡å•å…ƒè€Œè¨€ï¼Œé¢„æ¿€æ´»ç»å¯¹å€¼çš„å¹³å‡å€¼å¯ä»¥å‘Šè¯‰æˆ‘ä»¬è¯¥å•å…ƒçš„é¥±å’Œç¨‹åº¦ã€‚åœ¨æ·±åº¦ç½‘ç»œä¸­ï¼Œä¼ æ’­æ¢¯åº¦çš„å¿«é€Ÿå¢é•¿æˆ–å¿«é€Ÿæ¶ˆå¤±ï¼Œå¯èƒ½ä¼šé˜»ç¢ä¼˜åŒ–è¿‡ç¨‹ã€‚æœ€åï¼Œæ¯”è¾ƒå‚æ•°æ¢¯åº¦å’Œå‚æ•°çš„é‡çº§ä¹Ÿæ˜¯æœ‰å¸®åŠ©çš„ã€‚æ­£å¦‚ (Bottou, 2015) æ‰€å»ºè®®çš„ï¼Œæˆ‘ä»¬å¸Œæœ›å‚æ•°åœ¨ä¸€ä¸ªå°æ‰¹é‡æ›´æ–°ä¸­å˜åŒ–çš„å¹…åº¦æ˜¯å‚æ•°é‡å€¼ 1% è¿™æ ·çš„çº§åˆ«ï¼Œè€Œä¸æ˜¯50% æˆ–è€…0.001%ï¼ˆè¿™ä¼šå¯¼è‡´å‚æ•°ç§»åŠ¨å¾—å¤ªæ…¢ï¼‰ã€‚ä¹Ÿæœ‰å¯èƒ½æ˜¯æŸäº›å‚æ•°ä»¥è‰¯å¥½çš„æ­¥é•¿ç§»åŠ¨ï¼Œè€Œå¦ä¸€äº›åœæ»ã€‚å¦‚æœæ•°æ®æ˜¯ç¨€ç–çš„ï¼ˆæ¯”å¦‚è‡ªç„¶è¯­è¨€ï¼‰ï¼Œæœ‰äº›å‚æ•°å¯èƒ½å¾ˆå°‘æ›´æ–°ï¼Œæ£€æµ‹å®ƒä»¬å˜åŒ–æ—¶åº”è¯¥è®°ä½è¿™ä¸€ç‚¹ã€‚ å‚è€ƒ ã€ŠDeep Learningã€‹Book Ng, A. (2015). Advice for applying machine https://see.stanford.edu/materials/aimlcs229/ML-advice.pdf.","categories":[{"name":"æ·±åº¦å­¦ä¹ ","slug":"æ·±åº¦å­¦ä¹ ","permalink":"http://blog.a-stack.com/categories/æ·±åº¦å­¦ä¹ /"}],"tags":[{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"ç®—æ³•","slug":"ç®—æ³•","permalink":"http://blog.a-stack.com/tags/ç®—æ³•/"},{"name":"æ–‡çŒ®","slug":"æ–‡çŒ®","permalink":"http://blog.a-stack.com/tags/æ–‡çŒ®/"},{"name":"å®è·µ","slug":"å®è·µ","permalink":"http://blog.a-stack.com/tags/å®è·µ/"}]},{"title":"Thinking Stats","slug":"thinking-stats","date":"2018-06-20T12:09:03.000Z","updated":"2018-07-20T15:53:25.907Z","comments":true,"path":"2018/06/20/thinking-stats/","link":"","permalink":"http://blog.a-stack.com/2018/06/20/thinking-stats/","excerpt":"","text":"PandasæŠ€å·§1. ç»Ÿè®¡å±æ€§çš„ç‹¬ç«‹å€¼æ•°ç›®1pd[\"outcome\"].value_counts().sort_index() æ•°æ®çš„ç›¸å…³æ€§è¡¡é‡ä¸¤ç»„æ•°æ®æˆ–æ•°æ®çš„ä¸¤ä¸ªå˜é‡ï¼ˆç»´åº¦ï¼‰çº¿æ€§ç›¸å…³æ€§çš„æ–¹æ³•ä¸»è¦æœ‰ï¼š çš®å°”é€Šç›¸å…³ç³»æ•° æ–¯çš®å°”æ›¼ç›¸å…³ç³»æ•° æœ€å°äºŒä¹˜æ‹Ÿåˆ åæ–¹å·®æ ‡å‡†åˆ†æ•°(standard score): $z_i = (x_i - \\mu)/\\sigma$ å…¶ä¸­$x_i - \\mu$ç§°ä¸ºç¦»å·®ï¼Œæè¿°äº†$x_i$ä¸å‡å€¼$\\mu$çš„å·®å¼‚ï¼Œé™¤ä»¥æ–¹å·®æ˜¯ä¸ºäº†å½’ä¸€åŒ–åå·®ï¼Œè¿™æ ·å½¢æˆçš„æ•°æ®é›†$Z$å°±æ˜¯å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1ï¼Œä¸”ä¸åŸæ•°æ®é›†$X$åŒåˆ†å¸ƒï¼Œä¸”ç»Ÿä¸€å•ä½ä¸º1ï¼Œä¸éœ€è¦å†è€ƒè™‘åŸå…ˆä¸åŒæ•°æ®ç»´åº¦çš„å•ä½ä¸åŒçš„é—®é¢˜ã€‚ åæ–¹å·®(covariance)è¡¡é‡ç›¸å…³å˜é‡å˜åŒ–è¶‹åŠ¿æ˜¯å¦ç›¸åŒï¼Œå®šä¹‰å¦‚ä¸‹ï¼š Cov(X,Y) = \\frac{1}{n}\\sum(x_i-\\mu_x)(y_i-\\mu_y)ç”±å®šä¹‰å¯çŸ¥ï¼Œåæ–¹å·®æè¿°äº†ä¸¤ç»„æ•°æ®ç¦»å·®ç›¸ä¹˜çš„åŠ å’Œï¼Œå¯ä»¥æè¿°ä¸¤ä¸ªåºåˆ—çš„å˜åŒ–æ˜¯å¦ä¸€è‡´ã€‚ ä½†ç”±äºX,Yæœ¬èº«å•ä½æœ‰å¯èƒ½ä¸åŒï¼Œæ²¡æœ‰è¢«å½’ä¸€åŒ–ï¼Œå¯¼è‡´ç»“æœå¾ˆéš¾ååº”å®é™…çš„æƒ…å†µã€‚ çš®å°”é€Šç›¸å…³ç³»æ•°çš®å°”é€Šç›¸å…³ç³»æ•°ï¼ˆPearsonâ€™s correlationï¼‰: \\rho = \\frac{1}{n}\\sum\\frac{(x_i-\\mu_x)}{\\sigma_x} \\frac{(y_i-\\mu_y)}{\\sigma_y}=\\frac{Cov(X,Y)}{\\sigma_x \\sigma_y}è¿™æ ·ç›¸å…³ç³»æ•°çš„å•ä½ä¸º1ï¼Œä¸”å–å€¼èŒƒå›´ä¸º-1åˆ°1ã€‚$\\rho$å†³å®šå€¼çš„å¤§å°æè¿°äº†ä¸¤ä¸ªå˜é‡çš„çº¿æ€§ç›¸å…³ç¨‹åº¦ã€‚å½“$\\rho=1$æ—¶ï¼Œä¸¤ä¸ªå˜é‡å®Œå…¨æ­£ç›¸å…³ï¼Œå½“$\\rho=0$æ—¶ï¼Œä¸¤ä¸ªå˜é‡å®Œå…¨è´Ÿç›¸å…³ã€‚ ä½†æ˜¯$\\rho=0$å¹¶ä¸ä»£è¡¨ç€ä¸¤ä¸ªå˜é‡æ¯«æ— å…³ç³»ï¼Œçš®å°”é€Šç³»æ•°åªèƒ½è¡¡é‡ä¸¤ä¸ªå˜é‡ä¹‹é—´çš„çº¿æ€§å…³ç³»ï¼Œå¦‚æœä¸¤ä¸ªå˜é‡æ˜¯éçº¿æ€§ç›¸å…³ï¼Œæ— æ³•é€šè¿‡è¯¥ç³»æ•°æè¿°ã€‚ ä¸Šå›¾æè¿°äº†å…·æœ‰ä¸€å®šç›¸å…³æ€§çš„ç¤ºä¾‹æ•°æ®å’Œå¯¹åº”çš„ç›¸å…³ç³»æ•°ï¼Œç¬¬ä¸€è¡Œä¸ºä¸€ç»„æœ‰ç›¸å…³æ€§å’Œæ— çº¿æ€§ç›¸å…³æ€§çš„æ•°æ®ï¼Œç¬¬äºŒç»„ä¸ºå¯¹åº”çš„ä¸¥æ ¼ç›¸å…³æ•°æ®ï¼Œç¬¬ä¸‰è¡Œä¸ºéçº¿æ€§ç›¸å…³æ•°æ®ï¼Œä½†ç›¸å…³ç³»æ•°ä¸º0ã€‚ æ–¯çš®å°”æ›¼ç§©ç›¸å…³æ˜¯ä¸ºäº†è§£å†³çš®å°”é€Šç›¸å…³ç³»æ•°å¯¹å¼‚å¸¸å€¼æ•æ„Ÿçš„é—®é¢˜ï¼Œæ–¯çš®å°”æ›¼ç§©ç›¸å…³ç³»æ•°ï¼ˆSpearmanâ€™s Rank Correlationï¼‰å¯ä»¥ç”¨åœ¨å­˜åœ¨å¼‚ å¸¸å€¼å’Œå˜é‡åˆ†å¸ƒéå¸¸ä¸å¯¹ç§°çš„æƒ…å†µã€‚ é¦–å…ˆè®¡ç®—åºåˆ—ä¸­æ•°å€¼çš„ç§©ï¼ˆrankï¼‰ï¼Œå³æŸä¸ªæ•°æ®åœ¨åºåˆ—ä¸­å¤§å°æ’åºçš„åºå·ï¼Œå°†åºåˆ—è½¬æ¢ä¸ºç§©ä¹‹åå†è®¡ç®—çš®å°”é€Šç›¸å…³ç³»æ•°ã€‚ æ•£ç‚¹å›¾è§‚å¯Ÿæ•°æ®ç›¸å…³æ€§æ—¢ç„¶çš®å°”é€Šç³»æ•°æ— æ³•å®Œå…¨è¡¨å¾æ•°æ®çš„ç›¸å…³æ€§ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ç”»æ•£ç‚¹å›¾çš„æ–¹æ³•æ¥ç›´è§‚çš„è§‚å¯Ÿæ•°æ®çš„ç›¸å…³æ€§ã€‚ scatter hexbin è¡¥å……ç›¸å…³ä»£ç  æœ€å°äºŒä¹˜æ‹Ÿåˆç›¸å…³ç³»æ•°å¯ä»¥æè¿°ä¸¤ä¸ªå˜é‡çš„çº¿æ€§ç›¸å…³æ€§å¼ºå¼±ï¼Œä½†æ— æ³•è¯„ä¼°ä»–ä»¬çš„æ–œç‡ï¼Œæœ€å°äºŒä¹˜æ³•å¯ä»¥é€šè¿‡æ•°æ®æ‹Ÿåˆçš„æ–¹å¼è®¡ç®—æ–œç‡ã€‚é¦–å…ˆå®šä¹‰æ•°æ®çš„é¢„æµ‹åå·®(æ®‹å·®)ï¼š$\\epsilon_i = (\\alpha + \\beta x_i) - y_i$ï¼Œ é€šè¿‡æ±‚è§£æœ€å°åŒ–æ®‹å·®çš„å¹³æ–¹å’Œï¼Œå¯ä»¥è·å¾—ç›¸å…³å‚æ•°ã€‚ é€‰æ‹©æ®‹å·®å¹³æ–¹å’Œæœ€å°ä½œä¸ºæœ€ä¼˜åŒ–ç›®æ ‡çš„åŸå› ï¼š å¹³æ–¹èƒ½å°†æ­£æ®‹å·®å’Œè´Ÿæ®‹å·®éƒ½å˜æˆæ­£æ•°ï¼Œè¿™ç¬¦åˆæˆ‘ä»¬çš„ç›®æ ‡ã€‚ å¹³æ–¹ç›¸å½“äºç»™æ®‹å·®èµ‹äºˆäº†ä¸€ä¸ªæƒé‡ï¼Œè¶Šå¤§çš„æ®‹å·®ï¼ˆç»å¯¹é‡ï¼‰è¢«èµ‹äºˆ çš„æƒé‡è¶Šå¤§ã€‚ä½†æ˜¯å¹¶ä¸æ˜¯æ‰€æœ‰æƒ…å†µä¸‹å¤§çš„æ®‹å·®éƒ½åº”è¯¥è¢«èµ‹äºˆå¤§çš„æƒ é‡ï¼Œå› ä¸ºè¿™æ ·æ‹Ÿåˆæ–¹ç¨‹å°±å¾ˆå®¹æ˜“å—åˆ°å¼‚å¸¸å€¼çš„å½±å“ã€‚ åœ¨æ®‹å·®æœä»å‡å€¼ä¸º 0ã€æ–¹å·®ä¸º$\\sigma^2$çš„æ­£æ€åˆ†å¸ƒï¼Œä¸”åœ¨æ®‹å·®ä¸ x ç‹¬ç«‹çš„å‡è®¾ä¸‹ï¼Œå‚æ•°çš„æœ€å°äºŒä¹˜ä¼°è®¡ç»“æœä¸æå¤§ä¼¼ç„¶ä¼°è®¡é‡ç›¸åŒã€‚ æ–œç‡å¯ä»¥è®¡ç®—ä¸ºï¼š \\hat\\beta = \\frac{Cov(X,Y)}{Var(X)}ç›¸å…³æ€§ä¸ç­‰äºå› æœæ€§ä¸¤ä¸ªå˜é‡çš„ç›¸å…³å…³ç³»å¹¶ä¸ä»£è¡¨ä»–ä»¬ä¹‹é—´å­˜åœ¨å› æœå…³ç³»ï¼ŒCorrelation does not imply causationã€‚å¦‚ä½•ç¡®è®¤ä¸¤ä¸ªå˜é‡çš„å› æœå…³ç³»ï¼Œä¸€èˆ¬é‡‡ç”¨éšæœºå¯¹ç…§è¯•éªŒå’Œè‡ªç„¶è¯•éªŒ(natural experiment)ã€‚ éšæœºå¯¹ç…§è¯•éªŒå¤šç”¨äºå®éªŒç ”ç©¶å’Œè¯ç‰©ç ”å‘ï¼Œé€šè¿‡è®¾ç«‹å®éªŒç»„å’Œå¯¹ç…§ç»„æ¥æ§åˆ¶å˜é‡ï¼› è‡ªç„¶è¯•éªŒé€šè¿‡å°½é‡æ§åˆ¶ç¾¤ä½“åœ¨å„æ–¹é¢æ˜¯ç›¸ä¼¼çš„ï¼Œç„¶åå¯¹ä¸åŒç¾¤ä½“å®æ–½ä¸åŒçš„å¤„ç†ã€‚ ä¼°è®¡ æå¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMaximum Likelihood Estimatorï¼ŒMLEï¼‰ï¼šæ ¹æ®å·²æœ‰ä¿¡æ¯è·å¾—çš„æœ€å¤§å¯èƒ½ä¼°è®¡ï¼› æœ€å°è¯¯å·®å€¼ä¼°è®¡ï¼ˆæœ€å°äºŒä¹˜ä¼°è®¡ï¼‰ï¼šåˆ†å¸ƒæ•°æ®å‡åŒ€ï¼Œæ²¡æœ‰ä¸”å¾ˆå°‘æœ‰å¼‚å¸¸å€¼çš„æƒ…å†µä¸‹ï¼› æ— åä¼°è®¡ï¼š$\\sigma^2$çš„æ— åä¼°è®¡ä¸º$S_{n-1}^2$ ä¼°è®¡æ˜¯æ— åçš„ï¼šä¼°è®¡é‡çš„æ•°å­¦æœŸæœ›ç­‰äºè¢«ä¼°è®¡å‚æ•°çš„çœŸå®å€¼ï¼Œåˆ™ç§°æ­¤æ­¤ä¼°è®¡é‡ä¸ºè¢«ä¼°è®¡å‚æ•°çš„æ— åä¼°è®¡ï¼Œå³å…·æœ‰æ— åæ€§ï¼Œæ˜¯ä¸€ç§ç”¨äºè¯„ä»·ä¼°è®¡é‡ä¼˜è‰¯æ€§çš„å‡†åˆ™ã€‚æ— åä¼°è®¡çš„æ„ä¹‰æ˜¯ï¼šåœ¨å¤šæ¬¡é‡å¤ä¸‹ï¼Œå®ƒä»¬çš„å¹³å‡æ•°æ¥è¿‘æ‰€ä¼°è®¡çš„å‚æ•°çœŸå€¼ã€‚ è´å¶æ–¯ä¼°è®¡ è´å¶æ–¯ç½®ä¿¡åŒºé—´ ç»å…¸é—®é¢˜ï¼š ç«è½¦å¤´é—®é¢˜ï¼ˆå¾·å›½å¦å…‹é—®é¢˜ï¼‰ é“è·¯å…¬å¸å°†å®ƒæ‰€æœ‰çš„ç«è½¦å¤´éƒ½è¿›è¡Œäº†ç¼–å·ï¼Œä»1åˆ°Nã€‚æœ‰ä¸€å¤© ä½ çœ‹è§ä¸€ä¸ªç¼–å·ä¸º60çš„ç«è½¦å¤´ï¼Œé‚£è¯¥é“è·¯å…¬å¸æ€»å…±æœ‰å¤šå°‘ç« è½¦å¤´å‘¢ï¼Ÿ å¯¹äºä¸€ä¸ªç»™å®šçš„ä¼°è®¡é‡$\\hat N$ ï¼Œè§‚æµ‹åˆ°ç¼–å·ä¸º $i(i \\le \\hat N)$çš„ç«è½¦çš„æ¦‚ç‡ä¸º$1/\\hat N$ï¼Œ$i&gt;\\hat N$çš„æ¦‚ç‡ä¸º 0ã€‚æ‰€ä»¥ Nçš„æå¤§ä¼¼ç„¶ä¼°è®¡é‡æ˜¯$\\hat N =i$ ã€‚æ¢è¨€ä¹‹,å¦‚æœè§‚æµ‹åˆ°çš„ç«è½¦çš„ç¼–å·æ˜¯ 60ï¼Œè€Œä¸”æˆ‘ä»¬è¦ä»¥æœ€å¤§çš„æ¦‚ç‡ä¿è¯ç»“æœçš„ æ­£ç¡®æ€§ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±ä¼šçŒœæµ‹é“è·¯å…¬å¸æœ‰ 60 è¾†ç«è½¦ã€‚ ä½†ä»å‡æ–¹è¯¯å·®æœ€å°åŒ–çš„è§’åº¦æ¥çœ‹ï¼Œä¸Šè¿°ç»“æœä¸ç†æƒ³ï¼Œæˆ‘ä»¬éœ€è¦é€‰æ‹©ä¸€ä¸ª$\\hat N = ai$ ä½¿å¾—ä¼°è®¡çš„å‡æ–¹è¯¯å·®æœ€å°ï¼š \\min \\frac{1}{N}\\sum^N_{i=1} (ai-N)^2ä»æ— åä¼°è®¡è§’åº¦å‡ºå‘ï¼Œä»¤å¹³å‡è¯¯å·®ä¸ºé›¶ï¼Œå³ ME = \\frac{1}{N}\\sum^N_{i=1} (ai-N)=0è´å¶æ–¯ä¼°è®¡ å‡å¦‚æœ‰è¶³å¤Ÿçš„å…ˆéªŒä¿¡æ¯ï¼Œé‚£ä¹ˆæ‰€æœ‰çš„ä¼°è®¡é‡å°†å€¾å‘äºæ”¶æ•›åˆ°åŒä¸€ä¸ªå€¼ã€‚ æ—¶åºæ•°æ®åˆ†æå‚è€ƒ â€‹","categories":[{"name":"æ·±åº¦å­¦ä¹ ","slug":"æ·±åº¦å­¦ä¹ ","permalink":"http://blog.a-stack.com/categories/æ·±åº¦å­¦ä¹ /"}],"tags":[{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"ç®—æ³•","slug":"ç®—æ³•","permalink":"http://blog.a-stack.com/tags/ç®—æ³•/"},{"name":"æ–‡çŒ®","slug":"æ–‡çŒ®","permalink":"http://blog.a-stack.com/tags/æ–‡çŒ®/"}]},{"title":"Feature_Visualization_in_NN","slug":"Feature-Visualization-in-NN","date":"2018-05-22T02:23:04.000Z","updated":"2018-07-20T15:53:39.979Z","comments":true,"path":"2018/05/22/Feature-Visualization-in-NN/","link":"","permalink":"http://blog.a-stack.com/2018/05/22/Feature-Visualization-in-NN/","excerpt":"æ‘˜è¦ï¼š","text":"æ‘˜è¦ï¼š Feature visualization answers questions about what a network â€” or parts of a network â€” are looking for by generating examples. Attribution 1 studies what part of an example is responsible for the network activating a particular way. TODO: æ ¹æ®å‚è€ƒæ–‡çŒ®æ•´ç†ç›¸å…³å†…å®¹å’Œæ€è·¯ã€‚ å‚è€ƒ Feature Visualization -How neural networks build up their understanding of images The Building Blocks of Interpretability","categories":[{"name":"æ·±åº¦å­¦ä¹ ","slug":"æ·±åº¦å­¦ä¹ ","permalink":"http://blog.a-stack.com/categories/æ·±åº¦å­¦ä¹ /"}],"tags":[{"name":"ç®—æ³•","slug":"ç®—æ³•","permalink":"http://blog.a-stack.com/tags/ç®—æ³•/"},{"name":"æ–‡çŒ®","slug":"æ–‡çŒ®","permalink":"http://blog.a-stack.com/tags/æ–‡çŒ®/"},{"name":"å¯è§†åŒ–","slug":"å¯è§†åŒ–","permalink":"http://blog.a-stack.com/tags/å¯è§†åŒ–/"}]},{"title":"ç»å…¸ç½‘ç»œå½’çº³ï¼š ResNet","slug":"ResNet","date":"2018-05-21T12:14:49.000Z","updated":"2018-05-22T01:35:37.537Z","comments":true,"path":"2018/05/21/ResNet/","link":"","permalink":"http://blog.a-stack.com/2018/05/21/ResNet/","excerpt":"æ‘˜è¦ï¼š ä½œä¸ºæ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œçš„é‡Œç¨‹ç¢‘å¼çš„ä½œå“ï¼ŒResNetä¸ºå·ç§¯ç½‘ç»œå¾€æ›´æ·±å±‚æ¬¡æ‰©å±•æŒ‡æ˜äº†æ–¹å‘ï¼Œæœ¬æ–‡ç»“åˆç›¸å…³è®ºæ–‡æ€»ç»“ä¸€ä¸‹ResNetä¸­åˆ›é€ æ€§çš„æƒ³æ³•ã€‚","text":"æ‘˜è¦ï¼š ä½œä¸ºæ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œçš„é‡Œç¨‹ç¢‘å¼çš„ä½œå“ï¼ŒResNetä¸ºå·ç§¯ç½‘ç»œå¾€æ›´æ·±å±‚æ¬¡æ‰©å±•æŒ‡æ˜äº†æ–¹å‘ï¼Œæœ¬æ–‡ç»“åˆç›¸å…³è®ºæ–‡æ€»ç»“ä¸€ä¸‹ResNetä¸­åˆ›é€ æ€§çš„æƒ³æ³•ã€‚ æ¦‚è¿°éšç€ç½‘ç»œæ·±åº¦å¢åŠ ï¼Œäººä»¬å‘ç°å‡ºç°äº†Degradationé—®é¢˜ï¼Œè¿™ä¸æ˜¯è¿‡æ‹Ÿåˆå¯¼è‡´çš„ï¼Œå› ä¸ºåœ¨è®­ç»ƒæ•°æ®é›†ä¸Šå‘ç°äº†åŒæ ·çš„é—®é¢˜ã€‚ResNetè§£å†³äº†æ·±å±‚ç¥ç»ç½‘ç»œéš¾è®­ç»ƒçš„é—®é¢˜ï¼Œåœ¨æ­¤ä¹‹å‰è¦è®­ç»ƒä¸€ä¸ªå±‚æ¬¡è¾ƒæ·±çš„ç½‘ç»œéœ€è¦åœ¨å‚æ•°åˆå§‹åŒ–ä¸Šä¸‹åŠŸå¤«ï¼Œå½“ç„¶è¿˜éœ€è¦ä¸€å®šçš„è¿æ°”ã€‚ ResNetç½‘ç»œè·å¾—äº†2015å¹´æ‰€æœ‰çš„ä¸»æµæ¯”èµ›å† å†›ï¼Œç›¸å…³å†…å®¹è¢«å‘è¡¨åœ¨è®ºæ–‡ã€ŠDeep Residual Learning for Image Recognitionã€‹ä¸­ã€‚é™¤äº†æ®‹å·®ç½‘ç»œçš„å¼•å…¥ï¼Œåœ¨ResNetæˆ‘ä»¬ä¹Ÿçœ‹åˆ°é€æ¸æ‘’å¼ƒäº†å…¨è¿æ¥å±‚ã€æ± åŒ–å±‚ã€‚å…¨éƒ¨ç½‘ç»œä¸­åªåœ¨æœ€å¼€å§‹ä½¿ç”¨äº†ä¸€ä¸ªmax poolingå±‚ï¼Œåœ¨æœ€åä½¿ç”¨äº†average poolingå±‚ã€‚ 2016å¹´ï¼Œåœ¨ä¸Šè¿°è®ºæ–‡çš„åŸºç¡€ä¸Šï¼ŒHeå‘è¡¨äº†ç¬¬äºŒç¯‡æ”¹è¿›çš„è®ºæ–‡ 2 æ®‹å·®ç½‘ç»œ y = F(x, {W_i}) + x â€œFæ˜¯æ±‚å’Œå‰ç½‘ç»œæ˜ å°„ï¼ŒHæ˜¯ä»è¾“å…¥åˆ°æ±‚å’Œåçš„ç½‘ç»œæ˜ å°„ã€‚æ¯”å¦‚æŠŠ5æ˜ å°„åˆ°5.1ï¼Œé‚£ä¹ˆå¼•å…¥æ®‹å·®å‰æ˜¯Fâ€™(5)=5.1ï¼Œå¼•å…¥æ®‹å·®åæ˜¯H(5)=5.1, H(5)=F(5)+5, F(5)=0.1ã€‚è¿™é‡Œçš„Fâ€™å’ŒFéƒ½è¡¨ç¤ºç½‘ç»œå‚æ•°æ˜ å°„ï¼Œå¼•å…¥æ®‹å·®åçš„æ˜ å°„å¯¹è¾“å‡ºçš„å˜åŒ–æ›´æ•æ„Ÿã€‚æ¯”å¦‚sè¾“å‡ºä»5.1å˜åˆ°5.2ï¼Œæ˜ å°„Fâ€™çš„è¾“å‡ºå¢åŠ äº†1/51=2%ï¼Œè€Œå¯¹äºæ®‹å·®ç»“æ„è¾“å‡ºä»5.1åˆ°5.2ï¼Œæ˜ å°„Fæ˜¯ä»0.1åˆ°0.2ï¼Œå¢åŠ äº†100%ã€‚æ˜æ˜¾åè€…è¾“å‡ºå˜åŒ–å¯¹æƒé‡çš„è°ƒæ•´ä½œç”¨æ›´å¤§ï¼Œæ‰€ä»¥æ•ˆæœæ›´å¥½ã€‚æ®‹å·®çš„æ€æƒ³éƒ½æ˜¯å»æ‰ç›¸åŒçš„ä¸»ä½“éƒ¨åˆ†ï¼Œä»è€Œçªå‡ºå¾®å°çš„å˜åŒ–ï¼Œçœ‹åˆ°æ®‹å·®ç½‘ç»œæˆ‘ç¬¬ä¸€ååº”å°±æ˜¯å·®åˆ†æ”¾å¤§å™¨â€ åœ¨ResNetä¸­ï¼Œæ®‹å·®ä½¿å¾—ç½‘ç»œå­¦ä¹ æ›´å¿«ï¼Œå¯ä»¥ä½¿ç”¨æ›´é«˜çš„å­¦ä¹ ç‡ï¼Œæ¯”å¦‚å¸¸ç”¨çš„èµ·å§‹å­¦ä¹ ç‡ä¸º0.1ã€‚ Boottleneckæ®‹å·®ç½‘ç»œä¸­ï¼Œä¸€èˆ¬æœ€åä¸€ä¸ª1x1å·ç§¯çš„filteræ•°ç›®æ˜¯å¦å¤–ä¸¤ä¸ªçš„4å€ï¼› æ®‹å·®ç½‘ç»œå¯ä»¥ä»å¦ä¸€ä¸ªè§’åº¦ç†è§£ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæ®‹å·®ç½‘ç»œå¯ä»¥çœ‹æˆæ˜¯ç”±å¤šç§è·¯å¾„ç»„åˆçš„ä¸€ä¸ªç½‘ç»œï¼Œå³ï¼Œæ®‹å·®ç½‘ç»œå…¶å®æ˜¯å¾ˆå¤šå¹¶è¡Œå­ç½‘ç»œçš„ç»„åˆã€‚ ç½‘ç»œç»“æ„ Highway NetworksResNetçš„æ”¹è¿›åŠä¼˜åŒ– Heåœ¨2016å¹´å‘å¸ƒè®ºæ–‡ã€ŠIdentity Mappings in Deep Residual Networksã€‹ï¼Œå¯¹ResNetä¸­çš„ä¸€äº›å†…å®¹è¿›è¡Œäº†è¿›ä¸€æ­¥çš„ä¼˜åŒ–åŠå®Œå–„ï¼Œå¹¶è¯æ˜äº†â€œidentity Mappingâ€ çš„æœ€ä¼˜é…ç½®ï¼š$h(x_l) = x_l$ã€‚ è®ºæ–‡ä¸­æå‡ºäº†åœ¨ResNetå•å…ƒä¸­é‡‡å–â€œé¢„æ¿€æ´»â€çš„æ–¹å¼ï¼Œå‚è€ƒå›¾ï¼ˆbï¼‰ä¸­æ–¹æ¡ˆï¼Œåœ¨æƒé‡æ›´æ–°ä¹‹å‰å…ˆè¿›è¡ŒBNå±‚å’ŒReLUå±‚æ“ä½œã€‚å®è·µè¯æ˜ï¼Œé‡‡ç”¨è¿™ç§æ–¹å¼æ›´å®¹æ˜“è®­ç»ƒæ·±å±‚ç½‘ç»œ,åŒæ—¶å…·å¤‡æ›´å¥½çš„æ³›åŒ–æ€§èƒ½ã€‚é‡‡ç”¨ï¼ˆbï¼‰çš„è¯¯å·®ä¸º6.36%å°äº(a)çš„6.61% ä½œè€…ä½¿ç”¨å¦‚ä¸‹å›¾æ‰€ç¤ºçš„å¤šç§ä¸åŒçš„æ®‹å·®å•å…ƒæ¯”è¾ƒæ€§èƒ½ï¼Œç»“æœè¡¨æ˜ç›´è¿çš„æ–¹å¼æ•ˆæœæœ€ä½³ã€‚ ç½‘ç»œè®­ç»ƒæ—¶é—´ï¼š åœ¨CIFARæ•°æ®é›†ï¼ŒResNet-1001ï¼Œä½¿ç”¨2GPUè®­ç»ƒ27å°æ—¶ï¼› åœ¨ImageNetæ•°æ®é›†ï¼ŒResNet-200ä½¿ç”¨8å—GPUè®­ç»ƒ3å‘¨ å®ç°Kerasä¸­å·²ç»åŒ…å«äº†ResNet50 12from keras.applications.resnet50 import ResNet50ResNet50(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000) å½“ include_top=Falseæ—¶ï¼Œå¯ä»¥é€šè¿‡input_shape è°ƒæ•´è¾“å…¥å›¾åƒå°ºå¯¸ï¼Œä½†å›¾åƒé«˜åº¦ä¸å°äº197ï¼›é»˜è®¤å¤§å°ä¸º(224,24,3) pooling: å¯é€‰ï¼Œå½“ include_top ä¸º â€˜Falseâ€™ æ—¶ï¼Œè¯¥å‚æ•°æŒ‡å®šäº†ç‰¹å¾æå–æ—¶çš„æ± åŒ–æ–¹å¼ã€‚ None ä»£è¡¨ä¸æ± åŒ–ï¼Œç›´æ¥è¾“å‡ºæœ€åä¸€å±‚å·ç§¯å±‚çš„è¾“å‡ºï¼Œè¯¥è¾“å‡ºæ˜¯ä¸€ä¸ªå››ç»´å¼ é‡ã€‚ avg ä»£è¡¨å…¨å±€å¹³å‡æ± åŒ–ï¼ˆGLobalAveragePool2Dï¼‰ï¼Œç›¸å½“äºåœ¨æœ€åä¸€å±‚å·ç§¯å±‚åé¢å†åŠ ä¸€å±‚å…¨å±€å¹³å‡æ± åŒ–å±‚ï¼Œè¾“å‡ºæ˜¯ä¸€ä¸ªäºŒç»´å¼ é‡ã€‚ max ä»£è¡¨å…¨å±€æœ€å¤§æ± åŒ– åˆ©ç”¨ResNet50çš„è¿ç§»å­¦ä¹ æ–¹æ³• 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950from keras.preprocessing import imagefrom keras.applications.resnet50 import preprocess_input, decode_predictionsimport numpy as npfrom keras.applications.resnet50 import ResNet50model = ResNet50(weights='imagenet')## ç›´æ¥ä½¿ç”¨è¿›è¡Œå›¾åƒåˆ†ç±»img_path = 'elephant.jpg'img = image.load_img(img_path, target_size=(224, 224))x = image.img_to_array(img)x = np.expand_dims(x, axis=0)x = preprocess_input(x)preds = model.predict(x)## è¿ç§»å­¦ä¹ 1image_input = Input(shape=(224, 224, 3))model = ResNet50(input_tensor=image_input, include_top=True,weights='imagenet')last_layer = model.get_layer('avg_pool').outputx= Flatten(name='flatten')(last_layer)out = Dense(num_classes, activation='softmax', name='output_layer')(x)custom_resnet_model = Model(inputs=image_input,outputs= out)for layer in custom_resnet_model.layers[:-1]: layer.trainable = Falsecustom_resnet_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])## Fine Tuneimage_input = Input(shape=(224, 224, 3))model = ResNet50(weights='imagenet',include_top=False)last_layer = model.output# add a global spatial average pooling layerx = GlobalAveragePooling2D()(last_layer)# add fully-connected &amp; dropout layersx = Dense(512, activation='relu',name='fc-1')(x)x = Dropout(0.5)(x)x = Dense(256, activation='relu',name='fc-2')(x)x = Dropout(0.5)(x)# a softmax layer for 4 classesout = Dense(num_classes, activation='softmax',name='output_layer')(x)# this is the model we will traincustom_resnet_model2 = Model(inputs=model.input, outputs=out)for layer in custom_resnet_model2.layers[:-6]: layer.trainable = False custom_resnet_model2.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy']) å‚è€ƒ Deep Residual Learning for Image Recognition Identity Mappings in Deep Residual Networks Keraså®ç°","categories":[{"name":"æ·±åº¦å­¦ä¹ ","slug":"æ·±åº¦å­¦ä¹ ","permalink":"http://blog.a-stack.com/categories/æ·±åº¦å­¦ä¹ /"},{"name":"æœºå™¨è§†è§‰","slug":"æ·±åº¦å­¦ä¹ /æœºå™¨è§†è§‰","permalink":"http://blog.a-stack.com/categories/æ·±åº¦å­¦ä¹ /æœºå™¨è§†è§‰/"}],"tags":[{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"ç®—æ³•","slug":"ç®—æ³•","permalink":"http://blog.a-stack.com/tags/ç®—æ³•/"},{"name":"æœºå™¨è§†è§‰","slug":"æœºå™¨è§†è§‰","permalink":"http://blog.a-stack.com/tags/æœºå™¨è§†è§‰/"},{"name":"æ–‡çŒ®","slug":"æ–‡çŒ®","permalink":"http://blog.a-stack.com/tags/æ–‡çŒ®/"},{"name":"å›¾åƒåˆ†ç±»","slug":"å›¾åƒåˆ†ç±»","permalink":"http://blog.a-stack.com/tags/å›¾åƒåˆ†ç±»/"}]},{"title":"OpenCV and Python","slug":"OpenCV-and-Python","date":"2018-05-19T14:16:29.000Z","updated":"2018-05-22T07:07:39.842Z","comments":true,"path":"2018/05/19/OpenCV-and-Python/","link":"","permalink":"http://blog.a-stack.com/2018/05/19/OpenCV-and-Python/","excerpt":"æ‘˜è¦ï¼š æœ¬æ–‡æ•´ç†äº†å¸¸ç”¨çš„OpenCVå›¾åƒå¤„ç†æ“ä½œçš„pythonä»£ç ï¼Œä¾¿äºåç»­ä½¿ç”¨è¿‡ç¨‹ä¸­çš„é€ŸæŸ¥ã€‚","text":"æ‘˜è¦ï¼š æœ¬æ–‡æ•´ç†äº†å¸¸ç”¨çš„OpenCVå›¾åƒå¤„ç†æ“ä½œçš„pythonä»£ç ï¼Œä¾¿äºåç»­ä½¿ç”¨è¿‡ç¨‹ä¸­çš„é€ŸæŸ¥ã€‚ æ¦‚è¿°OpenCVï¼š is an image and video processing library with bindings in C++, C, Python, and Java. OpenCV is used for all sorts of image and video analysis, like facial recognition and detection, license plate reading, photo editing, advanced robotic vision, optical character recognition, and a whole lot more. python-OpenCV: OpenCVçš„pythonç‰ˆå®ç° python-OpenCV åªæ˜¯OpenCVéƒ¨åˆ†åŠŸèƒ½çš„å®ç°ï¼Œä¸€ä¸ªå®Œæ•´çš„OpenCVåŒ…å¤§å°è¶…è¿‡3G å›¾åƒ/è§†é¢‘è¯»å†™ å›¾åƒè¯»å†™ 123456789101112import cv2from matplotlib import pyplot as plt#IMREAD_GRAYSCALEï¼ˆ0ï¼‰ï¼ŒIMREAD_COLORï¼ˆ1ï¼‰ï¼ŒIMREAD_UNCHANGEDï¼ˆ-1ï¼‰img = cv2.imread('test.jpg',cv2.IMREAD_GRAYSCALE)cv2.imshow('image',img)cv2.waitKey(0)cv2.destroyAllWindows()plt.imshow(img, cmap = 'gray', interpolation = 'bicubic')# write an imagecv2.imwrite('watchgray.png',img) â€‹ è§†é¢‘æ“ä½œ 123456789101112131415import numpy as npimport cv2cap = cv2.VideoCapture(0) while(True): ret, frame = cap.read() gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) cv2.imshow('frame',gray) if cv2.waitKey(1) &amp; 0xFF == ord('q'): breakcap.release()cv2.destroyAllWindows() ä¿å­˜è§†é¢‘å½•åƒï¼š 123456789101112131415161718import numpy as npimport cv2cap = cv2.VideoCapture(1)fourcc = cv2.VideoWriter_fourcc(*'XVID')out = cv2.VideoWriter('output.avi',fourcc, 20.0, (640,480))while(True): ret, frame = cap.read() gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) out.write(frame) cv2.imshow('frame',gray) if cv2.waitKey(1) &amp; 0xFF == ord('q'): breakcap.release()out.release()cv2.destroyAllWindows() ç”»å›¾ Line cv2.line(img,(0,0),(150,150),(255,255,255),15) â€‹ å¯¹è±¡ï¼Œ èµ·å§‹ç‚¹ï¼Œ ç»“æŸç‚¹ï¼Œ é¢œè‰²ï¼Œ ç²—ç»† rectangle cv2.rectangle(img,(15,25),(200,150),(0,0,255),15) â€‹ å¯¹è±¡;èµ·ç‚¹(x,y); ç»ˆç‚¹(x,y); é¢œè‰²ï¼›ç²—ç»† circle cv2.circle(img,(100,63), 55, (0,255,0), -1) â€‹ ä¸­å¿ƒç‚¹ï¼›åŠå¾„ï¼› é¢œè‰²ï¼› ç²—ç»†ï¼ˆ-1â€”å¡«å……ï¼‰ å¤šè¾¹å½¢ 12345pts = np.array([[10,5],[20,30],[70,20],[50,10]], np.int32)# OpenCV documentation had this code, which reshapes the array to a 1 x 2. I did not # find this necessary, but you may:#pts = pts.reshape((-1,1,2))cv2.polylines(img, [pts], True, (0,255,255), 3) æ·»åŠ æ–‡å­— 123font = cv2.FONT_HERSHEY_SIMPLEXcv2.putText(img,'OpenCV Tuts!',(0,130), font, 1, (200,255,155), 2, cv2.LINE_AA)# èµ·ç‚¹ å¤§å° é¢œè‰² ç²—ç»† å›¾åƒæ“ä½œ12345print(img.shape)print(img.size)print(img.dtype)# å›¾åƒå¡«å……img[100:150,100:150] = [255,255,255] å åŠ å›¾åƒï¼ˆpngå›¾åƒæ•ˆæœä½³ï¼Œè°ƒæ•´ä¸ºsame sizeï¼‰ 123456789101112import cv2import numpy as np# 500 x 250img1 = cv2.imread('3D-Matplotlib.png')img2 = cv2.imread('mainsvmimage.png')add = img1+img2cv2.imshow('add',add)cv2.waitKey(0)cv2.destroyAllWindows() ä¸cv2.add(img1,img2)åŒºåˆ†ï¼Œcv2.add()æ˜¯æ¯ä¸ªåƒç´ å¤§å°çš„æ±‚å’Œï¼›å¯ä»¥é‡‡ç”¨åŠ æƒæ±‚å’Œç­–ç•¥ï¼Œweighted = cv2.addWeighted(img1, 0.6, img2, 0.4, 0) å›¾åƒç»„åˆ(TODO)Threshold123retval, threshold = cv2.threshold(grayscaled, 10, 255, cv2.THRESH_BINARY)# adaptive thresholdth = cv2.adaptiveThreshold(grayscaled, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 115, 1) æ¨¡æ¿åŒ¹é…1234567891011121314151617import cv2 import numpy as npimg = cv2.imread(\"test.jpg\")img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)template = cv2.imread(\"template.png\",0)w, h = template.shaperes = cv2.matchTemplate(img_gray,template,cv2.TM_CCOEFF_NORMED)threshold = 0.8loc = np.where( res &gt;= threshold)for pt in zip(*loc[::-1]): cv2.rectangle(img, pt, (pt[0] + w, pt[1] + h), (0,255,255), 2)cv2.imshow('Detected',img) å…¶å®ƒå‚è€ƒ OpenCV with Python Intro and loading Images tutorial","categories":[{"name":"å·¥å…·","slug":"å·¥å…·","permalink":"http://blog.a-stack.com/categories/å·¥å…·/"},{"name":"æœºå™¨è§†è§‰","slug":"å·¥å…·/æœºå™¨è§†è§‰","permalink":"http://blog.a-stack.com/categories/å·¥å…·/æœºå™¨è§†è§‰/"}],"tags":[{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"å·¥å…·","slug":"å·¥å…·","permalink":"http://blog.a-stack.com/tags/å·¥å…·/"},{"name":"OpenCV","slug":"OpenCV","permalink":"http://blog.a-stack.com/tags/OpenCV/"}]},{"title":"cs231nè¯¾ç¨‹ç¬”è®°:ï¼ˆLecture 6-7ï¼‰Training Neural Networks","slug":"cs231n-lecture-6","date":"2018-05-07T08:50:26.000Z","updated":"2018-05-16T14:00:03.181Z","comments":true,"path":"2018/05/07/cs231n-lecture-6/","link":"","permalink":"http://blog.a-stack.com/2018/05/07/cs231n-lecture-6/","excerpt":"","text":"æ‘˜è¦ï¼š è®¡åˆ’èŠ±ä¸€ä¸ªæœˆçš„æ—¶é—´åˆ·ä¸€éæ–¯å¦ç¦çš„æœºå™¨è§†è§‰è¯¾ç¨‹cs231nï¼Œå¹¶åšç¬”è®°è®°å½•æ¯å¤©å­¦ä¹ åˆ°çš„å†…å®¹ã€‚ æ¦‚è¿°cs231næ˜¯æ–¯å¦ç¦åœ¨æ·±åº¦å­¦ä¹ å’Œæœºå™¨è§†è§‰é¢†åŸŸçš„å…¥é—¨ç»å…¸è¯¾ç¨‹ï¼Œç›¸å…³èµ„æºå¦‚ä¸‹ï¼š è¯¾ç¨‹ä¸»é¡µï¼š http://cs231n.stanford.edu/ è¯¾ç¨‹Notesï¼šhttp://cs231n.github.io/ Lecture 6 Thursday April 19 Training Neural Networks, part I Activation functions, initialization, dropout, batch normalization [slides] Neural Nets notes 1Neural Nets notes 2Neural Nets notes 3tips/tricks: [1], [2], [3] (optional) Deep Learning [Nature] (optional) Discussion Section Friday April 20 Tips and tricks for tuning NNs [slides] Lecture 7 Tuesday April 24 Training Neural Networks, part II Update rules, ensembles, data augmentation, transfer learning [slides] Neural Nets notes 3 Batch Normalization Batch Normalizationçš„è®¡ç®— \\begin{align} \\mu_i = \\frac{1}{m} \\sum_{k \\in S_i} x_k\\\\ \\sigma_i = \\sqrt{\\frac{1}{m}\\sum_{k\\in S_i} (x_k-\\mu_i)^2 + \\epsilon}\\\\ y_i = \\lambda \\hat x_i + \\beta \\end{align}ç”±äºBNä¼šå—åˆ°batch sizeå¤§å°çš„å½±å“ï¼Œå¦‚æœbatch sizeå¤ªå°ï¼Œç®—å‡ºçš„å‡å€¼å’Œæ–¹å·®å°±ä¼šä¸å‡†ç¡®ï¼Œå¤ªå¤§å­˜å‚¨å¯èƒ½ä¸å¤Ÿç”¨ã€‚æ‰€ä»¥è¡ç”Ÿå‡ºäº†å‡ ç§ä¼˜åŒ–è¡¨è¾¾ã€‚ å…¶å®ƒå½’ä¸€åŒ–æ–¹æ³•ä¸BNçš„åŒºåˆ« BatchNormï¼š batchæ–¹å‘åšå½’ä¸€åŒ–ï¼Œè®¡ç®— N*H*W çš„å‡å€¼ï¼› LayerNormï¼š channelæ–¹å‘åšå½’ä¸€åŒ–ï¼Œè®¡ç®—C*H*W çš„å‡å€¼ï¼› InstanceNormï¼š ä¸€ä¸ªchannelå†…åšå½’ä¸€åŒ–ï¼Œè®¡ç®—H*Wçš„å‡å€¼ï¼› GroupNormï¼š å°†Channelæ–¹å‘åˆ†ä¸ºGroupï¼Œç„¶åæ¯ä¸ªGroupå†…åšå½’ä¸€åŒ–ï¼Œè®¡ç®—(C//G)*H*Wçš„å‡å€¼ å½“G=Cæ—¶ï¼ŒGroupNormä¸ºLayerNormï¼Œå½“G=1æ—¶ï¼ŒGroupNormä¸ºInstanceNorm è®­ç»ƒè¿‡ç¨‹çš„ç½‘ç»œä¼˜åŒ–æŠ€å·§ Parammeter tuning is more of an art. ç½‘ç»œä¼˜åŒ–/æå‡ç½‘ç»œæ€§èƒ½æ–¹æ³• è·å–æ›´å¤šè®­ç»ƒæ•°æ® å¢åŠ ç½‘ç»œå¤æ‚åº¦ é€‰æ‹©æ›´å¤šä¼˜åŒ–ç®—æ³• è®­ç»ƒæ›´é•¿æ—¶é—´ ä¿®æ”¹æ‰¹å¤§å° å°è¯•æ­£åˆ™åŒ– æƒè¡¡è¿‡æ‹Ÿåˆ/æ¬ æ‹Ÿåˆ â€¦ å‚æ•°è°ƒä¼˜è¾“å…¥ï¼ˆè¶…å‚ï¼‰ï¼š ç³»ç»Ÿæ¶æ„ å­¦ä¹ ç‡ã€ä¼˜åŒ–ç®—æ³• æ­£åˆ™åŒ–ï¼ˆDropoutï¼‰ æ‰¹å¤„ç†/æ‰¹é‡å½’ä¸€åŒ–ï¼ˆBNï¼‰ è¾“å‡ºï¼ˆåˆ†æå›¾è¡¨ï¼‰ï¼š æŸå¤±æ›²çº¿ æ¢¯åº¦åŸºå‡† å‡†ç¡®ç‡ è®­ç»ƒ/éªŒè¯æ•°æ®é›†æ€§èƒ½ å…¶å®ƒ æ¶æ„é€‰æ‹©ä¸è®¾è®¡ æ¶æ„é€‰æ‹© åˆ†ç±»é—®é¢˜ï¼šAlexNet,VGG, ResNet,DenseNet, â€¦ è¯­ä¹‰åˆ†å‰²ï¼šFCN, Dilated Convolution, Mask RCNN è¯†åˆ«ï¼š Faster-RCNN, YOLO, SSD å›¾åƒç”Ÿæˆï¼š UNet, Dilated Convolution, DCGAN, WGAN â€¦ è¾“å…¥é€‚é… æ•°æ®é›†é€‚é… è¾“å‡ºä»»åŠ¡é€‚é… è¾“å‡ºç»“æœåˆ†æ Lossä¸å˜åŒ–ï¼Œç½‘ç»œæ²¡æœ‰å­¦åˆ°ä»»ä½•ä¿¡æ¯ï¼šæ¢¯åº¦æ²¡æœ‰åº”ç”¨åˆ°æƒé‡ä¸Šï¼Œæˆ–è€…ä¸åŒ¹é… è¿‡æ‹Ÿåˆ ä¸æ”¶æ•›ï¼šè®­ç»ƒæ—¶é—´ä¸è¶³/å­¦ä¹ ç‡è¿‡ä½ æ…¢å¯åŠ¨ æ¢¯åº¦æ›´æ–°æ–¹å‘é”™è¯¯ æ•°æ®æœªæ‰“ä¹± æŸå¤±å‡½æ•°å‡ºç°nanså€¼ï¼šæ¨¡å‹ä¸­æ•°æ®ä¸ç¨³å®š/è¾ƒé«˜çš„å­¦ä¹ ç‡ éªŒè¯é›†æ•ˆæœä¼˜äºè®­ç»ƒé›†ï¼šéªŒè¯é›†å¤ªå°æˆ–åˆ†å¸ƒå¼‚å¸¸ æ­£åˆ™åŒ– DropOutæœ¬è´¨ä¸Šä¹Ÿæ˜¯ä¸€ç§æ¨¡å‹ç»„åˆå­¦ä¹  1234# trainH = np.maximum(0, np.dot(W,X) + b)U = (np.random.rand(*H.shape) &lt; p) / pH *= U â€‹ å‚è€ƒ Fei,Nish, Tips and tricks for tuning NNs","categories":[{"name":"è¯»ä¹¦ç¬”è®°","slug":"è¯»ä¹¦ç¬”è®°","permalink":"http://blog.a-stack.com/categories/è¯»ä¹¦ç¬”è®°/"},{"name":"è¯¾ç¨‹ç¬”è®°","slug":"è¯»ä¹¦ç¬”è®°/è¯¾ç¨‹ç¬”è®°","permalink":"http://blog.a-stack.com/categories/è¯»ä¹¦ç¬”è®°/è¯¾ç¨‹ç¬”è®°/"}],"tags":[{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"æœºå™¨è§†è§‰","slug":"æœºå™¨è§†è§‰","permalink":"http://blog.a-stack.com/tags/æœºå™¨è§†è§‰/"},{"name":"ç¬”è®°","slug":"ç¬”è®°","permalink":"http://blog.a-stack.com/tags/ç¬”è®°/"}]},{"title":"cs231nè¯¾ç¨‹ç¬”è®°:ï¼ˆLecture 5ï¼‰CNNåŸºç¡€","slug":"cs231n-lecture-5","date":"2018-05-03T08:55:26.000Z","updated":"2018-05-16T13:59:54.044Z","comments":false,"path":"2018/05/03/cs231n-lecture-5/","link":"","permalink":"http://blog.a-stack.com/2018/05/03/cs231n-lecture-5/","excerpt":"","text":"æ‘˜è¦ï¼š è®¡åˆ’èŠ±ä¸€ä¸ªæœˆçš„æ—¶é—´åˆ·ä¸€éæ–¯å¦ç¦çš„æœºå™¨è§†è§‰è¯¾ç¨‹cs231nï¼Œå¹¶åšç¬”è®°è®°å½•æ¯å¤©å­¦ä¹ åˆ°çš„å†…å®¹ã€‚ æ¦‚è¿°cs231næ˜¯æ–¯å¦ç¦åœ¨æ·±åº¦å­¦ä¹ å’Œæœºå™¨è§†è§‰é¢†åŸŸçš„å…¥é—¨ç»å…¸è¯¾ç¨‹ï¼Œç›¸å…³èµ„æºå¦‚ä¸‹ï¼š è¯¾ç¨‹ä¸»é¡µï¼š http://cs231n.stanford.edu/ è¯¾ç¨‹Notesï¼šhttp://cs231n.github.io/ Event Type Date Description Course Materials Lecture 5 Tuesday April 17 Convolutional Neural Networks History Convolution and pooling ConvNets outside vision [slides] ConvNet notes Convolutional Neural Network(CNN/ConvNet) æ›´å¤šå†…å®¹å‚è§4 FCN vs CNN CNNçš„å±‚æ¬¡ç»“æ„ The brain view. If youâ€™re a fan of the brain/neuron analogies, every entry in the 3D output volume can also be interpreted as an output of a neuron that looks at only a small region in the input and shares parameters with all neurons to the left and right spatially (since these numbers all result from applying the same filter). Local Connectivity. filter å¤§å°çš„åŒºåŸŸå†…å®¹ï¼Œå·ç§¯å±‚çš„æ¯ä¸ªç¥ç»å…ƒåªä¸å‰ä¸€å±‚filterä¸­çš„ç¥ç»å…ƒä¿æŒè¿æ¥ï¼Œæ·±åº¦ä¸ºä¸Šä¸€å±‚ç½‘ç»œçš„æ·±åº¦ã€‚ å·ç§¯å±‚çš„è¾“å‡ºï¼š \\frac{W - F + 2P}{S} + 1å…¶ä¸­ï¼Œ $W$ ä»£è¡¨è¾“å…¥å±‚å¤§å°ï¼› $F$ filterçš„å¤§å°ï¼› $P$ Zero-Paddingçš„å¤§å°ï¼› $S$ æ»‘åŠ¨çª—å£æ»‘åŠ¨æ­¥é•¿ å½“$S=1$, $P=(F-1)/2$ æ—¶ï¼Œè¾“å…¥è¾“å‡ºç½‘ç»œå…·æœ‰ç›¸åŒçš„å¤§å°ã€‚ å‚æ•°å…±äº«ï¼š å·ç§¯ç¥ç»ç½‘ç»œæ¯ä¸€å±‚å…±äº«åŒä¸€å¥—æƒé‡å‚æ•°ï¼ˆWï¼Œbï¼‰ï¼Œé™ä½å‚æ•°æ€»é‡ã€‚ å…¨éƒ¨å‚æ•°æ•°ç›®ä¸ºï¼š$(F\\cdot F \\cdot D_1 +1)* K$,å…¶ä¸­ $D_1$ ä¸ºä¸Šä¸€å±‚çš„æ·±åº¦ï¼Œ$K$ ä¸ºfilterä¸ªæ•°ã€‚ ç›´è§‚è§£é‡Šï¼Œåœ¨ä¸€ä¸ªå›¾åƒä¸€ä¸ªfilteråŒºåŸŸå­¦åˆ°çš„ç‰¹å¾ï¼ˆæ¯”å¦‚çº¹ç†ï¼‰ï¼Œåœ¨å›¾åƒå…¶å®ƒåœ°æ–¹ç”¨æ¥åŒ¹é…çº¹ç†ç‰¹å¾ä¹Ÿå¥æ•ˆ æ± åŒ–å±‚ ä¸€èˆ¬max poolingå¸¸é‡‡ç”¨çš„å‚æ•°ä¸º$F=3,S=2$ (Overlapping pooling),$F=2, S=2$ (Max Pooling); åå‘ä¼ æ’­æ—¶ï¼Œå¯¹äº$max(x,y)$ å½¢å¼ï¼Œæ¢¯åº¦ä¼ é€’æœ€å¤§çš„æ¿€æ´»å€¼ï¼› ä¸€èˆ¬å¾ˆå°‘ä½¿ç”¨$F \\gt 3$ çš„filter ç›®å‰å¾ˆå¤šæ–°çš„è®ºæ–‡ä¸­å·²ç»å°½é‡é¿å…ä½¿ç”¨æ± åŒ–æ“ä½œï¼Œæ„å»ºå…¨å·ç§¯çš„ç¥ç»ç½‘ç»œæ¶æ„ï¼Œé™¤äº†æœ€åä¸€å±‚é‡‡ç”¨å…¨å±€æ± åŒ–å±‚ã€‚ FCå’ŒCNNå¯ä»¥ç›¸äº’è½¬æ¢ FCè¡¨ç¤ºCNNï¼š ä½¿ç”¨ä¸€ä¸ªå¾ˆå¤§çš„å‚æ•°çŸ©é˜µï¼ŒçŸ©é˜µä¸­å¤šæ•°å•å…ƒä¸º0å°‘æ•°è¡¨å¾æœ¬åœ°è¿æ¥çš„åœ°æ–¹ä¸ºé0ï¼ŒåŒæ—¶å¾ˆå¤šå•å…ƒçš„æƒé‡ç›¸åŒï¼ˆå‚æ•°å…±äº«çš„æè¿°ï¼‰ï¼› CNNè¡¨ç¤ºFCï¼š ä½¿ç”¨Kå±‚çš„1x1å·ç§¯ç½‘ç»œå¯ä»¥æè¿°Kä¸ªèŠ‚ç‚¹çš„FCã€‚ VGG12345678910111213141516171819202122232425INPUT: [224x224x3] memory: 224*224*3=150K weights: 0CONV3-64: [224x224x64] memory: 224*224*64=3.2M weights: (3*3*3)*64 = 1,728CONV3-64: [224x224x64] memory: 224*224*64=3.2M weights: (3*3*64)*64 = 36,864POOL2: [112x112x64] memory: 112*112*64=800K weights: 0CONV3-128: [112x112x128] memory: 112*112*128=1.6M weights: (3*3*64)*128 = 73,728CONV3-128: [112x112x128] memory: 112*112*128=1.6M weights: (3*3*128)*128 = 147,456POOL2: [56x56x128] memory: 56*56*128=400K weights: 0CONV3-256: [56x56x256] memory: 56*56*256=800K weights: (3*3*128)*256 = 294,912CONV3-256: [56x56x256] memory: 56*56*256=800K weights: (3*3*256)*256 = 589,824CONV3-256: [56x56x256] memory: 56*56*256=800K weights: (3*3*256)*256 = 589,824POOL2: [28x28x256] memory: 28*28*256=200K weights: 0CONV3-512: [28x28x512] memory: 28*28*512=400K weights: (3*3*256)*512 = 1,179,648CONV3-512: [28x28x512] memory: 28*28*512=400K weights: (3*3*512)*512 = 2,359,296CONV3-512: [28x28x512] memory: 28*28*512=400K weights: (3*3*512)*512 = 2,359,296POOL2: [14x14x512] memory: 14*14*512=100K weights: 0CONV3-512: [14x14x512] memory: 14*14*512=100K weights: (3*3*512)*512 = 2,359,296CONV3-512: [14x14x512] memory: 14*14*512=100K weights: (3*3*512)*512 = 2,359,296CONV3-512: [14x14x512] memory: 14*14*512=100K weights: (3*3*512)*512 = 2,359,296POOL2: [7x7x512] memory: 7*7*512=25K weights: 0FC: [1x1x4096] memory: 4096 weights: 7*7*512*4096 = 102,760,448FC: [1x1x4096] memory: 4096 weights: 4096*4096 = 16,777,216FC: [1x1x1000] memory: 1000 weights: 4096*1000 = 4,096,000TOTAL memory: 24M * 4 bytes ~= 93MB / image (only forward! ~*2 for bwd)TOTAL params: 138M parameters å­˜å‚¨ç©ºé—´çš„ä½¿ç”¨ä¸»è¦æ˜¯å‰é¢å‡ å±‚ä¸­é—´å˜é‡çš„å­˜å‚¨ï¼›æƒé‡æ•°ç›®ä¸»è¦é›†ä¸­åœ¨åé¢å‡ ä¸ªå…¨è”é€šç½‘ç»œä¸­ã€‚ å­˜å‚¨ç©ºé—´çš„è®¡ç®—ï¼šæ•°æ®ä¸ªæ•° x 4(bytes) å‚è€ƒ 4. cs231n notes: CNN &#8617;","categories":[{"name":"è¯»ä¹¦ç¬”è®°","slug":"è¯»ä¹¦ç¬”è®°","permalink":"http://blog.a-stack.com/categories/è¯»ä¹¦ç¬”è®°/"},{"name":"è¯¾ç¨‹ç¬”è®°","slug":"è¯»ä¹¦ç¬”è®°/è¯¾ç¨‹ç¬”è®°","permalink":"http://blog.a-stack.com/categories/è¯»ä¹¦ç¬”è®°/è¯¾ç¨‹ç¬”è®°/"}],"tags":[{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"æœºå™¨è§†è§‰","slug":"æœºå™¨è§†è§‰","permalink":"http://blog.a-stack.com/tags/æœºå™¨è§†è§‰/"},{"name":"ç¬”è®°","slug":"ç¬”è®°","permalink":"http://blog.a-stack.com/tags/ç¬”è®°/"}]},{"title":"cs231nè¯¾ç¨‹ç¬”è®°ï¼šï¼ˆLecture 4ï¼‰ç¥ç»ç½‘ç»œåŸºç¡€","slug":"cs231n-lecture-4","date":"2018-05-03T08:52:26.000Z","updated":"2018-05-16T13:59:45.204Z","comments":false,"path":"2018/05/03/cs231n-lecture-4/","link":"","permalink":"http://blog.a-stack.com/2018/05/03/cs231n-lecture-4/","excerpt":"","text":"æ‘˜è¦ï¼š è®¡åˆ’èŠ±ä¸€ä¸ªæœˆçš„æ—¶é—´åˆ·ä¸€éæ–¯å¦ç¦çš„æœºå™¨è§†è§‰è¯¾ç¨‹cs231nï¼Œå¹¶åšç¬”è®°è®°å½•æ¯å¤©å­¦ä¹ åˆ°çš„å†…å®¹ã€‚ æ¦‚è¿°cs231næ˜¯æ–¯å¦ç¦åœ¨æ·±åº¦å­¦ä¹ å’Œæœºå™¨è§†è§‰é¢†åŸŸçš„å…¥é—¨ç»å…¸è¯¾ç¨‹ï¼Œç›¸å…³èµ„æºå¦‚ä¸‹ï¼š è¯¾ç¨‹ä¸»é¡µï¼š http://cs231n.stanford.edu/ è¯¾ç¨‹Notesï¼šhttp://cs231n.github.io/ Event Type Date Description Course Materials Lecture 4 Thursday April 12 Introduction to Neural Networks BackpropagationMulti-layer PerceptronsThe neural viewpoint [slides] [backprop notes][linear backprop example][derivatives notes] (optional) [Efficient BackProp] (optional)related: [1], [2], [3] (optional) Discussion Section Friday April 13 Backpropagation [slides] ç¥ç»ç½‘ç»œ æ›´å¤šå†…å®¹å‚è§123 è¿™è¯¾ç¨‹çš„å¤§å¤šæ•°å†…å®¹ä¹Ÿç»¼åˆäº†Lecture 6å’ŒLecutre 7çš„å†…å®¹ï¼Œæ‰€ä»¥é‚£ä¸¤èŠ‚è¯¾ä¸å•ç‹¬å†™åšå®¢äº†ã€‚ ä¸€ä¸ªäººçš„ç¥ç»ç³»ç»Ÿå¤§æ¦‚æœ‰860äº¿ä¸ªç¥ç»å…ƒï¼Œå½¢æˆ$10^{14}-10^{15}$ ä¸ªç¥ç»å…ƒé“¾æ¥ï¼› Coarse model. Itâ€™s important to stress that this model of a biological neuron is very coarse: For example, there are many different types of neurons, each with different properties. The dendrites in biological neurons perform complex nonlinear computations. The synapses are not just a single weight, theyâ€™re a complex non-linear dynamical system. The exact timing of the output spikes in many systems is known to be important, suggesting that the rate code approximation may not hold. Due to all these and many other simplifications, be prepared to hear groaning sounds from anyone with some neuroscience background if you draw analogies between Neural Networks and real brains. See this review (pdf), or more recently this review if you are interested. æ¿€æ´»å‡½æ•° Sigmoidï¼š $\\sigma(x) = 1 / (1 + e^{-x})$ 1)æ¢¯åº¦é¥±å’Œï¼›2)å‡½æ•°å½¢å¼ä¸æ˜¯ä¸­å¿ƒå¯¹ç§°çš„ï¼ˆè¿™ä¸ªç‰¹æ€§ä¼šå¯¼è‡´åé¢ç½‘ç»œå±‚çš„è¾“å…¥ä¹Ÿä¸æ˜¯é›¶ä¸­å¿ƒçš„ï¼Œè¿›è€Œå½±å“æ¢¯åº¦ä¸‹é™çš„è¿ä½œï¼‰ï¼› Tanh: $\\tanh(x) = 2 \\sigma(2x) -1$ 1)æ¢¯åº¦é¥±å’Œï¼›2ï¼‰ä¸­å¿ƒå¯¹ç§°[-1,1]ï¼› ReLU: $f(x) = \\max(0, x)$ 1)çº¿æ€§éé¥±å’Œçš„å½¢å¼ä½¿å¾—å…¶æ”¶æ•›é€Ÿåº¦æ˜¯Tanhçš„6å€ï¼› 2ï¼‰è®¡ç®—ä»£ä»·ä½ï¼›3ï¼‰éš¾è®­ç»ƒï¼Œå®¹æ˜“é™·å…¥â€æ­»åŒºâ€ï¼Œéœ€è¦ä¸¥æ ¼é…ç½®åˆé€‚çš„å­¦ä¹ ç‡ï¼› Leaky ReLUï¼š $f(x) = \\mathbb{1}(x &lt; 0) (\\alpha x) + \\mathbb{1}(x&gt;=0) (x)$ å¦ä¸€ç§æ³›åŒ–å½¢åŠ¿ä¸ºå‚æ•°ReLU å¦ä¸€ç§ELU Maxout: $\\max(w_1^Tx+b_1, w_2^Tx + b_2)$ ReLUå’ŒLeaky ReLUæ˜¯å…¶ç‰¹ä¾‹ï¼› å…³äºç½‘ç»œè§„æ¨¡å¤§å° ä¸€èˆ¬æµ…å±‚ç¥ç»ç½‘ç»œè®­ç»ƒè¿‡ç¨‹ä¸­å®¹æ˜“é™·å…¥å±€éƒ¨æå°å€¼ï¼Œå¾ˆéš¾è®­ç»ƒï¼› æ‰€ä»¥åŠæ—¶è¿‡æ‹Ÿåˆï¼Œä¹Ÿå°½é‡ä¸é‡‡ç”¨è¿‡å°çš„ç¥ç»ç½‘ç»œï¼ˆå¯ä»¥é‡‡ç”¨å…¶å®ƒæ‰‹æ®µå¤„ç†è¿‡æ‹Ÿåˆé—®é¢˜ï¼‰ æ•°æ®é¢„å¤„ç† å‡å€¼å¤„ç†ï¼ˆä¸­å¿ƒåŒ–ï¼‰ï¼šX -= np.mean(X, axis = 0) å½’ä¸€åŒ–ï¼šX /= np.std(X, axis = 0) ä½¿ç”¨å½’ä¸€åŒ–éœ€è¦æ³¨æ„ï¼š åªæœ‰åœ¨ä¸åŒå˜é‡çš„å¤§å°å¯¹äºè¾“å‡ºåŒç­‰é‡è¦çš„æƒ…å†µä¸‹é‡‡ç”¨å½’ä¸€åŒ–ï¼›å›¾åƒä¸­ç”±äºæ‰€æœ‰å˜é‡éƒ½å·²ç»åœ¨åŒºé—´[0,255]èŒƒå›´ä¹‹ä¸­ï¼Œæ‰€ä»¥æ²¡æœ‰å¿…è¦é‡‡ç”¨å½’ä¸€åŒ– PCAå’Œç™½åŒ– 1234567891011# Assume input data matrix X of size [N x D]X -= np.mean(X, axis = 0) # zero-center the data (important)cov = np.dot(X.T, X) / X.shape[0] # get the data covariance matrixUï¼ŒS, V = np.linalg.svd(cov)Xrot = np.dot(X, U) # decorrelate the data# 1. PCAXrot_reduced = np.dot(X, U[:,:100]) # Xrot_reduced becomes [N x 100]#2 . whiten the data:# divide by the eigenvalues (which are square roots of the singular values)Xwhite = Xrot / np.sqrt(S + 1e-5) Uä¸ºæ­£äº¤ç‰¹å¾å‘é‡ï¼Œæˆ‘ä»¬å¯ä»¥åªé€‰æ‹©top Né‡è¦çš„ç‰¹å¾å‘é‡æ¥è¿›è¡Œé™ç»´å¤„ç†ï¼› PCAï¼š ä¸‹å›¾æ‰€ç¤ºï¼Œæ•°æ®ä¸­å¿ƒå¯¹é½ï¼Œä»¥ç‰¹å¾å‘é‡æ–¹å‘æ—‹è½¬å¯¹é½ï¼› ç™½åŒ–æ“ä½œï¼šå¦‚æœè¾“å…¥æ•°æ®ä¸ºå¤šå…ƒé«˜æ–¯åˆ†å¸ƒï¼Œç™½åŒ–ç»“æœä¸ºé«˜æ–¯é›¶å‡å€¼ç‹¬ç«‹åæ–¹å·®çŸ©é˜µ ä»¥CIFAR-10ä¸ºä¾‹ï¼Œå¤„ç†ä¹‹åæ•ˆæœè§ä¸‹å›¾ï¼Œç¬¬2å¼ ä¸ºå–3072ä¸ªç‰¹å¾ä¸­å‰144ä¸ªç‰¹å¾ï¼š æ‰€æœ‰é¢„å¤„ç†è¿‡ç¨‹ä»…ä½œç”¨åˆ°è®­ç»ƒæ•°æ®ä¸­ï¼Œå¹¶è®°å½•ç›¸å…³å‚æ•°ï¼ŒéªŒè¯æ•°æ®å’Œæµ‹è¯•æ•°æ®é‡‡ç”¨è®­ç»ƒæ•°æ®çš„ç»“æœè¿›è¡Œé¢„å¤„ç† å‚æ•°åˆå§‹åŒ– W = 0.01* np.random.randn(D,H) w = np.random.randn(n) / sqrt(2.0/n) randn äº§ç”Ÿé›¶å‡å€¼å•ä½æ–¹å·®é«˜æ–¯åˆ†å¸ƒwå‚æ•°ä¸èƒ½å…¨éƒ¨åˆå§‹åŒ–ä¸ºé›¶ï¼ˆå¯¹ç§°æ•ˆåº”å¯¼è‡´ç½‘ç»œæ¿€æ´»ä¸æ›´æ–°ï¼‰ï¼Œbiaså‚æ•°ä¸€èˆ¬åˆå§‹åŒ–ä¸ºé›¶ç¬¬äºŒä¸ªå…¬å¼ä¸ºäº†è§£å†³è¾“å‡ºéšnçš„å¢åŠ è€Œæ¯”ä¾‹å¢åŠ çš„é—®é¢˜ \\begin{align} \\text{Var}(s) &= \\text{Var}(\\sum_i^n w_ix_i) \\\\ &= \\sum_i^n \\text{Var}(w_ix_i) \\\\ &= \\sum_i^n [E(w_i)]^2\\text{Var}(x_i) + E[(x_i)]^2\\text{Var}(w_i) + \\text{Var}(x_i)\\text{Var}(w_i) \\\\ &= \\sum_i^n \\text{Var}(x_i)\\text{Var}(w_i) \\\\ &= \\left( n \\text{Var}(w) \\right) \\text{Var}(x) \\end{align}æ­£åˆ™åŒ– L2æ­£åˆ™åŒ–å¯¹äºå³°å€¼æƒé‡å¢åŠ æ¯”è¾ƒå¤§çš„æƒ©ç½šï¼Œå¯¹å¹³æ»‘çš„æƒé‡çŸ©é˜µæ›´åŠ å‹å¥½ï¼› L1æ­£åˆ™åŒ–çš„ä¸€ä¸ªæ•ˆæœæ˜¯ä½¿å¾—è¾“å…¥å‚æ•°ç¨€ç–åŒ–ï¼Œä»è€Œè¿‡æ»¤è¾“å…¥ä¸­çš„å™ªå£°æ•°æ®ï¼› æœ€å¤§åŸºå‡†é—¨é™ï¼š$\\Vert \\vec{w} \\Vert_2 &lt; c$ Dropout: åœ¨é¢„æµ‹é˜¶æ®µä¸è¦ä½¿ç”¨ inverted dropout ä¸€èˆ¬ $p=0.5$ 12345678910111213141516171819202122232425\"\"\" Inverted Dropout: Recommended implementation example.We drop and scale at train time and don't do anything at test time.\"\"\"p = 0.5 # probability of keeping a unit active. higher = less dropoutdef train_step(X): # forward pass for example 3-layer neural network H1 = np.maximum(0, np.dot(W1, X) + b1) U1 = (np.random.rand(*H1.shape) &lt; p) / p # first dropout mask. Notice /p! H1 *= U1 # drop! H2 = np.maximum(0, np.dot(W2, H1) + b2) U2 = (np.random.rand(*H2.shape) &lt; p) / p # second dropout mask. Notice /p! H2 *= U2 # drop! out = np.dot(W3, H2) + b3 # backward pass: compute gradients... (not shown) # perform parameter update... (not shown) def predict(X): # ensembled forward pass H1 = np.maximum(0, np.dot(W1, X) + b1) # no scaling necessary H2 = np.maximum(0, np.dot(W2, H1) + b2) out = np.dot(W3, H2) + b3 ä»£ä»·å‡½æ•°ï¼ˆdata lossï¼‰ åˆ†ç±»é—®é¢˜ SVMä»£ä»·å‡½æ•°(åˆé¡µæŸå¤±å‡½æ•°) L_i = \\sum_{j\\neq y_i} \\max(0, f_j - f_{y_i} + 1) äº¤å‰ç†µæŸå¤±å‡½æ•° L_i = -\\log\\left(\\frac{e^{f_{y_i}}}{ \\sum_j e^{f_j} }\\right) å½“åˆ†ç±»æ•°ç›®ç‰¹åˆ«å¤§æ—¶ï¼Œå¯é‡‡ç”¨å±‚æ¬¡Softmax å¤šå±æ€§åˆ†ç±» å¦‚æœä¸€ä¸ªåˆ†ç±»ç›®æ ‡å¯¹åº”å¤šä¸ªæ­£ç¡®çš„ç»“æœï¼Œæ¯”å¦‚å¯¹ä¸€å¼ å›¾ç‰‡åˆ†ç±»ï¼Œå¯èƒ½åŒæ—¶æœ‰å¤šä¸ªæ­£ç¡®æ ‡ç­¾ã€‚å¯ä»¥å¯¹æ¯ä¸ªå±æ€§æ„å»ºä¸€ä¸ªäºŒå…ƒåˆ†ç±»å™¨ï¼š L_i = \\sum_j \\max(0, 1 - y_{ij} f_j)â€‹ å…¶ä¸­ï¼Œjä¸ºæŸä¸ªåˆ†ç±»ï¼Œ$y_{ij}$ ä¸º+1æˆ–-1ï¼Œè¡¨ç¤ºç¬¬iä¸ªæ ·æœ¬æ˜¯å¦å«æœ‰ç¬¬jä¸ªå±æ€§ï¼›$f_i$ ä¸ºæ­£ä»£è¡¨é¢„æµ‹æ­£ç¡®ï¼› â€‹ ç¬¬äºŒç§æ–¹æ³•æ˜¯å¯¹æ¯ä¸ªå±æ€§åº”ç”¨é€»è¾‘å›å½’åˆ†ç±»å™¨ï¼š L_i = \\sum_j y_{ij} \\log(\\sigma(f_j)) + (1 - y_{ij}) \\log(1 - \\sigma(f_j))â€‹ $\\partial{Li} / \\partial{f_j} = y{ij} - \\sigma(f_j)$ã€‚ å›å½’é—®é¢˜ L2: $L_i = \\Vert f - y_i \\Vert_2^2$ â€‹ L1: $L_i = \\Vert f - y_i \\Vert_1 = \\sum_j \\mid f_j - (y_i)_j \\mid$ â€‹ è®­ç»ƒ3æ¢¯åº¦æ ¡éªŒ \\frac{df(x)}{dx} = \\frac{f(x + h) - f(x - h)}{2h} \\hspace{0.1in} hå¯ä»¥è®¾ç½®ä¸º1e-5 å¯ä»¥ä½¿ç”¨å¦‚ä¸‹å€¼æ¥åˆ¤æ–­æ ¡éªŒç»“æœï¼š \\frac{\\mid f'_a - f'_n \\mid}{\\max(\\mid f'_a \\mid, \\mid f'_n \\mid)} relative error &gt; 1e-2 usually means the gradient is probably wrong 1e-2 &gt; relative error &gt; 1e-4 should make you feel uncomfortable 1e-4 &gt; relative error is usually okay for objectives with kinks. But if there are no kinks (e.g. use of tanh nonlinearities and softmax), then 1e-4 is too high. 1e-7 and less you should be happy. ç½‘ç»œå±‚æ•°è¶Šå¤šï¼Œç›¸å¯¹è¯¯å·®å€¼è¶Šå¤§ è¿›è¡Œæ¢¯åº¦æ ¡éªŒï¼Œå…³é—­dropoutã€æ•°æ®æ”¾å¤§(æˆ–ä½¿ç”¨random seed) Sanity Checks Losså‡½æ•°çš„åˆå§‹åŒ–è¾“å‡ºå€¼æ˜¯å¦åˆç†ï¼› å¢åŠ æ­£åˆ™åŒ–å‚æ•°ï¼Œlossæ˜¯å¦å¢åŠ  ä½¿ç”¨å°æ•°æ®é›†æµ‹è¯•æ˜¯å¦èƒ½å¤Ÿè¾¾åˆ°æ•°æ®è¿‡æ‹Ÿåˆï¼ˆé›¶Losså€¼ï¼‰ æ³¨æ„å…³é—­æ­£åˆ™åŒ– è®­ç»ƒè¿‡ç¨‹ç›‘æµ‹ ä»£ä»·å‡½æ•° è®­ç»ƒ/éªŒè¯é›†å‡†ç¡®ç‡ æ›´æ–°å‚æ•°æ¯”ä¾‹ A rough heuristic is that this ratio should be somewhere around 1e-3. If it is lower than this then the learning rate might be too low. If it is higher then the learning rate is likely too high. â€‹ 123456# assume parameter vector W and its gradient vector dWparam_scale = np.linalg.norm(W.ravel())update = -learning_rate*dW # simple SGD updateupdate_scale = np.linalg.norm(update.ravel())W += update # the actual updateprint update_scale / param_scale # want ~1e-3 è¶…å‚ä¼˜åŒ– learning_rate = 10 ** uniform(-6, 1) random serach &gt; grid search æ¨¡å‹ç»„åˆ Same model, different initializations. Use cross-validation to determine the best hyperparameters, then train multiple models with the best set of hyperparameters but with different random initialization. The danger with this approach is that the variety is only due to initialization. Top models discovered during cross-validation. Use cross-validation to determine the best hyperparameters, then pick the top few (e.g. 10) models to form the ensemble. This improves the variety of the ensemble but has the danger of including suboptimal models. In practice, this can be easier to perform since it doesnâ€™t require additional retraining of models after cross-validation Different checkpoints of a single model. If training is very expensive, some people have had limited success in taking different checkpoints of a single network over time (for example after every epoch) and using those to form an ensemble. Clearly, this suffers from some lack of variety, but can still work reasonably well in practice. The advantage of this approach is that is very cheap. Running average of parameters during training. Related to the last point, a cheap way of almost always getting an extra percent or two of performance is to maintain a second copy of the networkâ€™s weights in memory that maintains an exponentially decaying sum of previous weights during training. This way youâ€™re averaging the state of the network over last several iterations. You will find that this â€œsmoothedâ€ version of the weights over last few steps almost always achieves better validation error. The rough intuition to have in mind is that the objective is bowl-shaped and your network is jumping around the mode, so the average has a higher chance of being somewhere nearer the mode. åå‘ä¼ æ’­ Cache forward pass variables. To compute the backward pass it is very helpful to have some of the variables that were used in the forward pass. In practice you want to structure your code so that you cache these variables, and so that they are available during backpropagation. If this is too difficult, it is possible (but wasteful) to recompute them. Gradients add up at forks. The forward expression involves the variables x,y multiple times, so when we perform backpropagation we must be careful to use += instead of = to accumulate the gradient on these variables (otherwise we would overwrite it). This follows the multivariable chain rule in Calculus, which states that if a variable branches out to different parts of the circuit, then the gradients that flow back to it will add. å®ç° &lt;ä»£ç &gt; é…åˆAssignment 1ï¼š Implement a Neural Networkæ•´ç†ä¸€ä¸ªä»å¤´è®­ç»ƒ2å±‚å…¨è”é€šç½‘ç»œçš„ä¾‹å­ã€‚ ç½‘ç»œç»“æ„ï¼ˆåªæœ‰ä¸€ä¸ªéšå±‚çš„å…¨è”åŒç¥ç»ç½‘ç»œï¼‰,å…¶ä¸­è¾“å…¥è®­ç»ƒæ ·æœ¬ä¸ºX (N x D), ç¬¬ä¸€ä¸ªéšå±‚ç”±Hä¸ªèŠ‚ç‚¹ç»„æˆï¼Œè¾“å‡ºå±‚ç”±Cä¸ªèŠ‚ç‚¹ç»„æˆï¼š 12input - fully connected layer - ReLU - fully connected layer - softmaxï¼ˆN,Dï¼‰ H C å„å‚æ•°çš„å¤§å°å¦‚ä¸‹ï¼š input: X (N x D) W1 (H x D) ; b1 (H,) W2 (C x H); b2 (C,) å‚æ•°åˆå§‹åŒ– 12345678H = 100C = 10N,D = X.shapeW1 = std * np.random.randn(input_size, hidden_size)b1 = np.zeros(hidden_size)W2 = std * np.random.randn(hidden_size, output_size)b2 = np.zeros(output_size) å‰å‘ä¼ æ’­ï¼Œè®¡ç®—å¾—åˆ†å‡½æ•°å’Œä»£ä»·å‡½æ•° hiddenLayer = ReLU(X*W1 + b1) \\\\ ReLU(x) = \\max(0, x) scores = hidden\\_layer * W2 + b212hidden_layer = np.maximum(0, np.dot(X, W1) + b1) # N x Hsocres = np.dot(hidden_layer, W2) + b2 # N x C ä»£ä»·å‡½æ•°ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼š L_i = -\\log\\left(\\frac{e^{f_{y_i}}}{ \\sum_j e^{f_j} }\\right) \\hspace{0.5in} \\text{or equivalently} \\hspace{0.5in} L_i = -f_{y_i} + \\log\\sum_j e^{f_j}123456exp_scores = np.exp(scores)probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)correct_logprobs = -np.log(probs[range(N), y])loss = np.sum(correct_logprobs) / Nloss += 0.5*reg*(np.sum(W1*W1) + np.sum(W2*W2)) åå‘ä¼ æ’­ï¼Œè®¡ç®—æ¢¯åº¦ æ¢¯åº¦çš„è®¡ç®—åˆ©ç”¨åå‘ä¼ æ’­ï¼Œä»åå¾€å‰é€æ­¥æ¨å¯¼ï¼š é¦–å…ˆè®¡ç®—dscores \\begin{equation} \\frac{\\partial L}{\\partial scores} = \\left\\{ \\begin{array}{lr} -1 + \\frac{e^{\\hat f_{y_i}}}{\\sum_j e^{f_j}}, & j=i\\\\ \\frac{e^{\\hat f_{y_i}}}{\\sum_j e^{f_j}}, & j \\neq i \\end{array} \\right. \\end{equation}123dscores = probsdscores[range(N), y] -=1dscores /= N dW2 = H^T*dscores + 2\\lambda*W2 \\\\ db2 = dscores 12dW2 = np.dot(h1.T, dscores) + 2*reg * W2db2 = np.sum(dscores, axis=0) æ¥ç€è®¡ç®—éšå±‚çš„åå¯¼,å…¶ä¸­æ¿€æ´»å‡½æ•°ç”±äºä½¿ç”¨ReLUï¼Œåœ¨$x&lt;0$æ—¶ï¼Œå¯¼æ•°ä¸º0 12345dh1 = np.dot(dscores, W2.T)dh1[h1 &lt;= 0] = 0dW1 = np.dot(X.T, dh1) + 2*reg * W1db1 = np.sum(dh1, axis=0) å…¶å®ƒ å­¦ä¹ ç‡çš„è®¾è®¡ä¸€èˆ¬åœ¨[1e-3, 1e-5],10**uniform(-3,-6) å‚è€ƒ 1. cs231n notes: Neural Network &#8617; 2. cs231n notes: Setting up the Data and Loss &#8617; 3. cs231n notes: Learning and Evaluation &#8617;","categories":[{"name":"è¯»ä¹¦ç¬”è®°","slug":"è¯»ä¹¦ç¬”è®°","permalink":"http://blog.a-stack.com/categories/è¯»ä¹¦ç¬”è®°/"},{"name":"è¯¾ç¨‹ç¬”è®°","slug":"è¯»ä¹¦ç¬”è®°/è¯¾ç¨‹ç¬”è®°","permalink":"http://blog.a-stack.com/categories/è¯»ä¹¦ç¬”è®°/è¯¾ç¨‹ç¬”è®°/"}],"tags":[{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"æœºå™¨è§†è§‰","slug":"æœºå™¨è§†è§‰","permalink":"http://blog.a-stack.com/tags/æœºå™¨è§†è§‰/"},{"name":"ç¬”è®°","slug":"ç¬”è®°","permalink":"http://blog.a-stack.com/tags/ç¬”è®°/"}]},{"title":"cs231nè¯¾ç¨‹ç¬”è®°:ï¼ˆLecture 3ï¼‰çº¿æ€§åˆ†ç±»å™¨å’Œä¼˜åŒ–æ–¹æ³•","slug":"cs231n-lecture-3","date":"2018-05-03T08:51:26.000Z","updated":"2018-05-16T13:59:35.315Z","comments":false,"path":"2018/05/03/cs231n-lecture-3/","link":"","permalink":"http://blog.a-stack.com/2018/05/03/cs231n-lecture-3/","excerpt":"æ‘˜è¦ï¼š è®¡åˆ’èŠ±ä¸€ä¸ªæœˆçš„æ—¶é—´åˆ·ä¸€éæ–¯å¦ç¦çš„æœºå™¨è§†è§‰è¯¾ç¨‹cs231nï¼Œå¹¶åšç¬”è®°è®°å½•æ¯å¤©å­¦ä¹ åˆ°çš„å†…å®¹ã€‚","text":"æ‘˜è¦ï¼š è®¡åˆ’èŠ±ä¸€ä¸ªæœˆçš„æ—¶é—´åˆ·ä¸€éæ–¯å¦ç¦çš„æœºå™¨è§†è§‰è¯¾ç¨‹cs231nï¼Œå¹¶åšç¬”è®°è®°å½•æ¯å¤©å­¦ä¹ åˆ°çš„å†…å®¹ã€‚ æ¦‚è¿°cs231næ˜¯æ–¯å¦ç¦åœ¨æ·±åº¦å­¦ä¹ å’Œæœºå™¨è§†è§‰é¢†åŸŸçš„å…¥é—¨ç»å…¸è¯¾ç¨‹ï¼Œç›¸å…³èµ„æºå¦‚ä¸‹ï¼š è¯¾ç¨‹ä¸»é¡µï¼š http://cs231n.stanford.edu/ è¯¾ç¨‹Notesï¼šhttp://cs231n.github.io/ Event Type Date Description Course Materials Lecture 3 Tuesday April 10 Loss Functions and Optimization Linear classification IIHigher-level representations, image featuresOptimization, stochastic gradient descent [slides] [linear classification notes][optimization notes] çº¿æ€§åˆ†ç±»å™¨ 2 Interpretation of linear classifiers as template matching. Another interpretation for the weights WW is that each row of WW corresponds to a template (or sometimes also called a prototype) for one of the classes. The score of each class for an image is then obtained by comparing each template with the image using an inner product (or dot product) one by one to find the one that â€œfitsâ€ best. With this terminology, the linear classifier is doing template matching, where the templates are learned. Another way to think of it is that we are still effectively doing Nearest Neighbor, but instead of having thousands of training images we are only using a single image per class (although we will learn it, and it does not necessarily have to be one of the images in the training set), and we use the (negative) inner product as the distance instead of the L1 or L2 distance. çº¿æ€§åˆ†ç±»å™¨æœ¬è´¨ä¸Šå¯ä»¥ç†è§£ä¸ºä¸€ç§æ¨¡æ¿åŒ¹é…ç®—æ³•ï¼ŒåŒ¹é…ä¸åˆ†ç±»æ¨¡æ¿æœ€ç›¸è¿‘çš„æ¨¡æ¿ï¼Œä½†ç”±äºçº¿æ€§åˆ†ç±»å™¨çš„ç®€å•æ€§è´¨ï¼Œå¯¼è‡´æ¯ä¸ªç±»æœ€ç»ˆåªèƒ½å­¦ä¹ åˆ°ä¸€ä¸ªæ¨¡æ¿ï¼Œå¦‚æœç›®æ ‡ç±»åˆ«æœ‰è¾ƒå¤§çš„å·®å¼‚ï¼Œå°±éœ€è¦æŠŠè¿™äº›å·®å¼‚å¹³å‡åŒ–ã€‚ï¼ˆè¿™ä¹Ÿæ˜¯ç¥ç»ç½‘ç»œå±‚æ¬¡ç‰¹æ€§çš„ä¼˜è¶Šæ€§ï¼‰ ä»£ä»·å‡½æ•°å¤šåˆ†ç±»SVMä»£ä»·å‡½æ•°5SVMçš„ç›®æ ‡å‡½æ•°å®šä¹‰ï¼š \\begin{equation} \\min_{ {w},\\xi_n}\\frac{1}{2} {w}^T {w}+C\\sum_{n=1}^N\\xi_n \\\\ s.t. {w}^T {x}_ny_n\\ge1-\\xi_n \\ \\forall n \\\\ \\xi_n \\ge 0 \\ \\forall n \\end{equation}ä¸ºè®¡ç®—æ–¹ä¾¿ï¼Œå…¶ä¸­åç§»é‡å·²ç»è¢«åŒ…å«åœ¨æƒé‡ä¹‹ä¸­ã€‚ ä¸Šè¿°é—®é¢˜çš„ä¼˜åŒ–é—®é¢˜å¯¹ç­‰å¦‚ä¸‹é—®é¢˜(L1-SVM)ï¼š \\min_{\\bold{w}}\\frac{1}{2}\\bold{w}^T\\bold{w}+C\\sum_{n=1}^N \\max(1-\\bold{w}^T \\bold{x_n}y_n, 0)å’ŒL2-SVMï¼š \\min_{\\bold{w}}\\frac{1}{2}\\bold{w}^T\\bold{w}+C\\sum_{n=1}^N \\max(1-\\bold{w}^T \\bold{x_n}y_n, 0)^2å¯¹äºç¬¬iä¸ªæ ·æœ¬ï¼Œå¤šåˆ†ç±»SVMä»£ä»·å‡½æ•°å®šä¹‰ä¸ºï¼š L_i = \\sum_{j\\neq y_i} \\max(0, s_j - s_{y_i} + \\Delta) åˆé¡µæŸå¤±å‡½æ•°ï¼ˆhinge lossï¼‰ï¼Œä¸€èˆ¬æˆ‘ä»¬ä»¤$\\Delta =1$ å…¶ä¸­$s_{y_i}$ ä¸ºé¢„æµ‹å€¼ $j \\neq y_i$ çš„æ„æ€æ˜¯åªæœ‰é”™è¯¯çš„åˆ†ç±»æ‰å åŠ æŸå¤±ï¼Œæ­£ç¡®çš„åˆ†ç±»ä¸å¯¹æŸå¤±äº§ç”Ÿå½±å“ å¸¦æ­£åˆ™åŒ–çš„æŸå¤±å‡½æ•° L = \\underbrace{ \\frac{1}{N} \\sum_i L_i }_\\text{data loss} + \\underbrace{ \\lambda R(W) }_\\text{regularization loss} L = \\frac{1}{N} \\sum_i \\sum_{j\\neq y_i} \\left[ \\max(0, f(x_i; W)_j - f(x_i; W)_{y_i} + \\Delta) \\right] + \\lambda \\sum_k\\sum_l W_{k,l}^2 Note that biases do not have the same effect since, unlike the weights, they do not control the strength of influence of an input dimension. Therefore, it is common to only regularize the weights $W$ but not the biases $b$. $\\Delta=1.0$ å³å¯ï¼Œç”±äºæƒé‡å¯ä»¥æ¯”ä¾‹è°ƒèŠ‚ï¼Œæ‰€ä»¥å®é™…ä¸Š$\\Delta$ ç­‰äº1å’Œ100æ„ä¹‰æ˜¯ä¸€æ ·çš„ï¼› ä¸SVMçº¿æ€§åˆ†ç±»å™¨å…³ç³» SVMçº¿æ€§åˆ†ç±»å™¨æ˜¯å¤šåˆ†ç±»çš„ä¸€ä¸ªç‰¹ä¾‹ï¼Œ L_i = C \\max(0, 1 - y_i w^Tx_i) + R(W)[å¼•ç”³é˜…è¯»]SVM4 å•ç‹¬æ‘˜æˆä¸€ç¯‡åšæ–‡å§ï¼Œè¦æƒ³å½»åº•ææ¸…æ¥šSVMå†…å®¹å®åœ¨æ˜¯æœ‰ç‚¹å¤š Softmax åˆ†ç±»å™¨åœ¨Softmaxä¸­ä½¿ç”¨äº¤å‰ç†µ(cross-entropy loss)æŸå¤±å‡½æ•°ï¼Œ L_i = -\\log\\left(\\frac{e^{f_{y_i}}}{ \\sum_j e^{f_j} }\\right) \\hspace{0.5in} \\text{or equivalently} \\hspace{0.5in} L_i = -f_{y_i} + \\log\\sum_j e^{f_j}å…¶ä¸­å‡½æ•°$f_j(z) = \\frac{e^{z_j}}{\\sum_k e^{z_k}}$ ä¸ºSoftmaxå‡½æ•°,ç»™å‡ºäº†åˆ†ç±»ç»“æœçš„æ¦‚ç‡åˆ†å¸ƒæè¿°ã€‚ æ¢¯åº¦è®¡ç®—å…¬å¼ï¼š \\begin{equation} dW= \\left\\{ \\begin{array}{lr} (-1 + \\frac{e^{\\hat f_{y_i}}}{\\sum_j e^{f_j}})x_i, & j=i\\\\ \\frac{e^{\\hat f_{y_i}}}{\\sum_j e^{f_j}}x_i, & j \\neq i \\end{array} \\right. \\end{equation}å‘é‡åŒ–å®ç°ï¼š 1234567891011121314151617score = X.dot(W) # N x CN = X.shape[0]correct_score = score[np.arange(N),y].reshape(N,1)exp_sum = np.sum(np.exp(score),axis=1).reshape(N,1)loss += np.sum(np.log(exp_sum) - correct_score)loss /= Nloss += reg * 0.5 * np.sum(W*W)margin = np.exp(score)/exp_summargin[np.arange(N),y] -= 1dW = X.T.dot(margin)dW /=NdW += reg*W äº¤å‰ç†µå‡½æ•°ï¼š çœŸå®åˆ†ç±»çš„åˆ†å¸ƒ$p$ å’Œä¼°è®¡åˆ†å¸ƒ$q$ çš„äº¤å‰ç†µå®šä¹‰ä¸ºï¼š H(p,q) = - \\sum_x p(x) \\log q(x) Softmax æœ€å°åŒ–äº¤å‰ç†µæˆ–æœ€å¤§åŒ–æå¤§ä¼¼ç„¶å‡½æ•°æ¥æ±‚è§£é—®é¢˜ï¼›SVMé€šè¿‡å¯»æ‰¾æœ€å¤§ç•Œé¢è·ç¦»æ¥ä¼˜åŒ–ç›®æ ‡ã€‚ ä¼˜åŒ–ç®—æ³•3 æ¢¯åº¦æ•°å€¼è§£ï¼ˆæ¢¯åº¦æ ¡éªŒï¼‰ \\frac{df(x)}{dx} = \\lim_{h\\ \\to 0} \\frac{f(x + h) - f(x)}{h}$[f(x+h) - f(x-h)] / 2 h$ æ˜¯ä¸€ç§æ›´å¥½çš„å®ç°ã€‚ 123456789101112131415161718192021222324252627def eval_numerical_gradient(f, x): \"\"\" a naive implementation of numerical gradient of f at x - f should be a function that takes a single argument - x is the point (numpy array) to evaluate the gradient at \"\"\" fx = f(x) # evaluate function value at original point grad = np.zeros(x.shape) h = 0.00001 # iterate over all indexes in x it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite']) while not it.finished: # evaluate function at x+h ix = it.multi_index old_value = x[ix] x[ix] = old_value + h # increment by h fxh = f(x) # evalute f(x + h) x[ix] = old_value # restore to previous value (very important!) # compute the partial derivative grad[ix] = (fxh - fx) / h # the slope it.iternext() # step to next dimension return grad å½“é€‚åº”SVMä»£ä»·å‡½æ•°ï¼š L_i = \\sum_{j\\neq y_i} \\left[ \\max(0, w_j^Tx_i - w_{y_i}^Tx_i + \\Delta) \\right]ä»£ä»·å‡½æ•°å…³äºæƒé‡çš„åå¯¼ä¸ºï¼š \\nabla_{w_{y_i}} L_i = - \\left( \\sum_{j\\neq y_i} \\mathbb{1}(w_j^Tx_i - w_{y_i}^Tx_i + \\Delta > 0) \\right) x_i \\nabla_{w_j} L_i = \\mathbb{1}(w_j^Tx_i - w_{y_i}^Tx_i + \\Delta > 0) x_i å‚è€ƒ 2. CS231n Notes:linear classify &#8617; 3. CS231n Notes:Optimization &#8617; 4. CS229 Lecture Notes: SVM &#8617; 5. Deep Learning using Linear Support Vector Machines from Charlie Tang 2013 presents some results claiming that the L2SVM outperforms Softmax. &#8617;","categories":[{"name":"è¯»ä¹¦ç¬”è®°","slug":"è¯»ä¹¦ç¬”è®°","permalink":"http://blog.a-stack.com/categories/è¯»ä¹¦ç¬”è®°/"},{"name":"è¯¾ç¨‹ç¬”è®°","slug":"è¯»ä¹¦ç¬”è®°/è¯¾ç¨‹ç¬”è®°","permalink":"http://blog.a-stack.com/categories/è¯»ä¹¦ç¬”è®°/è¯¾ç¨‹ç¬”è®°/"}],"tags":[{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"æœºå™¨è§†è§‰","slug":"æœºå™¨è§†è§‰","permalink":"http://blog.a-stack.com/tags/æœºå™¨è§†è§‰/"},{"name":"ç¬”è®°","slug":"ç¬”è®°","permalink":"http://blog.a-stack.com/tags/ç¬”è®°/"}]},{"title":"cs231nè¯¾ç¨‹ç¬”è®°:ï¼ˆLecture 2ï¼‰å›¾åƒåˆ†ç±»","slug":"cs231n-lecture-2","date":"2018-05-03T08:50:26.000Z","updated":"2018-05-16T13:59:22.970Z","comments":true,"path":"2018/05/03/cs231n-lecture-2/","link":"","permalink":"http://blog.a-stack.com/2018/05/03/cs231n-lecture-2/","excerpt":"","text":"æ‘˜è¦ï¼š è®¡åˆ’èŠ±ä¸€ä¸ªæœˆçš„æ—¶é—´åˆ·ä¸€éæ–¯å¦ç¦çš„æœºå™¨è§†è§‰è¯¾ç¨‹cs231nï¼Œå¹¶åšç¬”è®°è®°å½•æ¯å¤©å­¦ä¹ åˆ°çš„å†…å®¹ã€‚ æ¦‚è¿°cs231næ˜¯æ–¯å¦ç¦åœ¨æ·±åº¦å­¦ä¹ å’Œæœºå™¨è§†è§‰é¢†åŸŸçš„å…¥é—¨ç»å…¸è¯¾ç¨‹ï¼Œç›¸å…³èµ„æºå¦‚ä¸‹ï¼š è¯¾ç¨‹ä¸»é¡µï¼š http://cs231n.stanford.edu/ è¯¾ç¨‹Notesï¼šhttp://cs231n.github.io/ Event Type Date Description Course Materials Lecture 2 Thursday April 5 Image Classification The data-driven approach K-nearest neighbor Linear classification I [slides] [python/numpy tutorial][image classification notes][linear classification notes] Python/Numpy Tutorial Note that unlike many languages, Python does not have unary increment (x++) or decrement (x--) operators. å­—ç¬¦ä¸²æ“ä½œ 12345678s = \"hello\"print(s.capitalize()) # Capitalize a string; prints \"Hello\"print(s.upper()) # Convert a string to uppercase; prints \"HELLO\"print(s.rjust(7)) # Right-justify a string, padding with spaces; prints \" hello\"print(s.center(7)) # Center a string, padding with spaces; prints \" hello \"print(s.replace('l', '(ell)')) # Replace all instances of one substring with another; # prints \"he(ell)(ell)o\"print(' world '.strip()) # Strip leading and trailing whitespace; prints \"world\" Listæ“ä½œ 123nums = [0, 1, 2, 3, 4]even_squares = [x ** 2 for x in nums if x % 2 == 0]print(even_squares) # Prints \"[0, 4, 16]\" å­—å…¸æ“ä½œ 123d = &#123;'person': 2, 'cat': 4, 'spider': 8&#125;for animal, legs in d.items(): print('A %s has %d legs' % (animal, legs)) 12nums = [0, 1, 2, 3, 4]even_num_to_square = &#123;x: x ** 2 for x in nums if x % 2 == 0&#125; Numpy æ›´å¤šå†…å®¹å‚è§ï¼šNumPy Reference 123456# æ•°å€¼ä¹˜print(x * y)print(np.multiply(x, y))# çŸ©é˜µä¹˜print(v.dot(w))print(np.dot(v, w)) 12345x = np.array([[1,2],[3,4]])print(np.sum(x)) # Compute sum of all elements; prints \"10\"print(np.sum(x, axis=0)) # Compute sum of each column; prints \"[4 6]\"print(np.sum(x, axis=1)) # Compute sum of each row; prints \"[3 7]\" 12#è½¬ç½®x.T SciPy æ›´å¤šå†…å®¹å‚è§: SciPy Tutorial Image Operations1234567891011121314151617181920# Image Operationsfrom scipy.misc import imread, imsave, imresize# Read an JPEG image into a numpy arrayimg = imread('assets/cat.jpg')print(img.dtype, img.shape) # Prints \"uint8 (400, 248, 3)\"# We can tint the image by scaling each of the color channels# by a different scalar constant. The image has shape (400, 248, 3);# we multiply it by the array [1, 0.95, 0.9] of shape (3,);# numpy broadcasting means that this leaves the red channel unchanged,# and multiplies the green and blue channels by 0.95 and 0.9# respectively.img_tinted = img * [1, 0.95, 0.9]# Resize the tinted image to be 300 by 300 pixels.img_tinted = imresize(img_tinted, (300, 300))# Write the tinted image back to diskimsave('assets/cat_tinted.jpg', img_tinted) Distance between points123456789101112131415161718import numpy as npfrom scipy.spatial.distance import pdist, squareform# Create the following array where each row is a point in 2D space:# [[0 1]# [1 0]# [2 0]]x = np.array([[0, 1], [1, 0], [2, 0]])print(x)# Compute the Euclidean distance between all rows of x.# d[i, j] is the Euclidean distance between x[i, :] and x[j, :],# and d is the following array:# [[ 0. 1.41421356 2.23606798]# [ 1.41421356 0. 1. ]# [ 2.23606798 1. 0. ]]d = squareform(pdist(x, 'euclidean'))print(d) å›¾åƒåˆ†ç±» Notes1 The task in Image Classification is to predict a single label (or a distribution over labels as shown here to indicate our confidence) for a given image. Images are 3-dimensional arrays of integers from 0 to 255, of size Width x Height x 3. The 3 represents the three color channels Red, Green, Blue. é¢ä¸´çš„æŒ‘æˆ˜ï¼š ä¸åŒè§†è§’. A single instance of an object can be oriented in many ways with respect to the camera. å°ºå¯¸å˜æ¢. Visual classes often exhibit variation in their size (size in the real world, not only in terms of their extent in the image). å˜å½¢. Many objects of interest are not rigid bodies and can be deformed in extreme ways. é®æŒ¡. The objects of interest can be occluded. Sometimes only a small portion of an object (as little as few pixels) could be visible. ä¸åŒå…‰ç…§æ¡ä»¶. The effects of illumination are drastic on the pixel level. èƒŒæ™¯å¹²æ‰°. The objects of interest may blend into their environment, making them hard to identify. ç±»å†…å·®å¼‚. The classes of interest can often be relatively broad, such as chair. There are many different types of these objects, each with their own appearance. Semantic Gap: è¯­ä¹‰é¸¿æ²Ÿï¼Œå¯¹äºäººç±»è€Œè¨€ï¼Œå›¾åƒåˆ†ç±»ååˆ†ç®€ç­”ï¼Œä½†å¯¹äºè®¡ç®—æœºç³»ç»Ÿä»åƒç´ ä¸­æå–ç‰¹å¾ç‰¹åˆ«éš¾ã€‚ æ•°æ®é©±åŠ¨çš„æ–¹å¼æ¥å®ç°å›¾åƒåˆ†ç±» KNN Demo ä¼ ç»Ÿç‰¹å¾æå–æ–¹æ³•å¾ˆéš¾æœ‰è´¨çš„æå‡å’Œæ³›åŒ–çš„æ€§èƒ½ï¼Œå°¤å…¶ç›´æ¥æ ¹æ®ç‰¹å¾è¿›è¡Œåˆ†ç±»ï¼Œä¸å¦‚åˆ©ç”¨å¤§é‡æ ‡è®°æ•°æ®è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œç„¶ååˆ©ç”¨è¯¥æ¨¡å‹å¯¹æœªçŸ¥æ•°æ®è¿›è¡Œé¢„æµ‹ã€‚ è¿‘é‚»ä¼˜åŒ–ç®—æ³•å¤„ç†å›¾åƒåˆ†ç±» åœ¨è®­ç»ƒé˜¶æ®µï¼ŒNNä»€ä¹ˆéƒ½ä¸åšï¼ŒçŸ¥è¯†æŠŠè®­ç»ƒæ•°æ®åŠ è½½åˆ°å†…å­˜ä¸­ï¼›$O(1)$ é¢„æµ‹é˜¶æ®µï¼Œå°†æœªçŸ¥æ•°æ®ä¸æ‰€æœ‰è®­ç»ƒæ•°æ®è¿›è¡Œæ¯”è¾ƒï¼Œå–æœ€è¿‘è·ç¦»çš„å›¾åƒæ‰€åœ¨çš„ç±»åˆ«ä½œä¸ºé¢„æµ‹ç±»åˆ«ï¼›$O(N)$ ç¼ºç‚¹ï¼š è®¡ç®—é‡å¤§(æ¯é¢„æµ‹ä¸€ä¸ªå›¾ç‰‡éƒ½éœ€è¦ä¸æ‰€æœ‰è®­ç»ƒæ•°æ®è®¡ç®—ä¸€éè·ç¦»)ï¼Œå‡†ç¡®ç‡ä½ï¼ˆ~40%å‡†ç¡®ç‡åœ¨ CIFAR-10ï¼‰ï¼› å›¾åƒçš„ä¸‰ç»´ç‰¹å¾å’Œè¾¹ç¼˜ç‰¹æ€§ï¼Œå¯¼è‡´ä»…ä»åƒç´ åŠ›åº¦ä¸Šå¾ˆéš¾è¿›è¡Œæ¯”å¯¹ï¼Œç»´åº¦è¶Šå¥½ï¼ŒNNç®—æ³•å°±è¶Šæ— èƒ½ä¸ºåŠ› å‚è€ƒ 1. CS231n Notes:Classification &#8617; 2. CS231n Notes:linear classify &#8617; 3. A Few Useful Things to Know About Machine Learning &#8617; 4. CS229 Lecture Notes: SVM &#8617; 5. Deep Learning using Linear Support Vector Machines from Charlie Tang 2013 presents some results claiming that the L2SVM outperforms Softmax. &#8617;","categories":[{"name":"è¯»ä¹¦ç¬”è®°","slug":"è¯»ä¹¦ç¬”è®°","permalink":"http://blog.a-stack.com/categories/è¯»ä¹¦ç¬”è®°/"},{"name":"è¯¾ç¨‹ç¬”è®°","slug":"è¯»ä¹¦ç¬”è®°/è¯¾ç¨‹ç¬”è®°","permalink":"http://blog.a-stack.com/categories/è¯»ä¹¦ç¬”è®°/è¯¾ç¨‹ç¬”è®°/"}],"tags":[{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"æœºå™¨è§†è§‰","slug":"æœºå™¨è§†è§‰","permalink":"http://blog.a-stack.com/tags/æœºå™¨è§†è§‰/"},{"name":"ç¬”è®°","slug":"ç¬”è®°","permalink":"http://blog.a-stack.com/tags/ç¬”è®°/"}]},{"title":"æœºå™¨å­¦ä¹ åœ£ç»","slug":"Holy-Bible-of-Machine-Learning","date":"2018-04-30T04:31:21.000Z","updated":"2018-05-15T09:14:33.416Z","comments":true,"path":"2018/04/30/Holy-Bible-of-Machine-Learning/","link":"","permalink":"http://blog.a-stack.com/2018/04/30/Holy-Bible-of-Machine-Learning/","excerpt":"æ‘˜è¦ï¼š æœºå™¨å­¦ä¹ ä¸­å……æ»¡å¾ˆå¤šéš¾ä»¥ç†è§£çš„æŠ€å·§å’Œæ–¹æ³•ï¼Œå§‘ä¸”åˆ©ç”¨æ‘„å½±ä¸­æ— å¿Œ77æ¡é‚£æ ·çš„æ‘„å½±åœ£ç»æ¥ç§°ä¹‹ä¸ºæœºå™¨å­¦ä¹ åœ£ç»å§ã€‚","text":"æ‘˜è¦ï¼š æœºå™¨å­¦ä¹ ä¸­å……æ»¡å¾ˆå¤šéš¾ä»¥ç†è§£çš„æŠ€å·§å’Œæ–¹æ³•ï¼Œå§‘ä¸”åˆ©ç”¨æ‘„å½±ä¸­æ— å¿Œ77æ¡é‚£æ ·çš„æ‘„å½±åœ£ç»æ¥ç§°ä¹‹ä¸ºæœºå™¨å­¦ä¹ åœ£ç»å§ã€‚ @[toc] è¿™ç¯‡æ–‡ç« çš„å†…å®¹ä¸»è¦æ¥è‡ªPedro Domingosçš„è®ºæ–‡ã€ŠA Few Useful Things to Know About Machine Learningã€‹1 ï¼Œä½œä¸ºä¸€ç¯‡è¯»ä¹¦ç¬”è®°ã€‚åŒæ—¶Pedroä¹Ÿæ˜¯ç•…é”€ä¹¦ã€ŠThe Master Algorithmã€‹ï¼ˆä¸­æ–‡è¯‘ä¸ºã€Šç»ˆæç®—æ³•:æœºå™¨å­¦ä¹ å’Œäººå·¥æ™ºèƒ½å¦‚ä½•é‡å¡‘ä¸–ç•Œã€‹ï¼‰çš„ä½œè€…ã€‚ æœºå™¨å­¦ä¹ ä¸­å……æ»¡å¾ˆå¤šéš¾ä»¥ç†è§£çš„æŠ€å·§å’Œæ–¹æ³•ï¼ŒPedroç§°ä¹‹ä¸ºblack artï¼Œå§‘ä¸”åˆ©ç”¨æ‘„å½±ä¸­æ— å¿Œ77æ¡é‚£æ ·çš„æ‘„å½±åœ£ç»æ¥ç§°ä¹‹ä¸ºæœºå™¨å­¦ä¹ åœ£ç»å§ã€‚ æœºå™¨å­¦ä¹ åœ£ç»1 ã€ŠThe Master Algorithmã€‹çš„ä½œè€… å­¦ä¹ =è¡¨ç¤º+è¯„ä»·+ä¼˜åŒ– (Learning = Representation + Evaluation + optimization) æ³›åŒ– æ¨¡å‹çš„æ³›åŒ–æ€§èƒ½æ˜¯æœºå™¨å­¦ä¹ ç®—æ³•è¿½æ±‚çš„æœ€ç»ˆç›®æ ‡ã€‚æ‰€æœ‰è®¾è®¡è‰¯å¥½çš„è®­ç»ƒæ•°æ®ã€éªŒè¯æ•°æ®å’Œæµ‹è¯•æ•°æ®å°¤ä¸ºå…³é”®ã€‚åœ¨æ—©æœŸçš„æœºå™¨å­¦ä¹ ç³»ç»Ÿä¸­ï¼Œç”±äºå­¦ä¹ å™¨å­¦åˆ°çš„æ¨¡å‹è¡¨ç¤ºååˆ†æœ‰é™ï¼Œæ‰€ä»¥è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„è¯¯å·®ä¸æ˜¯ååˆ†æ˜¾ç°ã€‚ åªæœ‰æ•°æ®è¿˜ä¸å¤Ÿ â€‹é™¤äº†æ•°æ®ï¼Œæˆ‘ä»¬è¿˜éœ€è¦çŸ¥è¯†ï¼ˆå½’çº³+æ¨ç†ï¼‰å’Œå‡è®¾ï¼ˆä¸€è‡´æ€§ã€åŒåˆ†å¸ƒã€ç‹¬ç«‹æ€§ï¼‰ï¼Œæ¥å®ç°æ¨¡å‹çš„æ³›åŒ–ç‰¹å¾ã€‚ è¿‡æ‹Ÿåˆçš„å¤šä¸ªæ–¹é¢ biaså’Œvariance Bias is a learnerâ€™s tendency to consistently learn the same wrong thing. Variance is the tendency to learn random things irrespective of the real signal. ç»´åº¦ç¾éš¾ éšç€ç»´åº¦å¢åŠ ï¼Œæ•°æ®ä¹‹é—´å·®å¼‚ä¼šå˜å°ï¼Œæ³›åŒ–å°†æŒ‡æ•°çº§çš„å˜éš¾ã€‚ ç†è®ºä¸Šçš„ä¿è¯ å½’çº³ä¸æ¼”ç»ï¼› è¾¹ç•Œä¿è¯ï¼Œç»™å®šä¸€ä¸ªè¶³å¤Ÿå¤§çš„è®­ç»ƒé›†ï¼Œå‘Šè¯‰ä½ åœ¨å¾ˆå¤§çš„æ¦‚ç‡ä¸Šä½ çš„å­¦ä¹ å™¨ä¼šè¿”å›ä¸€ä¸ªæˆåŠŸæ³›åŒ–çš„å‡è®¾ï¼Œè¿˜æ˜¯æ— æ³•æ‰¾åˆ°ä¸€ä¸ªä¿æŒæ­£ç¡®çš„å‡è®¾ã€‚ æ¸è¿›ä¿è¯æ˜¯ï¼Œç»™å®šæ— ç©·æ•°æ®ï¼Œå­¦ä¹ å™¨å°†ä¿è¯è¾“å‡ºæ­£ç¡®çš„åˆ†ç±»å™¨ã€‚ æœºå™¨å­¦ä¹ ä¸­ç†è®ºä¿è¯çš„ä¸»è¦ä½œç”¨å¹¶ä¸æ˜¯åœ¨å®è·µä¸­ä½œä¸ºå†³ç­–çš„æ ‡å‡†ï¼Œæœ€å¤šæ˜¯åœ¨ç®—æ³•è®¾è®¡æ—¶ç»™äº›æç¤ºã€‚ ç‰¹å¾å·¥ç¨‹ ç‰¹å¾å·¥ç¨‹ä¹‹æ‰€ä»¥æ¯”å­¦ä¹ è¿˜è¦å¤æ‚ï¼Œæ˜¯å› ä¸ºå®ƒæ˜¯å’Œé¢†åŸŸç›¸å…³çš„ï¼Œæœºå™¨å­¦ä¹ ç®—æ³•æ˜¯é€šç”¨çš„ã€‚ æ›´å¤šçš„æ•°æ®ç»å¯¹æ¯”ä¸€ä¸ªæ›´å¥½çš„ç®—æ³•æœ‰æ•ˆ é—®é¢˜çš„æœ¬è´¨å…¶å®æ˜¯æ—¶é—´ã€è®¡ç®—èµ„æºå’Œæ•°æ®ï¼Œå“ªä¸ªæ˜¯ç“¶é¢ˆçš„é—®é¢˜ã€‚æœ¬è´¨çš„ç“¶é¢ˆæ˜¯äººåŠ›ï¼ æ²¡æœ‰å…è´¹åˆé¤å®šå¾‹å‘Šè¯‰æˆ‘ä»¬ï¼Œåªè¦æ•°æ®å……åˆ†ï¼Œç®€å•çš„ç®—æ³•ä¹Ÿå¯ä»¥å®ç°å’Œå¤æ‚ç®—æ³•ç­‰æ•ˆçš„æ•ˆæœã€‚ æ¨¡å‹ç»„åˆ ä¸å°è¯•Nå¤šæ¨¡å‹ï¼Œé€‰æ‹©å…¶ä¸­æœ€å¥½çš„ç›¸æ¯”ï¼Œç»„åˆå¤šä¸ªä¸åŒçš„æ¨¡å‹ï¼ˆmodel ensemblesï¼‰æ•ˆæœå¾€å¾€æ›´å¥½ã€‚å¸¸è§ç»„åˆæœ‰baggingï¼Œboostingï¼Œstackingã€‚æ¨¡å‹ç»„åˆä¸è´å¶æ–¯æ¨¡å‹å¹³å‡çš„åŒºåˆ«ï¼šåœ¨è´å¶æ–¯æ¨¡å‹å¹³å‡æ–¹æ³•ä¸­ï¼Œå¯¹æ–°æ ·ä¾‹çš„é¢„æµ‹æ˜¯å¯¹å‡è®¾ç©ºé—´ä¸­çš„æ‰€æœ‰åˆ†ç±»å™¨çš„é¢„æµ‹å–å¹³å‡å¾—åˆ°çš„ï¼Œæ¯ä¸ªåˆ†ç±»å™¨ä¼šæ ¹æ®å®ƒè§£é‡Šè®­ç»ƒæ•°æ®çš„èƒ½åŠ›å’Œæˆ‘ä»¬å¯¹å®ƒçš„å…ˆéªŒä¿¡ä»»åº¦è€Œæœ‰ä¸åŒçš„æƒé‡ã€‚æ¨¡å‹ç»„åˆä¿®æ”¹äº†å‡è®¾ç©ºé—´ï¼›è´å¶æ–¯æ¨¡å‹å¹³å‡ç»™å‡è®¾ç©ºé—´æ·»åŠ å›ºå®šçš„æƒé‡ã€‚ Jensenâ€™s Inequalityï¼Œç®€æ£®ä¸ç­‰å¼æä¾›äº†ç†è®ºä¾æ® ç®€å• $\\neq$ å‡†ç¡® è‘—åçš„å¥¥åå§†å‰ƒåˆ€ï¼ˆoccamâ€™s razorï¼‰åŸç†ç§°ï¼šè‹¥æ— å¿…è¦ï¼Œå‹¿å¢å®ä½“ï¼ˆentities should not be multi-plied beyond necessityï¼‰ã€‚ä½†å¹¶éæ€»æ˜¯ç®€å•çš„æ¨¡å‹å¯ä»¥è·å¾—æ›´å¥½çš„æ³›åŒ–æ€§èƒ½ï¼Œæ¯”å¦‚æ¨¡å‹ç»„åˆæ˜¯åœ¨å¢åŠ æ¨¡å‹å¤æ‚åº¦æ¢å–æ›´å¥½çš„å‡†ç¡®ç‡ã€‚æ¨¡å‹å‚æ•°çš„æ•°é‡å’Œè¿‡æ‹Ÿåˆä¹‹é—´å¹¶æ— ç›´æ¥çš„è”ç³»ã€‚å¥¥åå§†æœ€åˆçš„æ„æ€æ˜¯è¯´ï¼Œå¼€å§‹çš„æ—¶å€™é€‰æ‹©ç®€å•çš„å‡è®¾ï¼Œå¯ä»¥ä¿®æ­£å®ƒï¼Œç›´åˆ°æ•ˆæœç†æƒ³ã€‚ä½†æ˜¯ä¸è¦ä¸€å¼€å§‹ä»å¤æ‚çš„åšèµ·ï¼Œè€Œä¸æ˜¯è¯´è¦æ‰¾ç®€å•ä½œä¸ºæœ€ç»ˆçš„å­¦ä¹ å™¨ã€‚ å¯è¡¨ç¤º $\\neq$ å¯å­¦ä¹  ç¥ç»ç½‘ç»œçš„ä¸‡æœ‰é€¼è¿‘åŸç†æè¿°äº†åªéœ€è¦ä¸€ä¸ªéšå±‚ï¼Œç¥ç»ç½‘ç»œå¯ä»¥è¿‘ä¼¼è¡¨ç¤ºæ‰€æœ‰çš„å‡½æ•°å½¢å¼ã€‚ä½†ä¸€ä¸ªå‡½æ•°å¯ä»¥è¢«è¡¨ç¤ºå¹¶ä¸ä»£è¡¨ç€å®ƒå¯ä»¥è¢«å¾ˆå¥½çš„å­¦ä¹ åˆ°ã€‚å³ä½¿å‡è®¾ç©ºé—´ä¸­çœŸå®å­˜åœ¨è¿™ä¸ªå‡½æ•°ï¼Œç”±äºå‡è®¾ç©ºé—´çš„èŒƒå›´ä¹‹å¤§ï¼Œåœ¨æœ‰é™æ•°æ®ã€æ—¶é—´å’Œè®¡ç®—èµ„æºçš„æƒ…å†µä¸‹ï¼Œä¸€èˆ¬å­¦ä¹ ç®—æ³•åªèƒ½è¦†ç›–å…¶ä¸­ä¸€ä¸ªå­é›†ï¼Œåœ¨è¿™ä¸ªå­é›†ç©ºé—´ä¸­æ˜¯å¦æœ‰ç›®æ ‡å‡½æ•°ï¼Œå¾€å¾€è·Ÿä½ é‡‡ç”¨çš„è¡¨ç¤ºæ–¹æ³•æœ‰å…³ã€‚ è¿™å‘Šè¯‰æˆ‘ä»¬ï¼Œé‡‡ç”¨ä¸åŒçš„è¡¨ç¤ºæ–¹æ³•ï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦èŠ±è´¹ä¸åŒçš„ä»£ä»·ï¼ˆä½¿ç”¨æ›´å°‘çš„æ•°æ®ï¼‰æ¥å­¦ä¹ åˆ°ç›®æ ‡å‡½æ•°ã€‚å¾ˆå¤šå­¦ä¹ å™¨çš„å·¥ä½œæœºåˆ¶æ­£å¼å°†ç®€å•çš„åŸºå‡½æ•°è¿›è¡Œçº¿æ€§ç»„åˆï¼Œæ¥é™ä½ç®—æ³•å¤æ‚åº¦ã€‚ ç›¸å…³æ€§ $\\neq$ å› æœæ€§ åˆ©ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹è¿›è¡Œé¢„æµ‹çš„å‰ææ˜¯æ•°æ®ä¹‹é—´çš„å› æœæ€§ä½“ç°è€Œéå˜é‡çš„ç›¸å…³æ€§ã€‚â€‹æœºå™¨å­¦ä¹ æ˜¯åŸºäºè§‚æµ‹æ•°æ®ï¼Œè€Œè§‚æµ‹æ•°æ®ä¸­æ˜¯å¦å«æœ‰å¯é¢„æµ‹å˜é‡æ˜¯ä¸å¯æ§çš„ï¼Œè¿™ç‚¹è·ŸåŸºäºå®éªŒæ•°æ®çš„ç»“è®ºä¸åŒã€‚å› æ­¤ï¼Œå¦‚æœä½ èƒ½å°½é‡å¤šçš„è·å¾—å®éªŒæ•°æ®ï¼Œé‚£å……åˆ†å‡†å¤‡è¶³å¤Ÿçš„å®éªŒæ•°æ®ã€‚ä¸€èˆ¬æˆ‘ä»¬è®¤ä¸ºï¼Œæ•°æ®çš„ç›¸å…³æ€§æ˜¯æ½œåœ¨å› æœæ€§çš„æ ‡å¿—ï¼Œä½†å› æœæ€§æ˜¯å¦çœŸçš„å­˜åœ¨æ²¡æœ‰åšå®çš„ä¾æ®ã€‚ å‚è€ƒ 1. A Few Useful Things to Know About Machine Learning &#8617;","categories":[{"name":"æœºå™¨å­¦ä¹ ","slug":"æœºå™¨å­¦ä¹ ","permalink":"http://blog.a-stack.com/categories/æœºå™¨å­¦ä¹ /"}],"tags":[{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"æŠ€å·§","slug":"æŠ€å·§","permalink":"http://blog.a-stack.com/tags/æŠ€å·§/"},{"name":"æœºå™¨å­¦ä¹ ","slug":"æœºå™¨å­¦ä¹ ","permalink":"http://blog.a-stack.com/tags/æœºå™¨å­¦ä¹ /"}]},{"title":"Everything-About-SVM","slug":"Everything-About-SVM","date":"2018-04-29T13:13:40.000Z","updated":"2018-05-15T09:14:33.431Z","comments":false,"path":"2018/04/29/Everything-About-SVM/","link":"","permalink":"http://blog.a-stack.com/2018/04/29/Everything-About-SVM/","excerpt":"æ‘˜è¦ï¼š","text":"æ‘˜è¦ï¼š @[toc] æ”¯æŒå‘é‡æœºSVMï¼Œæ˜¯ä¸€ç§äºŒç±»åˆ†ç±»æ¨¡å‹ï¼Œæ˜¯å®šä¹‰åœ¨ç‰¹å¾ç©ºé—´ä¸Šçš„é—´éš”æœ€å¤§åŒ–åŒ–çº¿æ€§åˆ†ç±»å™¨ï¼Œå¯å½¢å¼åŒ–ä¸ºæ±‚è§£å‡¸äºŒæ¬¡è§„åˆ’é—®é¢˜ï¼Œä¹Ÿç­‰ä»·äºæ­£åˆ™åŒ–çš„åˆé¡µæŸå¤±å‡½æ•°æœ€å°åŒ–é—®é¢˜ã€‚ä¸»è¦æ¶‰åŠå¦‚ä¸‹å…³é”®çŸ¥è¯†ç‚¹éœ€è¦åç»­è¿›ä¸€æ­¥æ•´ç†ï¼š çº¿æ€§å¯åˆ†çš„æ”¯æŒå‘é‡æœº çº¿æ€§æ”¯æŒå‘é‡æœº éçº¿æ€§æ”¯æŒå‘é‡æœº é—´éš”æœ€å¤§åŒ–é—®é¢˜ ç¡¬é—´éš”æœ€å¤§åŒ– è½¯é—´éš”æœ€å¤§åŒ– æ ¸æŠ€å·§ã€æ ¸å‡½æ•°ã€æ ¸æ–¹æ³• Hinge Loss å¿«é€Ÿå­¦ä¹ ç®—æ³•â€”â€”SMOï¼ˆæœ€å°æœ€ä¼˜åŒ–ç®—æ³•ï¼‰ å¤šåˆ†ç±»é—®é¢˜ æ„ŸçŸ¥æœºåˆ©ç”¨è¯¯åˆ†ç±»æœ€å°çš„ç­–ç•¥ï¼Œæ±‚å¾—åˆ†ç¦»è¶…å¹³é¢ï¼Œè¿™æ—¶è§£æœ‰æ— ç©·å¤šä¸ªã€‚çº¿æ€§å¯åˆ†æ”¯æŒå‘é‡æœºåˆ©ç”¨é—´éš”æœ€å¤§åŒ–æ±‚å¾—æœ€ä¼˜åˆ†ç¦»è¶…å¹³é¢ï¼Œè¿™æ—¶è§£æ˜¯å”¯ä¸€çš„ã€‚ å‚è€ƒ æèˆªï¼Œã€Šæœ€ç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹ CS229 Lecture Notes: SVM ç”¨ä¸€å¼ å›¾ç†è§£SVMçš„è„‰ç»œ","categories":[{"name":"æœºå™¨å­¦ä¹ ","slug":"æœºå™¨å­¦ä¹ ","permalink":"http://blog.a-stack.com/categories/æœºå™¨å­¦ä¹ /"}],"tags":[{"name":"ç®—æ³•","slug":"ç®—æ³•","permalink":"http://blog.a-stack.com/tags/ç®—æ³•/"},{"name":"æ–‡çŒ®","slug":"æ–‡çŒ®","permalink":"http://blog.a-stack.com/tags/æ–‡çŒ®/"},{"name":"æ”¯æŒå‘é‡æœº","slug":"æ”¯æŒå‘é‡æœº","permalink":"http://blog.a-stack.com/tags/æ”¯æŒå‘é‡æœº/"}]},{"title":"ã€Šæœºå™¨å­¦ä¹ ã€‹è¯¾ç¨‹å®éªŒå›é¡¾","slug":"machinelearning-labs","date":"2018-04-26T05:56:28.000Z","updated":"2018-05-15T09:14:33.479Z","comments":false,"path":"2018/04/26/machinelearning-labs/","link":"","permalink":"http://blog.a-stack.com/2018/04/26/machinelearning-labs/","excerpt":"","text":"æ‘˜è¦ï¼š Couseraä¸Šæœºå™¨å­¦ä¹ è¯¾ç¨‹æä¾›äº†å…«ä¸ªå®éªŒä½œä¸šï¼Œä½¿ç”¨MATLABè¿›è¡ŒåŠ¨æ‰‹å®éªŒï¼Œç†Ÿæ‚‰ç›¸å…³æŠ€æœ¯ï¼Œæœ¬æ–‡å¯¹å®éªŒä¸­çš„å…³é”®å†…å®¹è¿›è¡Œæ€»ç»“å½’çº³ï¼Œæ–¹ä¾¿ä»¥ååŠæ—¶æŸ¥æ‰¾ã€‚ æ¦‚è¦ å¯ä»¥ä½¿ç”¨Matlab Onlineè¿›è¡Œä»£ç æµ‹è¯•ï¼Œåœ°å€; ç›¸å…³ä»£ç å·²ç»ä¼ è¾“è‡³Githubï¼š https://github.com/ddebby/machine_learning_cousera.git Lab1: çº¿æ€§å›å½’1. ç®€å•çº¿æ€§å›å½’åœ¨ç¬¬ä¸€ä¸ªå®éªŒä¸­æä¾›äº†å•å˜é‡çº¿æ€§å›å½’çš„æ•°æ®ç”¨æ¥é¢„æµ‹å¿«é¤è½¦çš„ç›ˆåˆ©æƒ…å†µï¼Œå…¶ä¸­è¾“å…¥ä¸ºåŸå¸‚ä¸­çš„äººå£ä¿¡æ¯ï¼Œè¾“å‡ºä¸ºè¯¥åŸå¸‚å¿«é¤è½¦çš„ç›ˆåˆ©æƒ…å†µï¼Œæ•°æ®åˆ†å¸ƒæƒ…å†µè¯¦è§ä¸‹å›¾ï¼š ä»£ä»·å‡½æ•°å’Œæ¢¯åº¦æ›´æ–°å®ç°è®¡ç®—ä»£ä»·å‡½æ•° computeCost.m 123456789101112131415161718function J = computeCost(X, y, theta)%COMPUTECOST Compute cost for linear regression% J = COMPUTECOST(X, y, theta) computes the cost of using theta as the% parameter for linear regression to fit the data points in X and y% Initialize some useful valuesm = length(y); % number of training examples% You need to return the following variables correctly J = 0;% ====================== YOUR CODE HERE ======================% Instructions: Compute the cost of a particular choice of theta% You should set J to the cost.J = 1/(2*m) * (X*theta - y)'*(X*theta -y)% =========================================================================end æ¢¯åº¦æ›´æ–° gradientDescent.m 123456789101112131415161718192021222324252627function [theta, J_history] = gradientDescent(X, y, theta, alpha, num_iters)%GRADIENTDESCENT Performs gradient descent to learn theta% theta = GRADIENTDESCENT(X, y, theta, alpha, num_iters) updates theta by % taking num_iters gradient steps with learning rate alpha% Initialize some useful valuesm = length(y); % number of training examplesJ_history = zeros(num_iters, 1);for iter = 1:num_iters % ====================== YOUR CODE HERE ====================== % Instructions: Perform a single gradient step on the parameter vector % theta. % % Hint: While debugging, it can be useful to print out the values % of the cost function (computeCost) and gradient here. % theta = theta - alpha/m * X'*(X*theta - y); % ============================================================ % Save the cost J in every iteration J_history(iter) = computeCost(X, y, theta);endend å®ç°å¹¶æµ‹è¯•ï¼š 123456789101112131415161718192021222324252627282930313233data = load('ex1data1.txt');X = data(:, 1); y = data(:, 2);m = length(y); % number of training examplesX = [ones(m, 1), data(:,1)]; % Add a column of ones to xtheta = zeros(2, 1); % initialize fitting parameters% Some gradient descent settingsiterations = 1500;alpha = 0.01;% compute and display initial costJ = computeCost(X, y, theta);% further testing of the cost functionJ = computeCost(X, y, [-1 ; 2]);% run gradient descenttheta = gradientDescent(X, y, theta, alpha, iterations);% Plot the linear fithold on; % keep previous plot visibleplot(X(:,2), X*theta, '-')legend('Training data', 'Linear regression')hold off % don't overlay any more plots on this figure% Predict values for population sizes of 35,000 and 70,000predict1 = [1, 3.5] *theta;fprintf('For population = 35,000, we predict a profit of %f\\n',... predict1*10000);predict2 = [1, 7] * theta;fprintf('For population = 70,000, we predict a profit of %f\\n',... predict2*10000); $J(\\theta)$ çš„å¯è§†åŒ–123456789101112131415161718192021222324252627282930313233%% ============= Part 4: Visualizing J(theta_0, theta_1) =============fprintf('Visualizing J(theta_0, theta_1) ...\\n')% Grid over which we will calculate Jtheta0_vals = linspace(-10, 10, 100);theta1_vals = linspace(-1, 4, 100);% initialize J_vals to a matrix of 0'sJ_vals = zeros(length(theta0_vals), length(theta1_vals));% Fill out J_valsfor i = 1:length(theta0_vals) for j = 1:length(theta1_vals) t = [theta0_vals(i); theta1_vals(j)]; J_vals(i,j) = computeCost(X, y, t); endend% Because of the way meshgrids work in the surf command, we need to% transpose J_vals before calling surf, or else the axes will be flippedJ_vals = J_vals';% Surface plotfigure;surf(theta0_vals, theta1_vals, J_vals)xlabel('\\theta_0'); ylabel('\\theta_1');% Contour plotfigure;% Plot J_vals as 15 contours spaced logarithmically between 0.01 and 100contour(theta0_vals, theta1_vals, J_vals, logspace(-2, 3, 20))xlabel('\\theta_0'); ylabel('\\theta_1');hold on;plot(theta(1), theta(2), 'rx', 'MarkerSize', 10, 'LineWidth', 2); 2. å¤šå…ƒçº¿æ€§å›å½’åˆ©ç”¨å¤šå…ƒçº¿æ€§å›å½’é¢„æµ‹æˆ¿ä»·ï¼Œè¾“å…¥çš„ç‰¹å¾åŒ…æ‹¬æˆ¿å­å¤§å°ã€æˆ¿é—´æ•°ç›®ï¼Œè¾“å‡ºä¸ºæˆ¿å­ä»·æ ¼ã€‚ 2.1 ç‰¹å¾å½’ä¸€åŒ–featureNormalize.m 123456789101112131415161718192021function [X_norm, mu, sigma] = featureNormalize(X)%FEATURENORMALIZE Normalizes the features in X % FEATURENORMALIZE(X) returns a normalized version of X where% the mean value of each feature is 0 and the standard deviation% is 1. This is often a good preprocessing step to do when% working with learning algorithms.% You need to set these values correctlyX_norm = X;mu = zeros(1, size(X, 2));sigma = zeros(1, size(X, 2));% ====================== YOUR CODE HERE ======================% mu = mean(X,1);sigma = std(X,1);X_norm = (X - mu)./sigma;% ============================================================end The bsxfun is helpful for applying a function (limited to two arguments) in an element-wise fashion to rows of a matrix using a vector of source values. This is useful for feature normalization. An example you can enter at the octave command line: 1234567891011Z=[1 1 1; 2 2 2;];v=[1 1 1];bsxfun(@minus,Z,v);ans = 0 0 0 1 1 1 In this case, the corresponding elements of v are subtracted from each row of Z. The minus(a,b) function is equivalent to computing (a-b). ä»£ä»·å‡½æ•°å’Œæ¢¯åº¦æ›´æ–°ä¸ç®€å•çº¿æ€§å›å½’ç›¸åŒï¼› 2.2 è®¡ç®— $\\theta$ çš„æ•°å€¼è§£normalEqn.m 12345678910111213141516171819function [theta] = normalEqn(X, y)%NORMALEQN Computes the closed-form solution to linear regression % NORMALEQN(X,y) computes the closed-form solution to linear % regression using the normal equations.theta = zeros(size(X, 2), 1);% ====================== YOUR CODE HERE ======================% Instructions: Complete the code to compute the closed form solution% to linear regression and put the result in theta.%% ---------------------- Sample Solution ----------------------theta = pinv(X'*X)*X'*y;% -------------------------------------------------------------% ============================================================end Lab 2 - Lab 5: ç•™ä½œåç»­æ›´æ–° â€¦ Lab 6: SVMæœ¬å®éªŒåˆ©ç”¨SVMå®ç°éçº¿æ€§åˆ†ç±»å™¨ï¼Œæ ¸å‡½æ•°é€‰æ‹©é«˜æ–¯æ ¸å‡½æ•°ï¼Œé«˜æ–¯æ ¸å‡½æ•°çš„å®šä¹‰å¦‚ä¸‹ï¼š K_{gaussian}(x^{(i)},x^{(j)}) = exp(-\\frac{||x^{(i)}-x^{(j)}||^2}{2\\sigma^2})1234567891011121314%% ========== Part 5: Training SVM with RBF Kernel (Dataset 2) ==========% After you have implemented the kernel, we can now use it to train the % SVM classifier.% load('ex6data2.mat');% SVM ParametersC = 1; sigma = 0.1;% We set the tolerance and max_passes lower here so that the code will run% faster. However, in practice, you will want to run the training to% convergence.model= svmTrain(X, y, C, @(x1, x2) gaussianKernel(x1, x2, sigma)); visualizeBoundary(X, y, model); ç”±äºç›®å‰scikit-learnåº“å¯¹å„ç§SVMç®—æ³•éƒ½æœ‰æ¯”è¾ƒå¥½çš„å°è£…ï¼Œæ‰€ä»¥ä¹Ÿä¸åœ¨è¿›ä¸€æ­¥æ·±ç©¶matlabçš„å®ç°äº†ã€‚ Lab 7.1: K-Meansæœ¬å®éªŒä½¿ç”¨K-Meansè¿›è¡Œå›¾åƒå‹ç¼©ï¼ŒK-Meansç®—æ³•çš„åŸºæœ¬å®ç°ï¼š 1234567891011% Initialize centroidscentroids = kMeansInitCentroids(X, K);for iter = 1:iterations % Cluster assignment step: Assign each data point to the % closest centroid. idx(i) corresponds to cË†(i), the index % of the centroid assigned to example i idx = findClosestCentroids(X, centroids); % Move centroid step: Compute means based on centroid % assignments centroids = computeMeans(X, idx, K);end åœ¨å¾ªç¯ä¸­å…³é”®å®ç°ä¸¤ä¸ªæ­¥éª¤ï¼š1ï¼‰é‡æ–°åˆ’åˆ†èšç±»ï¼›2ï¼‰è®¡ç®—æ–°çš„å‡å€¼åŠä¸­å¿ƒç‚¹ å¯»æ‰¾æœ€è¿‘çš„èšç±»ä¸­å¿ƒç‚¹ï¼Œå¹¶èšç±» c^{(i)}:=j \\ that \\ minimizes \\ ||x^{(i)} - \\mu_j ||^2 1234567891011121314151617181920212223242526272829function idx = findClosestCentroids(X, centroids)%FINDCLOSESTCENTROIDS computes the centroid memberships for every example% idx = FINDCLOSESTCENTROIDS (X, centroids) returns the closest centroids% in idx for a dataset X where each row is a single example. idx = m x 1 % vector of centroid assignments (i.e. each entry in range [1..K])%% Set KK = size(centroids, 1);% You need to return the following variables correctly.idx = zeros(size(X,1), 1);% Instructions: Go over every example, find its closest centroid, and store% the index inside idx at the appropriate location.% Concretely, idx(i) should contain the index of the centroid% closest to example i. Hence, it should be a value in the % range 1..K%% Note: You can use a for-loop over the examples to compute this.%for i=1:size(X,1) for j = 1: size(centroids,1) dis(j) = sum((centroids(j, :) - X(i, :)) .^ 2, 2); end [t,idx(i)] = min(dis);end end æ›´æ–°èšç±»ä¸­å¿ƒç‚¹ä½ç½® \\mu_k = \\frac{1}{|C_k|} \\sum_{i \\in C_k} x^{(i)}123456789101112131415161718192021function centroids = computeCentroids(X, idx, K)%COMPUTECENTROIDS returns the new centroids by computing the means of the %data points assigned to each centroid.% centroids = COMPUTECENTROIDS(X, idx, K) returns the new centroids by % computing the means of the data points assigned to each centroid. It is% given a dataset X where each row is a single data point, a vector% idx of centroid assignments (i.e. each entry in range [1..K]) for each% example, and K, the number of centroids. You should return a matrix% centroids, where each row of centroids is the mean of the data points% assigned to it.%% Useful variables[m n] = size(X);% You need to return the following variables correctly.centroids = zeros(K, n);for i = 1:K centroids(i,:) = mean(X(find(idx==i),:));end 3.åˆå§‹èµ·ç‚¹çš„éšæœºé€‰å– 1234% Randomly reorder the indices of examples randidx = randperm(size(X, 1)); % Take the first K examples as centroids centroids = X(randidx(1:K), :); ä½¿ç”¨K-Meanså‹ç¼©å›¾ç‰‡ æˆ‘ä»¬å°†ä¸€å¼ 24bitçš„ç…§ç‰‡ï¼Œå‹ç¼©ä¸º4-bitï¼ˆ16ä¸ªè‰²å½©ï¼‰ï¼›å¯¹äºæ¯ä¸ªåƒç´ ç‚¹ï¼Œå°†é€‰æ‹©æœ€è¿‘çš„ç±»ç°‡è¿›è¡Œé¢œè‰²è¡¨ç¤ºã€‚é€šè¿‡å‹ç¼©å°†128x128x24=393,216bitsçš„å›¾åƒå‹ç¼©ä¸º16x24 + 128x128x4=65,920bitsï¼ˆå…¶ä¸­éœ€è¦é¢å¤–æ¯ç§é¢œè‰²éœ€è¦ä¸€ä¸ª24bitç©ºé—´å­˜å‚¨å„ä¸ªé¢œè‰²å­—å…¸ï¼‰ã€‚ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061%% ============= Part 4: K-Means Clustering on Pixels ===============% In this exercise, you will use K-Means to compress an image. To do this,% you will first run K-Means on the colors of the pixels in the image and% then you will map each pixel onto its closest centroid.%% Load an image of a birdA = double(imread('bird_small.png'));% If imread does not work for you, you can try instead% load ('bird_small.mat');A = A / 255; % Divide by 255 so that all values are in the range 0 - 1% Size of the imageimg_size = size(A);% Reshape the image into an Nx3 matrix where N = number of pixels.% Each row will contain the Red, Green and Blue pixel values% This gives us our dataset matrix X that we will use K-Means on.X = reshape(A, img_size(1) * img_size(2), 3);% Run your K-Means algorithm on this data% You should try different values of K and max_iters hereK = 16; max_iters = 10;% When using K-Means, it is important the initialize the centroids% randomly. % You should complete the code in kMeansInitCentroids.m before proceedinginitial_centroids = kMeansInitCentroids(X, K);% Run K-Means[centroids, idx] = runkMeans(X, initial_centroids, max_iters);%% ================= Part 5: Image Compression ======================% In this part of the exercise, you will use the clusters of K-Means to% compress an image. To do this, we first find the closest clusters for% each example. After that, we % Find closest cluster membersidx = findClosestCentroids(X, centroids);% Essentially, now we have represented the image X as in terms of the% indices in idx. % We can now recover the image from the indices (idx) by mapping each pixel% (specified by its index in idx) to the centroid valueX_recovered = centroids(idx,:);% Reshape the recovered image into proper dimensionsX_recovered = reshape(X_recovered, img_size(1), img_size(2), 3);% Display the original image subplot(1, 2, 1);imagesc(A); title('Original');% Display compressed image side by sidesubplot(1, 2, 2);imagesc(X_recovered)title(sprintf('Compressed, with %d colors.', K)); Lab 7.2ï¼š PCAæœ¬å®éªŒåˆ©ç”¨PCAå®ç°æ•°æ®é™ç»´åŠå¯è§†åŒ–ã€‚ æ•°æ®å½’ä¸€åŒ– è®¡ç®—åæ–¹å·®å’Œå¥‡å¼‚å€¼åˆ†è§£ \\Sigma =\\frac{1}{m}X^TX [U, S, V] = svd(\\Sigma) é™ç»´ 1Z = X * U(:,1:K); æ•°æ®æ¢å¤ 1X_rec = Z * U(:,1:K)'; æ•°æ®å¯è§†åŒ–çš„é™ç»´æ˜¾ç¤º12345678% Use PCA to project this cloud to 2D for visualization% X (16383,3)% Subtract the mean to use PCA[X_norm, mu, sigma] = featureNormalize(X);% PCA and project the data to 2D[U, S] = pca(X_norm);Z = projectData(X_norm, U, 2); Lab 8.1: å¼‚å¸¸æ£€æµ‹æœ¬å®éªŒæ­å»ºä¸€ä¸ªå¼‚å¸¸æ£€æµ‹ç³»ç»Ÿï¼Œç”¨æ¥æ£€æµ‹æœåŠ¡å™¨çš„å¼‚å¸¸ä¿¡æ¯ï¼Œè¾“å…¥ä¸ºæ¯å°æœåŠ¡å™¨çš„æ¯åˆ†é’Ÿåå(mb/s)å’Œå“åº”å»¶æ—¶ï¼ˆmsï¼‰ï¼Œæ•°æ®æä¾›äº†m=307ç»„æ ·æœ¬æ•°æ®ã€‚æœŸæœ›é€šè¿‡éç›‘ç£å­¦ä¹ çš„æ‰‹æ®µæ¥æ£€æµ‹å¼‚å¸¸ã€‚ ä¸ºäº†å¯¹æ•°æ®å¼‚å¸¸è¿›è¡Œæ£€æµ‹ï¼Œé¦–å…ˆéœ€è¦å°†åŸå§‹æ•°æ®æ‹Ÿåˆåˆ°ä¸€ä¸ªåˆ†å¸ƒæ¨¡å‹é‡Œï¼Œæˆ‘ä»¬é€‰æ‹©ä½¿ç”¨å¤šå…ƒé«˜æ–¯æ¨¡å‹è¿›è¡Œæ•°æ®æ‹Ÿåˆ: p(x;\\mu,\\Sigma) = \\dfrac{1}{(2\\pi)^{n/2} |\\Sigma|^{1/2}} exp(-1/2(x-\\mu)^T\\Sigma^{-1}(x-\\mu)) é¦–å…ˆéœ€è¦å¯¹å‚æ•°$\\mu$ ,$\\sigma$ è¿›è¡Œä¼°è®¡ï¼Œå‚è§å¦‚ä¸‹ä»£ç ï¼š 12345mu = mean(X, 1);sigma2 = var(X, 1);p = multivariateGaussian(X, mu, sigma2);% Visualize the fitvisualizeFit(X, mu, sigma2); æ‹Ÿåˆé«˜æ–¯åˆ†å¸ƒçš„è½®å»“å›¾å¦‚ä¸‹ï¼š å¤šå…ƒé«˜æ–¯åˆ†å¸ƒå‡½æ•°multivariateGaussian()çš„å®šä¹‰å¦‚ä¸‹ï¼š 12345678910111213141516171819202122function p = multivariateGaussian(X, mu, Sigma2)%MULTIVARIATEGAUSSIAN Computes the probability density function of the%multivariate gaussian distribution.% p = MULTIVARIATEGAUSSIAN(X, mu, Sigma2) Computes the probability % density function of the examples X under the multivariate gaussian % distribution with parameters mu and Sigma2. If Sigma2 is a matrix, it is% treated as the covariance matrix. If Sigma2 is a vector, it is treated% as the \\sigma^2 values of the variances in each dimension (a diagonal% covariance matrix)%k = length(mu);if (size(Sigma2, 2) == 1) || (size(Sigma2, 1) == 1) Sigma2 = diag(Sigma2);endX = bsxfun(@minus, X, mu(:)');p = (2 * pi) ^ (- k / 2) * det(Sigma2) ^ (-0.5) * ... exp(-0.5 * sum(bsxfun(@times, X * pinv(Sigma2), X), 2));end é˜ˆå€¼$\\epsilon$ çš„é€‰æ‹©ï¼Œé€šè¿‡è®¡ç®—æ¯ä¸ªé˜ˆå€¼çš„F1å¾—åˆ†æ¥è¯„ä»·éªŒè¯é›†æ•°æ®ï¼Œé€‰æ‹©æœ€ä¼˜å¾—åˆ†çš„é˜ˆå€¼ï¼š 123456789101112131415161718192021222324252627282930313233343536373839function [bestEpsilon bestF1] = selectThreshold(yval, pval)%SELECTTHRESHOLD Find the best threshold (epsilon) to use for selecting%outliers% [bestEpsilon bestF1] = SELECTTHRESHOLD(yval, pval) finds the best% threshold to use for selecting outliers based on the results from a% validation set (pval) and the ground truth (yval).bestEpsilon = 0;bestF1 = 0;F1 = 0;stepsize = (max(pval) - min(pval)) / 1000;for epsilon = min(pval):stepsize:max(pval) % Instructions: Compute the F1 score of choosing epsilon as the % threshold and place the value in F1. The code at the % end of the loop will compare the F1 score for this % choice of epsilon and set it to be the best epsilon if % it is better than the current choice of epsilon. % % Note: You can use predictions = (pval &lt; epsilon) to get a binary vector % of 0's and 1's of the outlier predictions cvPredictions = (pval &lt; epsilon); fp = sum((cvPredictions == 1)&amp; (yval == 0)); tp = sum((cvPredictions == 1)&amp;(yval == 1)); fn = sum((cvPredictions == 0)&amp;(yval == 1)); prec = tp/(tp + fp); rec = tp/(tp + fn); F1 = 2*prec*rec/(prec + rec); if F1 &gt; bestF1 bestF1 = F1; bestEpsilon = epsilon; endendendpval = multivariateGaussian(Xval, mu, sigma2);[epsilon F1] = selectThreshold(yval, pval); åœ¨æ›´å¤æ‚åœºæ™¯ä¸‹çš„åº”ç”¨ï¼Œç¤ºä¾‹æä¾›äº†ä¸ªè¾“å…¥ä¸º11ç»´ç‰¹å¾çš„æ•°æ®ï¼Œå¯¹å…¶å¼‚å¸¸æ•°æ®è¿›è¡Œé¢„æµ‹ï¼Œä»£ç ç‰‡æ®µå¦‚ä¸‹ï¼š 123456789101112131415% Apply the same steps to the larger dataset[mu sigma2] = estimateGaussian(X);% Training set p = multivariateGaussian(X, mu, sigma2);% Cross-validation setpval = multivariateGaussian(Xval, mu, sigma2);% Find the best threshold[epsilon F1] = selectThreshold(yval, pval);fprintf('Best epsilon found using cross-validation: %e\\n', epsilon);fprintf('Best F1 on Cross Validation Set: %f\\n', F1);fprintf('# Outliers found: %d\\n\\n', sum(p &lt; epsilon)); â€‹ Lab 8.2ï¼šæ¨èç³»ç»Ÿæœ¬å®éªŒå°†å®ç°ååŒè¿‡æ»¤ç®—æ³•ï¼Œå¹¶åº”ç”¨åˆ°ç”µå½±æ¨èä¹‹ä¸­ã€‚æ•°æ®é›†æ¥è‡ª943ä¸ªç”¨æˆ·çš„1682éƒ¨ç”µå½±çš„è¯„åˆ†æ•°æ®ï¼Œæ¯ä¸ªè¯„åˆ†èŒƒå›´ä¸º1-5ï¼Œå¯ä»¥å­˜åœ¨å¤šä¸ªæœªè¯„åˆ†æ•°æ®ã€‚ $X$ ä¸ºnum_movies x num_featuresï¼Œæ˜¯ç”µå½±çš„ç‰¹å¾çŸ©é˜µ $Y$ ä¸ºnum_movies x num_userçŸ©é˜µï¼Œæè¿°äº†æ¯ä¸ªè¯„åˆ†å€¼$y^{(i,j)}$ $R$ ä¸ºä¸$Y$ åŒç»´åº¦çš„äºŒå€¼çŸ©é˜µï¼Œ$R(i,j)=1$ ä»£è¡¨ç”¨æˆ·$j$ å¯¹ç”µå½±$i$ è¿›è¡Œäº†è¯„åˆ† ä»£ä»·å‡½æ•°çš„å®šä¹‰ J(x,\\theta) = \\dfrac{1}{2} \\displaystyle \\sum_{(i,j):r(i,j)=1}((\\theta^{(j)})^Tx^{(i)} - y^{(i,j)})^2 + \\dfrac{\\lambda}{2}\\sum_{i=1}^{n_m} \\sum_{k=1}^{n} (x_k^{(i)})^2 + \\dfrac{\\lambda}{2}\\sum_{j=1}^{n_u} \\sum_{k=1}^{n} (\\theta_k^{(j)})^212345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152function [J, grad] = cofiCostFunc(params, Y, R, num_users, num_movies, ... num_features, lambda)%COFICOSTFUNC Collaborative filtering cost function% [J, grad] = COFICOSTFUNC(params, Y, R, num_users, num_movies, ...% num_features, lambda) returns the cost and gradient for the% collaborative filtering problem.%% Unfold the U and W matrices from paramsX = reshape(params(1:num_movies*num_features), num_movies, num_features);Theta = reshape(params(num_movies*num_features+1:end), ... num_users, num_features); % You need to return the following values correctlyJ = 0;X_grad = zeros(size(X));Theta_grad = zeros(size(Theta));% Instructions: Compute the cost function and gradient for collaborative% filtering. %% Notes: X - num_movies x num_features matrix of movie features% Theta - num_users x num_features matrix of user features% Y - num_movies x num_users matrix of user ratings of movies% R - num_movies x num_users matrix, where R(i, j) = 1 if the % i-th movie was rated by the j-th user%% You should set the following variables correctly:%% X_grad - num_movies x num_features matrix, containing the % partial derivatives w.r.t. to each element of X% Theta_grad - num_users x num_features matrix, containing the % partial derivatives w.r.t. to each element of Theta%J = 1/2 * sum(sum(((X * Theta' - Y).*R).^2));X_grad = ((X * Theta' - Y).*R) * Theta;Theta_grad = ((X*Theta' -Y).*R)' * X;% Regular versionJ = J + lambda/2 * sum(sum(Theta .^2)) + lambda/2 * sum(sum(X.^2));X_grad = X_grad + lambda * X;Theta_grad = Theta_grad + lambda * Theta;grad = [X_grad(:); Theta_grad(:)];end% Evaluate cost functionJ = cofiCostFunc([X(:) ; Theta(:)], Y, R, num_users, num_movies, num_features, 1.5); å‘èµ·é¢„æµ‹ï¼Œåœ¨æ•°æ®åº“ä¸­åŠ å…¥è‡ªå·±çš„æ•°æ®ï¼Œéšä¾¿å¯¹ä¸€éƒ¨åˆ†ç”µå½±è¿›è¡Œæ‰“åˆ†ï¼š 1234567891011121314151617181920212223242526272829%% ============== Part 6: Entering ratings for a new user ===============% Before we will train the collaborative filtering model, we will first% add ratings that correspond to a new user that we just observed. This% part of the code will also allow you to put in your own ratings for the% movies in our dataset!%movieList = loadMovieList();% Initialize my ratingsmy_ratings = zeros(1682, 1);% Check the file movie_idx.txt for id of each movie in our dataset% For example, Toy Story (1995) has ID 1, so to rate it \"4\", you can setmy_ratings(1) = 4;% Or suppose did not enjoy Silence of the Lambs (1991), you can setmy_ratings(98) = 2;% We have selected a few movies we liked / did not like and the ratings we% gave are as follows:my_ratings(7) = 3;my_ratings(12)= 5;my_ratings(54) = 4;my_ratings(64)= 5;my_ratings(66)= 3;my_ratings(69) = 5;my_ratings(183) = 4;my_ratings(226) = 5;my_ratings(355)= 5; æˆ‘ä»¬æ‹¥æœ‰äº†ä¸€ä»½æ–°çš„ç”¨æˆ·å¯¹ç”µå½±æ‰“åˆ†çš„æ•°æ®ï¼š 123456789101112New user ratings:Rated 4 for Toy Story (1995)Rated 3 for Twelve Monkeys (1995)Rated 5 for Usual Suspects, The (1995)Rated 4 for Outbreak (1995)Rated 5 for Shawshank Redemption, The (1994)Rated 3 for While You Were Sleeping (1995)Rated 5 for Forrest Gump (1994)Rated 2 for Silence of the Lambs, The (1991)Rated 4 for Alien (1979)Rated 5 for Die Hard 2 (1990)Rated 5 for Sphere (1998) è®­ç»ƒç®—æ³• 1234567891011121314151617181920212223242526272829303132333435363738394041424344%% ================== Part 7: Learning Movie Ratings ====================% Now, you will train the collaborative filtering model on a movie rating % dataset of 1682 movies and 943 users%% Load dataload('ex8_movies.mat');% Add our own ratings to the data matrixY = [my_ratings Y];R = [(my_ratings ~= 0) R];% Normalize Ratings[Ynorm, Ymean] = normalizeRatings(Y, R);% Useful Valuesnum_users = size(Y, 2);num_movies = size(Y, 1);num_features = 10;% Set Initial Parameters (Theta, X)X = randn(num_movies, num_features);Theta = randn(num_users, num_features);initial_parameters = [X(:); Theta(:)];% Set options for fmincgoptions = optimset('GradObj', 'on', 'MaxIter', 100);% Set Regularizationlambda = 10;theta = fmincg (@(t)(cofiCostFunc(t, Ynorm, R, num_users, num_movies, ... num_features, lambda)), ... initial_parameters, options);% Unfold the returned theta back into U and WX = reshape(theta(1:num_movies*num_features), num_movies, num_features);Theta = reshape(theta(num_movies*num_features+1:end), ... num_users, num_features);fprintf('Recommender system learning completed.\\n');fprintf('\\nProgram paused. Press enter to continue.\\n');pause; å…¶ä¸­ï¼Œå‡½æ•°normalizeRatings ç”¨äºå¯¹æ•°æ®è¿›è¡Œå½’ä¸€åŒ–ï¼Œå‡å»å‡å€¼ï¼›å‡½æ•°fmincgä¸ºMATLABè‡ªå¸¦çš„ä¼˜åŒ–å‡½æ•°ï¼› åˆ©ç”¨ç®—æ³•è¿›è¡Œæ¨è 1234567891011121314151617%% ================== Part 8: Recommendation for you ====================% After training the model, you can now make recommendations by computing% the predictions matrix.%p = X * Theta';my_predictions = p(:,1) + Ymean;movieList = loadMovieList();[r, ix] = sort(my_predictions, 'descend');fprintf('\\nTop recommendations for you:\\n');for i=1:10 j = ix(i); fprintf('Predicting rating %.1f for movie %s\\n', my_predictions(j), ... movieList&#123;j&#125;);end è¾“å‡ºç»“æœï¼š 1234567891011Top recommendations for you:Predicting rating 5.0 for movie Someone Else's America (1995)Predicting rating 5.0 for movie Aiqing wansui (1994)Predicting rating 5.0 for movie Great Day in Harlem, A (1994)Predicting rating 5.0 for movie Prefontaine (1997)Predicting rating 5.0 for movie They Made Me a Criminal (1939)Predicting rating 5.0 for movie Entertaining Angels: The Dorothy Day Story (1996)Predicting rating 5.0 for movie Saint of Fort Washington, The (1993)Predicting rating 5.0 for movie Santa with Muscles (1996)Predicting rating 5.0 for movie Star Kid (1997)Predicting rating 5.0 for movie Marlene Dietrich: Shadow and Light (1996) å‚è€ƒ â€‹","categories":[{"name":"åŠ¨æ‰‹å®è·µè¥","slug":"åŠ¨æ‰‹å®è·µè¥","permalink":"http://blog.a-stack.com/categories/åŠ¨æ‰‹å®è·µè¥/"}],"tags":[{"name":"æœºå™¨å­¦ä¹ ","slug":"æœºå™¨å­¦ä¹ ","permalink":"http://blog.a-stack.com/tags/æœºå™¨å­¦ä¹ /"},{"name":"å…¬å¼€è¯¾","slug":"å…¬å¼€è¯¾","permalink":"http://blog.a-stack.com/tags/å…¬å¼€è¯¾/"},{"name":"å®éªŒ","slug":"å®éªŒ","permalink":"http://blog.a-stack.com/tags/å®éªŒ/"},{"name":"çº¿æ€§å›å½’","slug":"çº¿æ€§å›å½’","permalink":"http://blog.a-stack.com/tags/çº¿æ€§å›å½’/"},{"name":"é€»è¾‘å›å½’","slug":"é€»è¾‘å›å½’","permalink":"http://blog.a-stack.com/tags/é€»è¾‘å›å½’/"}]},{"title":"Machine Learning Notes","slug":"machinelearning-notes","date":"2018-04-26T05:56:13.000Z","updated":"2018-05-15T09:14:33.448Z","comments":false,"path":"2018/04/26/machinelearning-notes/","link":"","permalink":"http://blog.a-stack.com/2018/04/26/machinelearning-notes/","excerpt":"","text":"æ‘˜è¦ï¼š æœ€è¿‘èŠ±äº†ä¸¤å‘¨æ—¶é—´åˆ·å®Œäº†å´æ©è¾¾åœ¨Couseraä¸Šå…³äºæœºå™¨å­¦ä¹ çš„ç»å…¸è¯¾ç¨‹, è¿™å·²ç»æ˜¯è¿‘ä¸¤ä¸ªæœˆæ¥åˆ·å®Œçš„ç¬¬åä¸ªCouseraè¯¾ç¨‹äº†ã€‚è™½ç„¶è¯¾ç¨‹æ˜¯å¤šå¹´å‰å¼€è®¾çš„ï¼Œä½†ç›¸å…³æœºå™¨å­¦ä¹ ç†è®ºå’Œæ–¹æ³•å†…å®¹ä»‹ç»ä»ç„¶å…·å¤‡å¾ˆå¼ºçš„æ—¶æ•ˆæ€§ï¼Œæ˜¯æœºå™¨å­¦ä¹ å…¥é—¨çš„å¿…é€‰è¯¾ç¨‹ã€‚ @[toc] æœ€è¿‘èŠ±äº†ä¸¤å‘¨æ—¶é—´åˆ·å®Œäº†å´æ©è¾¾åœ¨Couseraä¸Šå…³äºæœºå™¨å­¦ä¹ çš„ç»å…¸è¯¾ç¨‹, è¿™å·²ç»æ˜¯è¿‘ä¸¤ä¸ªæœˆæ¥åˆ·å®Œçš„ç¬¬åä¸ªCouseraè¯¾ç¨‹äº†ã€‚è™½ç„¶è¯¾ç¨‹æ˜¯å¤šå¹´å‰å¼€è®¾çš„ï¼Œä½†ç›¸å…³æœºå™¨å­¦ä¹ ç†è®ºå’Œæ–¹æ³•å†…å®¹ä»‹ç»ä»ç„¶å…·å¤‡å¾ˆå¼ºçš„æ—¶æ•ˆæ€§ï¼Œæ˜¯æœºå™¨å­¦ä¹ å…¥é—¨çš„å¿…é€‰è¯¾ç¨‹ã€‚ä¸ºäº†å·©å›ºå¯¹è¯¾ç¨‹å†…å®¹å’Œè¯¾åå®éªŒçš„ç†è§£ï¼Œå°†åœ¨æœªæ¥ä¸€å‘¨å®è·µå†™å‡ ç¯‡æ€»ç»“æ€§ç¬”è®°ï¼Œä½œä¸ºå¯¹è¯¾ç¨‹å†…å®¹çš„å›é¡¾å’Œæ€»ç»“ã€‚ Lecture 1ï¼š æœºå™¨å­¦ä¹ çš„å®šä¹‰ Tom Mitchell provides a modern definition: â€œA computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.â€ ç›‘ç£å­¦ä¹ çš„ä¸€ä¸ªä¸»è¦ç‰¹ç‚¹ï¼Œæ˜¯åœ¨æ‹¿åˆ°æ•°æ®çš„é‚£ä¸€åˆ»ï¼Œæˆ‘ä»¬å·²ç»çŸ¥é“æ­£ç¡®çš„è¾“å‡ºç›®æ ‡èŒƒå›´ï¼› ç›‘ç£å­¦ä¹ å¯ä»¥åˆ†ä¸ºåˆ†ç±»é—®é¢˜å’Œå›å½’é—®é¢˜ï¼› é¸¡å°¾é…’ä¼šé—®é¢˜åŠé¸¡å°¾é…’ä¼šç®—æ³•ï¼šWiki, å±äºéèšç±»çš„éç›‘ç£é—®é¢˜ Lecture 2ï¼š çº¿æ€§å›å½’ï¼ˆå¤šå±æ€§ï¼‰å˜é‡å®šä¹‰$x_j^{(i)}$ : ç¬¬$i^{th}$è®­ç»ƒæ ·æœ¬çš„ç¬¬$j$ä¸ªç‰¹å¾å‘é‡ï¼› $x^{(i)}$ : ç¬¬$i^{th}$è®­ç»ƒæ ·æœ¬çš„ç‰¹å¾å‘é‡ï¼› $m$ ï¼š è®­ç»ƒæ ·æœ¬æ•°ç›®ï¼› $n$ ï¼š ç‰¹å¾æ•°ç›® å¤šå…ƒçº¿æ€§è§„åˆ’æ¨¡å‹å‡è®¾å‡½æ•° \\begin{equation} h_\\theta (x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\theta_3 x_3 + \\cdots + \\theta_n x_n = \\theta ^T x \\tag{1.a} \\end{equation} ä»¥ä¸Šè¡¨è¾¾å¼ä¸­å¯¹$\\theta$ å’Œ $x$ è¿›è¡Œäº†ç»´åº¦å˜æ¢ï¼Œ$x_0=1,for(i\\in1,â€¦,m)$ $\\theta .shape = (n+1, 1)$ $x.shape = (m,n+1)$ ä»£ä»·å‡½æ•° J(\\theta) = \\dfrac {1}{2m} \\displaystyle \\sum_{i=1}^m \\left (h_\\theta (x^{(i)}) - y^{(i)} \\right)^2 = \\dfrac {1}{2m} (X\\theta - \\vec{y})^{T} (X\\theta - \\vec{y})æ¢¯åº¦ \\theta := \\theta - \\frac{\\alpha}{m} X^{T} (X\\theta - \\vec{y})ç‰¹å¾æ­£åˆ™åŒ– Feature scaling å’Œ mean normalizationå®ç°; å½’ä¸€åŒ–çš„ç›®çš„ï¼Œæ˜¯ä¸ºäº†æ”¶æ•›åŸŸå¯¹å…¶ï¼Œæ›´å®¹æ˜“æ”¶æ•›ï¼Œæ¢¯åº¦ä¸‹é™æ›´å®¹æ˜“æ‰¾åˆ°æœ€ä½³æ–¹å‘ï¼› å´æ©è¾¾æ‰“äº†ä¸ªå¾ˆå¥½çš„æ¯”å–»ï¼Œä¸¤ä¸ªå‚æ•°èŒƒå›´ä¸ä¸€è‡´ï¼Œæ¢¯åº¦ä¸‹é™æ˜¯ä¸€ä¸ªæ¤­åœ†ï¼› x_i := \\dfrac{x_i - \\mu_i}{s_i}å‚æ•°åˆ†æ \\theta = (X^T X)^{-1}X^T y Gradient Descent Normal Equation Need to choose alpha No need to choose alpha Needs many iterations No need to iterate $O(kn^2)$ $O(n^3)$ ,è®¡ç®—å¤æ‚åº¦æ¥è‡ª$X^TX$ çš„è®¡ç®— Works well when n is large Slow if n is very large Lecture 3ï¼šé€»è¾‘å›å½’ é€»è¾‘å›å½’åç§°çš„ç”±æ¥ï¼šé€»è¾‘å›å½’æ¥æºäºLogistic åˆ†å¸ƒï¼Œè™½ç„¶åå­—å¸¦å›å½’ï¼Œä½†è§£å†³çš„æ˜¯åˆ†ç±»é—®é¢˜ã€‚è€Œå…¶å¯†åº¦å‡½æ•°æ›²çº¿æ­£å¯¹åº”ç€Sigmoidå‡½æ•°çš„æ›²çº¿å½¢çŠ¶ã€‚ å‡è®¾å‡½æ•° \\begin{align*} h_\\theta (x) = g ( \\theta^T x ) \\\\ z = \\theta^T x \\\\g(z) = \\dfrac{1}{1 + e^{-z}}\\end{align*}å‡è®¾å‡½æ•°è¾“å‡ºçš„åˆ†ç±»ç›®æ ‡çš„æ¡ä»¶æ¦‚ç‡ï¼š \\begin{align*}& h_\\theta(x) = P(y=1 | x ; \\theta) = 1 - P(y=0 | x ; \\theta) \\newline& P(y = 0 | x;\\theta) + P(y = 1 | x ; \\theta) = 1\\end{align*}ä»£ä»·å‡½æ•° \\begin{align*}& J(\\theta) = \\dfrac{1}{m} \\sum_{i=1}^m \\mathrm{Cost}(h_\\theta(x^{(i)}),y^{(i)})=-\\frac{1}{m}(y^Tlog(h)+(1-y)^T(1-h)) \\newline & \\mathrm{Cost}(h_\\theta(x),y) = -\\log(h_\\theta(x)) \\; & \\text{if y = 1} \\newline & \\mathrm{Cost}(h_\\theta(x),y) = -\\log(1-h_\\theta(x)) \\; & \\text{if y = 0}\\end{align*}æ¢¯åº¦ \\theta := \\theta - \\frac{\\alpha}{m} X^{T} (g(X \\theta ) - \\vec{y}) \\sigma(x)'=\\sigma(x)(1 - \\sigma(x)) ä¸€äº›æ¢¯åº¦ä¸‹é™ç®—æ³•ä¹‹å¤–çš„é€‰æ‹©ï¼š é™¤äº†æ¢¯åº¦ä¸‹é™ç®—æ³•ä»¥å¤–ï¼Œè¿˜æœ‰ä¸€äº›å¸¸è¢«ç”¨æ¥ä»¤ä»£ä»·å‡½æ•°æœ€å°çš„ç®—æ³•ï¼Œè¿™äº›ç®—æ³•æ›´åŠ å¤æ‚å’Œä¼˜è¶Šï¼Œè€Œä¸”é€šå¸¸ä¸éœ€è¦äººå·¥é€‰æ‹©å­¦ä¹ ç‡ï¼Œé€šå¸¸æ¯”æ¢¯åº¦ä¸‹é™ç®—æ³•è¦æ›´åŠ å¿«é€Ÿã€‚è¿™äº›ç®—æ³•æœ‰ï¼šå…±è½­æ¢¯åº¦ï¼ˆConjugate Gradientï¼‰ï¼Œå±€éƒ¨ä¼˜åŒ–æ³•(Broyden fletcher goldfarb shann,BFGS)å’Œæœ‰é™å†…å­˜å±€éƒ¨ä¼˜åŒ–æ³•(LBFGS)fminuncæ˜¯ matlabå’Œoctave ä¸­éƒ½å¸¦çš„ä¸€ä¸ªæœ€å°å€¼ä¼˜åŒ–å‡½æ•°ï¼Œä½¿ç”¨æ—¶æˆ‘ä»¬éœ€è¦æä¾›ä»£ä»·å‡½æ•°å’Œæ¯ä¸ªå‚æ•°çš„æ±‚å¯¼ å¤šåˆ†ç±»ï¼š One-vs-allæ¯ä¸ªåˆ†ç±»ç›®æ ‡å¯¹åº”ä¸€ä¸ªåˆ†ç±»å™¨ï¼Œè®¡ç®—åˆ†ç±»è¿‡ç¨‹ä¸­ï¼Œå–é¢„æµ‹å€¼æœ€å¤§çš„åˆ†ç±»å™¨è¾“å‡ºä½œä¸ºæœ€ç»ˆåˆ†ç±»ç»“æœï¼š prediction = \\max_i( h_\\theta ^{(i)}(x) )æ­£åˆ™åŒ–æ­£åˆ™åŒ–çš„çº¿æ€§å›å½’ \\begin{align*} & \\text{Repeat}\\ \\lbrace \\newline & \\ \\ \\ \\ \\theta_0 := \\theta_0 - \\alpha\\ \\frac{1}{m}\\ \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})x_0^{(i)} \\newline & \\ \\ \\ \\ \\theta_j := \\theta_j - \\alpha\\ \\left[ \\left( \\frac{1}{m}\\ \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \\right) + \\frac{\\lambda}{m}\\theta_j \\right] &\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ j \\in \\lbrace 1,2...n\\rbrace\\newline & \\rbrace \\end{align*}æ·»åŠ æ­£åˆ™åŒ–çš„æ•°å€¼è§£ \\begin{align*}& \\theta = \\left( X^TX + \\lambda \\cdot L \\right)^{-1} X^Ty \\newline& \\text{where}\\ \\ L = \\begin{bmatrix} 0 & & & & \\newline & 1 & & & \\newline & & 1 & & \\newline & & & \\ddots & \\newline & & & & 1 \\newline\\end{bmatrix}\\end{align*}æ­£åˆ™åŒ–çš„é€»è¾‘å›å½’ J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^m \\large[ y^{(i)}\\ \\log (h_\\theta (x^{(i)})) + (1 - y^{(i)})\\ \\log (1 - h_\\theta(x^{(i)}))\\large] + \\frac{\\lambda}{2m}\\sum_{j=1}^n \\theta_j^2 \\begin{array}& \\text{Repeat}\\ \\lbrace \\newline& \\ \\ \\ \\ \\theta_0 := \\theta_0 - \\alpha\\ \\frac{1}{m}\\ \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})x_0^{(i)} \\newline& \\ \\ \\ \\ \\theta_j := \\theta_j - \\alpha\\ \\left[ \\left( \\frac{1}{m}\\ \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \\right) + \\frac{\\lambda}{m}\\theta_j \\right] &\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ j \\in \\lbrace 1,2...n\\rbrace\\newline& \\rbrace\\end{array}Lecture 4-5: ç¥ç»ç½‘ç»œ å¤§è„‘å­¦ä¹ çš„åŸç†ä¸¾ä¾‹ï¼š äººç±»å¤±å»çœ¼ç›ï¼Œå¯ä»¥å­¦ä¹ é€šè¿‡è¶…å£°æ¥åˆ¤æ–­ç‰©ä½“å’Œæ–¹ä½ï¼Œå…·å¤‡çœ‹çš„èƒ½åŠ›ï¼› If networkhas $s_j$ units in layer j and $s_j +1$ units in layer j+1, then Î˜(j) willbe of dimension sj+1Ã—(sj+1). å¤šåˆ†ç±» \\begin{align*}\\begin{bmatrix}x_0 \\newline x_1 \\newline x_2 \\newline\\cdots \\newline x_n\\end{bmatrix} \\rightarrow\\begin{bmatrix}a_0^{(2)} \\newline a_1^{(2)} \\newline a_2^{(2)} \\newline\\cdots\\end{bmatrix} \\rightarrow\\begin{bmatrix}a_0^{(3)} \\newline a_1^{(3)} \\newline a_2^{(3)} \\newline\\cdots\\end{bmatrix} \\rightarrow \\cdots \\rightarrow\\begin{bmatrix}h_\\Theta(x)_1 \\newline h_\\Theta(x)_2 \\newline h_\\Theta(x)_3 \\newline h_\\Theta(x)_4 \\newline\\end{bmatrix} \\rightarrow\\end{align*}ä»£ä»·å‡½æ•° \\begin{gather*}\\large J(\\Theta) = - \\frac{1}{m} \\sum_{i=1}^m \\sum_{k=1}^K \\left[y^{(i)}_k \\log ((h_\\Theta (x^{(i)}))_k) + (1 - y^{(i)}_k)\\log (1 - (h_\\Theta(x^{(i)}))_k)\\right] + \\frac{\\lambda}{2m}\\sum_{l=1}^{L-1} \\sum_{i=1}^{s_l} \\sum_{j=1}^{s_{l+1}} ( \\Theta_{j,i}^{(l)})^2\\end{gather*}åå‘ä¼ æ’­ å‚è§ï¼š Backpropagation-in-Neural-Network æ¢¯åº¦æ ¡éªŒ \\dfrac{\\partial}{\\partial\\Theta_j}J(\\Theta) \\approx \\dfrac{J(\\Theta_1, \\dots, \\Theta_j + \\epsilon, \\dots, \\Theta_n) - J(\\Theta_1, \\dots, \\Theta_j - \\epsilon, \\dots, \\Theta_n)}{2\\epsilon}Lecture 6ï¼šé‡‡ç”¨æœºå™¨å­¦ä¹ çš„å»ºè®®bias ä¸ variance é«˜åå·®==æ¬ æ‹Ÿåˆ é«˜æ–¹å·®==è¿‡æ‹Ÿåˆ æ­£åˆ™åŒ–ä¸åå·®/æ–¹å·®ï¼š å¤§çš„$\\lambda$ :é«˜åå·®ï¼ˆæ¬ æ‹Ÿåˆï¼‰ï¼› å°çš„$\\lambda$ :é«˜æ–¹å·®ï¼ˆè¿‡æ‹Ÿåˆï¼‰ï¼› é€‰æ‹©åˆé€‚çš„æ­£åˆ™åŒ–å‚æ•° å­¦ä¹ æ›²çº¿ï¼ˆLearning Curvesï¼‰ é”™è¯¯ç‡éšæ ·æœ¬æ•°ç›®å˜åŒ–çš„æ›²çº¿ï¼› å¦‚æœç®—æ³•è¿‡æ‹Ÿåˆï¼Œå¢å¤§æ ·æœ¬æ•°æœ‰åŠ©äºæå‡ç®—æ³•æ€§èƒ½ Lecture 7ï¼š SVM z = \\theta^Tx \\text{cost}_0(z) = \\max(0, k(1+z)) \\text{cost}_1(z) = \\max(0, k(1-z)) æ›´å¤šå†…å®¹æŸ¥çœ‹WiKiï¼š Hingle loss ä»£ä»·å‡½æ•° J(\\theta) = C\\sum_{i=1}^m y^{(i)} \\ \\text{cost}_1(\\theta^Tx^{(i)}) + (1 - y^{(i)}) \\ \\text{cost}_0(\\theta^Tx^{(i)}) + \\dfrac{1}{2}\\sum_{j=1}^n \\Theta^2_j C = \\frac{1}{\\lambda} å› ä¸ºSVMçš„ä¼˜åŒ–ç›®æ ‡ä¸ºæœ€å¤§åŒ–è¾¹ç•Œä¸¾ä¾‹ï¼Œæ‰€æœ‰SVMä¹Ÿå«åšLarge Margin Classifier æ ¸å‡½æ•°å®ç°SVMéçº¿æ€§åˆ†ç±»çš„åŸºç¡€ï¼Œå°†ä½ç»´ç©ºé—´ç‚¹æŠ•å°„åˆ°é«˜ç»´ç©ºé—´ï¼Œå®šä¹‰è¿‘ä¼¼å‡½æ•°ï¼š é«˜æ–¯æ ¸å‡½æ•°(ä¸»è¦å‚æ•°ä¸º $\\sigma$) f_i = similarity(x, l^{(i)}) = \\exp(-\\dfrac{\\sum^n_{j=1}(x_j-l_j^{(i)})^2}{2\\sigma^2})å‚æ•° $C=\\frac{1}{\\lambda}$ å¦‚æœ$C$ è¿‡å¤§ï¼Œé«˜æ–¹å·®ã€ä½åå·®ï¼› å¦‚æœ$C$ è¿‡å°ï¼Œé«˜åå·®ã€ä½æ–¹å·®ï¼› $\\sigma^2$ å¦‚æœ$\\sigma^2$ è¿‡å¤§ï¼Œç‰¹å¾æ›´åŠ å¹³ç¼“ï¼Œå¯¼è‡´é«˜åå·®ï¼Œä½æ–¹å·®ï¼› å¦‚æœ$\\sigma^2$ è¿‡å°ï¼Œç‰¹å¾åˆ†å¸ƒæ›´é›†ä¸­ï¼Œå¯¼è‡´é«˜æ–¹å·®ï¼Œä½åå·®ï¼› Lecture 8: K-Means å’Œ PCAK-Means ç®—æ³•å®ç°(Cluster Assignment+Move Centroid)ï¼š 123456Randomly initialize K cluster centroids mu(1), mu(2), ..., mu(K)Repeat: for i = 1 to m: c(i):= index (from 1 to K) of cluster centroid closest to x(i) for k = 1 to K: mu(k):= average (mean) of points assigned to cluster k c^{(i)} = argmin_k\\ ||x^{(i)} - \\mu_k||^2ä¼˜åŒ–ç›®æ ‡ J(c^{(i)},\\dots,c^{(m)},\\mu_1,\\dots,\\mu_K) = \\dfrac{1}{m}\\sum_{i=1}^m ||x^{(i)} - \\mu_{c^{(i)}}||^2æ³¨æ„äº‹é¡¹ Kä¸ªåˆå§‹å¯¹è±¡çš„é€‰æ‹©åº”ä¸ºéšæœºé€‰å–kä¸ªè®­ç»ƒæ ·æœ¬ï¼› ä¸ºäº†å°½é‡é¿å…é™·å…¥å±€éƒ¨æå°å€¼ï¼Œéœ€è¦è¿›è¡Œå¤šæ¬¡éšæœºåˆå§‹åŒ–æ±‚è§£ï¼Œé€‰æ‹©ä»£ä»·å‡½æ•°æœ€å°çš„è§£ï¼› Kçš„é€‰æ‹©ï¼Œå¯ä»¥é‡‡ç”¨elbow methodï¼š Choose K at the point where the cost function starts to flatten out. PCAé™ç»´çš„ç›®çš„ï¼š 1. æ•°æ®å‹ç¼©ï¼›2. å¯è§†åŒ–ï¼› The goal of PCA is to reduce the average of all the distances of every feature to the projection line. PCAä¸çº¿æ€§å›å½’ä¸åŒä¹‹å¤„åœ¨äºï¼Œè®¡ç®—çš„å„ç‚¹åˆ°åˆ†å‰²çº¿çš„æœ€çŸ­è·ç¦»ï¼› ç®—æ³•æµç¨‹ æ•°æ®é¢„å¤„ç†ï¼šå½’ä¸€åŒ–ï¼› è®¡ç®—åæ–¹å·®çŸ©é˜µ \\Sigma = \\dfrac{1}{m}\\sum^m_{i=1}(x^{(i)})(x^{(i)})^T è®¡ç®—$\\Sigma$ çš„ç‰¹å¾çŸ©é˜µ 1[U,S,V] = svd(Sigma); å–$U$ çš„å‰kåˆ—è®¡ç®—$z$ z^{(i)} = Ureduce^T \\cdot x^{(i)} æ¢å¤ x_{approx}^{(1)} = U_{reduce} \\cdot z^{(1)}kå€¼çš„é€‰æ‹© \\dfrac{\\dfrac{1}{m}\\sum^m_{i=1}||x^{(i)} - x_{approx}^{(i)}||^2}{\\dfrac{1}{m}\\sum^m_{i=1}||x^{(i)}||^2} \\leq 0.01 æè¿°äº†ä¸¢å¤±ç‰¹å¾çš„æ¯”ä¾‹ å¯ä»¥é€šè¿‡SVDåˆ†è§£ä¹‹åçš„Så€¼æ¥åšåŒæ ·çš„äº‹æƒ…ï¼š \\dfrac{\\sum_{i=1}^kS_{ii}}{\\sum_{i=1}^nS_{ii}} \\geq 0.99Lecture 9ï¼š åº”ç”¨1-å¼‚å¸¸æ£€æµ‹ x(i)= features of user iâ€™s activities Model p(x) from the data. Identify unusual users by checking which have p(x)&lt;Ïµ. é«˜æ–¯åˆ†å¸ƒ $x \\sim \\mathcal{N}(\\mu, \\sigma^2)$ p(x;\\mu,\\sigma^2) = \\frac{1}{\\sigma\\sqrt{(2\\pi)}}e^{-\\frac{1}{2}(\\frac{x - \\mu}{\\sigma})^2} p(x) = p(x_1;\\mu_1,\\sigma_1^2)p(x_2;\\mu_2,\\sigma^2_2)\\cdots p(x_n;\\mu_n,\\sigma^2_n)= \\displaystyle \\prod^n_{j=1} p(x_j;\\mu_j,\\sigma_j^2)ç®—æ³•æµç¨‹ è®¡ç®—å‡å€¼å’Œæ–¹å·® è®¡ç®—æ¦‚ç‡åˆ†å¸ƒå‡½æ•° p(x) = \\displaystyle \\prod^n_{j=1} p(x_j;\\mu_j,\\sigma_j^2) = \\prod\\limits^n_{j=1} \\dfrac{1}{\\sqrt{2\\pi}\\sigma_j}exp(-\\dfrac{(x_j - \\mu_j)^2}{2\\sigma^2_j}) åˆ©ç”¨æ ‡è®°æ•°æ®ç¡®å®šÏµ æ•°æ®é¢„å¤„ç†ä¸ºäº†æ»¡è¶³é«˜æ–¯åˆ†å¸ƒï¼Œéœ€è¦å¯¹åŸå§‹æ•°æ®è¿›è¡Œè½¬æ¢ï¼š log(x) log(x+1) log(x+c) for some constant $\\sqrt x$ $x^{1/3}$ å¤šå…ƒé«˜æ–¯åˆ†å¸ƒ p(x;\\mu,\\Sigma) = \\dfrac{1}{(2\\pi)^{n/2} |\\Sigma|^{1/2}} exp(-1/2(x-\\mu)^T\\Sigma^{-1}(x-\\mu)) ä¼ ç»Ÿé«˜æ–¯æ¨¡å‹ä¹˜ç§¯æ˜¯å¤šå…ƒå¤šå…ƒé«˜æ–¯çš„ä¸€ç§ç‰¹ä¾‹ $\\Sigma$ ä¸ºåæ–¹å·®çŸ©é˜µï¼Œå¦‚ä½•å‡è®¾$A$ ä¸ºéå¥‡å¼‚çŸ©é˜µï¼Œè¿›è¡Œç‰¹å¾å˜æ¢ï¼š$y=Ax$,åˆ™$\\Sigma = AA^T$ å¤šå…ƒé«˜æ–¯åˆ†å¸ƒ vs ä¼ ç»Ÿé«˜æ–¯æ¨¡å‹ å¤šå…ƒ æ›´èƒ½æ•è·ç‰¹å¾ä¹‹é—´çš„å…³è”æ€§ï¼› å¤šå…ƒ è®¡ç®—æ›´è€—æ—¶ï¼› å¤šå…ƒçš„å‰æï¼Œæ ·æœ¬æ•° &gt; ç‰¹å¾æ•°ï¼›m&gt;10n Lecture 10: åº”ç”¨2-æ¨èç³»ç»Ÿé—®é¢˜æŠ½è±¡ä»¥ç”µå½±æ¨èä¸ºä¾‹ï¼Œå®šä¹‰å¦‚ä¸‹å˜é‡ï¼š $n_\\mu$ = ç”¨æˆ·æ•°ç›® $n_m$ = ç”µå½±æ•°ç›® $r(i,j)=1$ = 1,å¦‚æœç”¨æˆ·jå¯¹ç”µå½±iè¯„åˆ† $y(i,j)=rating_score$ åŸºäºå†…å®¹çš„æ¨è min_{\\theta^{(1)},\\dots,\\theta^{(n_u)}} = \\dfrac{1}{2}\\displaystyle \\sum_{j=1}^{n_u} \\sum_{i:r(i,j)=1} ((\\theta^{(j)})^T(x^{(i)}) - y^{(i,j)})^2 + \\dfrac{\\lambda}{2} \\sum_{j=1}^{n_u} \\sum_{k=1}^n(\\theta_k^{(j)})^2ååŒè¿‡æ»¤ æ—¢å­¦ä¹ å‚æ•°åˆå­¦ä¹ ç‰¹å¾è¡¨ç¤º J(x,\\theta) = \\dfrac{1}{2} \\displaystyle \\sum_{(i,j):r(i,j)=1}((\\theta^{(j)})^Tx^{(i)} - y^{(i,j)})^2 + \\dfrac{\\lambda}{2}\\sum_{i=1}^{n_m} \\sum_{k=1}^{n} (x_k^{(i)})^2 + \\dfrac{\\lambda}{2}\\sum_{j=1}^{n_u} \\sum_{k=1}^{n} (\\theta_k^{(j)})^2å‚è€ƒ SVMï¼šhttp://web.mit.edu/6.034/wwwbob/svm-notes-long-08.pdf â€‹","categories":[{"name":"æœºå™¨å­¦ä¹ ","slug":"æœºå™¨å­¦ä¹ ","permalink":"http://blog.a-stack.com/categories/æœºå™¨å­¦ä¹ /"}],"tags":[{"name":"ç®—æ³•","slug":"ç®—æ³•","permalink":"http://blog.a-stack.com/tags/ç®—æ³•/"},{"name":"æœºå™¨å­¦ä¹ ","slug":"æœºå™¨å­¦ä¹ ","permalink":"http://blog.a-stack.com/tags/æœºå™¨å­¦ä¹ /"},{"name":"çº¿æ€§å›å½’","slug":"çº¿æ€§å›å½’","permalink":"http://blog.a-stack.com/tags/çº¿æ€§å›å½’/"},{"name":"é€»è¾‘å›å½’","slug":"é€»è¾‘å›å½’","permalink":"http://blog.a-stack.com/tags/é€»è¾‘å›å½’/"},{"name":"ç¬”è®°","slug":"ç¬”è®°","permalink":"http://blog.a-stack.com/tags/ç¬”è®°/"},{"name":"ç¥ç»ç½‘ç»œ","slug":"ç¥ç»ç½‘ç»œ","permalink":"http://blog.a-stack.com/tags/ç¥ç»ç½‘ç»œ/"}]},{"title":"æœºå™¨å­¦ä¹ ä¸‰è¦ç´ ï¼šæ¨¡å‹,ç­–ç•¥ä¸ç®—æ³•","slug":"æœºå™¨å­¦ä¹ ä¸‰è¦ç´ -æ¨¡å‹-ç­–ç•¥ä¸ç®—æ³•","date":"2018-04-21T15:12:04.000Z","updated":"2018-05-15T09:14:33.495Z","comments":false,"path":"2018/04/21/æœºå™¨å­¦ä¹ ä¸‰è¦ç´ -æ¨¡å‹-ç­–ç•¥ä¸ç®—æ³•/","link":"","permalink":"http://blog.a-stack.com/2018/04/21/æœºå™¨å­¦ä¹ ä¸‰è¦ç´ -æ¨¡å‹-ç­–ç•¥ä¸ç®—æ³•/","excerpt":"","text":"æ‘˜è¦ï¼š æèˆªåœ¨ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹ä¸­å°†ç»Ÿè®¡å­¦ä¹ æ–¹æ³•çš„ä¸‰è¦ç´ â€”â€”æ¨¡å‹ã€ç­–ç•¥ã€ç®—æ³•æ€»ç»“ä¸ºæœºå™¨å­¦ä¹ æ–¹æ³•çš„æçº²æŒˆé¢†ã€‚è¿™ç¯‡åšæ–‡ä¸»è¦æ€»ç»“å½’çº³ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹ä¸­å¯¹äºè¿™ä¸‰è¦ç´ çš„é˜è¿°ã€‚ @[toc] æœ€è¿‘åœ¨è¯»æèˆªçš„ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹ï¼Œä½œè€…ä»ç»Ÿè®¡å­¦ä¹ çš„æ–¹æ³•æ¥åˆ†ææœºå™¨å­¦ä¹ æŠ€æœ¯ï¼Œåˆ†æå¾ˆç»†è‡´æ·±åˆ»ï¼Œå€¼å¾—åæ€ï¼Œæœªæ¥å°†é€æ­¥æ€»ç»“ç›¸å…³å†…å®¹ï¼ŒæœŸå¾…æ›´å¤šå…±é¸£ä¸æ€è€ƒã€‚ ä»€ä¹ˆæ˜¯ç»Ÿè®¡æœºå™¨å­¦ä¹ ç»Ÿè®¡å­¦ä¹ åˆå«ç»Ÿè®¡æœºå™¨å­¦ä¹ ï¼Œæ˜¯å…³äºè®¡ç®—æœºåŸºäºæ•°æ®æ„å»ºæ¦‚ç‡ç»Ÿè®¡æ¨¡å‹å¹¶è¿ç”¨æ¨¡å‹å¯¹æ•°æ®è¿›è¡Œé¢„æµ‹ä¸åˆ†æçš„ä¸€é—¨å­¦ç§‘ã€‚ ç»Ÿè®¡å­¦ä¹ çš„å¯¹è±¡æ˜¯å…·å¤‡ä¸€å®šç»Ÿè®¡è§„å¾‹çš„æ•°æ®ï¼ŒåŒæ—¶å¯¹æ•°æ®æœ‰ä¸€ä¸ªå¼ºå‡è®¾ï¼šæ•°æ®æ˜¯ç‹¬ç«‹åŒåˆ†å¸ƒäº§ç”Ÿçš„ã€‚å­¦ä¹ çš„æ¨¡å‹å±äºæŸä¸ªå‡½æ•°çš„é›†åˆï¼Œç§°ä¸ºå‡è®¾ç©ºé—´(hypothesis space)ï¼Œåº”ç”¨æŸä¸ªè¯„ä»·å‡†åˆ™(evaluation criterion) ä»å‡è®¾ç©ºé—´ä¸­é€‰å–ä¸€ä¸ªæœ€ä¼˜çš„æ¨¡å‹ï¼Œä½¿å®ƒå¯¹å·²çŸ¥è®­ç»ƒæ•°æ®å’ŒæœªçŸ¥æµ‹è¯•æ•°æ®åœ¨ç»™å®šè¯„ä»·å‡†åˆ™ä¸‹æœ‰æœ€ä¼˜çš„é¢„æµ‹ç»“æœï¼Œè¿™ä¸ªæ¨¡å‹çš„é€‰å–è¿‡ç¨‹ç”±ç®—æ³•å®ç°ã€‚è¿™æ ·ç»Ÿè®¡å­¦ä¹ çš„æ–¹æ³•ç”±æ¨¡å‹çš„å‡è®¾ç©ºé—´ã€æ¨¡å‹é€‰æ‹©çš„å‡†åˆ™ä»¥åŠæ¨¡å‹çš„å­¦ä¹ ç®—æ³•ç»„æˆï¼Œç§°ä¸ºç»Ÿè®¡æœºå™¨å­¦ä¹ çš„ä¸‰è¦ç´ ã€‚ æ¦‚å¿µå®šä¹‰ è¾“å…¥ç©ºé—´ï¼š è¾“å…¥å˜é‡$X={x_1, x_2, â€¦, x_N}$ æ„æˆçš„ç©ºé—´ï¼› è¾“å‡ºç©ºé—´ï¼šå¯¹äºè¾“å…¥å˜é‡çš„çœŸå®è¾“å‡º$Y={y_1, y_2,â€¦,y_N}$ æ„æˆçš„ç©ºé—´ï¼› ç‰¹å¾ç©ºé—´ï¼šæ¯ä¸ªè¾“å…¥å˜é‡éƒ½å¯ä»¥ç”±ä¸€ç»„ç‰¹å¾å‘é‡è¡¨ç¤ºï¼Œè¿™äº›ç‰¹å¾å‘é‡æ„æˆäº†ç‰¹å¾ç©ºé—´ï¼› æ¨¡å‹å®é™…ä¸Šéƒ½æ˜¯å®šä¹‰åœ¨ç‰¹å¾ç©ºé—´ä¸Šçš„ï¼› å‡è®¾ç©ºé—´ï¼š åŒ…å«æ‰€æœ‰å¯èƒ½çš„æ˜ å°„å…³ç³»é›†åˆ $F={ f|y=f_{\\theta}(X), \\theta \\in R^n}$ è¾“å…¥åˆ°è¾“å‡ºçš„æ˜ å°„çš„é›†åˆï¼Œè¡¨ç¤ºä¸ºæ¡ä»¶æ¦‚ç‡åˆ†å¸ƒ$\\hat P(X|Y)$ æˆ–å†³ç­–å‡½æ•° $Y = \\hat f(X)$ å‚æ•°ç©ºé—´ï¼š æ„æˆå‡è®¾ç©ºé—´æ¯ä¸ªæ˜ å°„å‡½æ•°çš„å‚æ•°æ‰€å½¢æˆçš„ç©ºé—´ï¼› ç›‘ç£å­¦ä¹ çš„è”åˆæ¦‚ç‡åˆ†å¸ƒï¼š ç›‘ç£å­¦ä¹ å‡è®¾è¾“å…¥ä¸è¾“å‡ºçš„éšæœºå˜é‡$X$ å’Œ $Y$ éµå¾ªè”åˆæ¦‚ç‡åˆ†å¸ƒ $P(X,Y)$ , æœºå™¨å­¦ä¹ çš„å‰ææ˜¯å‡è®¾è¯¥æ¦‚ç‡åˆ†å¸ƒå­˜åœ¨ï¼Œä½†å…·ä½“å®šä¹‰æ˜¯æœªçŸ¥çš„ï¼ˆå¦‚æœçŸ¥é“çš„è¯ä¹Ÿæ²¡å¿…è¦é€šè¿‡æœºå™¨å­¦ä¹ æ¥è·å–çš„äº†ï¼Œç›´æ¥å¯ä»¥é€šè¿‡æ¡ä»¶å‡½æ•°æ¥é¢„æµ‹æœªçŸ¥ç»“æœï¼‰ã€‚è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®è¢«çœ‹ä½œæ˜¯ä¾æ®è”åˆæ¦‚ç‡åˆ†å¸ƒ$P(X,Y)$ ç‹¬ç«‹åŒåˆ†å¸ƒäº§ç”Ÿçš„ã€‚è¿™æ˜¯æœºå™¨å­¦ä¹ æ•°æ®å…·å¤‡ä¸€å®šç»Ÿè®¡è§„å¾‹çš„åŸºæœ¬å‡è®¾ã€‚ æ¨¡å‹å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œåœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œæ¨¡å‹æè¿°çš„æ˜¯ä¸€ç»„ä»è¾“å…¥åˆ°è¾“å‡ºçš„æ˜ å°„å…³ç³»çš„å‡½æ•°è¡¨ç¤ºã€‚ åœ¨ç›‘ç£å­¦ä¹ ä¸­ï¼Œæ¨¡å‹å°±æ˜¯ä»å‡è®¾ç©ºé—´ä¸­æ‰€è¦å­¦ä¹ æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒ$\\hat P(X|Y)$ æˆ–å†³ç­–å‡½æ•° $Y = \\hat f(X)$ ã€‚ ç­–ç•¥ç­–ç•¥æè¿°äº†å­¦ä¹ çš„ç›®æ ‡å‡½æ•°ï¼Œé€šè¿‡ä»€ä¹ˆæ ·çš„å‡†åˆ™ä½¿å­¦ä¹ çš„æ–¹å‘æœ€ç»ˆé€¼è¿‘æœ€ç»ˆçš„ä¼˜åŒ–ç›®æ ‡ä»è€Œèƒ½å¤Ÿä»å‡è®¾ç©ºé—´ä¸­é€‰å–æœ€ä¼˜çš„æ¨¡å‹ã€‚ä¸€èˆ¬é‡‡ç”¨æŸå¤±å‡½æ•°æˆ–ä»£ä»·å‡½æ•°æ¥å¯¹æ¨¡å‹çš„å¥½åè¿›è¡Œåº¦é‡ã€‚æŸå¤±å‡½æ•°æ˜¯$f(X)$ å’Œ $Y$ çš„éè´Ÿå®å€¼å‡½æ•°ï¼Œè®°ä½œ $L(Y, f(X))$ ã€‚ æŸå¤±å‡½æ•°æ•°å€¼è¶Šå°ï¼Œæ¨¡å‹è¶Šå¥½ï¼ŒæŸå¤±å‡½æ•°çš„æœŸæœ›ä¸ºï¼š R_{exp} (f) = E_p [L(Y,f(x))] = \\int_{x\\times y} L(y,f(x))P(x,y)dxdyè¿™æ˜¯ç†è®ºä¸Šæ¨¡å‹$f(X)$ å…³äºè”åˆåˆ†å¸ƒçš„å¹³å‡æ„ä¹‰ä¸‹çš„æŸå¤±ï¼Œç§°ä¸ºé£é™©å‡½æ•°æˆ–æœŸæœ›æŸå¤±ã€‚ç”±äº$P(X,Y)$ æœªçŸ¥ï¼Œæ‰€ä»¥æœŸæœ›æŸå¤±æ— æ³•ç›´æ¥è®¡ç®—ã€‚å› æ­¤å¼•å…¥å¦ä¸€ä¸ªæ¦‚å¿µï¼šç»éªŒé£é™©ï¼ˆæŸå¤±ï¼‰ï¼š R_{emp} (f) = \\frac{1}{N} \\sum_{i=1}^NL(y_i,f(x_i))ç»éªŒé£é™©æ˜¯æ¨¡å‹å…³äºè®­ç»ƒæ ·æœ¬çš„å¹³å‡æŸå¤±ã€‚æ ¹æ®å¤§æ•°å®šç†ï¼Œå½“æ ·æœ¬å®¹é‡Nè¶‹äºæ— ç©·æ—¶ï¼Œç»éªŒé£é™©è¶‹äºæœŸæœ›é£é™©ã€‚æ‰€ä»¥å¯ä»¥ç”¨ç»éªŒé£é™©ä¼°è®¡æœŸæœ›é£é™©ï¼Œä½†ç”±äºç°å®ä¸–ç•Œä¸­è®­ç»ƒæ ·æœ¬æ•°ç›®æœ‰é™ï¼Œæ‰€ä»¥éœ€è¦å¯¹ç»éªŒé£é™©è¿›è¡Œä¸€å®šçš„çŸ«æ­£(å¦‚æ­£åˆ™åŒ–)ã€‚ å½“æ ·æœ¬å®¹é‡å¾ˆå°æ—¶ï¼Œç»éªŒé£é™©æœ€å°åŒ–å­¦ä¹ ä¼šäº§ç”Ÿè¿‡æ‹Ÿåˆç°è±¡ï¼Œäºæ˜¯å¼•å…¥ä¿®æ­£æ–¹æ¡ˆï¼šç»“æ„é£é™©æœ€å°åŒ–ï¼ˆSRMï¼‰ï¼š R_{emp} (f) = \\frac{1}{N} \\sum_{i=1}^NL(y_i,f(x_i)) + \\lambda J(f)ç»“æ„é£é™©æ˜¯åœ¨ç»éªŒé£é™©åŸºç¡€ä¸ŠåŠ ä¸Šè¡¨ç¤ºæ¨¡å‹å¤æ‚åº¦çš„æ­£åˆ™åŒ–é¡¹ï¼ˆæƒ©ç½šé¡¹ï¼‰$J(f)$ ï¼Œå®ƒæè¿°äº†æ¨¡å‹çš„å¤æ‚åº¦ã€‚ è¿‡æ‹Ÿåˆï¼šå¦‚æœåœ¨å‡è®¾ç©ºé—´ä¸­å­˜åœ¨â€œçœŸâ€æ¨¡å‹ï¼Œè¿‡æ‹Ÿåˆå¯ä»¥ç†è§£ä¸ºæ‰€é€‰æ¨¡å‹å¤æ‚åº¦ç”±äºæ¯”çœŸæ¨¡å‹æ›´é«˜ï¼ŒåŒ…å«äº†æ›´å¤šçš„å‚æ•°ï¼Œå¯¹è®­ç»ƒæ•°æ®é¢„æµ‹æ¯”â€çœŸâ€æ¨¡å‹æ›´å¥½ï¼Œä½†å¯¹æ–°æ•°æ®çš„é¢„æµ‹å¾ˆå·®ã€‚ï¼ˆè®­ç»ƒæ•°æ®ä¸­æºæ‚ç€å™ªå£°ï¼Œæ‰€ä»¥å³ä½¿â€çœŸâ€æ¨¡å‹ä¹Ÿæ— æ³•ä¸€å®šå®Œå…¨æ‹Ÿåˆè®­ç»ƒæ•°æ®ï¼‰ã€‚ è¿‡æ‹Ÿåˆé—®é¢˜å‘Šè¯‰æˆ‘ä»¬ï¼Œå¯¹æ¨¡å‹å¥½åçš„è¯„ä»·ä¸æ˜¯å®Œå…¨é åœ¨è®­ç»ƒæ•°æ®ä¸Šçš„ç»éªŒé£é™©æˆ–ç»“æ„é£é™©æ¥å†³å®šçš„ï¼Œè€Œæ˜¯å­¦ä¹ æ–¹æ³•çš„æ³›åŒ–èƒ½åŠ›ï¼Œè¿™æ˜¯æœŸæœ›æŸå¤±æœ¬èº«è¦è¡¨è¾¾çš„æ„æ€ã€‚å¦‚æœå­¦åˆ°ä¸€ä¸ªæ¨¡å‹$\\hat f$,é‚£ä¹ˆç”¨è¿™ä¸ªæ¨¡å‹å¯¹æœªçŸ¥æ•°æ®é¢„æµ‹çš„è¯¯å·®å³ä¸ºæ³›åŒ–è¯¯å·®ï¼š R_{exp} (\\hat f) = E_p [L(Y,\\hat f(x))] = \\int_{x\\times y} L(y,\\hat f(x))P(x,y)dxdyæ³›åŒ–è¯¯å·®å…·å¤‡å¦‚ä¸‹æ€§è´¨ï¼š å®ƒæ˜¯æ ·æœ¬å®¹é‡çš„å‡½æ•°ï¼Œéšç€æ ·æœ¬å®¹é‡å¢åŠ ï¼Œæ³›åŒ–è¯¯å·®ä¸Šç•Œè¶‹äº0ï¼› å®ƒæ˜¯å‡è®¾ç©ºé—´å®¹é‡çš„å‡½æ•°ï¼Œå‡è®¾ç©ºé—´è¶Šå¤§ï¼Œæ¨¡å‹å°±è¶Šéš¾å­¦ï¼Œæ³›åŒ–è¯¯å·®ä¸Šç•Œå°±è¶Šå¤§ã€‚ ç®—æ³•ç®—æ³•å°†æœºå™¨å­¦ä¹ é—®é¢˜è½¬æ¢ä¸ºæœ€ä¼˜åŒ–é—®é¢˜è¿›è¡Œæ±‚è§£ã€‚è®¾è®¡ç›®æ ‡æ˜¯å¯»æ‰¾å…¨å±€æœ€ä¼˜è§£å¹¶ä½¿å¾—æ±‚è§£è¿‡ç¨‹è¶³å¤Ÿé«˜æ•ˆã€‚ å‚è€ƒ â€‹ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹","categories":[{"name":"æœºå™¨å­¦ä¹ ","slug":"æœºå™¨å­¦ä¹ ","permalink":"http://blog.a-stack.com/categories/æœºå™¨å­¦ä¹ /"}],"tags":[{"name":"æ¨¡å‹","slug":"æ¨¡å‹","permalink":"http://blog.a-stack.com/tags/æ¨¡å‹/"},{"name":"ç®—æ³•","slug":"ç®—æ³•","permalink":"http://blog.a-stack.com/tags/ç®—æ³•/"},{"name":"æœºå™¨å­¦ä¹ ","slug":"æœºå™¨å­¦ä¹ ","permalink":"http://blog.a-stack.com/tags/æœºå™¨å­¦ä¹ /"},{"name":"ç­–ç•¥","slug":"ç­–ç•¥","permalink":"http://blog.a-stack.com/tags/ç­–ç•¥/"}]},{"title":"Backpropagation in Neural Network","slug":"Backpropagation-in-Neural-Network","date":"2018-04-20T01:09:14.000Z","updated":"2018-07-07T05:54:29.862Z","comments":false,"path":"2018/04/20/Backpropagation-in-Neural-Network/","link":"","permalink":"http://blog.a-stack.com/2018/04/20/Backpropagation-in-Neural-Network/","excerpt":"","text":"æ‘˜è¦ï¼š åå‘ä¼ æ’­æ¯‹åº¸ç½®ç–‘æ˜¯æ•´ä¸ªç¥ç»ç½‘ç»œçš„ç²¾é«“ï¼Œæ­£æ˜¯ç”±äºå®ƒçš„æå‡ºæ ‡å¿—ç€æ·±åº¦ç¥ç»ç½‘ç»œçš„è®­ç»ƒåœ¨æœ‰é™ç®—åŠ›åŸºç¡€ä¸Šæˆä¸ºå¯èƒ½ï¼Œä½†åå‘ä¼ æ’­æœ¬èº«çš„åŸç†åŒæ ·å€¼å¾—å“è¯»å’Œæ€è€ƒã€‚ æœ¬æ–‡ä¸»è¦æ€»ç»“ç¥ç»ç½‘ç»œä¸­åå‘ä¼ æ’­ç®—æ³•çš„æ¨å¯¼æµç¨‹å¹¶æŒ–æ˜ä¸€äº›æ·±å±‚æ¬¡çš„åŸç†ã€‚åå‘ä¼ æ’­ç®—æ³•åœ¨1970å¹´å°±å·²ç»æå‡ºï¼Œç›´åˆ°1986å¹´ David Rumelhart, Geoffrey Hinton, and Ronald Williamsåœ¨ä¸€ç¯‡è®ºæ–‡ä¸­å¯¹å…¶å®ç°çš„åˆ†ææ‰å¾—ä»¥æ™®åŠã€‚ 1. è¡¨è¾¾å¼çš„å®šä¹‰ $w_{jk}^l$ ä»£è¡¨ç¬¬lâˆ’1å±‚ç¬¬kä¸ªç¥ç»å…ƒï¼Œä¸ç¬¬lå±‚ç¬¬jä¸ªç¥ç»å…ƒä¹‹é—´çš„æƒé‡ï¼ˆæ³¨æ„jä¸kçš„é¡ºåºï¼‰ï¼› $b_j^l$ ä»£è¡¨ç¬¬lå±‚ä¸­ç¬¬jä¸ªç¥ç»å…ƒçš„åç§»ï¼› $a_j^l$ ä»£è¡¨ç¬¬lå±‚ä¸­ç¬¬jä¸ªç¥ç»å…ƒçš„æ¿€æ´»å‡½æ•°å€¼ï¼› $L$ ä»£è¡¨ç¥ç»ç½‘ç»œçš„æ€»å±‚æ•°ï¼› $J(W,b)$ ç®€å†™ä¸º$J$ ä»£è¡¨ç¥ç»ç½‘ç»œçš„ä»£ä»·å‡½æ•°ï¼› å‡è®¾æˆ‘ä»¬æœ‰$m$ ä¸ªè®­ç»ƒæ ·æœ¬${(x^{(1)},y^{(1)}),â€¦, (x^{(m)},y^{(m)})}$ ,å¯¹äºæ¯ä¸ªè®­ç»ƒæ ·æœ¬$(x,y)$ å®šä¹‰ä»£ä»·å‡½æ•°ä¸ºï¼š J(W,b;x,y) = \\frac{1}{2} ||h_{W,b}(x) - y||^2å¯¹äº$m$ä¸ªè®­ç»ƒæ ·æœ¬ï¼Œæ€»çš„ä»£ä»·å‡½æ•°ä¸ºï¼š J(W,b) = [\\frac{1}{m} \\sum_{i=1}^m J(W,b;x^{(i)},y^{(i)}] + \\frac{\\lambda}{2} \\sum_{l=1}^{n_l -1}\\sum_{i=1}^{s_l}\\sum_{j=1}^{s_{l+1}}(W_{ji}^{(l)})^2æ ¹æ®ç¥ç»ç½‘ç»œå±‚ä¸å±‚ä¹‹é—´å…³ç³»çš„å®šä¹‰ï¼Œæˆ‘ä»¬æœ‰å¦‚ä¸‹è¡¨è¾¾å¼ï¼ˆå‘é‡å½¢å¼ï¼‰ï¼š z^l = w^l a^{l-1} + b^l, l=2,3,...,L a^l = \\sigma (z^l), l=2,3,...,L a^1=z^1=Xå…¶ä¸­ z_j^l = \\sum_k w_{jk}^l a_k^{l-1} + b_j^låˆ©ç”¨æ¢¯åº¦ä¸‹é™æ³•è¿›è¡Œç›®æ ‡ä¼˜åŒ–ä½¿ç”¨çš„ä¸»è¦æ¢¯åº¦æ›´æ–°å…¬å¼ï¼š w^l := w^l - \\alpha \\frac{\\partial J}{\\partial w^l} b^l := b^l - \\alpha \\frac{\\partial J}{\\partial b^l}å› ä¸ºç¥ç»ç½‘ç»œçš„å¤æ‚æ€§å¯¼è‡´$\\frac{\\partial J}{\\partial w^l}$ æ— æ³•ç›´æ¥è®¡ç®—æˆ–è€…è®¡ç®—ä»£ä»·å¤ªå¤§ï¼ˆæ¯ä¸ªæƒé‡çš„è®¡ç®—éƒ½éœ€è¦è¿›è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­ï¼‰ï¼Œåå‘ä¼ æ’­çš„ç›®çš„åœ¨äºæä¾›ä¸€ç§æ›´åŠ é«˜æ•ˆçš„æ‰‹æ®µï¼Œå®Œæˆä¸Šè¿°æ¢¯åº¦çš„æ›´æ–°æ“ä½œã€‚ 2. åå‘ä¼ æ’­çš„ç›´è§‚ç†è§£åå‘ä¼ æ’­æ˜¯ç”¨äºç†è§£æ”¹å˜ç½‘ç»œä¸­çš„ä»»ä¸€æƒé‡å¦‚ä½•å½±å“ç½‘ç»œä»£ä»·å‡½æ•°çš„è¿‡ç¨‹ã€‚å‡è®¾ç¥ç»ç½‘ç»œä¸­æŸä¸ªæƒé‡$w_{jk}^l$ äº§ç”Ÿäº†è½»å¾®çš„æ‰°åŠ¨è¯¯å·® $\\Delta w_{jk}^l$ ,æ‰°åŠ¨è¯¯å·®å¯¼è‡´è¯¥ç¥ç»å…ƒçš„è¾“å‡ºäº§ç”Ÿè¯¯å·® $\\Delta z_j^l$ ,è¿™ä¸ªæ‰°åŠ¨å°†ä½¿å¯¹åº”çš„ç¥ç»å…ƒ$a_j^l$ äº§ç”Ÿä¸€ä¸ªæ‰°åŠ¨è¯¯å·® $\\Delta a_j^l$ ï¼Œè¯¥è¯¯å·®å°†é€æ­¥å‘åå±‚ä¼ é€’ï¼Œç›´è‡³è¾¾åˆ°è¾“å‡ºå±‚ï¼Œå¹¶æœ€ç»ˆå½±å“ä»£ä»·å‡½æ•°ï¼Œç”Ÿæˆä¸€ä¸ªä»£ä»·è¯¯å·® $\\Delta J = \\frac{\\partial J}{\\partial z_j^l}\\Delta z_j^l$ ã€‚æˆ‘ä»¬å¯ä»¥ç»™å‡ºå¦‚ä¸‹å¼å­æ¥ä¸ºé€šè¿‡è¯¯å·®è¿‘ä¼¼è®¡ç®—æ¢¯åº¦æä¾›æ–¹å‘ï¼š \\Delta J \\approx \\frac{\\partial J}{\\partial a^L_m} \\frac{\\partial a^L_m}{\\partial a^{L-1}_n} \\frac{\\partial a^{L-1}_n}{\\partial a^{L-2}_p} \\ldots \\frac{\\partial a^{l+1}_q}{\\partial a^l_j} \\frac{\\partial a^l_j}{\\partial w^l_{jk}} \\Delta w^l_{jk} \\frac{\\Delta J}{\\Delta z_{j}^l}=\\delta_j^l=\\frac{\\partial J}{\\partial z_j^l}å…¶ä¸­ï¼Œ$\\delta_j^l$ å¯ä»¥å®šä¹‰ä¸º$l$å±‚ç¬¬$j$ä¸ªç¥ç»å…ƒä¸Šçš„è¯¯å·®ã€‚ æˆ‘ä»¬å…ˆä»è®¡ç®—æœ€åä¸€å±‚è¯¯å·®$\\delta_j^L$ å¼€å§‹ï¼Œ \\delta^L_j = \\frac{\\partial J}{\\partial a^L_j} \\sigma'(z^L_j)å…¬å¼E1ï¼ˆå‘é‡å½¢å¼ï¼‰ï¼š \\delta^L = \\nabla_a J \\odot \\sigma'(z^L)è¯æ˜ï¼š \\delta^L_j =\\frac{\\partial J}{\\partial z_j^L}=\\frac{\\partial J}{\\partial a_j^L}.\\frac{\\partial a_j^L}{\\partial z_j^L}= \\frac{\\partial J}{\\partial a^L_j} \\sigma'(z^L_j).ç°åœ¨æŠŠé—®é¢˜è½¬å˜ä¸ºå¦‚ä½•åˆ©ç”¨åå‘ä¼ æ’­ç”±åå¾€å‰é€æ­¥è®¡ç®—è¯¯å·®$\\delta_j^l$ ï¼Œä¸ºè®¡ç®—ä¸åŒå±‚ä¹‹é—´è¯¯å·®ä¹‹é—´çš„å…³ç³»ï¼Œåˆ©ç”¨é“¾å¼æ³•åˆ™ç»™å‡ºå¦‚ä¸‹æ¨ç†è¿‡ç¨‹ï¼š \\delta^l =\\frac{\\partial J}{\\partial z^l} = \\frac{\\partial J}{\\partial z^{l+1}}.\\frac{\\partial z^{l+1}}{\\partial z^l}=\\delta^{l+1}.(\\frac{\\partial z^{l+1}}{\\partial a^l}.\\frac{\\partial a^l}{\\partial z^l})= ((w^{l+1})^T\\delta^{l+1})\\odot \\sigma'(z^l)å³å…¬å¼E2ï¼š \\delta^l = ((w^{l+1})^T \\delta^{l+1}) \\odot \\sigma'(z^l)æœ‰äº†ä»¥ä¸Šè¯¯å·®çš„åå‘ä¼ æ’­è®¡ç®—æ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨è®¡ç®—çš„è¯¯å·®è®¡ç®—æƒé‡çš„æ¢¯åº¦å¦‚ä¸‹ï¼š å…¬å¼E3ï¼š \\frac{\\partial J}{\\partial b^l_j} =\\delta^l_jå…¬å¼E4ï¼š \\frac{\\partial J}{\\partial w^l_{jk}} = a^{l-1}_k \\delta^l_jå…¶ä¸­å…¬å¼ï¼ˆ4ï¼‰ä¹Ÿå¯ä»¥å†™æˆï¼š \\frac{\\partial J}{\\partial w} = a_{\\rm in} \\delta_{\\rm out}è¯æ˜ï¼š \\frac{\\partial J}{\\partial b^l_j} =\\frac{\\partial J}{\\partial z^l_j}.\\frac{\\partial z^l_j}{\\partial b^l_j}= \\delta^l_j \\frac{\\partial J}{\\partial w^l_{jk}} = \\frac{\\partial J}{\\partial z^l_{jk}}.\\frac{\\partial z_{jk}^l}{\\partial w^l_{jk}}=a^{l-1}_k \\delta^l_jå¦ä¸€ç§æ±‚è§£æ–¹å¼ \\dfrac{\\partial J}{\\partial w_{ij}^l} =\\frac{\\partial J}{\\partial a_j^l}.\\frac{\\partial a_j^l}{\\partial z_j^l}.\\frac{\\partial z_j^l}{w_{ij}^l}=\\frac{\\partial J}{\\partial a_j^l}.\\sigma^{'}(z_j^l)a_i^{l-1}å¦‚ä½•æˆ‘ä»¬ä»¤$\\delta_j^l =\\frac{\\partial J}{\\partial a_j^l}$ ä¹Ÿå¯ä»¥æŒ‰ç…§ä¸Šè¿°è¿‡ç¨‹ç±»ä¼¼çš„æ–¹æ³•æ¨åˆ°å‡ºç›¸å…³å…¬å¼ 3. åå‘ä¼ æ’­ç®—æ³•çš„è®¡ç®—æµç¨‹ è¾“å…¥$x$ï¼Œä»¤$a^1=z^1=x$; å‰å‘ä¼ æ’­ï¼š å¯¹äºæ¯å±‚$l=2,3,â€¦,L$è®¡ç®—$z^l$å’Œ$a^l$ï¼› æ ¹æ®å…¬å¼E1è®¡ç®—è¾“å‡ºè¯¯å·®ï¼š$\\delta^L = \\nabla_a J \\odot \\sigmaâ€™(z^L)$ ; åå‘ä¼ æ’­ï¼šå¯¹äºæ¯å±‚$l=L-1,L-2,â€¦,2$ åˆ©ç”¨å…¬å¼E2è®¡ç®—è¯¯å·®ï¼š$\\delta^l = ((w^{l+1})^T \\delta^{l+1}) \\odot \\sigmaâ€™(z^l)$ ï¼› åˆ©ç”¨å…¬å¼E3å’ŒE4è®¡ç®—å‚æ•°æ¢¯åº¦ï¼› æ›´æ–°æƒé‡ å‚è€ƒ CS231nè®²ä¹‰ï¼šBackpropagation, Intuitions Neural Networks and Deep Learning Machine Learning Cousera Course","categories":[{"name":"æ·±åº¦å­¦ä¹ ","slug":"æ·±åº¦å­¦ä¹ ","permalink":"http://blog.a-stack.com/categories/æ·±åº¦å­¦ä¹ /"},{"name":"åŸºç¡€çŸ¥è¯†","slug":"æ·±åº¦å­¦ä¹ /åŸºç¡€çŸ¥è¯†","permalink":"http://blog.a-stack.com/categories/æ·±åº¦å­¦ä¹ /åŸºç¡€çŸ¥è¯†/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://blog.a-stack.com/tags/AI/"},{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"ç®—æ³•","slug":"ç®—æ³•","permalink":"http://blog.a-stack.com/tags/ç®—æ³•/"},{"name":"æ–‡çŒ®","slug":"æ–‡çŒ®","permalink":"http://blog.a-stack.com/tags/æ–‡çŒ®/"}]},{"title":"ä½¿ç”¨TensorFlow Object Detection APIè¯†åˆ«ä»ªè¡¨è¡¨ç›˜","slug":"TensorFlow-Object-Detection-API","date":"2018-04-14T13:16:41.000Z","updated":"2018-05-23T12:42:43.515Z","comments":false,"path":"2018/04/14/TensorFlow-Object-Detection-API/","link":"","permalink":"http://blog.a-stack.com/2018/04/14/TensorFlow-Object-Detection-API/","excerpt":"","text":"å‰é¢ç”¨åˆ°äº†Tensorflowçš„ç‰©ä½“è¯†åˆ«APIåšäº†ä¸€ä¸ªæ£€æµ‹ä»ªè¡¨è¡¨ç›˜çš„å®è·µï¼Œè®°å½•å®è·µè¿‡ç¨‹ä¸­çš„æŠ€å·§ã€‚ 1. æ¦‚è¿°æœ¬æ–‡ä¸»è¦ä»‹ç»å¦‚ä½•ä½¿ç”¨Tensorflow ç‰©ä½“è¯†åˆ«APIåº”ç”¨è‡ªå·±ä¸šåŠ¡åœºæ™¯è¿›è¡Œç‰©ä½“è¯†åˆ«ã€‚å°†ç»“åˆä»äº‹çš„ä¸€äº›å®é™…ç»éªŒï¼Œåˆ†äº«ä¸€ä¸ªä»ªè¡¨è¡¨ç›˜è¯†åˆ«çš„æ¡ˆä¾‹ã€‚æˆ‘ä»¬åœ¨ä¸€ä¸ªåˆ©ç”¨æœºå™¨è§†è§‰æŠ€æœ¯è‡ªåŠ¨è¯†åˆ«ä»ªè¡¨è¡¨è¯»æ•°çš„é¡¹ç›®ä¸­ï¼Œéœ€è¦é¦–å…ˆè¯†åˆ«å„ç§ä¸åŒç±»å‹è¡¨ç›˜çš„æ˜¾ç¤ºå±ä½ç½®ã€‚æœ¬æ¡ˆä¾‹åˆ†æå°†é’ˆå¯¹é¢æ¿è¯†åˆ«ä¸­é‡‡ç”¨çš„å…³é”®æŠ€æœ¯è¿›è¡Œåˆ†æï¼Œè¯¦ç»†é˜è¿°å¦‚ä½•åˆ©ç”¨ç‰©ä½“è¯†åˆ«æŠ€æœ¯å’Œå·²è®­ç»ƒå¥½çš„æ¨¡å‹å¿«é€Ÿå®ç°ä½¿ç”¨ç”¨æˆ·æ•°æ®è®¾è®¡ä¸€ä¸ªé¢å‘ç‰¹å®šç‰©ä½“è¯†åˆ«çš„æ·±åº¦ç¥ç»ç½‘ç»œã€‚ ç›®æ ‡ï¼š ä»ç»™å®šçš„æ°´è¡¨å›¾ç‰‡ä¸­å°†å…³é”®çš„æ•°å­—é¢æ¿ç»™æ‰£å–å‡ºæ¥ã€‚ å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå¦‚æœé‡‡ç”¨é€šç”¨OCRæŠ€æœ¯å¯¹æ°´è¡¨å›¾ç‰‡é¢æ¿è¿›è¡Œæ£€æµ‹ï¼Œå°†åŒæ—¶æå–å¾ˆå¤šç‰¹å¾é¡¹ï¼Œå¯¹å®é™…çš„æ£€æµ‹å€¼é€ æˆæ¯”è¾ƒå¤§çš„å¹²æ‰°ã€‚ 1.1 æ¨¡å‹åŠç®—æ³•é€‰å‹åœ¨æ–¹æ¡ˆè®¾è®¡åˆæœŸæˆ‘ä»¬åˆ†åˆ«ä½¿ç”¨å…¬æœ‰äº‘æœåŠ¡ã€ç°æœ‰çš„æˆç†ŸOCRè½¯ä»¶ã€å¼€æºçš„OCRæ–¹æ¡ˆå¯¹ç›®æ ‡å¯¹è±¡è¿›è¡Œäº†åˆæ­¥è¯†åˆ«åŠåˆ†æã€‚é€šè¿‡å®æµ‹ï¼Œç°æœ‰æ–¹æ¡ˆæ— æ³•æ»¡è¶³æˆ‘ä»¬çš„ä»»åŠ¡éœ€æ±‚ã€‚ä¸ºæ­¤å¸Œæœ›èƒ½å¤Ÿåˆ©ç”¨æ·±åº¦å­¦ä¹ åœ¨ç‰©ä½“è¯†åˆ«é¢†åŸŸçš„æˆç†Ÿæ–¹æ¡ˆï¼Œæ„å»ºä¸€ä¸ªé¢å‘æ°´è¡¨å›¾ç‰‡é¢æ¿è¯†åˆ«çš„ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚ è®¡ç®—æ¡†æ¶ï¼š Tensorflow (v1.4) ä½¿ç”¨æ¥å£ï¼š Tensorflow Object Detection API1 ç®—æ³•æ¨¡å‹ï¼š æ ¹æ®é¢„è®­ç»ƒé‡‡ç”¨çš„æ•°æ®é›†ä¸åŒï¼Œå¯ç”¨çš„æ¨¡å‹åˆ—è¡¨å¦‚ä¸‹ï¼š COCO dataset Model name Speed (ms) COCO mAP2 Outputs ssd_mobilenet_v1_coco 30 21 Boxes ssd_inception_v2_coco 42 24 Boxes faster_rcnn_inception_v2_coco 58 28 Boxes faster_rcnn_resnet50_coco 89 30 Boxes faster_rcnn_resnet50_lowproposals_coco 64 Boxes rfcn_resnet101_coco 92 30 Boxes faster_rcnn_resnet101_coco 106 32 Boxes faster_rcnn_resnet101_lowproposals_coco 82 Boxes faster_rcnn_inception_resnet_v2_atrous_coco 620 37 Boxes faster_rcnn_inception_resnet_v2_atrous_lowproposals_coco 241 Boxes faster_rcnn_nas 1833 43 Boxes faster_rcnn_nas_lowproposals_coco 540 Boxes Kitti dataset Model name Speed (ms) Pascal mAP@0.5 (ms) Outputs faster_rcnn_resnet101_kitti 79 87 Boxes Open Images dataset Model name Speed (ms) Open Images mAP@0.52 Outputs faster_rcnn_inception_resnet_v2_atrous_oid 727 37 Boxes faster_rcnn_inception_resnet_v2_atrous_lowproposals_oid 347 Boxes å‡ ç§æ¨¡å‹ä¸»è¦åœ¨ç²¾åº¦å’Œé€Ÿåº¦æ–¹é¢è¿›è¡Œäº†å–èˆï¼Œå¦‚æœéœ€è¦ä¸€ä¸ªé«˜ç²¾åº¦çš„æ¨¡å‹å¯ä»¥é€‰æ‹©faster R-CNNï¼Œå¦‚æœå¸Œæœ›é€Ÿåº¦å¿«æ¯”å¦‚å®æ—¶æ£€æµ‹ï¼Œåˆ™å¯ä»¥é€‰æ‹©SSDæ¨¡å‹ã€‚é‰´äºæœ¬æ–¹æ¡ˆä¸­è®¾è®¡æ£€æµ‹ç›®æ ‡ç‰¹å¾å°†ä¸ºç®€å•ï¼Œå¯é‡‡ç”¨æœ€è½»é‡çº§çš„MobileSSDè¿›è¡Œä¼˜åŒ–ã€‚ 2. å®ç°æµç¨‹2.1 æ•°æ®å‡†å¤‡æ•°æ®å‡†å¤‡çš„ç¯èŠ‚æ˜¯é™¤äº†è®­ç»ƒè¿‡ç¨‹ä¹‹å¤–æœ€ä¸ºè€—æ—¶çš„ç¯èŠ‚ï¼Œå‡†å¤‡æ•°æ®çš„è´¨é‡å’Œæ•°é‡å°†ç›´æ¥å†³å®šäº†è®­ç»ƒæ¨¡å‹çš„å¥½åã€‚å›¾ç‰‡æ•°æ®æœ€å¥½åœ¨å…‰çº¿ã€è§’åº¦ã€æ¸…æ™°åº¦ç­‰æ–¹é¢èƒ½æœ€å¤§åŒ–çš„æ³›åŒ–å®é™…çš„ä¸šåŠ¡åœºæ™¯ã€‚ç”±äºåœ¨è¿™ä¸ªæ¡ˆä¾‹ä¸­æˆ‘ä»¬åªéœ€è¦è¾“å‡ºä¸€ä¸ªåˆ†ç±»å¯¹è±¡ï¼Œè€Œä¸”è¾“å…¥å¯¹è±¡è¢«é™å®šåœ¨æ°´è¡¨å›¾ç‰‡ä¸Šï¼Œæ‰€ä»¥æ•´ä½“æ¶‰åŠéœ€è¦æå–çš„ç‰¹å¾å‚æ•°ç©ºé—´ä¸æ˜¯å¾ˆå¤§ï¼Œå°‘é‡ç»è¿‡å¤„ç†å¥½çš„æ˜æ˜¾å¯ä¾›è¾¨è¯†çš„æ°´è¡¨å›¾ç‰‡å³å¯ã€‚ç›®å‰å¯ç”¨æ°´è¡¨å›¾ç‰‡æ”»å‡»229å¼ ï¼Œæˆ‘ä»¬é‡‡ç”¨80%ç”¨äºè®­ç»ƒï¼Œ20%ç”¨äºæµ‹è¯•çš„æ–¹å¼è¿›è¡Œåˆ’åˆ†ã€‚ å¦‚æœåˆ†ç±»è¾ƒå¤šï¼Œæ•°æ®æœ‰é™ï¼Œå¯ä»¥é€‰æ‹©ä»äº’è”ç½‘ä¸Šä¸‹è½½æˆ–è€…åœ¨å¼€æºæ•°æ®é›†ä¸­è·å¾—æ‰€éœ€çš„æ•°æ®ã€‚ å¦å¤–éœ€è¦æ³¨æ„å›¾ç‰‡çš„å¤§å°ï¼Œå›¾ç‰‡å¤ªå¤§ä¸€æ–¹é¢å½±å“è®­ç»ƒè¿‡ç¨‹çš„å¤„ç†æ—¶é—´ï¼Œå¦å¤–å¤§é‡å›¾ç‰‡è½½å…¥å†…å­˜å°†å¾ˆå®¹å¯¼è‡´å†…å­˜æº¢å‡ºï¼Œæ‰€ä»¥å¦‚æœå›¾åƒç‰¹å¾ç²’åº¦ä¸æ˜¯ç‰¹åˆ«ç²¾ç»†å¯ä»¥é‡‡ç”¨ä½åˆ†è¾¨ç‡å›¾ç‰‡è¿›è¡Œåˆ†æã€‚ æ•°æ®æ ‡è®°å¯¹äºç‰©ä½“è¯†åˆ«è€Œè¨€ï¼Œæ•°æ®æ ‡è®°è¿‡ç¨‹æ˜¯ä¸€ä¸ªç›¸å¯¹å¤æ‚çš„è¿‡ç¨‹ï¼Œç›®å‰é™¤äº†äººå·¥æ ‡è®°æ²¡æœ‰å¤ªå¥½çš„è‡ªåŠ¨æˆ–åŠç›‘ç£æ‰‹æ®µï¼Œå¹¸å¥½é’ˆå¯¹å›¾ç‰‡çš„æ ‡è®°å·²ç»æœ‰äº†å‡ æ¬¾å¾ˆå¥½ç”¨çš„å·¥å…·ï¼š LabelImg è¿™æ˜¯ä¸€ä¸ªå¯ä»¥ç›´æ¥åœ¨å›¾ç‰‡ä¸Šåšæ³¨é‡Šæ¡†è‡ªåŠ¨ç”Ÿæˆæ ‡è®°ä¿¡æ¯çš„è½¯ä»¶ï¼Œæ³¨é‡Šä¿¡æ¯å°†è¢«ä¿å­˜ä¸ºPASCAL VOC æ ¼å¼çš„XMLæ–‡ä»¶ï¼ˆImageNetçš„æ–‡ä»¶æ ¼å¼ï¼‰ FIAT (Fast Image Data Annotation Tool) è¯¥å·¥å…·ç”Ÿæˆcsvæ ¼å¼çš„æ³¨é‡Šæ–‡ä»¶ ImageMagick å›¾ç‰‡é¢„å¤„ç†å·¥å…· Use ImageMagickÂ® to create, edit, compose, or convert bitmap images. It can read and write images in a variety of formats (over 200) including PNG, JPEG, GIF, HEIC, TIFF, DPX, EXR, WebP, Postscript, PDF, and SVG. Use ImageMagick to resize, flip, mirror, rotate, distort, shear and transform images, adjust image colors, apply various special effects, or draw text, lines, polygons, ellipses and BÃ©zier curves. åœ¨æœ¬æ–¹æ¡ˆä¸­æˆ‘ä»¬ä½¿ç”¨å·¥å…·LabelImageå°†229å¼ æ°´è¡¨å›¾ç‰‡è¿›è¡Œäº†æ ‡æ³¨ï¼ŒåŒæ—¶ç”Ÿæˆäº†PASCALæ ¼å¼çš„XMLæ–‡ä»¶ï¼Œåå­—ä¸º000001.jpgçš„å›¾ç‰‡æ³¨é‡Šæ ¼å¼å¦‚ä¸‹ï¼š 1234567891011121314151617181920212223242526&lt;annotation&gt; &lt;folder&gt;imgs&lt;/folder&gt; &lt;filename&gt;000001.jpg&lt;/filename&gt; &lt;source&gt; &lt;database&gt;VOC&lt;/database&gt; &lt;annotation&gt;PASCAL VOC&lt;/annotation&gt; &lt;/source&gt; &lt;size&gt; &lt;width&gt;2448&lt;/width&gt; &lt;height&gt;3264&lt;/height&gt; &lt;depth&gt;3&lt;/depth&gt; &lt;/size&gt; &lt;segmented&gt;0&lt;/segmented&gt; &lt;object&gt; &lt;name&gt;panel&lt;/name&gt; &lt;pose&gt;Frontal&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;739&lt;/xmin&gt; &lt;ymin&gt;430&lt;/ymin&gt; &lt;xmax&gt;1475&lt;/xmax&gt; &lt;ymax&gt;796&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt;&lt;/annotation&gt; æˆ‘ä»¬åœ¨æ ¹ç›®å½•æ–°å»ºä¸€ä¸ªannotationsçš„æ–‡ä»¶å¤¹å­˜å‚¨229å¼ å›¾ç‰‡çš„XMLæè¿°æ–‡ä»¶ï¼ŒåŒæ—¶æ ¹ç›®å½•imagesæ–‡ä»¶å¤¹ç”¨äºå­˜å‚¨æ‰€æœ‰çš„è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®ã€‚ æ•°æ®æè¿°æ ¼å¼ åœ¨TensorFlow ç‰©ä½“æ£€æµ‹APIä¸­ä½¿ç”¨ TFRecord file formatæ ¼å¼å¯¹å›¾åƒæ ‡è®°ä¿¡æ¯è¿›è¡Œæè¿°ï¼Œæ‰€ä»¥æˆ‘ä»¬æ— è®ºé‡‡å–ä¸‹é¢çš„é‚£ç§æ ‡è®°æ–¹å¼ï¼Œæœ€ç»ˆéœ€è¦ç”ŸæˆTFRcordæ ¼å¼çš„æ–‡ä»¶æ ¼å¼ã€‚ TFRecordæ ¼å¼è¦å»å¦‚ä¸‹ï¼š For every example in your dataset, you should have the following information: An RGB image for the dataset encoded as jpeg or png. A list of bounding boxes for the image. Each bounding box should contain: A bounding box coordinates (with origin in top left corner) defined by 4floating point numbers [ymin, xmin, ymax, xmax]. Note that we store thenormalized coordinates (x / width, y / height) in the TFRecord dataset. The class of the object in the bounding box. TensorFlowé’ˆå¯¹ä¸»æµçš„ç‰©ä½“è¯†åˆ«ç±»æ•°æ®é›†æ ¼å¼æä¾›äº†è½¬æ¢å·¥å…·ï¼ŒåŒ…æ‹¬ PASCAL VOC dataset ï¼Œ Oxford Pet datasetç­‰ï¼› PASCAL VOC 1234567891011# From tensorflow/models/research/wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tartar -xvf VOCtrainval_11-May-2012.tarpython object_detection/dataset_tools/create_pascal_tf_record.py \\ --label_map_path=object_detection/data/pascal_label_map.pbtxt \\ --data_dir=VOCdevkit --year=VOC2012 --set=train \\ --output_path=pascal_train.recordpython object_detection/dataset_tools/create_pascal_tf_record.py \\ --label_map_path=object_detection/data/pascal_label_map.pbtxt \\ --data_dir=VOCdevkit --year=VOC2012 --set=val \\ --output_path=pascal_val.record Oxford-IIIT Pet 123456789# From tensorflow/models/research/wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gzwget http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gztar -xvf annotations.tar.gztar -xvf images.tar.gzpython object_detection/dataset_tools/create_pet_tf_record.py \\ --label_map_path=object_detection/data/pet_label_map.pbtxt \\ --data_dir=`pwd` \\ --output_dir=`pwd` å¦‚æœä½ ä½¿ç”¨äº†è‡ªå·±çš„æ ¼å¼ï¼Œå¯ä»¥å‚è€ƒTensorFlowå®˜æ–¹æ–‡æ¡£å®Œæˆæ ¼å¼è½¬æ¢ï¼› åœ¨æœ¬æ–¹æ¡ˆä¸­æˆ‘ä»¬é‡‡ç”¨è‡ªå·±å¤„ç†çš„æ–¹å¼æ¥è¿›è¡Œæ ¼å¼è½¬æ¢ï¼Œä½¿ç”¨æ–‡ä»¶xml_to_csv.pyå°†æ‰€æœ‰å›¾ç‰‡çš„PASCALæ ¼å¼æ–‡ä»¶è½¬åŒ–ä¸ºä¸€ä¸ªcsvæ–‡ä»¶ï¼Œç„¶åè¿›ä¸€æ­¥çš„åˆ©ç”¨TensorFLowå·¥å…·generate_tfrecord.pyç”ŸæˆTFRecordæ ¼å¼æ–‡ä»¶ï¼š æ‰§è¡Œpython xml_to_csv.py,è¯¥æ–‡ä»¶å°†åœ¨æ ¹ç›®å½•çš„annotationsçš„æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰çš„*xmlæ–‡ä»¶ï¼Œå¹¶ç”Ÿæˆscreen_labels.csvæ–‡ä»¶ï¼› ä½¿ç”¨å¦‚ä¸‹ä»£ç éšæœºç”Ÿæˆè®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®ï¼š 123456789101112import numpy as npimport pandas as pdnp.random.seed(1)full_labels = pd.read_csv('screen_labels.csv')gb = full_labels.groupby('filename')grouped_list = [gb.get_group(x) for x in gb.groups]train_index = np.random.choice(len(grouped_list), size=180, replace=False)test_index = np.setdiff1d(list(range(229)), train_index)train = pd.concat([grouped_list[i] for i in train_index])test = pd.concat([grouped_list[i] for i in test_index])train.to_csv('train_labels.csv', index=None)test.to_csv('test_labels.csv', index=None) åˆ†åˆ«æ‰§è¡Œè„šæœ¬å°†è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®è½¬æ¢ä¸ºTFRecordï¼š 1234567# From tensorflow/models/research/protoc object_detection/protos/*.proto --python_out=.# Create train data: python generate_tfrecord.py --csv_input=data/train_labels.csv --output_path=train.record # Create test data: python generate_tfrecord.py --csv_input=data/test_labels.csv --output_path=test.record å°†train.recordå’Œtest.recordçš„æ–‡ä»¶å­˜å‚¨è‡³æ ¹ç›®å½•çš„dataæ–‡ä»¶å¤¹ä¸‹ è‡³æ­¤æ•°æ®å‡†å¤‡åŸºæœ¬ç»“æŸï¼Œæˆ‘ä»¬åˆ›å»ºäº†å¦‚ä¸‹ç›®å½•ç»“æ„ 1234567891011121314151617181920212223.â”œâ”€â”€ annotationsâ”‚ â”œâ”€â”€ 000001.xml ...â”‚ â””â”€â”€ 000229.xmlâ”œâ”€â”€ dataâ”‚ â”œâ”€â”€ screen_labels.csvâ”‚ â”œâ”€â”€ test_labels.csvâ”‚ â”œâ”€â”€ test.recordâ”‚ â”œâ”€â”€ train_labels.csvâ”‚ â””â”€â”€ train.recordâ”œâ”€â”€ generate_tfrecord.pyâ”œâ”€â”€ imagesâ”‚ â”œâ”€â”€ 000001.jpg ...â”‚ â””â”€â”€ 000229.jpgâ”œâ”€â”€ __init__.pyâ”œâ”€â”€ README.mdâ”œâ”€â”€ split labels.ipynbâ”œâ”€â”€ test_generate_tfrecord.pyâ”œâ”€â”€ test_xml_to_csv.pyâ””â”€â”€ xml_to_csv.pyâ€‹ 2.2 æ¨¡å‹é…ç½®/è¿ç§»å­¦ä¹  å®Œå…¨ä»å¤´è®­ç»ƒä¸€ä¸ªç”¨äºç‰©ä½“æ£€æµ‹çš„æ¨¡å‹å³ä½¿é‡‡ç”¨å¤§é‡GPUèµ„æºè‡³å°‘ä¹Ÿéœ€è¦æ•°å‘¨æ—¶é—´ï¼Œä¸ºäº†åŠ é€Ÿæ¨¡å‹åˆæœŸè¿­ä»£è¿‡ç¨‹ï¼Œæˆ‘ä»¬é€‰æ‹©äº†ä¸€ä¸ªå·²ç»åœ¨COCOæ•°æ®é›†é’ˆå¯¹å…¶ä»–å¤šç§ç‰©ä½“è¯†åˆ«åœºæ™¯é¢„è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œé€šè¿‡é‡å¤ä½¿ç”¨è¯¥æ¨¡å‹çš„å¤šæ•°å‚æ•°æ¥å¿«é€Ÿç”Ÿæˆæˆ‘ä»¬çš„æ¨¡å‹ã€‚æ›´å¤šæŠ€æœ¯å†…å®¹å¯ä»¥å‚ç…§è¿ç§»å­¦ä¹ çš„æŠ€æœ¯å®ç°ã€‚ ç”±äºæ²¡æœ‰è¶³å¤Ÿçš„èµ„æºä»å¤´è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œæˆ‘ä»¬å°†é‡‡ç”¨è¿ç§»å­¦ä¹ æŠ€æœ¯ï¼Œåˆ©ç”¨ä¸€ä¸ªå·²ç»è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œè¿ç§»å­¦ä¹ åŠè®­ç»ƒã€‚ ä»æµ‹è¯•è§’åº¦è€ƒè™‘ï¼Œæœ¬æµ‹è¯•æ–¹æ¡ˆé€‰æ‹©äº†ä½“ç§¯æœ€å°ï¼Œé€Ÿåº¦æœ€å¿«çš„ç”¨äºåµŒå…¥å¼è®¾å¤‡çš„SSDæ¨¡å‹ï¼šssd_mobilenet_v1_coco ä¸‹è½½æ¨¡å‹åŒ…ï¼Œå¯ä»¥å¾—åˆ°å¦‚ä¸‹æ–‡ä»¶ï¼š 1234567891011.â”œâ”€â”€ object-detection.pbtxt â”œâ”€â”€ ssd_mobilenet_v1_pets.configâ”œâ”€â”€ checkpointâ”œâ”€â”€ frozen_inference_graph.pbâ”œâ”€â”€ model.ckpt.data-00000-of-00001â”œâ”€â”€ model.ckpt.indexâ”œâ”€â”€ model.ckpt.metaâ””â”€â”€ saved_model â”œâ”€â”€ saved_model.pb â””â”€â”€ variables a graph proto (graph.pbtxt) a checkpoint (model.ckpt.data-00000-of-00001, model.ckpt.index, model.ckpt.meta) a frozen graph proto with weights baked into the graph as constants (frozen_inference_graph.pb) to be used for out of the box inference a config file (pipeline.config) which was used to generate the graph. These directly correspond to a config file in the samples/configs) directory but often with a modified score threshold. æˆ‘ä»¬ä¸‹è½½å¹¶åœ¨æ ¹ç›®å½•è§£å‹æ¨¡å‹åŒ…ssd_mobilenet_v1_cocoï¼ŒåŒæ—¶åˆ›å»ºä¸€ä¸ªtrainingæ–‡ä»¶ï¼Œå­˜å‚¨å¦‚ä¸‹æ–‡ä»¶ï¼š 123training/â”œâ”€â”€ object-detection.pbtxtâ””â”€â”€ ssd_mobilenet_v1_pets.config å…¶ä¸­ object-detection.pbtxtæ˜¯æˆ‘ä»¬æ¨¡å‹æ‰€æœ‰åˆ†ç±»çš„æ ‡ç­¾ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼Œå¦‚æœæœ‰å¤šä¸ªåˆ†ç±»idä»1å¼€å§‹é€’å¢ï¼ŒåŒæ—¶ç»™æ¯ä¸ªæ ‡ç­¾ä¸€ä¸ªå”¯ä¸€çš„åç§° 12345678item &#123; id: 1 name: 'panel'&#125;item&#123; id: 2 name: 'å…¶ä»–åˆ†ç±»'&#125; é…ç½®ç‰©ä½“è¯†åˆ«è®­ç»ƒæµç¨‹æ–‡ä»¶ æ›´å¤šå†…å®¹å‚è€ƒï¼šhttps://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/configuring_jobs.md Tensorflow Object Detection API ä½¿ç”¨ protobuf æ–‡ä»¶æ¥é…ç½®è®­ç»ƒå’Œæ£€æµ‹çš„æµç¨‹ã€‚é€šè¿‡é…ç½®Training Piplelineçš„å‚æ•°é…ç½®å¯ä»¥å†³å®šè®­ç»ƒå‚æ•°çš„é€‰æ‹©ï¼Œæˆ‘ä»¬å°†å°½é‡å¤šçš„åˆ©ç”¨å·²ç»è®­ç»ƒå¥½çš„å‚æ•°è¿›è¡Œè®­ç»ƒã€‚ ä¸€ä¸ªé…ç½®æ–‡ä»¶ç”±5éƒ¨åˆ†ç»„æˆï¼š 123456789101112131415161718model &#123;(... Add model config here...)&#125;train_config : &#123;(... Add train_config here...)&#125;train_input_reader: &#123;(... Add train_input configuration here...)&#125;eval_config: &#123;&#125;eval_input_reader: &#123;(... Add eval_input configuration here...)&#125; The model configuration. This defines what type of model will be trained (ie. meta-architecture, feature extractor). The train_config, which decides what parameters should be used to train model parameters (ie. SGD parameters, input preprocessing and feature extractor initialization values). The eval_config, which determines what set of metrics will be reported for evaluation (currently we only support the PASCAL VOC metrics). The train_input_config, which defines what dataset the model should be trained on. The eval_input_config, which defines what dataset the model will be evaluated on. Typically this should be different than the training input dataset. ssd_mobilenet_v1_pets.configä¸ºæ¨¡å‹é…ç½®æ–‡ä»¶ï¼Œæˆ‘ä»¬åœ¨æ ·ä¾‹(è¯¦è§ï¼šobject_detection/samples/configs æ–‡ä»¶å¤¹)ä¸Šè¿›è¡Œå¦‚ä¸‹ä¿®æ”¹ï¼š 1234567891011121314151617181920212223242526 ssd &#123; num_classes: 1 #ä¿®æ”¹ç±»åˆ«ä¸ºå®é™…ç±»åˆ«å€¼ box_coder &#123; faster_rcnn_box_coder &#123; y_scale: 10.0 x_scale: 10.0 height_scale: 5.0 width_scale: 5.0 &#125; &#125;fine_tune_checkpoint: \"ssd_mobilenet_v1_coco_2017_11_17/model.ckpt\" #æŒ‡å‘æ¨¡å‹æ–‡ä»¶ä¸­çš„checkpointæ–‡ä»¶train_input_reader: &#123; tf_record_input_reader &#123; input_path: \"data/train.record\" #ä¿®æ”¹ä¸ºä¸Šä¸€ä¸ªæ­¥éª¤ç”Ÿæˆçš„è®­ç»ƒrecordè·¯å¾„ &#125; label_map_path: \"data/object-detection.pbtxt\" #ä¿®æ”¹ä¸ºpbtxtæ–‡ä»¶è·¯å¾„ï¼Œæè¿°ç±»åˆ«æ ‡ç­¾&#125;eval_input_reader: &#123; tf_record_input_reader &#123; input_path: \"data/test.record\" #ä¿®æ”¹ä¸ºä¸Šä¸€ä¸ªæ­¥éª¤ç”Ÿæˆçš„æµ‹è¯•æ•°æ®recordè·¯å¾„ &#125; label_map_path: \"data/object-detection.pbtxt\" #ä¿®æ”¹ä¸ºpbtxtæ–‡ä»¶è·¯å¾„ï¼Œæè¿°ç±»åˆ«æ ‡ç­¾ shuffle: false num_readers: 1&#125; train_config provides two fields to specify pre-existing checkpoints: fine_tune_checkpoint and from_detection_checkpoint. fine_tune_checkpoint should provide a path to the pre-existing checkpoint (ie:â€/usr/home/username/checkpoint/model.ckpt-#####â€). from_detection_checkpoint is a boolean value. If false, it assumes the checkpoint was from an object classification checkpoint. Note that starting from a detection checkpoint will usually result in a faster training job than a classification checkpoint. The list of provided checkpoints can be found here. 2.3 è®­ç»ƒTensorflow Object Detection API å®‰è£… ä»GitHubä¸‹è½½Tensorflow Object Detection API 1git clone https://github.com/tensorflow/models.git é…ç½®åŸºæœ¬ç¯å¢ƒ 12345678910Tensorflow Object Detection API depends on the following libraries:- Protobuf 2.6- Pillow 1.0- lxml- tf Slim (which is included in the \"tensorflow/models/research/\" checkout)- Tensorflowsudo apt-get install protobuf-compiler python-pil python-lxmlæˆ–è€…sudo pip install pillowsudo pip install lxml 3.Protobuf ç¼–è¯‘ Tensorflowé€šè¿‡Googleçš„Protobufsæ¥é…ç½®å’Œè®­ç»ƒæ¨¡å‹ï¼Œæ‰€ä»¥åœ¨å¼€å§‹ä½¿ç”¨ä¹‹å‰éœ€è¦å¯¹protobufç›¸å…³åº“è¿›è¡Œç¼–è¯‘ã€‚ 12# From tensorflow/models/research/protoc object_detection/protos/*.proto --python_out=. Add Libraries to PYTHONPATH[é‡è¦] åœ¨è·¯å¾„ tensorflow/models/research/ ä¸‹æ·»åŠ PYTHONPATHè·¯å¾„ï¼Œå®ç°å…¨å±€å¼•ç”¨ 12# From tensorflow/models/research/export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim Note: This command needs to run from every new terminal you start. If you wish to avoid running this manually, you can add it as a new line to the end of your ~/.bashrc file. å¯åŠ¨è®­ç»ƒè¿‡ç¨‹ å°†åœ¨æ•°æ®å‡†å¤‡å’Œæ¨¡å‹é…ç½®é˜¶æ®µçš„æ–‡ä»¶å¤åˆ¶åˆ°tensorflow object_detectæ–‡ä»¶å¤¹ä¸‹/models/research/object_detection,åŒ…æ‹¬data/æ–‡ä»¶å¤¹ï¼Œimage/æ–‡ä»¶å¤¹ï¼Œtraining/æ–‡ä»¶å¤¹ï¼Œssd_mobilenet_v1_coco_2017_11_17/åŸå§‹æ¨¡å‹æ–‡ä»¶å¤¹ æ‰§è¡Œå¦‚ä¸‹ä»£ç å¯åŠ¨è®­ç»ƒè¿‡ç¨‹ï¼š 1234567# From the tensorflow/models/research/ directorypython object_detection/train.py \\ --logtostderr \\ --pipeline_config_path=$&#123;PATH_TO_YOUR_PIPELINE_CONFIG&#125; \\ --train_dir=$&#123;PATH_TO_TRAIN_DIR&#125;-------------------------------------------------------------------------------------------- python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v1_pets.config ä½¿ç”¨TensorBoard è·Ÿè¸ªè®­ç»ƒè¿‡ç¨‹è®­ç»ƒè¿‡ç¨‹ä¼šæŒç»­å‡ ä¸ªå°æ—¶åˆ°åå‡ ä¸ªå°æ—¶ï¼Œå¯ä»¥é€šè¿‡tensorboardæŸ¥çœ‹è®­ç»ƒçš„æƒ…å†µ ä½¿ç”¨ä¸€å°Azureçš„CPUè™šæ‹Ÿæœºè¿›è¡Œè®­ç»ƒ~4sè¿›è¡Œä¸€æ¬¡è¿­ä»£ï¼Œæ­£å¸¸æ¨¡å‹æœ‰æ¯”è¾ƒä¸é”™ç»“æœè¿­ä»£æ¬¡æ•°å¤§æ¦‚åœ¨10Kä»¥ä¸Šã€‚ 1tensorboard --logdir=/training 2.4 å¯¼å‡ºæ¨¡å‹æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¼šæ¯éš”ä¸€æ®µæ—¶é—´ç”Ÿæˆä¸€ä¸ªcheckpointï¼Œä¸€ä¸ªcheckpointè‡³å°‘åŒ…æ‹¬ä¸‰ä¸ªæ–‡ä»¶ï¼š model.ckpt-${CHECKPOINT_NUMBER}.data-00000-of-00001 model.ckpt-${CHECKPOINT_NUMBER}.index model.ckpt-${CHECKPOINT_NUMBER}.meta å¯ä»¥é€šè¿‡å¦‚ä¸‹å‘½ä»¤ä»checkpointsä¸­æå–æ¨¡å‹ï¼š 123456789101112131415161718Example Usage:--------------python export_inference_graph \\ --input_type image_tensor \\ --pipeline_config_path path/to/ssd_inception_v2.config \\ --trained_checkpoint_prefix path/to/model.ckpt \\ --output_directory path/to/exported_model_directory -----The expected output would be in the directorypath/to/exported_model_directory (which is created if it does not exist)with contents: - graph.pbtxt - model.ckpt.data-00000-of-00001 - model.ckpt.info - model.ckpt.meta - frozen_inference_graph.pb + saved_model (a directory) 123456789101112131415# From tensorflow/models/research/export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slimpython export_inference_graph.py \\ --input_type image_tensor \\ --pipeline_config_path training/ssd_mobilenet_v1_pets.config \\ --trained_checkpoint_prefix training/model.ckpt-10116 \\ --output_directory water_meter_panel----------WARNING:tensorflow:From /home/gaoc/data/test/object_detect/models/research/object_detection/exporter.py:357: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.Instructions for updating:Please switch to tf.train.get_or_create_global_step2018-01-20 06:34:08.551446: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA2018-01-20 06:34:14.056881: I tensorflow/core/grappler/devices.cc:51] Number of eligible GPUs (core count &gt;= 8): 0Converted 199 variables to const ops. å¦‚æœExportor.pyæ–‡ä»¶æŠ¥bugï¼Œè¯·å‚è€ƒhttps://github.com/tensorflow/models/issues/2861 ä¿®å¤ è¿è¡Œä»¥ä¸Šä»£ç ï¼Œå°†åœ¨water_meter_panelæ–‡ä»¶å¤¹ä¸‹ç”Ÿæˆæ¨¡å‹æ‰€éœ€çš„ç›¸å…³æ–‡ä»¶ï¼š 1234567891011121314151617gaoc@DataScience:~/data/test/object_detect/models/research/object_detection$ ls -l water_meter_panel/total 44820-rw-r--r-- 1 gaoc root 77 Jan 20 06:34 checkpoint-rw-r--r-- 1 gaoc root 22636802 Jan 20 06:34 frozen_inference_graph.pb-rw-r--r-- 1 gaoc root 22174240 Jan 20 06:34 model.ckpt.data-00000-of-00001-rw-r--r-- 1 gaoc root 8873 Jan 20 06:34 model.ckpt.index-rw-r--r-- 1 gaoc root 1058139 Jan 20 06:34 model.ckpt.metadrwxr-xr-x 3 gaoc root 4096 Jan 20 06:34 saved_modelwater_meter_panel/â”œâ”€â”€ checkpointâ”œâ”€â”€ frozen_inference_graph.pbâ”œâ”€â”€ model.ckpt.data-00000-of-00001â”œâ”€â”€ model.ckpt.indexâ”œâ”€â”€ model.ckpt.metaâ””â”€â”€ saved_model â”œâ”€â”€ saved_model.pb â””â”€â”€ variables 2.5 æµ‹è¯•123456# From the tensorflow/models/research/ directorypython object_detection/eval.py \\ --logtostderr \\ --pipeline_config_path=$&#123;PATH_TO_YOUR_PIPELINE_CONFIG&#125; \\ --checkpoint_dir=$&#123;PATH_TO_TRAIN_DIR&#125; \\ --eval_dir=$&#123;PATH_TO_EVAL_DIR&#125; ç‰©ä½“è¯†åˆ«é¢†åŸŸçš„ç®—æ³•æ€§èƒ½è¯„ä»·æŒ‡æ ‡å¤šæ•°é€‰æ‹©APå’ŒmAPï¼ˆmean average precisionï¼‰ï¼Œå¤šä¸ªç±»åˆ«ç‰©ä½“æ£€æµ‹ä¸­ï¼Œæ¯ä¸€ä¸ªç±»åˆ«éƒ½å¯ä»¥æ ¹æ®recallå’Œprecisionç»˜åˆ¶ä¸€æ¡æ›²çº¿ï¼ŒAPå°±æ˜¯è¯¥æ›²çº¿ä¸‹çš„é¢ç§¯ï¼ŒmAPæ˜¯å¤šä¸ªç±»åˆ«APçš„å¹³å‡å€¼ 12345678Average Precision (AP):AP% AP at IoU=.50:.05:.95 (primary challenge metric) APIoU=.50% AP at IoU=.50 (PASCAL VOC metric) APIoU=.75% AP at IoU=.75 (strict metric) AP Across Scales:APsmall% AP for small objects: area &lt; 322 APmedium% AP for medium objects: 322 &lt; area &lt; 962 APlarge% AP for large objects: area &gt; 962 Average Recall (AR):ARmax=1% AR given 1 detection per image ARmax=10% AR given 10 detections per image ARmax=100% AR given 100 detections per image AR Across Scales:ARsmall% AR for small objects: area &lt; 322 ARmedium% AR for medium objects: 322 &lt; area &lt; 962 ARlarge% AR for large objects: area &gt; 962 ä»æ€§èƒ½æµ‹è¯•ç»“æœæ¥çœ‹è¯¥æ¨¡å‹å·²ç»å…·å¤‡96%çš„æ£€æµ‹ç²¾åº¦äº†ï¼Œå…·å¤‡æŠ•å…¥ç”Ÿäº§ç¯å¢ƒæ‰€éœ€çš„æ€§èƒ½ã€‚ é¢„æµ‹ç»“æœè§ä¸‹å›¾ï¼Œå‡†ç¡®ç‡è¾¾åˆ°äº†99%ä»¥ä¸Šã€‚ 3. ç»“è®º å¯¹äºç®€å•ä¸šåŠ¡åœºæ™¯çš„ç‰©ä½“è¯†åˆ«ç±»æ¡ˆä¾‹ï¼Œå¯ä»¥é€šè¿‡è¿ç§»å­¦ä¹ åˆ©ç”¨å·²æœ‰çš„æˆç†Ÿæ¨¡å‹å¿«é€Ÿè¿­ä»£ç”Ÿæˆæ–°çš„ç‰¹å®šæ¨¡å‹ï¼› è¿™ç§è¿ç§»çš„å¦ä¸€ä¸ªä¼˜åŠ¿æ˜¯å¯¹å°æ•°æ®æ ·æœ¬å…·å¤‡å¾ˆå¥½çš„é€‚åº”èƒ½åŠ›ï¼Œå¯ä»¥è§£å†³å‰æœŸæ•°æ®ä¸è¶³å’Œæ•°æ®è´¨é‡å·®çš„é—®é¢˜ï¼› å½“ç„¶é‡‡ç”¨è¿™ç§æ–¹å¼ä¹ŸåŒæ—¶å­˜åœ¨ä¸€å®šçš„å¼Šç«¯ï¼Œæ¯”å¦‚ç”±äºæ¨¡å‹é¢„è®­ç»ƒå‚æ•°è¾ƒå¤šï¼Œæ¨¡å‹ä½“ç§¯è¾ƒå¤§ï¼Œæ¨¡å‹çš„é€‰å–éœ€è¦åå¤æµ‹è¯•å’Œä¼˜åŒ–ã€‚ 3.1 ç»éªŒæ€»ç»“ è™½ç„¶Tensorflow Object Detection APIæä¾›äº†ä¸°å¯Œçš„æ–‡æ¡£ä»‹ç»ç›¸å…³å·¥ä½œæµç¨‹ï¼Œä½†ç”±äºæŠ€æœ¯ã€å¹³å°å’Œè½¯ä»¶ç‰ˆæœ¬æœ¬èº«æ›´æ–°è¾ƒå¿«ï¼Œå®è·µä¸­è¿˜æ˜¯æˆ–å¤šæˆ–å°‘ä¼šé‡åˆ°ä¸å°‘é—®é¢˜ï¼Œé™ä¸‹å¿ƒæ¥å¤šç¿»ç¿»Githubçš„issuesé‡Œä¸€èˆ¬éƒ½æœ‰åˆ«äººçš„æé—®åŠè§£ç­”ï¼›å»ºè®®è¿˜æ˜¯å…ˆæ ¹æ®æ–‡æ¡£è·‘é€šdemoï¼Œç†Ÿæ‚‰ç›¸å…³å·¥å…·å’Œæµç¨‹å†å°†æ¡†æ¶è¿ç§»åˆ°è‡ªå·±çš„æ•°æ®é›†ä¹‹ä¸Šï¼› å»ºè®®è‡ªå·±è¯†åˆ«çš„é¡¹ç›®æ–‡ä»¶å•ç‹¬å»ºç«‹ä¸€ä¸ªæ•°æ®å‡†å¤‡æ–‡ä»¶å¤¹è¿›è¡Œæ•°æ®å‡†å¤‡å’Œç›¸å…³é…ç½®è„šæœ¬çš„å‡†å¤‡ï¼Œä¸è¦è·ŸGithubå…‹éš†çš„Object Detectioné¡¹ç›®æ··åœ¨ä¸€èµ·ï¼Œä¸å®¹æ˜“ç®¡ç†ï¼Œä¹Ÿä¸åˆ©äºé‡å¤åˆ©ç”¨ï¼› TFOD APIæä¾›çš„Tensorflowå¯è§†åŒ–ç›¸å½“å®Œå¤‡ï¼Œå¯åŠ¨è®­ç»ƒä»»åŠ¡ä¹‹åï¼Œä¸€å®šè¦åŒæ­¥å¯åŠ¨éªŒè¯è„šæœ¬ï¼Œå¯ä»¥å®æ—¶è·Ÿè¸ªè®­ç»ƒè¿›ç¨‹ï¼› å¾ˆå®¹æ˜“ç–å¿½çš„ä¸€ä¸ªæ­¥éª¤æ˜¯å…³äºPYTHON PATHçš„å¤„ç†ï¼Œåœ¨æ‰§è¡Œç›¸å…³APIä¹‹å‰ä¸€å®šè¦è®°å¾—EXPORTç›¸å…³pathï¼Œå¯ä»¥äº›ä¸€ä¸ªbashæ–‡ä»¶ï¼Œåœ¨æ‰§è¡Œå‘½ä»¤çš„Terminalä¸­sourceä¸€ä¸‹ï¼›å¸¸è§é”™è¯¯å¦‚ä¸‹ï¼š 1ImportError: No module named â€™object_detectionâ€™ å……åˆ†åˆ©ç”¨GPUå’ŒCPUè¿›è¡Œè®­ç»ƒï¼š å¦‚æœä½¿ç”¨CPUè®­ç»ƒï¼Œæ§åˆ¶é…ç½®å‚æ•°ä¸­num_examplesä¸ºä¸€ä¸ªå¾ˆå°çš„å€¼ï¼ˆ5-10ï¼‰ï¼Œè¿™æ ·å°†ä½¿ç”¨éªŒè¯æ•°æ®ä¸­çš„ä¸€éƒ¨åˆ†è¿›è¡ŒéªŒè¯è€Œä¸æ˜¯å…¨éƒ¨ï¼› é…ç½®CUDA_VISIBLE_DEVICESç¯å¢ƒå˜é‡ï¼Œé€‰æ‹©ä½¿ç”¨å“ªä¸ªGPUæˆ–CPUæ¥åˆ†é…å†…å­˜èµ„æºï¼š 12$ export CUDA_VISIBLE_DEVICES=\"0\"... 12$ export CUDA_VISIBLE_DEVICES=\"1\"... another scripts é…ç½®ä¸ºç©ºä½¿ç”¨CPU å°½é‡ä½¿ç”¨æœ€æ–°ç‰ˆçš„Tensorflowï¼Œåœ¨æ’°å†™æœ¬æ–‡æ—¶å·²ç»æ˜¯1.7äº†ï¼Œå½“æ—¶åšå®éªŒç”¨çš„æ˜¯1.4ï¼Œå¤ç°çš„æ—¶å€™å‘ç°1.4ç‰ˆæœ¬å·²ç»æŠ›é”™äº†â€¦ å‚è€ƒ 1. The TensorFlow Object Detection API is an open source framework built on top of TensorFlow that makes it easy to construct, train and deploy object detection models. &#8617; 2. See MSCOCO evaluation protocol. &#8617; Image classification with a pre-trained deep neural network How to train your own Object Detector with TensorFlowâ€™s Object Detector API https://github.com/datitran/raccoon_dataset","categories":[{"name":"åŠ¨æ‰‹å®è·µè¥","slug":"åŠ¨æ‰‹å®è·µè¥","permalink":"http://blog.a-stack.com/categories/åŠ¨æ‰‹å®è·µè¥/"},{"name":"æœºå™¨è§†è§‰","slug":"åŠ¨æ‰‹å®è·µè¥/æœºå™¨è§†è§‰","permalink":"http://blog.a-stack.com/categories/åŠ¨æ‰‹å®è·µè¥/æœºå™¨è§†è§‰/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://blog.a-stack.com/tags/AI/"},{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"ç‰©ä½“è¯†åˆ«","slug":"ç‰©ä½“è¯†åˆ«","permalink":"http://blog.a-stack.com/tags/ç‰©ä½“è¯†åˆ«/"},{"name":"å®è·µ","slug":"å®è·µ","permalink":"http://blog.a-stack.com/tags/å®è·µ/"},{"name":"å·¥å…·","slug":"å·¥å…·","permalink":"http://blog.a-stack.com/tags/å·¥å…·/"}]},{"title":"ç‰©ä½“è¯†åˆ«æŠ€æœ¯ä¹‹Faster R-CNN","slug":"Object-Detection-Faster-RCNN","date":"2018-04-13T06:45:52.000Z","updated":"2018-05-23T12:43:12.780Z","comments":false,"path":"2018/04/13/Object-Detection-Faster-RCNN/","link":"","permalink":"http://blog.a-stack.com/2018/04/13/Object-Detection-Faster-RCNN/","excerpt":"","text":"æ‘˜è¦: 2015å¹´æå‡ºçš„Faster R-CNNæ¶æ„åœ¨åŸºäºæœºå™¨è§†è§‰çš„ç‰©ä½“è¯†åˆ«é¢†åŸŸå æ®é‡è¦çš„åœ°ä½ï¼Œä»R-CNNåˆ°fast R-CNNå†åˆ°faster R-CNN,ä¹ƒè‡³åç»­çš„Mask-R-CNNå½¢æˆäº†ä¸€æ¡å®Œæ•´çš„ä¸¤æ­¥è¯†åˆ«çš„ç‰©ä½“è¯†åˆ«æŠ€æœ¯ç”Ÿæ€ã€‚ æ¦‚è¿°ç‰©ä½“è¯†åˆ«æŠ€æœ¯ä¸€ç›´æ˜¯æœºå™¨è§†è§‰ä¸­ä¸šåŠ¡åœºæ™¯æœ€ä¸°å¯Œï¼Œå…³æ³¨åº¦æœ€é«˜çš„ä¸€ä¸ªç±»åˆ«ã€‚å°†èŠ±å‡ æœŸæ¥åˆ†åˆ«å¯¹ä¸»æµçš„ç‰©ä½“è¯†åˆ«æŠ€æœ¯å¦‚Faster RCNNï¼ŒSSDï¼ŒYOLOï¼ŒMask-RCNNè¿›è¡Œæ•´ç†å’Œåˆ†æï¼Œå¹¶åˆ©ç”¨å®è·µçš„æ–¹å¼è¿›è¡Œå¼ºåŒ–ã€‚ åœ¨R-CNN,Fast R-CNNï¼ŒFaster R-CNNä¸­ï¼Œç‰©ä½“è¯†åˆ«è¢«åˆ†ä¸ºä¸¤ä¸ªæ­¥éª¤å®ç°ï¼ˆä¸SSDã€YOLOçš„ä¸»è¦å·®å¼‚ï¼‰ï¼šå€™é€‰åŒºåŸŸé€‰æ‹©å’ŒåŸºäºæ·±åº¦ç½‘ç»œçš„ç‰©ä½“è¯†åˆ«ã€‚ ä¼ ç»Ÿçš„ç‰©ä½“è¯†åˆ«ç®—æ³•ä¼ ç»Ÿçš„ç‰©ä½“è¯†åˆ«æŠ€æœ¯é‡‡ç”¨çš„æ»‘åŠ¨çª—å£+å›¾åƒé‡‘å­—å¡”+åˆ†ç±»å™¨çš„ç®—æ³•ï¼Œå¯ä»¥å‚è§å‰è¿°åšæ–‡åœ¨åŸºäºæœºå™¨è§†è§‰æŠ€æœ¯çš„å“ç‰ŒLOGOæ£€æµ‹ä¸­åšçš„å®é™…æµ‹è¯•ï¼ŒåŸç†æ˜“äºç†è§£ï¼Œä½†æ•ˆç‡è¾ƒä½ï¼Œå¾ˆéš¾è¾¾åˆ°å®æ—¶å¤„ç†çš„éœ€æ±‚ï¼š é€Ÿåº¦æ…¢ï¼Œæ•ˆç‡ä½ï¼šéœ€è¦åˆ©ç”¨æ»‘åŠ¨çª—å£éå†å›¾åƒçš„ä¸åŒä½ç½®ï¼› å—å›¾åƒç•¸å˜å½±å“ä¸¥é‡ï¼šç”±äºCNNçš„è¾“å…¥å¿…é¡»æ˜¯å›ºå®šå¤§å°çš„å›¾åƒï¼Œæ‰€ä»¥é™åˆ¶äº†æ£€æµ‹ç›®æ ‡çš„é•¿å®½æ¯”ä¾‹ï¼Œæ¯”å¦‚è¿™ç§æ–¹æ³•ä¸èƒ½åŒæ—¶æ£€æµ‹çŸ®èƒ–å¯¹è±¡å’Œé•¿ç˜¦å¯¹è±¡ï¼› é”™è¯¯ç‡é«˜ï¼Œæ²¡æ³•è¯†åˆ«å›¾åƒçš„å…¨å±€ç‰¹å¾ï¼Œæ¯ä¸ªçª—å£åªèƒ½çœ‹åˆ°å±€éƒ¨ç‰¹å¾ï¼Œæ‰€ä»¥æ£€æµ‹ç²¾åº¦ä¹Ÿå—åˆ°äº†æ¯”è¾ƒå¤§çš„å½±å“ã€‚ ç‰©ä½“è¯†åˆ«ç²¾åº¦çš„è¡¡é‡æŒ‡æ ‡ IoU(Intersection over Union) IoU = \\frac{Area\\ of\\ Overlap}{Area\\ of\\ Union} mAP(Mean Average Precision) æ‰€æœ‰åˆ†ç±»çš„IoUå‡å€¼ï¼› å‚è€ƒè®ºæ–‡ R-CNNï¼š Rich feature hierarchies for accurate object detection and semantic segmentation Faster R-CNN R-CNN è®ºæ–‡ï¼š Rich feature hierarchies for accurate object detection and semantic segmentationï¼Œ2013ï¼ŒGirshick é—®é¢˜ï¼šè§£å†³ç›®æ ‡æ£€æµ‹ç½‘ç»œ R-CNNçš„å®ç°åŒ…æ‹¬å¦‚ä¸‹å›¾æ‰€ç¤ºçš„4ä¸ªä¸»è¦æ­¥éª¤ï¼š æ¥å—è¾“å…¥å›¾åƒï¼› åˆ©ç”¨Selective Searchç®—æ³•ä»å›¾åƒä¸­æŠ½å–å¤§çº¦2000ä¸ªå€™é€‰åŒºåŸŸï¼› å¯¹æ¯ä¸ªå€™é€‰åŒºåŸŸåˆ©ç”¨é¢„è®­ç»ƒçš„CNNè¿›è¡Œç‰¹å¾æŠ½å–ï¼ˆè¿ç§»å­¦ä¹ ï¼‰ï¼› å¯¹æ¯ä¸ªç‰¹å¾æŠ½å–åŒºåŸŸåˆ©ç”¨çº¿æ€§SVMè¿›è¡Œåˆ†ç±» è®ºæ–‡çš„ä¸»è¦è´¡çŒ®ï¼š ä½¿ç”¨Selective Searchæ›¿ä»£äº†ç‰¹å¾é‡‘å­—å¡”å’Œæ»‘åŠ¨çª—å£å®ç°çš„å…´è¶£åŒºåŸŸé€‰æ‹©ï¼Œæå‡äº†æ•ˆç‡ï¼› åˆ©ç”¨é¢„è®­ç»ƒçš„ç¥ç»ç½‘ç»œè¿›è¡Œç‰¹å¾æå–æ›¿ä»£äº†æ‰‹å·¥ç‰¹å¾å¦‚HOGçš„ç‰¹å¾æå–æ–¹æ³•ï¼Œæ­£æ˜¯ç”±äºCNNå­¦ä¹ çš„ç‰¹å¾å…·å¤‡çš„é²æ£’æ€§å¤§å¤§æä¾›äº†ç³»ç»Ÿçš„æ³›åŒ–æ€§èƒ½ ä»ç„¶å­˜åœ¨çš„é—®é¢˜ï¼š è¯†åˆ«æ…¢ï¼Œæ•ˆç‡ä½ï¼› ä¸æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„è§£å†³æ–¹æ¡ˆ Selective Searchç®—æ³• è®ºæ–‡ï¼šSelective Search for Object Recognitionï¼Œ2012ï¼ŒJ.R.R.Uijings ä¹‹å‰å¾ˆå¤šç®—æ³•éƒ½æ˜¯åŸºäºè›®åŠ›æœç´¢(Exhaustive Search),å¯¹æ•´å¼ å›¾ç‰‡è¿›è¡Œæ‰«æï¼Œæˆ–è€…æ˜¯é‡‡ç”¨åŠ¨æ€çª—å£çš„æ–¹æ³•ï¼Œè¿™ç§æ–¹æ³•è€—æ—¶ä¸¥é‡ï¼Œæ“ä½œéº»çƒ¦ã€‚J.R.Ræå‡ºçš„é€‰æ‹©æ€§æœç´¢çš„æ–¹æ³•ï¼Œåœ¨è¯†åˆ«å‰æœŸåœ¨æ•´å¼ å›¾ç‰‡ä¸­ç”Ÿæˆ1~3Kä¸ªproposalçš„æ–¹æ³•ï¼Œå†å¯¹æ¯ä¸ªproposalè¿›è¡Œå¤„ç†ã€‚ Selective Search [4], one of the most popular methods, greedily merges superpixels based on engineered low-level features. ç¼ºç‚¹ï¼šæ•ˆç‡ä½ï¼Œè®¡ç®—é‡å¤§ï¼Œä½¿ç”¨1ä¸ªCPUå¤„ç†ä¸€å¼ å›¾ç‰‡ï¼Œéœ€è¦2s1 Fast R-CNNé—®é¢˜æå‡ºï¼šè§£å†³ç«¯åˆ°ç«¯è®­ç»ƒçš„é—®é¢˜ï¼Œæå‡ºäº†Region of Interestï¼ˆROIï¼‰Pooling è·ŸR-CNNä¸­ä½¿ç”¨æ·±åº¦CNNçš„æ–¹å¼ä¸åŒï¼ŒFast R-CNNä¸­é¦–å…ˆå°†CNNåº”ç”¨åˆ°æ•´ä¸ªå›¾åƒä¸­è¿›è¡Œç‰¹å¾æå–ï¼Œåˆ©ç”¨ä¸€ä¸ªå›ºå®šçª—å£åœ¨æŠ½å–ç‰¹å¾ä¸Šæ»‘åŠ¨ï¼Œåˆ†åˆ«è¿›è¡Œåˆ†ç±»é¢„æµ‹å’Œå›å½’é¢„æµ‹ã€‚Fast R-CNNçš„ä¸»è¦å¤„ç†æµç¨‹åŒ…æ‹¬ï¼š è¾“å…¥å›¾åƒå’Œæ ‡å®šçš„è¯†åˆ«æ¡†ä¿¡æ¯ï¼› åˆ©ç”¨æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œæŠ½å–å›¾åƒç‰¹å¾ï¼› åˆ©ç”¨ROI poolingè·å–ROIç‰¹å¾å‘é‡ï¼› åˆ©ç”¨ä¸¤ä¸ªå…¨è”é€šå±‚è¿›è¡Œåˆ†ç±»å’Œå›å½’é¢„æµ‹ ç«¯åˆ°ç«¯çš„è®­ç»ƒè¿‡ç¨‹æºäºæå‡ºäº†å¤šä»»åŠ¡æŸå¤±å‡½æ•°ï¼Œå°†åˆ†ç±»é—®é¢˜å’Œå›å½’é—®é¢˜æ•´åˆåœ¨ä¸€èµ·ï¼Œæ‰“é€šäº†æ¢¯åº¦çš„æ›´æ–°è·¯å¾„ï¼Œä¸‹å›¾æè¿°äº†Fast R-CNNçš„è®­ç»ƒå’Œæµ‹è¯•è¿‡ç¨‹ï¼š ç¼ºç‚¹ï¼šä»ç„¶æ²¡æœ‰æ‘†è„±Selective Searchç®—æ³•åœ¨æ¨ç†é˜¶æ®µè¿›è¡Œå€™é€‰åŒºåŸŸç”Ÿæˆã€‚ Faster R-CNN è®ºæ–‡ï¼šFaster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks, 2015, Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun å®ç°ï¼šGithubä¸Šä½œè€…æä¾›çš„Pythonå®ç° å•†ä¸šå®ç°ï¼šPinterests2 é—®é¢˜æå‡ºï¼šåœ¨åŸºäºå€™é€‰åŒºåŸŸé€‰æ‹©çš„CNNï¼ˆregion-based CNNï¼‰ç‰©ä½“è¯†åˆ«ç½‘ç»œä¸­ï¼Œå€™é€‰åŒºåŸŸé€‰æ‹©çš„æ•ˆç‡æˆä¸ºäº†æ•´ä¸ªç³»ç»Ÿçš„ç“¶é¢ˆï¼›Faster R-CNNä¸­æå‡ºäº†Region Proposal Netwrokä¸ç‰©ä½“è¯†åˆ«ç½‘ç»œå…±äº«ç½‘ç»œå‚æ•°ï¼ˆæ›¿ä»£äº†Fast R-CNNä¸­çš„Selective Searchç®—æ³•ï¼‰ï¼Œé™ä½äº†å€™é€‰åŒºåŸŸé€‰æ‹©çš„æ—¶é—´ä»£ä»·ã€‚ åŸºç¡€ç½‘ç»œï¼ˆBase Networkï¼‰ï¼šç‰¹å¾æŠ½å–ï¼ˆè¿ç§»å­¦ä¹ ï¼‰ï¼ŒæŠ½å–çš„ç‰¹å¾å°†åŒæ—¶åº”ç”¨äºRPNå’ŒRoIPé˜¶æ®µ RPNï¼šå€™é€‰åŒºåŸŸé€‰æ‹©ï¼ˆåˆ©ç”¨äº†ç½‘ç»œçš„Attentionæœºåˆ¶ï¼‰ï¼Œç”¨äºå‘æ˜å›¾åƒä¸­æ½œåœ¨çš„å¯èƒ½å­˜åœ¨ç‰©ä½“çš„åŒºåŸŸ RoIPï¼šå…´è¶£åŒºåŸŸç‰¹å¾æå– R-CNNï¼šåˆ†ç±»é¢„æµ‹å’Œå€™é€‰æ¡†å›å½’ ä½¿ç”¨ä¸€å—GPUï¼Œæ€§èƒ½å¤§æ¦‚åœ¨7-10 FPS åŸºç¡€ç½‘ç»œåŸºç¡€ç½‘ç»œçš„ä¸»è¦ä½œç”¨æ˜¯åˆ©ç”¨è¿ç§»å­¦ä¹ å®ŒæˆåŸå§‹å›¾åƒçš„ç‰¹å¾æŠ½å–ï¼Œåœ¨è®ºæ–‡ä¸­ä½¿ç”¨äº† åœ¨ImageNeté¢„è®­ç»ƒçš„ZF æˆ– VGGæ¥å®Œæˆè¿™ä¸€ä»»åŠ¡ã€‚å½“ç„¶æ ¹æ®ç‰©ä½“è¯†åˆ«ä»»åŠ¡çš„ä¸åŒåº”ç”¨åœºæ™¯å¯ä»¥åœ¨æ¨¡å‹ç²¾åº¦å’Œæ¨ç†æ—¶é—´ä¸Šè¿›è¡ŒæŠ˜ä¸­é€‰æ‹© MobileNet, ResNet-152ï¼Œ DenseNetã€‚ æ–‡çŒ®ä¸­ï¼ŒFaster R-CNNçš„åŸºç¡€ç½‘ç»œåœ¨ä½¿ç”¨VGGä½œä¸ºç‰¹å¾æå–ç½‘ç»œæ—¶ï¼Œä½¿ç”¨conv5/conv5_1å±‚çš„è¾“å‡ºç‰¹å¾ï¼› ç›®å‰ResNetåœ¨å¾ˆå¤šæƒ…å†µä¸‹å·²ç»æ›¿ä»£äº†VGG16ä½œä¸ºç‰¹å¾æå–ç½‘ç»œï¼› ä¸ºäº†ä¿è¯ç½‘ç»œæ˜¯å…¨å·ç§¯ç¥ç»ç½‘ç»œæ¶æ„ï¼Œéœ€è¦æŠŠå…¨è¿æ¥å±‚å‰”é™¤ï¼Œä¿è¯å¯ä»¥è¾“å…¥ä»»æ„ç»´åº¦çš„è¾“å…¥å›¾åƒ Anchor Box æ›¿ä»£ä¼ ç»Ÿç®—æ³•çš„ç‰¹å¾é‡‘å­—å¡”æˆ–filteré‡‘å­—å¡” ä¸€å¼ å›¾åƒä¸­è¢«è¯†åˆ«ç›®æ ‡å½¢çŠ¶å¤§å°å„å¼‚ï¼Œè¿™ä¹Ÿæ˜¯åœ¨åŸå§‹ç®—æ³•ä¸­åŠ å…¥ç‰¹å¾é‡‘å­å¡”æ¥å¯¹åŸå§‹å›¾åƒè¿›è¡Œå¤šä¸ªç»´åº¦ç‰¹å¾å˜æ¢çš„åŸå› ã€‚ Anchor Boxä¹Ÿæ˜¯ä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥ä¸æ”¹å˜å›¾åƒçš„å½¢çŠ¶ï¼Œé€šè¿‡æ”¹å˜é¢„æµ‹æ¯ä¸ªåŒºåŸŸç‰©ä½“çš„â€œçª—å£â€æ¥æ¡†å‡ºä¸åŒå¤§å°çš„ç‰©ä½“ã€‚é¦–å…ˆåœ¨åŸå§‹å›¾åƒä¸­å‡åŒ€çš„é€‰å–ä¸€äº›Anchor Boxä¸­å¿ƒç‚¹ï¼Œç„¶ååœ¨æ¯ä¸ªä¸­å¿ƒç‚¹ä¸Šé¢„åˆ¶å¤šä¸ªAnchor Boxã€‚ åœ¨Faster R-CNNæ˜¯ä½¿ç”¨3ä¸ªä¸åŒå½¢çŠ¶ï¼ˆ1:1, 1:2,2:1ï¼‰å’Œ3ä¸ªä¸åŒå¤§å°(128x128,256x256,512x512ï¼ŒæŒ‰ç…§åŸå›¾å°ºå¯¸ç”Ÿæˆ)è¿›è¡Œç»„åˆå…±è®¡3x3=9ç§ä¸åŒçš„Anchor boxã€‚ ä½¿ç”¨VGG16åšç‰¹å¾æå–çš„æƒ…å†µä¸‹ï¼Œä¸€å¼ è¾“å…¥å›¾ç‰‡æ€»å…±å¯ä»¥åˆ»ç”»ä¸º512ä¸ªçª—å£åŒºåŸŸï¼Œç”Ÿæˆ512x(4+2)x9ä¸ªè¾“å‡ºå‚æ•°ã€‚ ç”±äºç›´æ¥é¢„æµ‹bouding boxéš¾ä»¥å®ç°ï¼Œä½œè€…å°†é—®é¢˜è½¬å˜ä¸ºé¢„æµ‹é¢„æµ‹å€¼ä¸çœŸå®å€¼ä¹‹é—´çš„åç§»ï¼Œå°†é—®é¢˜è½¬å˜ä¸ºå››ä¸ªåç§»å€¼çš„é¢„æµ‹é—®é¢˜ã€‚ Region Proposal Network(RPN)RPNçš„ä¸»è¦ç›®çš„æ˜¯å¯¹æ¯ä¸ªåŒºåŸŸæ˜¯å¦å¯èƒ½æœ‰ç‰©ä½“è¿›è¡Œæ‰“åˆ†ï¼ŒåŸºäºæ‰“åˆ†å€¼å†³å®šæ˜¯å¦è¿›è¡Œä¸‹ä¸€æ­¥çš„åˆ†ç±»ä»»åŠ¡ã€‚åœ¨åŸºç¡€ç½‘ç»œæŠ½å–çš„ç‰¹å¾å›¾ä¸Šä½¿ç”¨ä¸€ä¸ª3x3çš„æ»‘åŠ¨çª—å£ï¼ˆ512ä¸ªå·ç§¯æ ¸ï¼‰ï¼Œæ¯ä¸ªæ»‘åŠ¨çª—å£çš„ä¸­å¿ƒç‚¹ä½ç½®ä¸ºä¸Šè¿°Achor Boxçš„ä¸­å¿ƒç‚¹åŒºåŸŸï¼Œåœ¨æ¯ä¸ªæ»‘åŠ¨çª—å£åŒºåŸŸï¼Œå°†å¾—åˆ°ä¸¤ä¸ª1x1å·ç§¯ç½‘ç»œè¾“å‡ºï¼Œåˆ†åˆ«ä¸º2kçš„å‰æ™¯/èƒŒæ™¯é¢„æµ‹ï¼ˆè¯¥åŒºåŸŸæ˜¯å¦å­˜åœ¨å¯è¢«é¢„æµ‹ç‰©ä½“ï¼Œåˆ†ç±»é—®é¢˜ï¼‰ä»¥åŠ4kçš„ä½ç½®ä¿¡æ¯é¢„æµ‹ï¼ˆå›å½’é—®é¢˜ï¼‰ï¼Œå››ä¸ªå€¼åˆ†åˆ«æ˜¯ $\\Delta{center{x}}$, $\\Delta{center{y}}$, $\\Delta{width}$, $\\Delta{height}$ã€‚ kæ˜¯Anchor Boxçš„æ•°ç›® æˆ‘ä»¬å°†ä»å€™é€‰åŒºåŸŸä¸­é€‰æ‹©æ‰“åˆ†è¾ƒé«˜çš„å‰Nä¸ªè¿›è¡Œä¸‹ä¸€è½®åˆ†æï¼Œå¦‚æœç‰©ä½“æ‰“åˆ†è¶³å¤Ÿé«˜ï¼Œä¸‹ä¸€æ­¥å°†è¿›è¡Œéæå¤§æŠ‘åˆ¶å’ŒåŒºåŸŸé€‰æ‹©ï¼Œå¦‚æœæ‰“åˆ†å€¼å¾ˆä½å°†æŠ›å¼ƒè¿™äº›åŒºåŸŸ ç›®æ ‡å’ŒæŸå¤±å‡½æ•°The RPN does two different type of predictions: the binary classification and the bounding box regression adjustment. For training, we take all the anchors and put them into two different categories. Those that overlap a ground-truth object with an Intersection over Union (IoU) bigger than 0.5 are considered â€œforegroundâ€ and those that donâ€™t overlap any ground truth object or have less than 0.1 IoU with ground-truth objects are considered â€œbackgroundâ€. L({p_i}, {t_i}) = \\frac{1}{N_{cls}}\\sum_iL_{cls}(p_i,p_i^*)+\\lambda\\frac{1}{N_{reg}}\\sum_ip_i^*L_{reg}(t_i,t_i^*)å…¶ä¸­åˆ†ç±»çš„æŸå¤±å‡½æ•°ä¸ºï¼š L_{cls}(p_i,p_i^*) = -log[p_i^*p_i+(1-p_i^*)(1-p_i)]$p_i$ä¸ºç¬¬$i$ä¸ªå‚è€ƒæ¡†æ˜¯ç‰©ä½“çš„é¢„æµ‹æ¦‚ç‡å€¼ï¼Œ$p_i^*$ä¸ºå®é™…å€¼ï¼Œå¦‚æœanchoræ˜¯ç‰©ä½“çš„è¯è¯¥å€¼ä¸º1ï¼Œå¦åˆ™ä¸º0ã€‚ å›å½’æŸå¤±å‡½æ•°ä¸ºï¼š L_{reg}(t_i,t_i^*)=R(t_i-t_i^*)å…¶ä¸­Rä¸ºsmooth L1å¹³æ»‘æ–¹ç¨‹ï¼š smooth_{L_1}(x)=\\left\\{ \\begin{array}{lr} 0.5x^2 & if \\ |x|","categories":[{"name":"æ·±åº¦å­¦ä¹ ","slug":"æ·±åº¦å­¦ä¹ ","permalink":"http://blog.a-stack.com/categories/æ·±åº¦å­¦ä¹ /"},{"name":"æœºå™¨è§†è§‰","slug":"æ·±åº¦å­¦ä¹ /æœºå™¨è§†è§‰","permalink":"http://blog.a-stack.com/categories/æ·±åº¦å­¦ä¹ /æœºå™¨è§†è§‰/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://blog.a-stack.com/tags/AI/"},{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"ç®—æ³•","slug":"ç®—æ³•","permalink":"http://blog.a-stack.com/tags/ç®—æ³•/"},{"name":"ç‰©ä½“è¯†åˆ«","slug":"ç‰©ä½“è¯†åˆ«","permalink":"http://blog.a-stack.com/tags/ç‰©ä½“è¯†åˆ«/"},{"name":"æ–‡çŒ®","slug":"æ–‡çŒ®","permalink":"http://blog.a-stack.com/tags/æ–‡çŒ®/"}]},{"title":"åˆ©ç”¨è¿ç§»å­¦ä¹ å®ç°è½¦è¾†è¯†åˆ«","slug":"Vechicle-identification-by-stanford-car-dataset","date":"2018-04-11T06:44:58.000Z","updated":"2018-05-15T09:14:33.589Z","comments":false,"path":"2018/04/11/Vechicle-identification-by-stanford-car-dataset/","link":"","permalink":"http://blog.a-stack.com/2018/04/11/Vechicle-identification-by-stanford-car-dataset/","excerpt":"","text":"æ‘˜è¦ï¼š åˆ©ç”¨è¿ç§»å­¦ä¹ æŠ€æœ¯è®­ç»ƒè¯†åˆ«æ±½è½¦å‚å•†å’Œæ¬¾å¼çš„æ¨¡å‹ã€‚ @[toc] æ¦‚è¿°æ•°æ®é›†ï¼š Stanford Cars Dataset æ•°æ®é›†ç»„æˆï¼šåŒ…å«196ç§è½¦è¾†çš„16,185å¼ ç…§ç‰‡ï¼›å…¶ä¸­è®­ç»ƒé›†8144ï¼Œæµ‹è¯•é›†8041ï¼› å…³é”®ç‰¹å¾åŒ…æ‹¬ï¼šè½¦è¾†åˆ¶é€ å•†ã€æ¬¾å¼ã€ç”Ÿäº§æ—¥æœŸï¼ˆæ¯”å¦‚ï¼š2012 Tesla Model Sï¼‰ï¼› ä¸‹è½½åœ°å€ï¼šhttps://ai.stanford.edu/~jkrause/cars/car_dataset.htmlï¼› ç›¸å…³è®ºæ–‡ï¼š3D Object Representations for Fine-Grained Categorizationï¼ŒJonathan Krause, Michael Stark, Jia Deng, Li Fei-Fei æ•°æ®é›†ç‰¹ç‚¹ï¼š å­˜åœ¨æ˜æ˜¾çš„æ•°æ®ä¸å¹³è¡¡é—®é¢˜ï¼› æ¯ä¸ªåˆ†ç±»å›¾åƒæ•°ç›®è¿‡å°‘ï¼Œæ— æ³•è¾¾åˆ°å‡†ç¡®é¢„æµ‹åˆ†ç±»ç›®æ ‡çš„åŸºå‡†ï¼› é’ˆå¯¹æ•°æ®é›†çš„ç‰¹ç‚¹ï¼Œåˆ©ç”¨è¿ç§»å­¦ä¹ Fine-Tuneæ¥è®­ç»ƒä¸€ä¸ªåœ¨ImageNetä¸Šé¢„è®­ç»ƒçš„æ¨¡å‹æ˜¯ä¸€ä¸ªä¸é”™çš„æ–¹å¼ï¼Œä¸‹é¢æˆ‘ä»¬å°†ä»æ•°æ®çš„å‡†å¤‡å¼€å§‹ä¸€æ­¥æ­¥å¾—å®Œæˆæ¨¡å‹çš„è®­ç»ƒä»»åŠ¡ã€‚ æ•°æ®å‡†å¤‡åœ¨è¿™ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†è¯»å…¥åŸå§‹æ•°æ®ï¼Œè¿›è¡ŒåŸºæœ¬çš„æ•°æ®å¤„ç†ï¼Œç„¶åå¯¹æ•°æ®è¿›è¡Œç»Ÿä¸€å­˜å‚¨ï¼Œä¸€èˆ¬é¢å¯¹å¤§è§„æ¨¡çš„æ•°æ®é›†å¯ä»¥é€‰ç”¨HDF5æˆ–MXNetçš„.LSTæ ¼å¼è¿›è¡Œå­˜å‚¨ã€‚ é€šè¿‡è¿™ç§æ–¹å¼è¿›è¡Œå­˜å‚¨å¯ä»¥è§£å†³æ¯å¼ å›¾ç‰‡è¯»å–éƒ½è¦äº§ç”Ÿä¸€æ¬¡IOå¸¦æ¥çš„è®¿é—®æ—¶å»¶ï¼ŒåŒæ—¶å¯ä»¥åˆ©ç”¨å­˜å‚¨ç³»ç»Ÿè¿ç»­è¯»çš„æ–¹å¼ï¼Œç›´æ¥å¯¹å¤§è§„æ¨¡æ•°æ®é›†è¿›è¡Œåˆ‡ç‰‡æ“ä½œã€‚ é…ç½®ä¿¡æ¯ä¸ºäº†é…åˆåç»­å¤„ç†æµç¨‹æ–¹ä¾¿ï¼Œæ–°å»ºä¸€ä¸ªcar.configçš„é…ç½®æ–‡ä»¶ï¼Œç”¨äºå¯¹ç›¸å…³é…ç½®ä¿¡æ¯çš„å­˜å‚¨ï¼š 1234567891011121314151617181920212223242526272829303132333435from os import path# define the base path to the cars datasetBASE_PATH = \"Path-to-car-dataset\"# based on the base path, derive the images path and meta file pathIMAGES_PATH = path.sep.join([BASE_PATH, \"car_ims\"])LABELS_PATH = path.sep.join([BASE_PATH, \"complete_dataset.csv\"])#define path for HDF5TRAIN_HDF5 = path.sep.join([MX_OUTPUT, \"hdf5/train.hdf5\"])VAL_HDF5 = path.sep.join([MX_OUTPUT, \"hdf5/val.hdf5\"])TEST_HDF5 = path.sep.join([MX_OUTPUT, \"hdf5/test.hdf5\"])#define path for storing Mean R G B dataDATASET_MEAN = path.sep.join([BASE_PATH, \"output/car_mean.json\"])# define the path to the output directory used for storing plots,# classification reports, etc.OUTPUT_PATH = \"output\"MODEL_PATH = path.sep.join([OUTPUT_PATH,\"inceptionv3_stanfordcar.hdf5\"])FIG_PATH = path.sep.join([OUTPUT_PATH,\"inceptionv3_stanfordcar.png\"])JSON_PATH = path.sep.join([OUTPUT_PATH,\"inceptionv3_stanfordcar.json\"])# define the path to the label encoderLABEL_ENCODER_PATH = path.sep.join([BASE_PATH, \"output/le.cpickle\"])# define the percentage of validation and testing images relative# to the number of training imagesNUM_CLASSES = 164NUM_VAL_IMAGES = 0.15NUM_TEST_IMAGES = 0.15# define the batch sizeBATCH_SIZE = 64 é…ç½®æ–‡ä»¶ä¸­åŒ…æ‹¬HDF5æ–‡ä»¶çš„å­˜æ”¾ä½ç½®æè¿°ï¼ŒåŸå§‹æ•°æ®å’Œæ•°æ®æè¿°æ–‡ä»¶è·¯å¾„ï¼ŒRGBå‡å€¼å­˜å‚¨ä½ç½®ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­è¾“å‡ºçš„å›¾åƒå’Œæ—¥å¿—å­˜å‚¨ä½ç½®ç­‰ä¿¡æ¯ã€‚ æ•°æ®æ¦‚è§ˆ æˆ‘ä»¬å…ˆå°†æ•°æ®æè¿°æ–‡ä»¶complete_dataset.csvå¯¼å…¥ï¼Œäº†è§£ä¸‹æ•°æ®æ ¼å¼ï¼š 1234import pandas as pd# loading image paths and labelsdf = pd.read_csv(config.LABELS_PATH)df.head() id Image FileName Make Model Vechicle Typle Year 0 car_ims/000090.jpg Acura RL Sedan 2012 1 car_ims/000091.jpg Acura RL Sedan 2012 2 car_ims/000092.jpg Acura RL Sedan 2012 3 car_ims/000093.jpg Acura RL Sedan 2012 éå†æ–‡ä»¶åˆ—è¡¨ï¼Œå°†æ–‡ä»¶åœ°å€å’Œæ ·æœ¬æ ‡ç­¾åˆ†åˆ«è¿›è¡Œå­˜å‚¨ï¼Œåœ¨æœ¬å®éªŒä¸­å€¼ä½¿ç”¨äº†åˆ¶é€ å•†å’Œæ¬¾å¼ä¸¤ç§ç‰¹å¾ï¼Œæ‰€ä»¥æ„æˆåˆ†ç±»æ€»å…±æœ‰164ä¸ªï¼š 1234567891011import osfrom sklearn.preprocessing import LabelEncodertrainPaths = []trainLabels = []for id,name in enumerate(df[\"Image Filename\"]): trainPaths.append(os.sep.join([config.IMAGES_PATH,name])) trainLabels.append(\"&#123;&#125;:&#123;&#125;\".format(df.iloc[id][\"Make\"], df.iloc[id][\"Model\"]))#Encoding labels to numle = LabelEncoder()trainLabels = le.fit_transform(trainLabels) æŒ‰ç…§70%ï¼Œ15%ï¼Œ15%åˆ‡åˆ†è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ï¼š 1234567891011121314from sklearn.model_selection import train_test_splitnumVal = int(len(trainPaths)*0.15)numTest = int(len(trainPaths)*0.15)# perform sampling from the training set to construct a a validation setsplit = train_test_split(trainPaths, trainLabels, test_size=numVal, stratify=trainLabels)(trainPaths, valPaths, trainLabels, valLabels) = split# perform stratified sampling from the training set to construct a testing setsplit = train_test_split(trainPaths, trainLabels, test_size=numTest, stratify=trainLabels)(trainPaths, testPaths, trainLabels, testLabels) = split åˆå§‹åŒ–ç›¸å…³é…ç½®ï¼š 12345678910# initialize the lists of RGB channel averages(R, G, B) = ([], [], [])# construct a list pairing the training, validation, and testing# image paths along with their corresponding labels and output list# filesdatasets = [ (\"train\", trainPaths, trainLabels, config.TRAIN_HDF5), (\"val\", valPaths, valLabels, config.VAL_HDF5), (\"test\", testPaths, testLabels, config.TEST_HDF5)] éå†æ•°æ®é›†å¹¶å­˜å‚¨è‡³HDF5æ–‡ä»¶ï¼š 123456789101112131415161718192021222324252627282930313233343536373839404142434445import HDF5DatasetWriterimport AspectAwarePreprocessorimport progressbar#resize images to (256,256,3)aap = AspectAwarePreprocessor(256,256)# loop over the dataset tuplesfor (dType, paths, labels, outputPath) in datasets: # create HDF5 writer print(\"[INFO] building &#123;&#125;...\".format(outputPath)) writer = HDF5DatasetWriter((len(paths), 256, 256, 3), outputPath) # initialize the progress bar widgets = [\"Building Dataset: \", progressbar.Percentage(), \" \", progressbar.Bar(), \" \", progressbar.ETA()] pbar = progressbar.ProgressBar(maxval=len(paths), widgets=widgets).start() # loop over the image paths for (i, (path, label)) in enumerate(zip(paths, labels)): # load the image from disk try: image = cv2.imread(path) image = aap.preprocess(image) #print(image.shape) # if we are building the training dataset, then compute the # mean of each channel in the image, then update the respective lists if dType == \"train\": (b, g, r) = cv2.mean(image)[:3] R.append(r) G.append(g) B.append(b) # add the image and label to the HDF5 dataset writer.add([image], [label]) pbar.update(i) except: print(path) print(label) break # close the HDF5 writer pbar.finish() writer.close() æˆ‘ä»¬é¦–å…ˆç»Ÿä¸€å°†æ–‡ä»¶è°ƒæ•´åˆ°(256,256,3)å¤§å°ï¼Œå†è¿›è¡Œå­˜å‚¨ï¼Œæ‰€ä»¥åœ¨è¯»å–æ–‡ä»¶ä¹‹åè¿›è¡Œäº†ç®€å•çš„é¢„å¤„ç†ã€‚ å°†RGBå‡å€¼å­˜å‚¨è‡³å•ç‹¬æ–‡ä»¶ 12345678import pandas as pdimport json# construct a dictionary of averages, then serialize the means to a JSON fileprint(\"[INFO] serializing means...\")D = &#123;\"R\": np.mean(R), \"G\": np.mean(G), \"B\": np.mean(B)&#125;f = open(config.DATASET_MEAN, \"w\")f.write(json.dumps(D))f.close() è‡³æ­¤ï¼Œæˆ‘ä»¬å®Œæˆäº†å°†å›¾åƒæ–‡ä»¶åˆ†ä¸ºä¸‰ä¸ªç±»åˆ«å¹¶åˆ†åˆ«å­˜åˆ°äº†ä¸‰ä¸ªHDF5æ–‡ä»¶ä¹‹ä¸­ã€‚ å…³äºHDF5æ–‡ä»¶å­˜å‚¨ç›¸å…³å†…å®¹ï¼Œè¯¦è§åç»­æ¨å‡ºçš„é¢„å¤„ç†åšå®¢~~ å¦‚æœä½¿ç”¨MXNETçš„listå’Œrecæ¥æ„å»ºæ•°æ®å­˜å‚¨é›†åˆï¼Œåœ¨ä¸Šè¿°æ­¥éª¤3çš„åŸºç¡€ä¸Šï¼ŒæŒ‰å¦‚ä¸‹æ­¥éª¤ï¼š æ„å»ºæ•°æ®é›†åˆ—è¡¨æ–‡ä»¶â€™.listâ€™æ–‡ä»¶ 1234567891011121314151617181920212223# construct a list pairing the training, validation, and testing# image paths along with their corresponding labels and output list# filesdatasets = [ (\"train\", trainPaths, trainLabels, config.TRAIN_MX_LIST), (\"val\", valPaths, valLabels, config.VAL_MX_LIST), (\"test\", testPaths, testLabels, config.TEST_MX_LIST)]# loop over the dataset tuplesfor (dType, paths, labels, outputPath) in datasets: # open the output file for writing print(\"[INFO] building &#123;&#125;...\".format(outputPath)) f = open(outputPath, \"w\") # loop over each of the individual images + labels for (i, (path, label)) in enumerate(zip(paths, labels)): # write the image index, label, and output path to file row = \"\\t\".join([str(i), str(label), path]) f.write(\"&#123;&#125;\\n\".format(row)) # close the output file f.close() å°†Labelåç§°åºåˆ—åŒ–å­˜å‚¨ï¼Œä¾¿äºåç»­è°ƒç”¨ï¼š 123f = open(config.LABEL_ENCODER_PATH, \"wb\")f.write(pickle.dumps(le))f.close() 3.åˆ©ç”¨MXNetå·¥å…·im2recåˆ›å»ºè®°å½•æ–‡ä»¶ 12345$ /dsvm/tools/mxnet/bin/im2rec ./raid/datasets/cars/lists/train.lst \"\" ./raid/datasets/cars/rec/train.rec resize=256 encoding='.jpg' quality=100$ /dsvm/tools/mxnet/bin/im2rec ./raid/datasets/cars/lists/test.lst \"\" ./raid/datasets/cars/rec/test.rec resize=256 encoding='.jpg' quality=100$ /dsvm/tools/mxnet/bin/im2rec ./raid/datasets/cars/lists/val.lst \"\" ./raid/datasets/cars/rec/val.rec resize=256 encoding='.jpg' quality=100 è®­ç»ƒè¿ç§»å­¦ä¹ ç½‘ç»œåœ¨è¿ç§»å­¦ä¹ çš„æ¨¡å‹é€‰æ‹©ä¸Šæˆ‘ä»¬é€‰æ‹©äº†åŸºäºKerasæä¾›çš„InceptionV3,å¯é€šè¿‡Keraså®˜æ–¹æ–‡æ¡£äº†è§£æ›´å¤šä½¿ç”¨è¯´æ˜ã€‚ä¸‹è¡¨åˆ—å‡ºäº†åœ¨kerasä¸­å„æ¨¡å‹çš„è¡¨ç°ï¼š æ¨¡å‹ å¤§å° Top1å‡†ç¡®ç‡ Top5å‡†ç¡®ç‡ å‚æ•°æ•°ç›® æ·±åº¦ Xception 88MB 0.790 0.945 22,910,480 126 VGG16 528MB 0.715 0.901 138,357,544 23 VGG19 549MB 0.727 0.910 143,667,240 26 ResNet50 99MB 0.759 0.929 25,636,712 168 InceptionV3 92MB 0.788 0.944 23,851,784 159 IncetionResNetV2 215MB 0.804 0.953 55,873,736 572 MobileNet 17MB 0.665 0.871 4,253,864 88 æ•°æ®è¯»å…¥è¾“å…¥è¯»å…¥è¿‡ç¨‹ä¸»è¦åŒ…æ‹¬å‡ ä¸ªå…³é”®ä»»åŠ¡ï¼šè¯»å–RGBå‡å€¼æ–‡ä»¶ï¼Œå¯¹åŸå§‹æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼šå›¾åƒæ‰£å–ã€æ•°æ®å¢å¼ºã€å»é€šé“å‡å€¼ã€çŸ©é˜µåŒ–ç­‰ã€‚ è¿™å—å†…å®¹ä¸æ˜¯æœ¬ç¯‡é‡ç‚¹ï¼Œåªèƒ½æŒ–å‘ç•™ç»™åç»­æ›´æ–°ã€‚ 12345678910111213141516171819# construct the training image generator for data augmentationaug = ImageDataGenerator(rotation_range=20, zoom_range=0.15, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15, horizontal_flip=True, fill_mode=\"nearest\")# load the RGB means for the training setmeans = json.loads(open(config.DATASET_MEAN).read())# initialize the image preprocessorssp = SimplePreprocessor(224, 224)pp = PatchPreprocessor(224, 224)mp = MeanPreprocessor(means[\"R\"], means[\"G\"], means[\"B\"])iap = ImageToArrayPreprocessor()# initialize the training and validation dataset generatorstrainGen = HDF5DatasetGenerator(config.TRAIN_HDF5, 64, aug=aug, preprocessors=[pp, mp, iap], classes=config.NUM_CLASSES)valGen = HDF5DatasetGenerator(config.VAL_HDF5, 64, preprocessors=[sp, mp, iap], classes=config.NUM_CLASSES) æ¨¡å‹è®¾è®¡æ¨¡å‹è®¾è®¡è¿‡ç¨‹å‚è€ƒäº†Keraså®˜æ–¹æ–‡æ¡£ç»™å‡ºçš„æ¼”ç¤ºï¼Œå¯¼å…¥æ²¡æœ‰topçš„é¢„è®­ç»ƒInceptionV3æ¨¡å‹ï¼Œ 12345678910111213141516171819202122232425262728from keras.applications.inception_v3 import InceptionV3from keras.preprocessing import imagefrom keras.models import Modelfrom keras.layers import Dense, GlobalAveragePooling2Dfrom keras import backend as K# load the Inception network, ensuring the head FC layer sets are left offbaseModel = InceptionV3(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))# initialize the new head of the network, a set of FC layers# followed by a softmax classifierx = baseModel.outputx = GlobalAveragePooling2D()(x)x = Dense(1024, activation='relu')(x)headModel = Dense(config.NUM_CLASSES, activation='softmax')(x)model = Model(inputs=baseModel.input, outputs=headModel)# loop over all layers in the base model and freeze them so they# will *not* be updated during the training processfor layer in baseModel.layers: layer.trainable = False# compile our model (this needs to be done after our setting our# layers to being non-trainableprint(\"[INFO] compiling model...\")opt = SGD(lr=0.005,momentum=0.9)model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"]) ç‰¹åˆ«æ³¨æ„åœ¨è¿ç§»å­¦ä¹ ä¸­ï¼Œç”±äºæ–°æ·»åŠ å¢çš„åˆå§‹æƒé‡æ˜¯éšæœºç”Ÿæˆçš„ï¼Œè€Œå‰é¢å¤§é‡ç½‘ç»œå‚æ•°å¹¶frozenä¹‹åä¸å†å‘ç”Ÿå˜åŒ–ï¼Œæ‰€ä»¥éœ€è¦ä¸€ä¸ªé¢„æµ‹çš„è¿‡ç¨‹æ¥å­¦ä¹ å‚æ•°åˆ°ä¸€å®šæ°´å¹³ï¼Œéœ€è¦æ§åˆ¶å­¦ä¹ ç‡åœ¨ä¸€ä¸ªæ¯”è¾ƒå°çš„èŒƒå›´ã€‚ è¿™ä¸ªè¿‡ç¨‹å¯èƒ½éœ€è¦åå¤å°è¯•è¯•é”™ã€‚ è®­ç»ƒè¿‡ç¨‹ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹å‚è€ƒäº†ã€ŠDeep Learning for Computer Vison with Pythonã€‹ä½œè€…ç»™å‡ºçš„Ctrl+Cè®­ç»ƒæ–¹æ³•ï¼Œå¯ä»¥éšæ—¶ä¿å­˜è®­ç»ƒç°åœºï¼Œè°ƒæ•´è®­ç»ƒç‡ç»§ç»­è¿›è¡Œè®­ç»ƒã€‚ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import argparseimport jsonimport osimport logging# construct the argument parse and parse the argumentsap = argparse.ArgumentParser()ap.add_argument(\"-c\", \"--checkpoints\", required=True, help=\"path to output checkpoint directory\")ap.add_argument(\"-m\", \"--model\", type=str, help=\"path to *specific* model checkpoint to load\")ap.add_argument(\"-s\", \"--start-epoch\", type=int, default=0, help=\"epoch to restart training at\")args = vars(ap.parse_args())# set the logging level and output filelogging.basicConfig(level=logging.DEBUG, filename=\"training_&#123;&#125;.log\".format(args[\"start_epoch\"]), filemode=\"w\")if args[\"model\"] is None:# load the VGG16 network, ensuring the head FC layer sets are left off ... ## å®ç°ä¸Šä¸€æ­¥éª¤çš„é¢„è®­ç»ƒæ¨¡å‹å®šä¹‰å’Œæ¨¡å‹é¢„çƒ­ else: print(\"[INFO] loading &#123;&#125;...\".format(args[\"model\"])) model = load_model(args[\"model\"]) # update the learning rate print(\"[INFO] old learning rate: &#123;&#125;\".format(K.get_value(model.optimizer.lr))) K.set_value(model.optimizer.lr, 1e-3) print(\"[INFO] new learning rate: &#123;&#125;\".format(K.get_value(model.optimizer.lr))) # construct the set of callbackscallbacks = [ EpochCheckpoint(args[\"checkpoints\"], every=5, startAt=args[\"start_epoch\"]), TrainingMonitor(config.FIG_PATH, jsonPath=config.JSON_PATH, startAt=args[\"start_epoch\"])]# train the networkprint(\"[INFO] training network...\")model.fit_generator( trainGen.generator(), steps_per_epoch=trainGen.numImages // config.BATCH_SIZE, validation_data=valGen.generator(), validation_steps=valGen.numImages // config.BATCH_SIZE, epochs=100, max_queue_size=config.BATCH_SIZE * 2, callbacks=callbacks, verbose=1) å‚è€ƒ deep learning for computer vision with python","categories":[{"name":"åŠ¨æ‰‹å®è·µè¥","slug":"åŠ¨æ‰‹å®è·µè¥","permalink":"http://blog.a-stack.com/categories/åŠ¨æ‰‹å®è·µè¥/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://blog.a-stack.com/tags/AI/"},{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"ç®—æ³•","slug":"ç®—æ³•","permalink":"http://blog.a-stack.com/tags/ç®—æ³•/"},{"name":"æœºå™¨è§†è§‰","slug":"æœºå™¨è§†è§‰","permalink":"http://blog.a-stack.com/tags/æœºå™¨è§†è§‰/"},{"name":"å¼€æ”¾æ•°æ®é›†","slug":"å¼€æ”¾æ•°æ®é›†","permalink":"http://blog.a-stack.com/tags/å¼€æ”¾æ•°æ®é›†/"},{"name":"å›¾åƒåˆ†ç±»","slug":"å›¾åƒåˆ†ç±»","permalink":"http://blog.a-stack.com/tags/å›¾åƒåˆ†ç±»/"}]},{"title":"åŸºäºæœºå™¨è§†è§‰æŠ€æœ¯çš„å“ç‰ŒLOGOæ£€æµ‹","slug":"Deep-Learning-Lab-Logo-Detection","date":"2018-04-09T04:45:13.000Z","updated":"2018-05-15T14:45:46.067Z","comments":false,"path":"2018/04/09/Deep-Learning-Lab-Logo-Detection/","link":"","permalink":"http://blog.a-stack.com/2018/04/09/Deep-Learning-Lab-Logo-Detection/","excerpt":"","text":"åˆ©ç”¨Flickr LOGOæ•°æ®é›†è®­ç»ƒä¸€ä¸ªæ£€æµ‹å“ç‰ŒLOGOçš„ç½‘ç»œï¼Œå¯¹æœºå™¨è§†è§‰çš„ç‰©ä½“è¯†åˆ«æŠ€æœ¯è¿›è¡ŒéªŒè¯ã€‚ @[toc] æ¦‚è¿°æœ€è¿‘åœ¨åšä¸€ä¸ªåˆ©ç”¨æœºå™¨è§†è§‰æŠ€æœ¯è¿›è¡Œè¶…å¸‚ç‰©å“æ£€ç‚¹çš„é¡¹ç›®è°ƒç ”åˆ†æï¼Œéœ€è¦å…ˆå¯»æ‰¾ä¸€ä¸ªå¯è¡Œçš„æŠ€æœ¯æ–¹æ¡ˆéªŒè¯å¯è¡Œæ€§ï¼ŒFlickræä¾›çš„LOGOæ•°æ®é›†æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„å“ç‰ŒLOGOè¯†åˆ«ä¾‹å­ï¼Œæœ¬æ–‡è®°å½•åˆ©ç”¨Flickr LOGOæ•°æ®é›†è®­ç»ƒä¸€ä¸ªç‰©ä½“è¯†åˆ«çš„æ·±åº¦ç¥ç»ç½‘ç»œè¿‡ç¨‹ã€‚ æ•°æ®é›†Flickr LOGOæ•°æ®é›†æä¾›äº†ä¸‰ç§ä¸åŒç±»å‹çš„LOGOæ•°æ®é›†é›†åˆï¼Œåˆ†åˆ«ä¸ºFlickr Logos 27 datasetï¼ŒDatasets: FlickrLogos-32ä»¥åŠDatasets: FlickrLogos-47ã€‚æˆ‘ä»¬å…ˆæ¥çœ‹ä¸€ä¸‹æ¯ç§æ•°æ®é›†çš„ç»„æˆåŠæ•°æ®ç»“æ„ï¼š Flickr Logos 27 dataset è®­ç»ƒé›†åŒ…å«27ä¸ªåˆ†ç±»çš„810å¼ æ ‡è®°ç…§ç‰‡ï¼Œæ¯ä¸ªåˆ†ç±»30å¼ ç…§ç‰‡ åˆ†æ•£é›†åŒ…å«4207å¼ logoå›¾ç‰‡ æµ‹è¯•é›†æœ‰270å¼ ç…§ç‰‡ï¼Œæ¯ä¸ªåˆ†ç±»5å¼ ç…§ç‰‡ï¼Œå¦å¤–æœ‰135å¼ åˆ†ç±»å¤–ç…§ç‰‡é›† 27ä¸ªåˆ†ç±»åŒ…æ‹¬ï¼šAdidas, Apple, BMW, Citroen, Coca Cola, DHL, Fedex, Ferrari, Ford, Google, Heineken, HP, McDonalds, Mini, Nbc, Nike, Pepsi, Porsche, Puma, Red Bull, Sprite, Starbucks, Intel, Texaco, Unisef, Vodafone and Yahoo. ä¸‹è½½åœ°å€ï¼šä¸‹è½½ æ•°æ®æ ¼å¼ï¼šä¸‹è½½æ–‡ä»¶å¤¹ä¸­æä¾›ä¸€ä¸ªtxtæ–‡ä»¶ç”¨äºæè¿°æ¯ä¸ªæ–‡ä»¶ä¸­LOGOçš„åˆ†ç±»å’Œä½ç½®ä¿¡æ¯ 12345678910# FileName ClassName subset Coordinatesï¼ˆx1 y1 x2 y2ï¼‰4763210295.jpg Adidas 1 91 288 125 306 4763210295.jpg Adidas 1 182 63 229 94 4763210295.jpg Adidas 1 192 291 225 306 4763210295.jpg Adidas 1 285 61 317 79 4763210295.jpg Adidas 1 285 298 324 329 4763210295.jpg Adidas 1 377 292 421 324 4763210295.jpg Adidas 1 383 55 416 76 1230939811.jpg Adidas 2 129 326 257 423 1230939811.jpg Adidas 2 137 336 243 395 Flickr Logos 32/47 dataset FlickrLogos-32 was designed for logo retrieval and multi-class logo detection and object recognition. However, the annotations for object detection were often incomplete,since only the most prominent logo instances were labelled. FlickrLogos-47 uses the same image corpus as FlickrLogos-32 but has been re-annotated specifically for the task of object detection and recognition. 2.1 Flickr Logos-32 32ä¸ªåˆ†ç±»åŒ…æ‹¬ï¼š Adidas, Aldi, Apple, Becks, BMW,Carlsberg, Chimay, Coca-Cola, Corona, DHL, Erdinger, Esso,Fedex, Ferrari, Ford, Fosterâ€™s, Google, Guiness, Heineken, HP,Milka, Nvidia, Paulaner, Pepsi, Ritter Sport, Shell, Singha,Starbucks, Stella Artois, Texaco, Tsingtao and UPS æ•°æ®é›†è¢«åˆ’åˆ†ä¸ºP1,P2,P3ä¸‰ä¸ªå­é›†ï¼š Partition Description Images #Images P1 (training set) Hand-picked images 10 per class 320 images P2 (validation set) Images showing at least a single logo under various views 30 per class + 3000 non-logo images 3960 images P3 (test set = query set) Images showing at least a single logo under various views 30 per class + 3000 non-logo images 3960 images / / / 8240 images 2.2 FlickrLogos-47 47ä¸ªåˆ†ç±»åŒ…æ‹¬ï¼šAdidas (Symbol), Adidas (Text), Aldi,Apple, Becks (Symbol), Becks (Text), BMW, Carlsberg (Symbol),Carlsberg (Text), Chimay (Symbol), Chimay (Text), Coca-Cola,Corona (Symbol), Corona (Text), DHL, Erdinger (Symbol),Erdinger (Text), Esso (Symbol), Esso (Text), Fedex, Ferrari, Ford,Fosterâ€™s (Symbol), Fosterâ€™s (Text), Google, Guiness (Symbol),Guiness (Text), Heineken, HP, Milka (Symbol), Milka (Text), Nvidia (Symbol), Nvidia (Text), Paulaner (Symbol), Paulaner (Text), Pepsi (Symbol), Pepsi (Text), Ritter Sport, Shell, Singha (Symbol),Singha (Text), Starbucks, Stella Artois (Symbol), Stella Artois (Text), Texaco, Tsingtao (Symbol) Tsingtao (Text) and UPS. å°ç»“ Flickr Logoæ•°æ®é›†è™½ç„¶ç±»åˆ«æ•°ç›®ä¼—å¤šï¼Œä½†å…·ä½“åˆ°æ¯ä¸ªåˆ†ç±»æä¾›çš„æ ·æœ¬æ•°ç›®æœ‰é™ï¼Œåœ¨æ•°æ®é¢„å¤„ç†ç¯èŠ‚éœ€è¦é…åˆæ•°æ®å¢å¼ºæ‰‹æ®µæ¥æ‰©å……æ•°æ®é›†çš„æ•°ç›®ï¼› å¦å¤–ä¹Ÿå¯ä»¥ä»¿ç…§è½¦ç‰Œè¯†åˆ«çš„æ–¹æ³•ï¼Œå°†æ‰£å–çš„LOGOå›¾åƒæ·»åŠ åˆ°ä¸åŒèƒŒæ™¯å™ªå£°çš„å›¾åƒä¸­ï¼Œç”Ÿæˆå¤šç§è®­ç»ƒæ•°æ®ï¼› ç”±äºLOGOå›¾åƒåŒ…å«å›¾åƒç‰¹å¾æœ‰é™ï¼ŒåŒæ—¶æä¾›å°æ ·æœ¬æ•°æ®ï¼Œé€šè¿‡è¿ç§»å­¦ä¹ çš„æ–¹æ¡ˆåˆ©ç”¨ImageNetè®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œè¿ç§»å­¦ä¹ æ˜¯ä¸€ç§å¾ˆå¥½çš„æ–¹å¼ï¼Œæœ¬æ–‡å°†å¯¹è¿™ç§æ–¹å¼è¿›è¡Œè®¨è®ºåŠå®ç°ï¼› ä¸‰ç§æ•°æ®é›†é¢å‘ä¸åŒçš„åŠŸèƒ½ä¹Ÿè®¾è®¡éœ€æ±‚ï¼Œä»å›¾åƒè´¨é‡ä¸Šæ¥çœ‹Flickr-47è´¨é‡ç›¸å¯¹è¾ƒå¥½ï¼ŒåŒæ—¶åœ¨32åˆ†ç±»å’Œ47åˆ†ç±»ä¸­æä¾›äº†å¯¹å›¾åƒè¯­ä¹‰åˆ†å‰²çš„æ ‡å®šæ•°æ®ï¼› åœ¨æ¦‚è§ˆè¿‡ä»»åŠ¡æ•°æ®é›†ä¹‹åï¼Œæˆ‘ä»¬å°†æŒ‰ç…§æ·±åº¦å­¦ä¹ ä¸šåŠ¡å¤„ç†æµç¨‹ï¼Œé€æ­¥è¿›è¡Œæ•°æ®çš„é¢„å¤„ç†ã€æ¨¡å‹å‡†å¤‡ã€è®­ç»ƒå’ŒéªŒè¯ç­‰å·¥ä½œã€‚ä¸ºç®€åŒ–é—®é¢˜å¤„ç†éš¾åº¦ï¼Œæˆ‘ä»¬ä½¿ç”¨Flickr Logo -27æ¥è¿›è¡Œæœ¬æ¬¡å®éªŒã€‚ æ•°æ®å‡†å¤‡æ•°æ®å‡†å¤‡ç¯èŠ‚ä¸»è¦ä½¿ç”¨å¦‚ä¸‹åŸºæœ¬çš„å·¥å…·å’Œåº“æ–‡ä»¶ï¼š 1234567import numpy as npimport pandas as pdimport osimport matplotlib.pyplot as pltimport matplotlib.patches as patchesimport cv2import imutils å…¶ä¸­ï¼Œ numpyç”¨æ¥åšåŸºæœ¬çš„çŸ©é˜µå¤„ç†ï¼› pandasç”¨äºè¯»å–å’Œåˆ†ææ•°æ®æè¿°æ–‡ä»¶ï¼› matplotlibç”¨äºè¾…åŠ©æ˜¾ç¤ºé¢„å¤„ç†ç»“æœï¼› cv2æ˜¯opencvçš„pythonå°è£…ï¼Œè¿›è¡Œå›¾åƒè¯»å–ã€å›¾åƒåˆ†æç­‰æ“ä½œï¼› imutilsæ˜¯ä¸€ä¸ªå¾ˆå¥½ç”¨çš„å›¾åƒå¤„ç†åº“ï¼Œå¯ä»¥æ»¡è¶³åŸºæœ¬çš„å›¾åƒå¤„ç†éœ€æ±‚ é¦–å…ˆæˆ‘ä»¬å…ˆæŸ¥çœ‹ä»flickr-27ä¸Šä¸‹è½½çš„æ–‡ä»¶flickr_logos_27_dataset_training_set_annotation.txtæ¥äº†è§£åŸºæœ¬çš„å›¾åƒæ•°æ®ä¿¡æ¯å’Œåˆ†ç±»ä¿¡æ¯ï¼š 1234df=pd.read_csv(\"./flickr_logos_27_dataset/flickr_logos_27_dataset_training_set_annotation.txt\",sep=\" \", header=None)df.drop(df.columns[-1],axis=1, inplace=True)df.columns=[\"Name\",\"labels\",\"subset\",\"x1\",\"y1\",\"x2\",\"y2\"]df.head() 1234567output:&gt;&gt;&gt;&gt; Name labels subset x1 y1 x2 y20 144503924.jpg Adidas 1 38 12 234 1421 2451569770.jpg Adidas 1 242 208 413 3312 390321909.jpg Adidas 1 13 5 89 603 4761260517.jpg Adidas 1 43 122 358 3544 4763210295.jpg Adidas 1 83 63 130 93 åœ¨æè¿°æ–‡ä»¶ä¸­æ€»å…±æä¾›äº†4536æ¡è®°å½•ï¼Œè€Œå®é™…æä¾›çš„å›¾åƒæ–‡ä»¶åªæœ‰1000å¤šå¼ ï¼Œè¿™è¯´æ˜å¾ˆå¤šæ–‡ä»¶åŒ…æ‹¬ä¸æ­¢ä¸€ä¸ªLOGOã€‚ 12len(df)&gt;&gt;&gt;: 4536 æˆ‘ä»¬å¯ä»¥åˆ©ç”¨pandaså¯¹æ–‡ä»¶è¿›è¡Œä¸€ä¸ªç®€å•çš„shuffleå¤„ç†ï¼Œä¾¿äºå¿«é€Ÿåˆ‡åˆ†æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼š 12# shuffle the datasetsdf = df.sample(frac=1).reset_index(drop=True) ä¸ºäº†å¿«é€ŸæŸ¥çœ‹æè¿°æ–‡ä»¶æä¾›çš„æ ‡è®°ä¿¡æ¯åœ¨å›¾åƒä¸­çš„æ˜¾ç¤ºæ•ˆæœï¼Œæˆ‘ä»¬å†™ä¸€ä¸ªå‡½æ•°æ¥æŸ¥çœ‹ä¸€ä¸‹LOGOæ ‡è®°ä¿¡æ¯çš„æ•ˆæœï¼š 123456789101112def show_image(id): fig = plt.figure() image = os.path.join(\"./flickr_logos_27_dataset/flickr_logos_27_dataset_images/\",df.loc[id][\"Name\"]) image = cv2.imread(image) plt.figure(8) plt.imshow(image) currentAxis=plt.gca() rect=patches.Rectangle((df[\"x1\"].iloc[id], df[\"y1\"].iloc[id]), df[\"x2\"].iloc[id]-df[\"x1\"].iloc[id], df[\"y2\"].iloc[id]-df[\"y1\"].iloc[id], linewidth=2,edgecolor='r',facecolor='none') currentAxis.add_patch(rect) å…¶ä¸­ç”¨åˆ°äº†plt.gca()å’Œmatplotlibçš„patcheså‡½æ•°ç”¨äºå›¾åƒçš„å åŠ æ˜¾ç¤ºï¼Œå½“ç„¶ä¹Ÿå¯ä»¥ç›´æ¥è°ƒç”¨cv2.rectangleå‡½æ•° éšæœºæŸ¥çœ‹ä¸€ä¸ªæ ‡è®°åœ¨å›¾åƒä¸­çš„æ˜¾ç¤ºæ•ˆæœ 123import randomid = random.randint(0,len(df))show_image(id) ä¸‹é¢éœ€è¦å†™ä¸€ä¸ªæŠ å›¾ç¨‹åºï¼ŒæŠŠæ‰€æœ‰LOGOä»åŸå§‹å›¾åƒä¸­æ‰£å–å‡ºæ¥ï¼Œå½¢æˆè®­ç»ƒç”¨æ•°æ®é›†ï¼Œåœ¨ä¿å­˜å›¾åƒä¹‹å‰è¿›è¡Œå›¾åƒç®€å•çš„é¢„å¤„ç†å’Œè°ƒæ•´å½¢çŠ¶ï¼š 12345678910111213141516171819def crop_img(id): image = os.path.join(\"./flickr_logos_27_dataset/flickr_logos_27_dataset_images/\",df.loc[id][\"Name\"]) image = cv2.imread(image) crop_image = image[df[\"y1\"].iloc[id]:df[\"y2\"].iloc[id],df[\"x1\"].iloc[id]:df[\"x2\"].iloc[id]] return crop_image WIDTH = 64HEIGHT = 64for id, name in enumerate(df[\"Name\"]): cropped_image = crop_img(id) try: resized_image = cv2.resize(cropped_image, (WIDTH,HEIGHT),interpolation=cv2.INTER_CUBIC) except: print(id) continue image_name = str(id)+\"_\"+df.iloc[id][\"labels\"]+\".jpg\" cv2.imwrite(os.path.join(\"./flickr_logos_27_dataset/cropped/\",image_name),resized_image) åœ¨å›¾åƒæ‰£å–è¿‡ç¨‹ä¸­ï¼Œæœ‰å‡ ç‚¹éœ€è¦æ³¨æ„ï¼š ç”±äºæè¿°é—®é¢˜æä¾›çš„ä¿¡æ¯æœ¬èº«çš„é—®é¢˜ï¼Œæœ‰ä¸€äº›å¼‚å¸¸æ•°æ®éœ€è¦å‰”é™¤ï¼Œæ¯”å¦‚æœ‰5æ¡è®°å½•æä¾›çš„x1=x2,æˆ–y1=y2ï¼Œå³åœ¨åŸå§‹å›¾åƒä¸Šæ²¡æœ‰è¿›è¡Œæ ‡è®°ï¼› å›¾åƒç¼©æ”¾å…¶å®ä¸åº”è¯¥é‡‡ç”¨è¿™ç§å‚»ç“œçš„å‹ç¼©æ–¹å¼ï¼Œåº”è¯¥å°½é‡æ§åˆ¶é•¿å®½æ¯”ï¼Œä¿è¯ä¸äº§ç”Ÿæ˜æ˜¾çš„å½¢å˜ï¼› å¤„ç†å®Œæˆä¹‹åï¼Œæ‰£å–å›¾åƒå°†åœ¨croppedæ–‡ä»¶å¤¹ä¸­ä»¥{id}_{label}.jpgçš„æ–‡ä»¶åå­˜å‚¨ã€‚ å›¾åƒæ‰£å–ä¹‹åï¼Œé€šè¿‡äººå·¥æ ¸å¯¹ï¼Œæˆ‘ä»¬å‘ç°ä»ç„¶å­˜åœ¨ä¸€äº›æ˜æ˜¾æœ‰é—®é¢˜çš„å›¾åƒï¼Œæ¯”å¦‚å¤šå¼ pumaçš„å›¾åƒï¼Œå…¶å®å­˜åœ¨æ˜æ˜¾çš„æ ‡è®°é—®é¢˜ï¼Œéœ€è¦ä»æ•°æ®é›†ä¸­å‰”é™¤ï¼š æ•°æ®é›†åˆ‡åˆ†æˆ‘ä»¬å°†æ‰£å–æ•°æ®è¯»å…¥è¿›è¡Œç®€å•é¢„å¤„ç†å’Œæ•°æ®åˆ‡åˆ†ï¼š 12345678910data = []labels = []for img in os.listdir(\"./flickr_logos_27_dataset/cropped/\"): img_file = cv2.imread(os.path.join(\"./flickr_logos_27_dataset/cropped/\",img)) data.append(img_file) labels.append(img.split(\"_\")[1].split(\".\")[0])data = np.stack(data)labels = np.stack(labels)data = data/255 å°†æ ‡ç­¾æ•°æ®è½¬å˜æˆOneHotçŸ©é˜µï¼š 123from sklearn.preprocessing import LabelBinarizerle = LabelBinarizer()labels = le.fit_transform(labels) åˆ‡åˆ†æ•°æ®é›† 1X,testX,y,testy = train_test_split(data, labels,test_size=0.1,stratify=labels,random_state=42 ) æ•°æ®å¢å¼ºæ•°æ®å¢å¼ºæ˜¯å›¾åƒå¤„ç†ä¸­ç»å¸¸é‡‡ç”¨çš„ä¸€ç§æ•°æ®å¤„ç†æ–¹å¼ï¼Œç”±äºæ¶‰åŠå†…å®¹è¾ƒå¤šï¼Œåœ¨æœ¬ç¯‡å®æˆ˜ä¸­ä¸å•ç‹¬å±•å¼€ï¼Œä»…æŠŠåˆ©ç”¨Kerasæ•°æ®å¢å¼ºå·¥å…·ImageDataGeneratorçš„æ–¹æ³•æä¾›ä¸€ä¸‹ï¼š 12345678from keras.preprocessing.image import ImageDataGenerator # construct the training image generator for data augmentationaug = ImageDataGenerator(rotation_range=18, zoom_range=0.15, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15, horizontal_flip=True, fill_mode=\"nearest\")gen_flow=aug.flow(X, y,batch_size=64,seed=0)validation=aug.flow(testX,testy,batch_size=32,seed=0) æ¨¡å‹å®šä¹‰æ ¹æ®å‰æ–‡å¯¹æ•°æ®çš„åˆ†æï¼Œæˆ‘ä»¬åˆ†åˆ«é‡‡å–ä¸¤ç§æ–¹å¼è®¾è®¡ç½‘ç»œæ¨¡å‹ï¼šä»å¤´è®­ç»ƒä¸€ä¸ªæ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œå’Œåˆ©ç”¨è¿ç§»å­¦ä¹ Fine-Tuneä¸€ä¸ªæ»¡è¶³éœ€æ±‚çš„ç½‘ç»œæ¨¡å‹ã€‚ ä»å¤´è®­ç»ƒä¸€ä¸ªç½‘ç»œæ¨¡å‹ç”±äºé—®é¢˜æœ¬è´¨æ˜¯ä¸€ä¸ªç‰©ä½“è¯†åˆ«ä»»åŠ¡ï¼Œæ‰€ä»¥åœ¨å®ç°ä¸Šåº”è¯¥åŒ…æ‹¬å›¾åƒåˆ†ç±»å’Œå®šä½çš„å›å½’ä¸¤ä¸ªå­ä»»åŠ¡ï¼Œæˆ‘ä»¬å¯ä»¥ç®€åŒ–é—®é¢˜é€šè¿‡ä¸€ä¸ªæ»‘åŠ¨çª—å£æ¥å¯¹è¾“å…¥å›¾åƒè¿›è¡Œæ‰«æï¼Œç„¶åé’ˆå¯¹æ¯ä¸ªæ‰«æçª—å£è¿›è¡Œå›¾åƒåˆ†ç±»ã€‚ å½“ç„¶å®é™…è¿‡ç¨‹ä¸­ï¼Œé—®é¢˜è¦è¿œæ¯”è¿™å¤æ‚ï¼Œå¾ˆéš¾é€‰æ‹©åˆé€‚çš„æ»‘åŠ¨çª—å£å¤§å°é€‚ç”¨ç°å®å›¾åƒçš„éœ€æ±‚ï¼Œæ‰€ä»¥åœ¨ä¸»æµçš„ç‰©ä½“è¯†åˆ«æ¨¡å‹ä¸­ä¸€èˆ¬éƒ½é‡‡ç”¨å¤šç§ä¸åŒå¤§å°çš„Anchor boxæ¥å›å½’å›¾åƒçš„ä½ç½®ã€‚ ç”±äºLOGOæ¯å¼ å›¾åƒåŒ…å«ç‰¹å¾æœ‰é™ï¼Œæˆ‘ä»¬åœ¨æœ¬æ¬¡å®éªŒä¸­åˆ©ç”¨LeNetçš„æ¶æ„ï¼Œè®¾è®¡äº†ä¸€ä¸ªç®€å•çš„å·ç§¯ç½‘ç»œæ¨¡å‹å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š æ¨¡å‹ä¸»ä½“åˆ©ç”¨ä¸‰ä¸ªCONV =&gt; RELU =&gt; POOLç»“æ„æ¥æŠ½å–å›¾åƒç‰¹å¾ï¼Œæœ€ååˆ©ç”¨å…¨è”é€šç½‘ç»œ+Softmaxåˆ†ç±»å™¨æ¥è·å¾—æœ€ç»ˆ27ç±»åˆ†ç±»ç»“æœã€‚ 12345678910111213141516171819202122232425262728293031323334from keras.models import Sequentialfrom keras.layers.convolutional import Conv2Dfrom keras.layers.convolutional import MaxPooling2Dfrom keras.layers.core import Activationfrom keras.layers.core import Flattenfrom keras.layers.core import Densefrom keras import backend as Kmodel = Sequential()inputShape = (HEIGHT, WIDTH, 3) # first set of CONV =&gt; RELU =&gt; POOL layersmodel.add(Conv2D(16, (3, 3), padding=\"same\",input_shape=inputShape))model.add(Activation(\"relu\"))model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))# second set of CONV =&gt; RELU =&gt; POOL layersmodel.add(Conv2D(32, (3, 3), padding=\"same\"))model.add(Activation(\"relu\"))model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))# third set of CONV =&gt; RELU =&gt; POOL layersmodel.add(Conv2D(64, (3, 3), padding=\"same\"))model.add(Activation(\"relu\"))model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))# first (and only) set of FC =&gt; RELU layersmodel.add(Flatten())model.add(Dense(500))model.add(Activation(\"relu\"))model.add(Dropout(0.25))# softmax classifiermodel.add(Dense(len(CLASSNAME)))model.add(Activation(\"softmax\")) å®šä¹‰ç›®æ ‡ä¼˜åŒ–å‡½æ•°ï¼š 123from keras.optimizers import Adam,SGD,RMSpropopt = RMSprop(lr=0.001, rho=0.9)model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"]) è¿­ä»£è®­ç»ƒ100ä¸ªepoch: 1234567history=model.fit_generator( gen_flow, steps_per_epoch=len(X) // 32, validation_data=aug.flow(testX,testy,batch_size=32,seed=0), validation_steps=len(testX) // 32, epochs=100, verbose=1) 100è½®ä¹‹åï¼ŒéªŒè¯é›†è¾¾åˆ°äº†99.89%çš„å‡†ç¡®ç‡ï¼ŒåŸºæœ¬æ»¡è¶³äº†è¦æ±‚ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­è®­ç»ƒæ•°æ®å’ŒéªŒè¯æ•°æ®çš„å‡†ç¡®ç‡åŠLosså˜åŒ–è¯¦è§ä¸‹å›¾ï¼š æµ‹è¯•1234567891011plt.figure(figsize = (15,40))for i,test_img in enumerate(os.listdir(\"./test\")): img = cv2.imread(os.path.join(\"./test\",test_img)) img = cv2.resize(img, (WIDTH,HEIGHT),interpolation=cv2.INTER_CUBIC) img = np.expand_dims(img,axis=0) result = model.predict(img) result = le.inverse_transform(result) plt.subplot(8,4, i+1) img = cv2.cvtColor(img[0], cv2.COLOR_BGR2RGB) plt.imshow(img) plt.title('pred:' + str(result[0])) è®¾è®¡æ»‘åŠ¨çª—å£å’Œç‰¹å¾é‡‘å­—å¡”å…¶ä¸­æ»‘åŠ¨çª—å£ç”¨æ¥éå†å›¾åƒï¼Œç‰¹å¾é‡‘å­—å¡”ç”¨äºå®ç°å›¾åƒçš„å¤šå°ºåº¦å˜æ¢ï¼Œä¿è¯å¤šç§ä¸åŒå¤§å°çš„LOGOéƒ½å¯ä»¥è¢«å‡†ç¡®è¯†åˆ«ã€‚ 123456789101112131415161718192021222324def sliding_window(image, step, ws): # slide a window across the image for y in range(0, image.shape[0] - ws[1], step): for x in range(0, image.shape[1] - ws[0], step): # yield the current window yield (x, y, image[y:y + ws[1], x:x + ws[0]])def image_pyramid(image, scale=1.5, minSize=(64, 64)): # yield the original image yield image # keep looping over the image pyramid while True: # compute the dimensions of the next image in the pyramid w = int(image.shape[1] / scale) image = imutils.resize(image, width=w) # if the resized image does not meet the supplied minimum # size, then stop constructing the pyramid if image.shape[0] &lt; minSize[1] or image.shape[1] &lt; minSize[0]: break # yield the next image in the pyramid yield image ç‰¹å¾é‡‘å­—å¡”ï¼š ä¸ºäº†æ£€æµ‹ä¸åŒå°ºåº¦çš„ç›®æ ‡ï¼Œä¾æ¬¡å°†åŸå›¾æŒ‰æ¯”ä¾‹ç¼©æ”¾å¹¶é€å…¥ç½‘ç»œã€‚ç¼ºç‚¹æ˜¯éœ€è¦å¤šæ¬¡resizeå›¾åƒï¼Œç¹çè€—æ—¶ã€‚ æˆ‘ä»¬å®šä¹‰äº†è¾“å…¥å›¾åƒçš„å°ºå¯¸ä¸º(150,150)ï¼Œæ»‘åŠ¨çª—å£å¤§å°ä¸æˆ‘ä»¬å‰é¢è®­ç»ƒçš„åˆ†ç±»ç½‘ç»œçš„è¾“å…¥ä¸€è‡´ä¸º(64,64),ç‰¹å¾é‡‘å­—å¡”çš„ç¼©å°æ¯”ä¾‹ä¸º1.5å€ï¼Œè¿™æ ·å°†åœ¨åŸå§‹å›¾åƒåŸºç¡€ä¸Šè¿›è¡Œä¸¤æ¬¡ç¼©æ”¾ï¼›å¦å¤–å®šä¹‰äº†æ»‘åŠ¨çª—å£çš„æ­¥é•¿ä¸º16ã€‚ 12345678# initialize variables used for the object detection procedureINPUT_SIZE = (150, 150)PYR_SCALE = 1.5WIN_STEP = 16ROI_SIZE = (64, 64)labels = &#123;&#125;CLASS_NAMES = list(lb.classes_) ä¸ºç®€åŒ–åç»­åˆ†æï¼Œå®šä¹‰ä¸€ä¸ªé¢„æµ‹å‡½æ•°ï¼Œç”¨äºè¿”å›å›¾åƒä¸­é¢„æµ‹å‡†ç¡®ç‡è¶…è¿‡minProbçª—å£åŠå¯¹è±¡åˆ†ç±»ï¼š 123456789101112131415def logo_prediction(model, batchROIs, batchLocs, labels, minProb=0.5,dims=(64, 64)): preds = model.predict(batchROIs) for i in range(0,len(preds)): prob = np.max(preds[i]) if prob &gt; 0.5: index = np.argmax(preds[i]) label = CLASS_NAMES[int(index)] # grab the coordinates of the sliding window for # the prediction and construct the bounding box (pX, pY) = batchLocs[i] box = (pX, pY, pX + dims[0], pY + dims[1]) L = labels.get(label, []) L.append((box,prob)) labels[label] = L return labels æˆ‘ä»¬å°†éå†æ¯ä¸ªç‰¹å¾é‡‘å­—å¡”å’Œæ¯ä¸ªæ»‘åŠ¨çª—å£ï¼Œå¯¹è¯†åˆ«ç»“æœè¿›è¡Œé¢„æµ‹ï¼š 1234567891011121314151617181920212223242526272829303132333435img_file = \"./test/2.jpg\"orig = cv2.imread(img_file)# resize the input image to be a squareresized = cv2.resize(orig, INPUT_SIZE, interpolation=cv2.INTER_CUBIC)# initialize the batch ROIs and (x, y)-coordinatesbatchROIs = NonebatchLocs = []# loop over the image pyramidfor image in image_pyramid(resized, scale=PYR_SCALE,minSize=ROI_SIZE): # loop over the sliding window locations for (x, y, roi) in sliding_window(resized, WIN_STEP, ROI_SIZE): # take the ROI and pre-process it so we can later classify the # region with Keras #roi = img_to_array(roi) roi = roi/255 roi = np.expand_dims(roi, axis=0) # roi = imagenet_utils.preprocess_input(roi) # if the batch is None, initialize it if batchROIs is None: batchROIs = roi # otherwise, add the ROI to the bottom of the batch else: batchROIs = np.vstack([batchROIs, roi]) # add the (x, y)-coordinates of the sliding window to the batch batchLocs.append((x, y)) # classify the batch, then reset the batch ROIs and # (x, y)-coordinates model.predict(batchROIs) labels = logo_prediction(model, batchROIs, batchLocs,labels, minProb=0.9) å½“è¿›è¡Œåˆ°è¿™æ­¥éª¤æ‰çªç„¶å‘ç°è®­ç»ƒåˆ†ç±»ä¸­ç¼ºäº†ä¸€ä¸ªå¾ˆé‡è¦çš„èƒŒæ™¯åˆ†ç±»ï¼Œå°†å¯¼è‡´åœ¨èƒŒæ™¯ä¸Šå¾ˆå¤šä¿¡æ¯çš„é¢„æµ‹ä¼šå‡ºé—®é¢˜ï¼Œåç»­ç­‰æ•´äº›èƒŒæ™¯å›¾ç‰‡å†é‡æ–°è®­ç»ƒç½‘ç»œï¼ŒğŸ˜­ æœ€åä¸€æ­¥æ˜¯é¢„æµ‹ç»“æœçš„æå¤§å€¼æŠ‘åˆ¶å’Œæ˜¾ç¤ºï¼š 1234567891011121314151617181920212223242526from imutils.object_detection import non_max_suppression# loop over the labels for each of detected objects in the imagefor k in labels.keys(): # clone the input image so we can draw on it clone = resized.copy() # loop over all bounding boxes for the label and draw them on the image for (box, prob) in labels[k]: (xA, yA, xB, yB) = box cv2.rectangle(clone, (xA, yA), (xB, yB), (0, 255, 0), 2) # grab the bounding boxes and associated probabilities for each # detection, then apply non-maxima suppression to suppress # weaker, overlapping detections boxes = np.array([p[0] for p in labels[k]]) proba = np.array([p[1] for p in labels[k]]) boxes = non_max_suppression(boxes, proba) # loop over the bounding boxes again, this time only drawing the # ones that were *not* suppressed for (xA, yA, xB, yB) in boxes: cv2.rectangle(clone, (xA, yA), (xB, yB), (0, 0, 255), 2) # show the output image print(\"[INFO] &#123;&#125;: &#123;&#125;\".format(k, len(boxes))) plt.imshow(clone) æå¤§å€¼æŠ‘åˆ¶æ˜¯ç‰©ä½“è¯†åˆ«ä¸­å¾ˆé‡è¦çš„ä¸€ä¸ªç¯èŠ‚ï¼Œç›¸å…³æ¦‚å¿µä»¥ååœ¨æ…¢æ…¢æ•´ç† åˆ©ç”¨è¿ç§»å­¦ä¹ ä¼˜åŒ–ä¸€ä¸ªç‰©ä½“è¯†åˆ«ç½‘ç»œæ¨¡å‹ä¸Šè¿°æ–¹æ³•è™½ç„¶ç®€å•å®¹æ˜“ç†è§£ï¼Œä½†å­˜åœ¨å¾ˆå¤§çš„è®¡ç®—æ•ˆç‡é—®é¢˜ï¼Œæ¯å¼ å›¾ç‰‡éœ€è¦è¿›è¡Œå¤šæ¬¡ç‰¹å¾æå–å’Œå¤šæ¬¡è¿ç®—ï¼Œå¯¹è®¡ç®—æ•ˆç‡é€ æˆå¾ˆå¤§å½±å“ã€‚ç›®å‰ä¸»æµçš„ç‰©ä½“è¯†åˆ«ç®—æ³•å¾€å¾€éƒ½å¯ä»¥åº”ç”¨äºå®æ—¶è§†é¢‘æµçš„åˆ†æï¼Œæ˜¾ç„¶ä½¿ç”¨ä¸Šè¿°æ–¹æ³•æ˜¯ä¸åˆé€‚çš„ã€‚æˆ‘ä»¬å°†åœ¨åé¢æ¢è®¨åˆ©ç”¨ç°æœ‰çš„ç‰©ä½“è¯†åˆ«ç½‘ç»œé€šè¿‡è¿ç§»å­¦ä¹ è§£å†³æˆ‘ä»¬çš„ç›®æ ‡è¯†åˆ«é—®é¢˜ã€‚ ç”±äºæœ¬ç¯‡å†…å®¹å¤ªå¤šï¼Œåˆ©ç”¨è¿ç§»å­¦ä¹ å®ç°çš„æ–¹æ³•ï¼Œå°†å•ç‹¬ä½œä¸ºä¸€ç¯‡ï¼Œæ­¤å¤„ç•™å¾…æ’å…¥é“¾æ¥ã€‚ æœ¬æ–‡æ¶‰åŠä»£ç è¯¦è§Github è®­ç»ƒä¸€ä¸ªäºŒåˆ†ç±»ç½‘ç»œæ£€æŸ¥è´§æ¶ä¸Šæ˜¯å¦æœ‰ç™¾äº‹å¯ä¹ å‚è€ƒGithubå®ç°ä¸€ä¸ªç‰©å“æ£€æµ‹åŸå‹ï¼šè®­ç»ƒä¸€ä¸ªäºŒåˆ†ç±»åˆ†ç±»å™¨ åœ¨æ•°æ®å‡†å¤‡é˜¶æ®µä¸ä¸Šè¿°è¿‡ç¨‹å”¯ä¸€ä¸åŒæ˜¯labelçš„è®¾ç½®ï¼Œå¦‚ä¸‹ï¼š 123456789101112131415import os, cv2import numpy as npdata = []labels = []HEIGHT = 64WIDTH = 64for img in os.listdir(\"./flickr_logos_27_dataset/cropped/\"): img_file = cv2.imread(os.path.join(\"./flickr_logos_27_dataset/cropped/\",img)) data.append(img_file) label = img.split(\"_\")[1].split(\".\")[0] if label != \"Pepsi\": label = \"Nop\" labels.append(label)data = np.stack(data)labels = np.stack(labels) ç”±äºæ˜¯äºŒåˆ†ç±»é—®é¢˜ï¼Œæ‰€ä»¥åªéœ€è¦æœ€åä¸€å±‚ä½¿ç”¨sigmoidå‡½æ•°æ„å»ºåˆ†ç±»å™¨å³å¯ï¼Œlabelçš„åºåˆ—è¯æ–¹é¢ä½¿ç”¨LabelEncoderè½¬æ¢ä¸º0æˆ–è€…1å³å¯ï¼š 1234from sklearn.model_selection import train_test_splitfrom sklearn.preprocessing import LabelEncoderlb = LabelEncoder()y = lb.fit_transform(labels) æ•°æ®å¢å¼ºä¸å‰æ–‡ç±»ä¼¼ï¼Œä¸å†èµ˜è¨€ã€‚åœ¨ç½‘ç»œç»“æ„ä¸Šï¼Œåªéœ€è¦ä¿®æ”¹æœ€åä¸ºsigmoidå‡½æ•°è¾“å‡ºï¼Œä¼˜åŒ–ç›®æ ‡ä½¿ç”¨binary_crossentropyï¼š 12345...model.add(Activation(\"sigmoid\"))...model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"]) ç”±äºåªæœ‰ä¸¤ä¸ªåˆ†ç±»ï¼Œæ‰€ä»¥æ¨¡å‹å¾ˆå®¹æ˜“æ”¶æ•›ï¼Œæœ€åå‡†ç¡®ç‡ä¹Ÿæ¥è¿‘100%ã€‚ æœ€ååˆ©ç”¨ä¸€ä¸ªæ»‘åŠ¨çª—å£ä¸åœçš„æ‰«æå›¾åƒå¹¶åˆ©ç”¨cv2å±•ç¤ºç»“æœå³å¯ï¼š 12345678910111213141516171819202122for (x, y, window) in sliding_window(img, stepSize=32, windowSize=(winW, winH)): # if the window does not meet our desired window size, ignore it if window.shape[0] != winH or window.shape[1] != winW: continue crop_img=crop_image(sample_path,x, y, x + winW, y + winH) crop_img=imresize(crop_img,(64,64)) crop_img = crop_img/255 prediction=model.predict(crop_img.reshape(1,64,64,3)) if prediction == 1: pred = 'Pepsi' else: pred=' ' clone = img.copy() cv2.putText(clone, pred, (10, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2) cv2.rectangle(clone, (x, y), (x + winW, y + winH), (0, 255, 0), 2) clone = cv2.cvtColor(clone,cv2.COLOR_BGR2RGB) cv2.imshow(\"Window\", clone) cv2.waitKey(1) time.sleep(0.5) â€‹ Logoæ£€æµ‹çš„åº”ç”¨åŠåˆ†æDeepSense.aiç»™å‡ºäº†ä¸€ç§Logoæ£€æµ‹çš„åˆ†ææ–¹æ³•ï¼Œé€šè¿‡åˆ†æè§†é¢‘ä¸­ä¸åŒå“ç‰Œçš„logoå‘ˆç°ï¼Œç»Ÿè®¡äº†ä¸åŒå“ç‰Œåœ¨åŒä¸€ä¸ªè§†é¢‘ä¸­Logoå‡ºç°çš„æ—¶é—´ã€å‡ºç°çš„æ–¹å¼ã€å‘ˆç°çš„æ•ˆæœç­‰ï¼Œæœ€ç»ˆæä¾›ç»™å®¢æˆ·ä¸€ä¸ªLogo Visubility Reportã€‚ æ–¹æ¡ˆçš„ä¸»è¦æµç¨‹å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š ç”Ÿæˆçš„åˆ†ææŠ¥å‘Šå‚è§ä¸‹å›¾ï¼š é’ˆå¯¹çš„åˆ†æè§†é¢‘å¦‚ä¸‹ï¼š å‚è€ƒ Flickr Logos 27 dataset Datasets: FlickrLogos-32 / FlickrLogos-47 â€‹","categories":[{"name":"åŠ¨æ‰‹å®è·µè¥","slug":"åŠ¨æ‰‹å®è·µè¥","permalink":"http://blog.a-stack.com/categories/åŠ¨æ‰‹å®è·µè¥/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://blog.a-stack.com/tags/AI/"},{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"ç®—æ³•","slug":"ç®—æ³•","permalink":"http://blog.a-stack.com/tags/ç®—æ³•/"},{"name":"æœºå™¨è§†è§‰","slug":"æœºå™¨è§†è§‰","permalink":"http://blog.a-stack.com/tags/æœºå™¨è§†è§‰/"},{"name":"ç‰©ä½“è¯†åˆ«","slug":"ç‰©ä½“è¯†åˆ«","permalink":"http://blog.a-stack.com/tags/ç‰©ä½“è¯†åˆ«/"},{"name":"å¼€æ”¾æ•°æ®é›†","slug":"å¼€æ”¾æ•°æ®é›†","permalink":"http://blog.a-stack.com/tags/å¼€æ”¾æ•°æ®é›†/"}]},{"title":"æ·±åº¦å­¦ä¹ åŸºç¡€ä¹‹ä¼˜åŒ–ç®—æ³•","slug":"æ·±åº¦å­¦ä¹ åŸºç¡€ä¹‹ä¼˜åŒ–ç®—æ³•","date":"2018-04-01T07:35:01.000Z","updated":"2018-07-02T15:47:11.000Z","comments":true,"path":"2018/04/01/æ·±åº¦å­¦ä¹ åŸºç¡€ä¹‹ä¼˜åŒ–ç®—æ³•/","link":"","permalink":"http://blog.a-stack.com/2018/04/01/æ·±åº¦å­¦ä¹ åŸºç¡€ä¹‹ä¼˜åŒ–ç®—æ³•/","excerpt":"åˆé€‚ä¼˜åŒ–ç®—æ³•çš„é€‰æ‹©æœ‰åŠ©äºæå‡è®­ç»ƒæ•ˆç‡å’Œæ”¶æ•›çš„é€Ÿåº¦ï¼Œæœ¬æ–‡å¯¹å¸¸ç”¨çš„ä¼˜åŒ–ç®—æ³•è¿›è¡Œæ€»ç»“ã€‚åœ¨è¿™ç« ä¸­å°†å½’çº³SGDã€RMSpropã€Adamç­‰çš„åŸºç¡€åŸç†ã€‚ä¼˜åŒ–ç®—æ³•çš„ä¼˜åŠ£æ¥è‡ªäºå¯¹ç›¸å…³ç®—æ³•çš„ç†Ÿæ‚‰ç¨‹åº¦ã€‚","text":"åˆé€‚ä¼˜åŒ–ç®—æ³•çš„é€‰æ‹©æœ‰åŠ©äºæå‡è®­ç»ƒæ•ˆç‡å’Œæ”¶æ•›çš„é€Ÿåº¦ï¼Œæœ¬æ–‡å¯¹å¸¸ç”¨çš„ä¼˜åŒ–ç®—æ³•è¿›è¡Œæ€»ç»“ã€‚åœ¨è¿™ç« ä¸­å°†å½’çº³SGDã€RMSpropã€Adamç­‰çš„åŸºç¡€åŸç†ã€‚ä¼˜åŒ–ç®—æ³•çš„ä¼˜åŠ£æ¥è‡ªäºå¯¹ç›¸å…³ç®—æ³•çš„ç†Ÿæ‚‰ç¨‹åº¦ã€‚ æ·±åº¦å­¦ä¹ åŸºç¡€ç¯‡å°†ä»å‡ ä¸ªä¸åŒçš„å±‚é¢æ¥æ€»ç»“åœ¨è¿‡å»ä¸€æ®µæ—¶é—´å¯¹äºæ·±åº¦å­¦ä¹ å…³é”®æŠ€æœ¯çš„ç†è§£ï¼Œé€šè¿‡çŸ¥è¯†ä½“ç³»çš„å½’çº³äº†è§£çŸ¥è¯†ä½“ç³»çš„ä¸è¶³ï¼Œæå‡å¯¹æ ¸å¿ƒæŠ€æœ¯ç‚¹çš„è®¤è¯†ã€‚æ‰€æœ‰ç³»åˆ—æ–‡ç« å°†åœ¨æœªæ¥ä¸€æ®µæ—¶é—´å†…å®¹éšç€æŒæ¡äº†è§£çš„æ·±å…¥è¿­ä»£æ›´æ–°ã€‚ç›®å‰ä¸»è¦å¸Œæœ›å¯¹å¦‚ä¸‹å‡ ä¸ªé¢†åŸŸè¿›è¡Œå½’çº³æ±‡æ€»ï¼š é—®é¢˜å®šä¹‰ ç›®æ ‡åŠè¯„ä¼° æ•°æ®å‡†å¤‡ä¸é¢„å¤„ç† æ¿€æ´»å‡½æ•°çš„å½’çº³åŠæ€»ç»“ ä¼˜åŒ–ç®—æ³•çš„å½’çº³åŠæ€»ç»“ æ­£åˆ™åŒ–ä¸æ³›åŒ–æ€§èƒ½ æ¨¡å‹å‹ç¼© æ•°æ®æ‰©å…… å¼•è¨€æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒçš„ä¼˜åŒ–ç®—æ³•å¯ä»¥é€šè¿‡å¯»æ‰¾é™ä½ä»£ä»·å‡½æ•°$J(\\theta)$çš„ä¸€ç»„å‚æ•°$\\theta$æ¥å®ç°ä¼˜åŒ–ç›®æ ‡ã€‚å…¶ä¸­ä»£ä»·å‡½æ•°å¯ä»¥å®šä¹‰ä¸ºè®­ç»ƒé›†ä¸Šçš„è¯„ä»·æŸå¤±ï¼š J(\\theta)=E_{(x,y)\\sim \\hat{p}_{data}} L(f(\\boldsymbol{x}; \\boldsymbol{\\theta}), y)å…¶ä¸­ï¼Œ$\\hat p_{data}$ ä¸ºç»éªŒåˆ†å¸ƒï¼Œ$L$æ˜¯æ¯ä¸ªæ ·æœ¬çš„æŸå¤±å‡½æ•°ã€‚ç”±äºåˆ†å¸ƒåªæ˜¯çœŸå®æ•°æ®åˆ†å¸ƒçš„ä¸€éƒ¨åˆ†ï¼Œè¯¥å¼å«åšç»éªŒé£é™©æœ€å°åŒ–ã€‚æˆ‘ä»¬å¹¶ä¸ç›´æ¥æœ€ä¼˜åŒ–é£é™©ï¼Œè€Œæ˜¯æœ€ä¼˜åŒ–ç»éªŒé£é™©ï¼Œå¸Œæœ›ä¹Ÿèƒ½å¤Ÿå¾ˆå¤§åœ°é™ä½é£é™©ã€‚ä¸€æ–¹é¢ç”±äºç»éªŒé£é™©æœ€å°åŒ–å¾ˆå®¹æ˜“è¿‡æ‹Ÿåˆè®­ç»ƒæ•°æ®ï¼Œå¦ä¸€æ–¹é¢æ·±åº¦å­¦ä¹ ä¸­å¾ˆå¤šæŸå¤±å‡½æ•°æ²¡æœ‰æœ‰æ•ˆçš„å¯¼æ•°å½¢å¼ï¼Œæ‰€ä»¥ä¸€èˆ¬ä½¿ç”¨ä»£ç†æŸå¤±å‡½æ•°æ¥è¿‘ä¼¼ä¼˜åŒ–ç›®æ ‡ã€‚ å¥½çš„ä¼˜åŒ–ç®—æ³•åœ¨æ·±åº¦å­¦ä¹ ä¸­ä¸»è¦èµ·åˆ°å¦‚ä¸‹ä½œç”¨ï¼š æå‡æ”¶æ•›é€Ÿåº¦ï¼Œé™ä½è®­ç»ƒæ—¶é—´ï¼› ä½¿ç½‘ç»œæ¨¡å‹è¡¨ç°æ›´åŠ å…¨é¢ï¼Œè€Œä¸å•ä¾é å­¦ä¹ ç‡ï¼› è·å¾—æ›´å¥½çš„æ¨¡å‹æ€§èƒ½ã€‚ æ·±åº¦å­¦ä¹ ä¼˜åŒ–ç®—æ³•çš„æŒ‘æˆ˜ éå‡¸ä¼˜åŒ–ä¼—å¤šçš„å±€éƒ¨æå°å€¼ï¼› æ¢¯åº¦ä¸ºé›¶çš„ç‚¹â€”â€”éç‚¹ï¼›å¤šç±»éšæœºå‡½æ•°è¡¨ç°å‡ºä»¥ä¸‹æ€§è´¨ï¼šä½ç»´ç©ºé—´ä¸­ï¼Œå±€éƒ¨æå°å€¼å¾ˆæ™®éã€‚åœ¨æ›´é«˜ç»´ç©ºé—´ä¸­ï¼Œå±€éƒ¨æå°å€¼å¾ˆç½•è§ï¼Œè€Œéç‚¹åˆ™å¾ˆå¸¸è§ï¼› æ¢¯åº¦æ¶ˆå¤±ä¸æ¢¯åº¦çˆ†ç‚¸ï¼›ï¼ˆæ¢¯åº¦æˆªæ–­è§£å†³çˆ†ç‚¸é—®é¢˜ï¼‰ è®¸å¤šç°æœ‰ç ”ç©¶æ–¹æ³•åœ¨æ±‚è§£å…·æœ‰å›°éš¾å…¨å±€ç»“æ„çš„é—®é¢˜æ—¶ï¼Œæ—¨åœ¨å¯»æ±‚è‰¯å¥½çš„åˆå§‹ç‚¹ï¼Œ è€Œä¸æ˜¯å¼€å‘éå±€éƒ¨èŒƒå›´æ›´æ–°çš„ç®—æ³•ã€‚ ä¼˜åŒ–ç®—æ³•ä»ç»å…¸çš„SGDç®—æ³•å¼€å§‹ W = W-lr * dWå…¶ä¸­ï¼Œ W ä¸ºæƒé‡çŸ©é˜µ lr ä¸ºå­¦ä¹ ç‡ dW ä¸ºæƒé‡Wçš„æ¢¯åº¦ åœ¨ç»å…¸SGDä¸­ï¼Œå­¦ä¹ ç‡lræ˜¯å›ºå®šçš„ï¼Œä¸ºäº†å®ç°å­¦ä¹ ç‡çš„è‡ªé€‚åº”ï¼Œæå‡ºäº†å¤šç§ç®—æ³•æ¥åº”å¯¹ä¸åŒçš„åœºæ™¯éœ€æ±‚ã€‚ mini-batchå’Œæ¢¯åº¦ä¸‹é™åœ¨æ¯ä¸€è½®ï¼ˆepochï¼‰ä¸­ï¼Œä½¿ç”¨1ä¸ªmini-batchçš„æ ·æœ¬æ¥è®¡ç®—æ¢¯åº¦ä¸‹é™æ–¹å‘ï¼›ä½¿ç”¨mini-batchçš„æ¢¯åº¦è¿‘ä¼¼å…¨éƒ¨æ ·æœ¬çš„æ¢¯åº¦ï¼›æ˜¯Batchæ¢¯åº¦ä¸‹é™å’Œéšæœºæ¢¯åº¦ä¸‹é™çš„æŠ˜ä¸­ã€‚ æ¯æ¬¡åªä½¿ç”¨å•ä¸ªæ ·æœ¬çš„ä¼˜åŒ–ç®—æ³•æœ‰æ—¶è¢«ç§°ä¸ºéšæœºï¼ˆstochasticï¼‰æˆ–è€…åœ¨çº¿ï¼ˆonlineï¼‰ç®—æ³•ã€‚æœ¯è¯­ â€œåœ¨çº¿â€™â€™ é€šå¸¸æ˜¯æŒ‡ä»è¿ç»­äº§ç”Ÿæ ·æœ¬çš„æ•°æ®æµä¸­æŠ½å–æ ·æœ¬çš„æƒ…å†µï¼Œè€Œ ä¸æ˜¯ä»ä¸€ä¸ªå›ºå®šå¤§å°çš„è®­ç»ƒé›†ä¸­éå†å¤šæ¬¡é‡‡æ ·çš„æƒ…å†µã€‚ ä½¿ç”¨mini-batchçš„å¦ä¸€ä¸ªä¸»è¦åŸå› æ˜¯ä¸ºäº†åˆ©ç”¨å‘é‡åŒ–çš„å¹¶è¡Œè®¡ç®—æ¥æå‡å¤„ç†æ•ˆç‡ã€‚ ç†è®ºä¸Šï¼Œä»mini-batchä¸­è·å¾—æ¢¯åº¦çš„ç»Ÿè®¡ä¼°è®¡æºäºè®­ç»ƒé›†çš„å†—ä½™ã€‚mini-batchçš„é€‰æ‹©ä¸»è¦ç”±å¦‚ä¸‹å‡ ä¸ªå› ç´ å†³å®šï¼š æ›´å¤§çš„æ‰¹é‡ä¼šè®¡ç®—æ›´ç²¾ç¡®çš„æ¢¯åº¦ä¼°è®¡ï¼Œä½†æ˜¯æ±‡æŠ¥ç¡®å®å°äºçº¿æ€§çš„ï¼› å¦‚æœæ‰¹é‡å¤„ç†ä¸­çš„æ‰€æœ‰æ ·æœ¬å¯ä»¥å¹¶è¡Œåœ°å¤„ç†ï¼ˆé€šå¸¸ç¡®æ˜¯å¦‚æ­¤ï¼‰ï¼Œé‚£ä¹ˆå†…å­˜æ¶ˆè€—å’Œæ‰¹é‡å¤§å°ä¼šæ­£æ¯”ï¼› åœ¨æŸäº›ç¡¬ä»¶ä¸Šä½¿ç”¨ç‰¹å®šå¤§å°çš„æ•°ç»„æ—¶ï¼Œè¿è¡Œæ—¶é—´ä¼šæ›´å°‘ã€‚å°¤å…¶æ˜¯åœ¨ä½¿ç”¨GPUæ—¶ï¼Œ é€šå¸¸ä½¿ç”¨ 2 çš„å¹‚æ•°ä½œä¸ºæ‰¹é‡å¤§å°å¯ä»¥è·å¾—æ›´å°‘çš„è¿è¡Œæ—¶é—´ï¼› å¯èƒ½æ˜¯ç”±äºå°æ‰¹é‡åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­åŠ å…¥äº†å™ªå£°ï¼Œå®ƒä»¬ä¼šæœ‰ä¸€äº›æ­£åˆ™åŒ–æ•ˆæœ (Wilson and Martinez, 2003)ã€‚ å…¶ä¸­mini-batchçš„å¤§å°ä¸€èˆ¬è®¾ç½®ä¸º2çš„å¹‚æŒ‡æ•°ï¼Œæ¯”å¦‚64ï¼Œ128ï¼Œ256ï¼Œâ€¦,éœ€è¦æ ¹æ®CPU/GPUå†…å­˜å¤§å°è¿›è¡Œè®¾ç½® Momentum ç›®çš„ï¼šä½¿ç”¨æŒ‡æ•°ç§»åŠ¨å¹³å‡å¹³æ»‘æ¢¯åº¦ä¸‹é™çš„æŠ–åŠ¨,ä¸€èˆ¬$\\beta=0.9$, é€‚ç”¨äºå¤„ç†é«˜æ›²ç‡ã€å°ä½†ä¸€è‡´çš„æ¢¯åº¦æˆ–å¸¦æœ‰å™ªå£°çš„æ¢¯åº¦ï¼› å¯å–çš„å‚æ•°æœ‰[0.5, 0.9, 0.95, 0.99] v_{t} = \\beta v_{t-1} - lr*dW W_t = W_{t-1} + v_{t}Nesterovå‹åŠ¨é‡éšæœºä¸‹é™æ³• åœ¨ä¸Šè¿°åŠ¨é‡çš„åŸºç¡€ä¸ŠåŠ ä¸Šäº†å¯¹å½“å‰æ¢¯åº¦çš„çŸ«æ­£ã€‚Nesterovå¯¹å‡¸å‡½æ•°åœ¨æ”¶æ•›æ€§è¯æ˜ä¸Šæœ‰æ›´å¼ºçš„ç†è®ºä¿è¯ w_{ahead} = w_{t-1} +\\beta v_{t-1} v_{t} = \\beta v_{t-1} - \\alpha dw_{ahead} W += v_{t} 123v_prev = v # back this upv = mu * v - learning_rate * dx # velocity update stays the samex += -mu * v_prev + (1 + mu) * v # position update changes form é«˜çº§ä¼˜åŒ–ç®—æ³•ï¼ˆè‡ªé€‚åº”å­¦ä¹ ç‡ç®—æ³•ï¼‰ è‡ªé€‚åº”å­¦ä¹ ç‡çš„è®¾è®¡ æ›´å¤šå†…å®¹å‚è§ï¼šAn overview of gradient descent optimization algorithms Adagrad å¼•å…¥æ–°å˜é‡cacheæ¥è¡¡é‡æ¯ä¸ªmin-batchä¸­å“ªäº›å‚æ•°æ›´æ–°é¢‘ç¹ï¼Œç»™ä¸æ›´é«˜çš„å­¦ä¹ ç‡ã€‚ ç¼ºç‚¹ï¼š cacheæ˜¯ä¸ªç´¯åŠ å€¼ï¼Œå½“è®­ç»ƒæ¯”è¾ƒå¤šè½®çš„å¤§å‹ç½‘ç»œï¼Œåœ¨åæœŸå­¦ä¸åˆ°å¤ªå¤šä¸œè¥¿ã€‚ cache += {dW}^2 W += -\\frac{lr}{\\sqrt{cache}+\\epsilon} * dWAdadelta Adagradçš„æ‰©å±•ï¼Œä¿®æ­£äº†å­¦ä¹ ç‡å•è°ƒä¸‹é™çš„é—®é¢˜ã€‚å€¼ä½¿ç”¨è¿‘æœŸå‡ è½®çš„dWæ¥è¿›è¡Œå¹³æ»‘ç´¯ç§¯ã€‚ RMSprop Geoffery Hintonåœ¨å…¶Couseraè¯¾ç¨‹ä¸­æä¾›çš„ä¸€ç§æ–¹æ³•ï¼Œé‡‡ç”¨æŒ‡æ•°æƒé‡æ»‘åŠ¨å¹³å‡ä¿®æ­£Adagradçš„é—®é¢˜ã€‚ä¸€èˆ¬$\\rho=0.9$ã€‚ RMSpropæ€§èƒ½æ¯”Adagradå’ŒAdaeltaéƒ½ä¼˜ç§€ï¼Œæ”¶æ•›é€Ÿåº¦ä¹Ÿä¼˜äºSGDï¼Œæ˜¯ç›®å‰ç”¨çš„æ¯”è¾ƒå¤šçš„ä¼˜åŒ–ç®—æ³•ã€‚ä½¿ç”¨é¢‘æ¬¡ä»…æ¬¡äºSGDã€‚ å¦‚ä¸‹å›¾ï¼ŒRMSprorçš„æ•ˆæœï¼šå‡ç¼“å‚ç›´æ–¹å‘çš„å¤§å°ï¼Œå¢å¤§æ°´å¹³æ–¹å‘çš„å¤§å° cache = \\rho * cache + (1-\\rho) * {dW}^2 W += -\\frac{lr}{\\sqrt{cache}+\\epsilon} * dWAdam Adapitive Moment Estimation,2014å¹´æå‡ºã€‚å°†dWå’Œ$dW^2$çš„æ›´æ–°éƒ½é‡‡ç”¨äº†æ»‘åŠ¨å¹³å‡ã€‚ ä¸€èˆ¬åœ°ï¼Œ$\\beta_1=0.9, \\beta_2=0.999$ï¼› ç»éªŒè¯ï¼ŒAdamåœ¨å¤šä¸ªåœºæ™¯ä¸‹æ•ˆæœä¼˜äºRMSpropï¼› Adamå¯ä»¥è®¤ä¸ºRMSprop+åŠ¨é‡ï¼Œå¯¹åº”çš„Nadamç®—æ³•=RMSprop + NesterovåŠ é€Ÿ m = \\beta_1 * m + (1-\\beta_1)*dW v = \\beta_2 * v + (1-\\beta_2)*dW^2 m =\\frac{m}{1-\\beta^t_1} v =\\frac{v}{1-\\beta^t_2} W += -\\frac{lr}{\\sqrt{v}+\\epsilon} * m1234567891011m = config['beta1'] * config['m'] + (1-config['beta1']) * dwv = config['beta2'] * config['v'] + (1-config['beta2']) * np.square(dw)t = config['t'] + 1_m = m / (1-config['beta1']**t)_v = v / (1-config['beta2']**t)next_w = w - config['learning_rate']/(np.sqrt(_v) + config['epsilon']) * _mconfig['m'] = mconfig['v'] = vconfig['t'] = t å­¦ä¹ ç‡è¡°å‡ lr = \\frac{1}{1+decay\\_rate*epoch\\_num}*lr_0 å­¦ä¹ ç‡çš„è®¾ç½®åŸåˆ™ï¼š å¼€å§‹æ—¶å­¦ä¹ ç‡ä¸å®œè¿‡å¤§ï¼Œ0.01æˆ–0.001ä½œä¸ºèµ·ç‚¹ã€‚é€šè¿‡è§‚å¯Ÿæ”¶æ•›é€Ÿåº¦è°ƒæ•´å­¦ä¹ ç‡ï¼› å­¦ä¹ ç‡è¡°å‡å¯ä»¥é‡‡ç”¨ï¼š1ï¼‰ä¸Šå¼ä¸­éšè®­ç»ƒè½®æ•°è¡°å‡ï¼›2ï¼‰æŒ‡æ•°è¡°å‡ï¼›3ï¼‰åˆ†æ•°è¡°å‡ $lr=\\frac{lr_0}{1+kt}$ kerasä¸­æä¾›äº†decayå‚æ•°æ¥è°ƒèŠ‚å­¦ä¹ ç‡çš„å˜åŒ–æƒ…å†µï¼š 1opt = SGD(lr=0.01, decay=0.01 / 40, momentum=0.9, nesterov=True) ä½¿ç”¨å…¬å¼ï¼š \\alpha_{e+1} = \\alpha_e \\times 1 /(1+\\gamma * e) å¦ä¸€ç§å­¦ä¹ ç‡ä¸ºé˜¶æ¢¯å­¦ä¹ ç‡ï¼šctrl + c Kerasæä¾›ä¸€ä¸ªç±»ï¼šLearningrateScheduleræ¥é…ç½®è‡ªå®šä¹‰çš„å­¦ä¹ ç‡å‡½æ•° æ¯”å¦‚ï¼š \\alpha_{E+1} = \\alpha_1 \\times F^{(1+E)/D}1234567891011121314def step_decay(epoch): # initialize the base initial learning rate, drop factor, and epochs to drop every initAlpha = 0.01 factor = 0.25 dropEvery = 5 # compute learning rate for the current epoch alpha = initAlpha * (factor ** np.floor((1 + epoch) / dropEvery)) # return the learning rate return float(alpha) ##å®šä¹‰callbackcallbacks = [LearningRateScheduler(step_decay)] å½“å®šä¹‰äº†å­¦ä¹ ç‡ä¹‹åï¼ŒSGDä¸­å£°æ˜çš„é…ç½®ä¿¡æ¯å°†è¢«å¿½ç•¥ äºŒé˜¶è¿‘ä¼¼æ–¹æ³• ç‰›é¡¿æ³•ã€æ‹Ÿç‰›é¡¿æ³•ã€å…±è½­æ¢¯åº¦æ³•ã€BFGSæ³• å¦‚ä½•é€‰æ‹©ä¼˜åŒ–ç®—æ³•äº‹å®ä¸Šå„ç§ä¼˜åŒ–ç®—æ³•æ²¡æœ‰æœ¬è´¨çš„ä¼˜åŠ£ï¼Œä¹Ÿæ²¡æœ‰å®Œå…¨çš„é€‰æ‹©è§„åˆ™ï¼Œæ›´å¤šçš„é ç»éªŒå’Œè¯•é”™ã€‚ç®—æ³•çš„é€‰æ‹©æ›´å¤šçš„æ¥è‡ªäºæ¯ä¸ªäººå¯¹ç®—æ³•çš„ç†Ÿæ‚‰ç¨‹åº¦ã€‚æœ€å¸¸ç”¨çš„ä¸‰ç§ï¼šSGDã€Adamå’ŒRMSpropå¿…é¡»ç ”ç©¶é€ï¼ŒæŒæ¡å…¶æœ¬è´¨ã€‚ ç›®å‰å¾ˆå¤šä¸»æµçš„å­¦æœ¯è®ºæ–‡ä¸­è¿˜æ˜¯ä½¿ç”¨SGDä½œä¸ºè®­ç»ƒçš„ä¼˜åŒ–ç®—æ³•ï¼Œè™½ç„¶è‡ªé€‚åº”å­¦ä¹ ç‡ç®—æ³•å¯ä»¥æé«˜æ”¶æ•›é€Ÿåº¦ï¼Œä½†æ”¶æ•›é€Ÿåº¦ä¸æ˜¯ç®—æ³•çš„å…¨éƒ¨ï¼Œå°¤å…¶æ˜¯SGDæœ‰å¯èƒ½å¸¦æ¥æ›´é«˜çš„æ¨¡å‹ç²¾åº¦ã€‚ é€‰æ‹©ä¸€æ—å®¹æ˜“ä¼˜åŒ–çš„æ¨¡å‹æ¯”ä½¿ç”¨ä¸€ä¸ªå¼ºå¤§çš„ä¼˜åŒ–ç®—æ³•æ›´é‡è¦ã€‚ å‡ ç§ç®—æ³•æ€§èƒ½æ¯”è¾ƒä¸‹é¢å‡ å¼ gifå¯¹æ¯”äº†SGDã€Momentumã€Nesterovã€AdaGradã€AdaDeltaã€RMSPropç­‰ä¼˜åŒ–ç®—æ³•åœ¨ä¸åŒæƒ…å†µä¸‹çš„ç‰¹æ€§ã€‚ Long Valley Bealeâ€˜s Function Saddle Point å‚è€ƒ Kerasæ–‡æ¡£ Deep Learning for Computer Vision with Python Deep Learning Specialization An overview of gradient descent optimization algorithms Deep Learning Book","categories":[{"name":"æ·±åº¦å­¦ä¹ ","slug":"æ·±åº¦å­¦ä¹ ","permalink":"http://blog.a-stack.com/categories/æ·±åº¦å­¦ä¹ /"},{"name":"åŸºç¡€çŸ¥è¯†","slug":"æ·±åº¦å­¦ä¹ /åŸºç¡€çŸ¥è¯†","permalink":"http://blog.a-stack.com/categories/æ·±åº¦å­¦ä¹ /åŸºç¡€çŸ¥è¯†/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://blog.a-stack.com/tags/AI/"},{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"ç®—æ³•","slug":"ç®—æ³•","permalink":"http://blog.a-stack.com/tags/ç®—æ³•/"},{"name":"ä¼˜åŒ–","slug":"ä¼˜åŒ–","permalink":"http://blog.a-stack.com/tags/ä¼˜åŒ–/"}]},{"title":"Transfer Learning Summary","slug":"Transfer-Learning-Summary","date":"2018-03-30T15:36:52.000Z","updated":"2018-05-15T09:14:33.636Z","comments":true,"path":"2018/03/30/Transfer-Learning-Summary/","link":"","permalink":"http://blog.a-stack.com/2018/03/30/Transfer-Learning-Summary/","excerpt":"","text":"æœ¬æ–‡å¯¹è¿ç§»å­¦ä¹ åœ¨æœºå™¨è§†è§‰ä¸­çš„å®è·µæŠ€å·§è¿›è¡Œæ±‡æ€»æ•´ç† â€¦ â€¦ @toc Feature Extractionåœ¨è¿™ç§è¿ç§»å­¦ä¹ æ¨¡å¼ä¸­ï¼Œé¢„è®­ç»ƒæ¨¡å‹å°†è¢«å½“ä½œç‰¹å¾æå–å™¨ï¼ˆfeature extractorï¼‰,è·å¾—å›¾åƒçš„ç‰¹å¾è¡¨ç¤º(feature vactor)ã€‚è·å¾—ç‰¹å¾å‘é‡ä¹‹åï¼Œæˆ‘ä»¬åªéœ€ä¸€ä¸ªç®€å•çš„åˆ†ç±»å™¨æ¨¡å‹ï¼Œå¦‚SVMã€é€»è¾‘å›å½’åˆ†ç±»å™¨ã€éšæœºæ£®æ—å°±å¯ä»¥å®Œæˆç›®æ ‡åˆ†ç±»å™¨çš„è®¾è®¡ã€‚ VGG16å€’æ•°ç¬¬äºŒå±‚(å‚æ•°å±‚)çš„è¾“å‡ºç»´åº¦ä¸º: 7x7x512 = 25,088 HDF5æŠ½å–ç‰¹å¾çš„é«˜æ•ˆå­˜å‚¨å¯ä»¥é€‰ç”¨HDF5ã€‚Hierarchical Data Format(HDF)æ˜¯ä¸€ç§é’ˆå¯¹å¤§é‡æ•°æ®è¿›è¡Œç»„ç»‡å’Œå­˜å‚¨çš„æ–‡ä»¶æ ¼å¼ã€‚ç»å†äº†20å¤šå¹´çš„å‘å±•ï¼ŒHDFæ ¼å¼çš„æœ€æ–°ç‰ˆæœ¬æ˜¯HDF5ï¼Œå®ƒåŒ…å«äº†æ•°æ®æ¨¡å‹ï¼Œåº“ï¼Œå’Œæ–‡ä»¶æ ¼å¼æ ‡å‡†ã€‚ä»¥å…¶ä¾¿æ·æœ‰æ•ˆï¼Œç§»æ¤æ€§å¼ºï¼Œçµæ´»å¯æ‰©å±•çš„ç‰¹ç‚¹å—åˆ°äº†å¹¿æ³›çš„å…³æ³¨å’Œåº”ç”¨ã€‚å¾ˆå¤šå¤§å‹æœºæ„çš„æ•°æ®å­˜å‚¨æ ¼å¼éƒ½é‡‡ç”¨äº†HDF5ï¼Œæ¯”å¦‚NASAçš„åœ°çƒè§‚æµ‹ç³»ç»Ÿï¼ŒMATLABçš„.mæ–‡ä»¶ï¼Œæµä½“ç»†ç®—è½¯ä»¶CDFï¼Œéƒ½å°†HDF5ä½œä¸ºæ ‡å‡†æ•°æ®æ ¼å¼ã€‚HDF5æœ¬èº«ç”¨Cå®ç°ï¼Œå¯ä»¥ä½¿ç”¨pythonçš„åº“h5pyå¯¹HDF5æ–‡ä»¶è¿›è¡Œæ“ä½œã€‚å¯ä»¥åƒæ“ä½œNumpyæ•°ç»„ä¸€æ ·å¯¹å¤§å‹æ•°æ®è¿›è¡Œæ“ä½œï¼Œæ¯”å¦‚åˆ‡ç‰‡ï¼ŒæŒ‰è¡Œè¯»å– æ•°æ®åœ¨HDF5ä¸­é‡‡å–åˆ†å±‚å­˜å‚¨æ–¹å¼ï¼Œå¾ˆåƒæ–‡ä»¶ç³»ç»Ÿç®¡ç†æ–¹å¼ï¼Œç¬¬ä¸€çº§å«åšç»„ï¼Œç±»ä¼¼äºcontainerï¼Œæ¯ä¸ªç»„ä¸­å¯ä»¥åˆ›å»ºæ–°çš„ç»„æˆ–æ•°æ®é›†ï¼Œæ¯ä¸€ä¸ªdatasetåŒ…å«ä¸¤éƒ¨åˆ†çš„æ•°æ®ï¼ŒMetadataå’ŒDataã€‚å…¶ä¸­MetadataåŒ…å«Dataç›¸å…³çš„ä¿¡æ¯ï¼Œè€ŒDataåˆ™åŒ…å«æ•°æ®æœ¬èº«ã€‚ 12345678910import h5pyp = \"./datasets/hdf5/features.hdf5\"db = h5py.File(p)list(db.keys())&gt;&gt;&gt; [uâ€™featuresâ€™, uâ€™label_namesâ€™, uâ€™labelsâ€™]db[\"features\"].shape&gt;&gt;&gt; (3000, 25088)list(db[\"label_name\"])&gt;&gt;&gt; ['cat', 'dogs', 'panda'] Fine-Tune ä¸€èˆ¬è€Œè¨€ï¼Œfine-tuneåœ¨æ ·æœ¬æ•°æ®è¶³å¤Ÿçš„æƒ…å†µä¸‹è®­ç»ƒæ•ˆæœä¼˜äºç‰¹å¾æŠ½å–ï¼› å­¦ä¹ ç‡è¦æ§åˆ¶çš„å°½é‡å° å¦‚ä½•å–å±‚ï¼ˆKerasï¼‰123456789101112131415161718192021222324252627from keras.applications import VGG16model = VGG16(weights=\"imagenet\", include_top=False)model.layers&gt;&gt;&gt;[&lt;keras.engine.topology.InputLayer at 0x7ff06cc3b518&gt;, &lt;keras.layers.convolutional.Conv2D at 0x7ff06cc3b7f0&gt;, &lt;keras.layers.convolutional.Conv2D at 0x7ff06cc3b7b8&gt;, &lt;keras.layers.pooling.MaxPooling2D at 0x7ff06cc3bd30&gt;, &lt;keras.layers.convolutional.Conv2D at 0x7ff06cdb3b00&gt;, &lt;keras.layers.convolutional.Conv2D at 0x7ff06cdb3748&gt;, &lt;keras.layers.pooling.MaxPooling2D at 0x7ff06cbbb400&gt;, &lt;keras.layers.convolutional.Conv2D at 0x7ff06cbcc630&gt;, &lt;keras.layers.convolutional.Conv2D at 0x7ff06cb5dd68&gt;, &lt;keras.layers.convolutional.Conv2D at 0x7ff06cb6d208&gt;, &lt;keras.layers.pooling.MaxPooling2D at 0x7ff06cb7fdd8&gt;, &lt;keras.layers.convolutional.Conv2D at 0x7ff06cb30fd0&gt;, &lt;keras.layers.convolutional.Conv2D at 0x7ff06cb30e80&gt;, &lt;keras.layers.convolutional.Conv2D at 0x7ff06cb52978&gt;, &lt;keras.layers.pooling.MaxPooling2D at 0x7ff06caf6470&gt;, &lt;keras.layers.convolutional.Conv2D at 0x7ff06cb076a0&gt;, &lt;keras.layers.convolutional.Conv2D at 0x7ff06ca98dd8&gt;, &lt;keras.layers.convolutional.Conv2D at 0x7ff06caaa278&gt;, &lt;keras.layers.pooling.MaxPooling2D at 0x7ff06cab8e48&gt;]model.output&gt;&gt;&gt;&lt;tf.Tensor 'block5_pool/MaxPool:0' shape=(?, ?, ?, 512) dtype=float32&gt; å¦‚ä½•æ·»åŠ å±‚ï¼ˆKerasï¼‰12345678910111213# load the VGG16 network, ensuring the head FC layer sets are left # offbaseModel = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))# add new layersheadModel = baseModel.outputheadModel = Flatten(name=\"flatten\")(headModel)headModel = Dense(D_num, activation=\"relu\")(headModel)headModel = Dropout(0.5)(headModel)headModel = Dense(classes_num, activation=\"softmax\")(headModel)model = Model(inputs=baseModel.input, outputs=headModel)#freeze baseModel layersfor layer in baseModel.layers: layer.trainable = False Typically youâ€™ll allow your own FC head to warmup for 10-30 epochs, depending on your dataset.ä½¿ç”¨RMSpropä½œä¸ºä¼˜åŒ–ç®—æ³•ï¼›â€‹ 123456opt = RMSprop(lr=0.001)model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])# train the head of the network for a few epochs (all other # layers are frozen) -- this will allow the new FC layers to# start to become initialized with actual \"learned\" values # versus pure randomprint(\"[INFO] training head...\")model.fit_generator(aug.flow(trainX, trainY, batch_size=32), validation_data=(testX, testY), epochs=25, steps_per_epoch=len(trainX) // 32, verbose=1) ç„¶åå¯ä»¥é€‚å½“å¾€å‰è§£å†»ä¸€äº›å±‚ï¼Œé‡æ–°è®­ç»ƒï¼Œä¸€èˆ¬ä¼šè§£å†»æœ€åä¸€å±‚CONVï¼Œä½¿ç”¨SGDï¼ˆlr=0.001ï¼‰ä½œä¸ºä¼˜åŒ–ç®—æ³•ï¼› 123# now that the head FC layers have been trained/initialized, lets # unfreeze the final set of CONV layers and make them trainable for layer in baseModel.layers[15:]: layer.trainable = True 1234567# for the changes to the model to take affect we need to recompile # the model, this time using SGD with a *very* small learning rate print(\"[INFO] re-compiling model...\") opt = SGD(lr=0.001)model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])# train the model again, this time fine-tuning *both* the final set # of CONV layers along with our set of FC layers print(\"[INFO] fine-tuning model...\")model.fit_generator(aug.flow(trainX, trainY, batch_size=32), validation_data=(testX, testY), epochs=100, steps_per_epoch=len(trainX) // 32, verbose=1) è¿ç§»å­¦ä¹ çš„é€‰æ‹©ä¸»è¦ç”±æ ·æœ¬æ•°æ®é‡ä»¥åŠè®­ç»ƒç›®æ ‡äºåŸç›®æ ‡ä¹‹é—´çš„ç›¸ä¼¼ç¨‹åº¦å†³å®šã€‚ æ•°æ®è§„æ¨¡ ç›¸ä¼¼æ•°æ®åˆ†å¸ƒ ä¸åŒæ•°æ®åˆ†å¸ƒ å°æ ·æœ¬æ•°æ®é›† ç‰¹å¾æå–ï¼šFC+åˆ†ç±»å™¨ ç‰¹å¾æå–ï¼šä½å±‚æ¬¡çš„Conv+åˆ†ç±»å™¨ å¤§æ ·æœ¬æ•°æ®é›† Fine-Tune ä»å¤´è®­ç»ƒæ–°çš„ç½‘ç»œæ¨¡å‹","categories":[{"name":"ç®—æ³•","slug":"ç®—æ³•","permalink":"http://blog.a-stack.com/categories/ç®—æ³•/"},{"name":"è¿ç§»å­¦ä¹ ","slug":"ç®—æ³•/è¿ç§»å­¦ä¹ ","permalink":"http://blog.a-stack.com/categories/ç®—æ³•/è¿ç§»å­¦ä¹ /"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://blog.a-stack.com/tags/AI/"},{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"è¿ç§»å­¦ä¹ ","slug":"è¿ç§»å­¦ä¹ ","permalink":"http://blog.a-stack.com/tags/è¿ç§»å­¦ä¹ /"},{"name":"ç‰¹å¾æŠ½å–","slug":"ç‰¹å¾æŠ½å–","permalink":"http://blog.a-stack.com/tags/ç‰¹å¾æŠ½å–/"}]},{"title":"ç¥ç»ç½‘ç»œä¹‹æ„ŸçŸ¥æœºï¼ˆPerceptronï¼‰","slug":"ç¥ç»ç½‘ç»œä¹‹æ„ŸçŸ¥æœº","date":"2018-03-09T08:37:04.000Z","updated":"2018-05-15T09:14:33.671Z","comments":true,"path":"2018/03/09/ç¥ç»ç½‘ç»œä¹‹æ„ŸçŸ¥æœº/","link":"","permalink":"http://blog.a-stack.com/2018/03/09/ç¥ç»ç½‘ç»œä¹‹æ„ŸçŸ¥æœº/","excerpt":"æ„ŸçŸ¥æœºäº1957å¹´ç”±Rosenblattç­‰äººæå‡ºï¼Œæ˜¯ç¥ç»ç½‘ç»œå’Œæ”¯æŒå‘é‡æœºçš„åŸºç¡€ã€‚","text":"æ„ŸçŸ¥æœºäº1957å¹´ç”±Rosenblattç­‰äººæå‡ºï¼Œæ˜¯ç¥ç»ç½‘ç»œå’Œæ”¯æŒå‘é‡æœºçš„åŸºç¡€ã€‚ @[toc] 1. äººå·¥ç¥ç»ç½‘ç»œç°ä»£ç¥ç»ç½‘ç»œæ¦‚å¿µç”±äººå·¥ç¥ç»ç½‘ç»œå»¶ä¼¸è€Œæ¥ï¼Œå‡ºå‘ç‚¹åœ¨äºæ¨¡æ‹Ÿäººç±»ç¥ç»å…ƒçš„ä¿¡æ¯å¤„ç†æ–¹å¼ï¼Œè€Œäº‹å®ä¸Šç°åœ¨é‡‡ç”¨çš„ç¥ç»ç½‘ç»œå’Œäººç±»çš„æ€ç»´æ´»åŠ¨æ–¹å¼å­˜åœ¨å¾ˆå¤§çš„å·®å¼‚ã€‚ äººç±»å¤§è„‘ç”±å¤§äº100äº¿ä¸ªç¥ç»å…ƒç»„æˆï¼Œæ¯ä¸ªç¥ç»å…ƒä¸å‘¨å›´1ä¸‡ä¸€ä¸ªå…¶å®ƒç¥ç»å…ƒä¿æŒå…³è”ã€‚ 2.æ„ŸçŸ¥æœºï¼ˆPerceptronï¼‰æ„ŸçŸ¥æœºå¯ä»¥è¢«è®¤ä¸ºæ˜¯äººå·¥ç¥ç»ç½‘ç»œçš„åˆçº§åŸå‹ï¼Œæ˜¯åªæœ‰ä¸€ä¸ªç¥ç»å…ƒä¸€å±‚çš„ç¥ç»ç½‘ç»œï¼Œä½†äº‹å®ä¸Šæ„ŸçŸ¥æœºä¸æ”¯æŒå‘é‡æœºçš„å…³ç³»æ¯”ç¥ç»ç½‘ç»œè¿˜è¦å¯†åˆ‡ã€‚æ„ŸçŸ¥æœºæ˜¯ä¸ªäºŒåˆ†ç±»çš„çº¿æ€§åˆ†ç±»æ¨¡å‹ï¼Œè¾“å‡ºå®ä¾‹ä¸º+1å’Œ-1çš„äºŒå€¼ç»“æœã€‚æ„ŸçŸ¥æœºå­¦ä¹ çš„è¿‡ç¨‹æ—¨åœ¨åœ¨å‡è®¾ç©ºé—´ä¸­å¯»æ‰¾ä¸€ä¸ªåˆ†ç¦»è¶…å¹³é¢ï¼Œå°†çº¿æ€§å¯åˆ†çš„ç›®æ ‡æ•°æ®åˆ†ä¸ºä¸¤ç±»ã€‚ 2.1 æ„ŸçŸ¥æœºæ¨¡å‹å¯¹äºè¾“å…¥å‘é‡$x\\in X$ å’Œè¾“å‡ºå®ä¾‹$y\\in {+1,-1}$ ,ç”±è¾“å…¥ç©ºé—´åˆ°è¾“å‡ºç©ºé—´çš„å¦‚ä¸‹å‡½æ•°ç§°ä¸ºæ„ŸçŸ¥æœºï¼š f(x) = sign(w \\cdot x + b)å…¶ä¸­ï¼Œ$w$ å’Œ $b$ åˆ†åˆ«ä¸ºæƒå€¼å‘é‡å’Œåç½®ï¼Œ$sign$ æ˜¯ç¬¦å·å‡½æ•°ï¼Œå®šä¹‰å¦‚ä¸‹ï¼š sign(x)= \\left\\{ \\begin{array}{lr} +1, & x \\ge 0\\\\ -1, & x \\lt 0 \\end{array} \\right.å…¶ä¸­çº¿æ€§æ–¹ç¨‹$w \\cdot x + b =0$ å¯¹åº”äºç‰¹å¾ç©ºé—´ä¸­çš„ä¸€ä¸ªè¶…å¹³é¢$S$, $w$ ä¸ºè¶…å¹³é¢çš„æ³•å‘é‡ï¼Œ$b$ ä¸ºè¶…å¹³é¢çš„æˆªè·ã€‚è¿™ä¸ªè¶…å¹³é¢å°†ç‰¹å¾ç©ºé—´åˆ’åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼Œåˆ’åˆ†ä¸ºæ­£ã€è´Ÿä¸¤ä¸ªåˆ†ç±»ã€‚æ‰€ä»¥ï¼Œè¶…å¹³é¢Sè¢«ç§°ä¸ºåˆ†ç¦»è¶…å¹³é¢ã€‚ 2.2 æ„ŸçŸ¥æœºæ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹é¦–å…ˆéœ€è¦æŒ‡å‡ºçš„æ˜¯æ„ŸçŸ¥æœºè§£å†³çš„æ˜¯çº¿æ€§åˆ†ç±»é—®é¢˜ï¼Œé¢å‘çš„æ•°æ®é›†ä¸ºçº¿æ€§å¯åˆ†æ•°æ®é›†ã€‚ç»™å®šä¸€ä¸ªæ•°æ®é›†${ (x_1,y_1), (x_2,y_2), â€¦, (x_N, y_N)}$ ã€‚å³å¯¹æ‰€æœ‰çš„æ­£å®ä¾‹$y_i=+1$, æœ‰ $w \\cdot x_i + b \\gt 0$ ; åŒæ ·å¯¹æ‰€æœ‰çš„è´Ÿå®ä¾‹ $y_i = -1$, $w \\cdot x_i + b \\lt 0$ ã€‚ ç›®æ ‡æŸå¤±å‡½æ•°çš„å®šä¹‰ å¯¹äºçº¿æ€§å¯åˆ†æ•°æ®é›†ï¼Œæ„ŸçŸ¥æœºçš„è®­ç»ƒç›®æ ‡ä¸ºæ‰¾åˆ°ä¸€ä¸ªèƒ½å¤Ÿå°†è®­ç»ƒæ•°æ®æ­£è´Ÿå®ä¾‹å®Œå…¨åˆ†å¼€çš„åˆ†ç¦»è¶…å¹³é¢ã€‚ä¸ºæ»¡è¶³è¿™ä¸ªç›®æ ‡ï¼ŒæŸå¤±å‡½æ•°é€‰æ‹©ä¸ºè¯¯åˆ†ç±»ç‚¹åˆ°è¶…å¹³é¢Sçš„è·ç¦»æ€»å’Œã€‚ å¯¹äºä»»ä¸€è¯¯åˆ†ç±»æ•°æ®$(x_i, y_i)$ï¼Œ åˆ©ç”¨è¶…å¹³é¢çš„æ€§è´¨ï¼Œæˆ‘ä»¬å¾ˆå®¹æ˜“å¾—åˆ°ï¼š - y_i (w \\cdot x_i +b) > 0è¯¯åˆ†ç±»ç‚¹åˆ°è¶…å¹³é¢çš„è·ç¦»å¦‚ä¸‹ï¼š \\frac{1}{||w||} |w \\cdot x_i +b| =- \\frac{1}{||w||} y_i(w \\cdot x_i +b)å¦‚æœä¸è€ƒè™‘$\\frac{1}{||w||}$ ï¼ˆå› ä¸ºå®ƒå¯¹ç›®æ ‡æŸå¤±å‡½æ•°çš„å½±å“ä¸å‚æ•°$w$ ç­‰æ•ˆï¼‰æˆ‘ä»¬å¯ä»¥å®šä¹‰æ„ŸçŸ¥æœºçš„ç›®æ ‡æŸå¤±å‡½æ•°ä¸ºï¼š L(w,b) = -\\sum_{x_i \\in M} y_i(w \\cdot x_i + b)å…¶ä¸­$M$ ä¸ºè¯¯åˆ†ç±»ç‚¹çš„é›†åˆã€‚å¯¹äºä»»ä½•è®­ç»ƒæ•°æ®ï¼Œå¦‚æœè¯¥æ•°æ®å±äºè¯¯åˆ†ç±»ç‚¹åˆ™æŸå¤±å‡½æ•°ä¸ºå‚æ•°$w,b$ çš„çº¿æ€§å‡½æ•°ï¼Œå¦‚æœæ•°æ®ä¸ºæ­£ç¡®åˆ†ç±»æ•°æ®ä¸º0,æŸå¤±å‡½æ•°$L(w,b)$ æ˜¯$w,b$çš„è¿ç»­å¯å¯¼å‡½æ•°ã€‚ è®­ç»ƒè¿‡ç¨‹æ„ŸçŸ¥æœºçš„è®­ç»ƒè¿‡ç¨‹å¯ä»¥é€šè¿‡éšæœºæ¢¯åº¦ä¸‹é™æ³•å®ç°ï¼š é¦–å…ˆä»»æ„é€‰å–ä¸€ä¸ªè¶…å¹³é¢$w_0, b_0$ ä½œä¸ºè®­ç»ƒèµ·ç‚¹ï¼Œ é‡‡ç”¨æ¢¯åº¦ä¸‹é™æ³•æ¯æ¬¡é€‰å–ä¸€ä¸ªè®­ç»ƒæ•°æ®æ ·æœ¬ç‚¹æ›´æ–°å‚æ•°$w,b$ å€¼ï¼Œé€æ­¥é€¼è¿‘ç›®æ ‡æŸå¤±å‡½æ•°çš„æœ€å°å€¼ï¼š dw = \\frac{\\partial L(w,b)}{\\partial w} = - \\sum_{x_i \\in M}y_ix_i db = \\frac{\\partial L(w,b)}{\\partial b} = -\\sum_{x_i \\in M}y_i w := w + \\alpha \\sum_{x_i \\in N} (\\hat y_i - y_i)x_i b := b - \\alpha \\sum_{x_i \\in N}(\\hat y_i -y_i) åœ¨æƒé‡æ›´æ–°ä¸­ï¼Œå¼•å…¥äº†ä¸€ä¸ªå°æŠ€å·§ï¼Œå°†å¯¹è¯¯åˆ†ç±»æ•°æ®Mçš„æ›´æ–°æ‰©å±•åˆ°æ‰€æœ‰çš„è®­ç»ƒæ•°æ®Nã€‚å…¶ä¸­$\\hat y{i}$ è¡¨ç¤ºè¯¥ç‚¹çš„ä¼°è®¡å€¼ï¼Œå¦‚æœä¸ºæ­£ç¡®åˆ†ç±»æ•°æ®ï¼Œç”±äº$\\hat y{i}=y_i$ï¼Œ æ‰€ä»¥ä¸¤ä¸ªæƒé‡éƒ½ä¸ä¼šéœ€è¦è¿›è¡Œæ›´æ–°ã€‚ 2.3 æ„ŸçŸ¥æœºçš„å¯¹å¶å½¢å¼ f(x) = sign(\\sum_{j-1}^N \\sigma_j y_jx_j \\cdot x + b) æš‚æ—¶ä¸å¯¹è¿™éƒ¨åˆ†è¿‡å¤šè®¨è®ºï¼Œä»¥åç»“åˆSVMçš„å¯¹å¶å½¢å¼ä¸€å¹¶åˆ†æâ€¦ 3. æ„ŸçŸ¥æœºä½¿ç”¨è¿‡ç¨‹ä¸­æ³¨æ„ç‚¹ æ„ŸçŸ¥æœºåªèƒ½è§£å†³çº¿æ€§å¯åˆ†é—®é¢˜ï¼Œæ¯”å¦‚å¯¹äºXORæ±‚è§£å°±æ— èƒ½ä¸ºåŠ›ï¼› æ„ŸçŸ¥æœºç®—æ³•å­˜åœ¨è®¸å¤šè§£ï¼Œè¿™äº›è§£æ—¢ä¾èµ–åˆå€¼çš„é€‰æ‹©ï¼Œä¹Ÿä¾èµ–è¿­ä»£è¿‡ç¨‹ä¸­è¯¯åˆ†ç±»ç‚¹çš„é€‰æ‹©é¡ºåºï¼› ä¸ºäº†å¾—åˆ°å”¯ä¸€çš„åˆ†ç±»è¶…å¹³é¢ï¼Œéœ€è¦å¯¹åˆ†ç¦»è¶…å¹³é¢å¢åŠ çº¦æŸæ¡ä»¶ï¼Œè¿™æ­£æ˜¯çº¿æ€§æ”¯æŒå‘é‡æœºçš„å®ç°åŸç†ï¼› 4. åŠ¨æ‰‹å®ç°ä¸€ä¸ªæ„ŸçŸ¥æœºæ¨¡å‹1234567891011121314151617181920212223242526272829import numpy as npclass Perceptron: def __init__(self, N, alpha=0.1): self.W = np.random.randn(N + 1)/np.sqrt(N) # converge bias into W self.alpha = alpha def step(self, f_x): return 1 if f_x&gt;0 else -1 def fit(self, X, y, epochs=10): # insert a column into X X = np.c_[X, np.ones((X.shape[0]))] for epoch in np.arange(0, epochs): for (x, target) in zip(X,y): result = self.step(np.dot(x, self.W)) if result != target: error = result - target self.W += -self.alpha * error * x def predict(self, X, addBias=True): X = np.atleast_2d(X) if addBias: X = np.c_[X, np.ones((X.shape[0]))] return self.step(np.dot(X, self.W)) ä¸ºäº†è®¡ç®—æ–¹ä¾¿ï¼Œæˆ‘ä»¬å°†biaså‚æ•°æ•´åˆè¿›äº†wå‚æ•°ä¹‹ä¸­ã€‚ ä½¿ç”¨å’Œæµ‹è¯•æ„ŸçŸ¥æœºåˆ†ç±»å™¨ï¼š 12345678910## Test it on OR dataX = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])y = np.array([[-1], [1], [1], [1]])p = Perceptron(X.shape[1], alpha=0.1)p.fit(X,y,epochs=20)for (x,target) in zip(X,y): pred = p.predict(x) print(\"[INFO] data=&#123;&#125;, ground-truth=&#123;&#125;, pred=&#123;&#125;\".format(x, target[0], pred)) â€‹ å‚è€ƒ ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹â€”â€”æèˆª","categories":[{"name":"æ·±åº¦å­¦ä¹ ","slug":"æ·±åº¦å­¦ä¹ ","permalink":"http://blog.a-stack.com/categories/æ·±åº¦å­¦ä¹ /"},{"name":"åŸºç¡€çŸ¥è¯†","slug":"æ·±åº¦å­¦ä¹ /åŸºç¡€çŸ¥è¯†","permalink":"http://blog.a-stack.com/categories/æ·±åº¦å­¦ä¹ /åŸºç¡€çŸ¥è¯†/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://blog.a-stack.com/tags/AI/"},{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"æ„ŸçŸ¥æœº","slug":"æ„ŸçŸ¥æœº","permalink":"http://blog.a-stack.com/tags/æ„ŸçŸ¥æœº/"}]},{"title":"è¯»ä¹¦ç¬”è®°ï¼šã€ŠPractical Python and OpenCVã€‹","slug":"è¯»ä¹¦ç¬”è®°ï¼šã€ŠPractical-Python-and-OpenCVã€‹","date":"2018-03-05T08:52:33.000Z","updated":"2018-05-15T09:14:33.694Z","comments":true,"path":"2018/03/05/è¯»ä¹¦ç¬”è®°ï¼šã€ŠPractical-Python-and-OpenCVã€‹/","link":"","permalink":"http://blog.a-stack.com/2018/03/05/è¯»ä¹¦ç¬”è®°ï¼šã€ŠPractical-Python-and-OpenCVã€‹/","excerpt":"","text":"ã€ŠPractical Python and OpenCVã€‹è¯»ä¹¦æœ­è®°ã€‚ 1. Loadï¼ŒDisplay and Save an Image123456789import cv2# Load the image and show some basic information on itimage = cv2.imread(\"Path/to/Image\")# Show the image and wait for a keypresscv2.imshow(\"Image\", image)cv2.waitKey(0)# Save the image -- OpenCV handles converting filetypes# automaticallycv2.imwrite(\"newimage.jpg\", image) 2. cv2å›¾åƒä¸Šæ·»åŠ çº¿æ¡åŠå½¢çŠ¶ cv2.line(image, start_point, stop_point, color, thickness) cv2.rectangle(image,top_left, bottom_right, color, thickness) thickness ä¸ºè´Ÿæ•°ï¼Œå¡«å……å½¢çŠ¶ 12345678910111213141516171819202122# Initialize our canvas as a 300x300 with 3 channels,# Red, Green, and Blue, with a black backgroundcanvas = np.zeros((300, 300, 3), dtype = \"uint8\")# Draw a green line from the top-left corner of our canvas# to the bottom-rightgreen = (0, 255, 0)cv2.line(canvas, (0, 0), (300, 300), green)# Now, draw a 3 pixel thick red line from the top-right# corner to the bottom-leftred = (0, 0, 255)cv2.line(canvas, (300, 0), (0, 300), red, 3)# Draw a green 50x50 pixel square, starting at 10x10 and# ending at 60x60cv2.rectangle(canvas, (10, 10), (60, 60), green)# Draw another rectangle, this time we'll make it red and# 5 pixels thickcv2.rectangle(canvas, (50, 200), (200, 225), red, 5)# Let's draw one last rectangle: blue and filled inblue = (255, 0, 0)cv2.rectangle(canvas, (200, 50), (225, 125), blue, -1)cv2.imshow(\"Canvas\", canvas)cv2.waitKey(0) æ·»åŠ åœ†å½¢ cv2.circle(image, (centerX, centerY), r, color,thickness) 12345678910# Reset our canvas and draw a white circle at the center# of the canvas with increasing radii - from 25 pixels to# 150 pixelscanvas = np.zeros((300, 300, 3), dtype = \"uint8\")(centerX, centerY) = (canvas.shape[1] // 2, canvas.shape[0] // 2)white = (255, 255, 255)for r in range(0, 175, 25): cv2.circle(canvas, (centerX, centerY), r, white)cv2.imshow(\"Canvas\", canvas)cv2.waitKey(0) 123456789101112131415# Let's go crazy and draw 25 random circlesfor i in range(0, 25): # randomly generate a radius size between 5 and 200, # generate a random color, and then pick a random # point on our canvas where the circle will be drawn radius = np.random.randint(5, high = 200) color = np.random.randint(0, high = 256, size = (3,)).tolist() pt = np.random.randint(0, high = 300, size = (2,)) # draw our random circle cv2.circle(canvas, tuple(pt), radius, color, -1)# Show our masterpiececv2.imshow(\"Canvas\", canvas)cv2.waitKey(0) 3. Image Processing å¹³ç§» cv2.warpAffine() imutil 1234567def translate(image, x, y): # Define the translation matrix and perform the translation M = np.float32([[1, 0, x], [0, 1, y]]) shifted = cv2.warpAffine(image, M, (image.shape[1], image.shape[0])) # Return the translated image return shifted æ—‹è½¬ cv2.getRotationMatrix2D 123456789101112131415def rotate(image, angle, center = None, scale = 1.0): # Grab the dimensions of the image (h, w) = image.shape[:2] # If the center is None, initialize it as the center of # the image if center is None: center = (w / 2, h / 2) # Perform the rotation M = cv2.getRotationMatrix2D(center, angle, scale) rotated = cv2.warpAffine(image, M, (w, h)) # Return the rotated image return rotated ç¼©æ”¾ cv2.resize 1234567891011121314151617181920212223242526def resize(image, width = None, height = None, inter = cv2.INTER_AREA): # initialize the dimensions of the image to be resized and grab the image size dim = None (h, w) = image.shape[:2] # if both the width and height are None, then return the original image if width is None and height is None: return image # check to see if the width is None if width is None: # calculate the ratio of the height and construct the dimensions r = height / float(h) dim = (int(w * r), height) # otherwise, the height is None else: # calculate the ratio of the width and construct the dimensions r = width / float(w) dim = (width, int(h * r)) # resize the image resized = cv2.resize(image, dim, interpolation = inter) # return the resized image return resized åè½¬ cv2.flip(image, num) num=1, æ°´å¹³åè½¬ï¼›num=0ï¼Œå‚ç›´ç¿»è½¬ï¼›numä¸ºè´Ÿï¼Œå¯¹è§’åè½¬ bitwise 12bitwiseAnd = cv2.bitwise_and(rectangle, circle) cv2.imshow(\"AND\", bitwiseAnd) cv2.waitKey(0) MASKING 12345mask = np.zeros(image.shape[:2], dtype = \"uint8\") cv2.circle(mask, (cX, cY), 100, 255, -1) masked = cv2.bitwise_and(image, image, mask = mask) cv2.imshow(\"Mask\", mask) cv2.imshow(\"Mask Applied to Image\", masked) cv2.waitKey(0) è‰²å½©ç©ºé—´å˜æ¢ 123456789# Load the image and show itimage = cv2.imread(args[\"image\"])# Convert the image to grayscalegray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)# Convert the image to the HSV (Hue, Saturation, Value)# color spaceshsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)# Convert the image to the L*a*b* color spaceslab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB) å¹³æ»‘/æ¨¡ç³Šï¼ˆblurringï¼‰ 12345678# Averaging Blurringcv2.blur(image, (3, 3))# Gaussian Blurringcv2.GaussianBlur(image, (3, 3), 0)# Median Blurringcv2.medianBlur(image, 3)# Bilateral Blurringcv2.bilateralFilter(image, 5, 21, 21) Traditionally, the median blur method has been most effective when removing salt-and-pepper noise. Threshold 1234(T, thresh) = cv2.threshold(blurred, 155, 255, cv2.THRESH_BINARY) cv2.imshow(\"Threshold Binary\", thresh) (T, threshInv) = cv2.threshold(blurred, 155, 255, cv2. THRESH_BINARY_INV)cv2.bitwise_and(image, image, mask = threshInv) è¾¹ç¼˜æ£€æµ‹ 1234image = cv2.imread(img)image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)image = cv2.GaussianBlur(image, (5,5), 0)canny = cv2.Canny(image, 30 ,150) è½®å»“æ£€æµ‹ 12345678image = cv2.imread(img)image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)image = cv2.GaussianBlur(image, (11,11), 0)canny = cv2.Canny(image, 30 ,150)(_, cnts, _) = cv2.findContours(canny.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)print(\"I count &#123;&#125; coins in this image\".format(len(cnts)))coins = image.copy()cv2.drawContours(coins, cnts, -1, (0, 255, 255), 2) ä»å›¾åƒä¸­å°†å¯¹è±¡æ‰£å– 1234567891011121314151617# Now, let's loop over each contourfor (i, c) in enumerate(cnts): # We can compute the 'bounding box' for each contour, which is the rectangle that encloses the contour (x, y, w, h) = cv2.boundingRect(c) # Now that we have the contour, let's extract it using array slices print(\"Coin #&#123;&#125;\".format(i + 1)) coin = image[y:y + h, x:x + w] cv2.imshow(\"Coin\", coin) # Just for fun, let's construct a mask for the coin by finding The minumum enclosing circle of the contour mask = np.zeros(image.shape[:2], dtype = \"uint8\") ((centerX, centerY), radius) = cv2.minEnclosingCircle(c) cv2.circle(mask, (int(centerX), int(centerY)), int(radius), 255, -1) mask = mask[y:y + h, x:x + w] cv2.imshow(\"Masked Coin\", cv2.bitwise_and(coin, coin, mask = mask)) cv2.waitKey(0) â€‹ Tips ä¸ºè§£å†³python 2.7å’Œpython 3ä¸­printå‡½æ•°ä¸å…¼å®¹çš„é—®é¢˜ï¼Œå¯é€šè¿‡å¯¼å…¥å¦‚ä¸‹å‘½ä»¤è§£å†³åœ¨python 2.7ç¯å¢ƒè¿è¡Œpython 3ä¸­printå‡½æ•°ä¸å…¼å®¹çš„é—®é¢˜ï¼š 1from __future__ import print_function OpenCVå­˜å‚¨RGBä¿¡æ¯é‡‡ç”¨çš„é€†å‘å­˜å‚¨æ–¹å¼ï¼Œå³ä¸ºBGR; matplotlib.plotä¸­ä¸ºRGB np.random Method Desription rand(d0, d1, â€¦, dn) Random values in a given shape. randn(d0, d1, â€¦, dn) Return a sample (or samples) from the â€œstandard normalâ€ distribution. randint(low[, high, size, dtype]) Return random integers from low (inclusive) to high (exclusive). random_integers(low[, high, size]) Random integers of type np.int between low and high, inclusive. random_sample([size]) Return random floats in the half-open interval [0.0, 1.0). random([size]) Return random floats in the half-open interval [0.0, 1.0).äº§ç”ŸéšæœºçŸ©é˜µï¼Œå¦‚random.random([2,3])äº§ç”Ÿä¸€ä¸ª2x3ç»´çš„éšæœºæ•° ranf([size]) Return random floats in the half-open interval [0.0, 1.0). sample([size]) Return random floats in the half-open interval [0.0, 1.0). choice(a[, size, replace, p]) Generates a random sample from a given 1-D array bytes(length) Return random bytes.","categories":[{"name":"è¯»ä¹¦ç¬”è®°","slug":"è¯»ä¹¦ç¬”è®°","permalink":"http://blog.a-stack.com/categories/è¯»ä¹¦ç¬”è®°/"},{"name":"æœºå™¨è§†è§‰","slug":"è¯»ä¹¦ç¬”è®°/æœºå™¨è§†è§‰","permalink":"http://blog.a-stack.com/categories/è¯»ä¹¦ç¬”è®°/æœºå™¨è§†è§‰/"}],"tags":[{"name":"è¯»ä¹¦ç¬”è®°","slug":"è¯»ä¹¦ç¬”è®°","permalink":"http://blog.a-stack.com/tags/è¯»ä¹¦ç¬”è®°/"},{"name":"AI","slug":"AI","permalink":"http://blog.a-stack.com/tags/AI/"},{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"æœºå™¨è§†è§‰","slug":"æœºå™¨è§†è§‰","permalink":"http://blog.a-stack.com/tags/æœºå™¨è§†è§‰/"}]},{"title":"æ·±åº¦å­¦ä¹ åŸºç¡€ä¹‹æ­£åˆ™åŒ–","slug":"æ·±åº¦å­¦ä¹ åŸºç¡€ä¹‹æ­£åˆ™åŒ–","date":"2018-03-04T07:35:01.000Z","updated":"2018-05-15T09:14:33.716Z","comments":true,"path":"2018/03/04/æ·±åº¦å­¦ä¹ åŸºç¡€ä¹‹æ­£åˆ™åŒ–/","link":"","permalink":"http://blog.a-stack.com/2018/03/04/æ·±åº¦å­¦ä¹ åŸºç¡€ä¹‹æ­£åˆ™åŒ–/","excerpt":"æ˜ç¡®ä»»åŠ¡ç›®æ ‡å’Œè¯„ä»·å‡†åˆ™å¯¹äºæ¨¡å‹çš„è®¾è®¡åŠä¼˜åŒ–è‡³å…³é‡è¦ï¼Œæœ¬æ–‡å°†æ€»ç»“å¸¸ç”¨çš„ç›¸å…³æ–¹æ³•å’Œæ¨¡å‹æ€§èƒ½è¯„ä»·å‡†åˆ™ã€‚ä¸ºäº†ç®€åŒ–ï¼Œæœ¬æ–‡å°†ä¸»è¦é’ˆå¯¹å›å½’é—®é¢˜å’Œåˆ†ç±»é—®é¢˜åˆ†åˆ«äºˆä»¥å½’çº³ï¼Œå…¶å®ƒé—®é¢˜å¯é‡‡å–ç±»ä¼¼çš„æ–¹æ³•åŠæ‰‹æ®µã€‚","text":"æ˜ç¡®ä»»åŠ¡ç›®æ ‡å’Œè¯„ä»·å‡†åˆ™å¯¹äºæ¨¡å‹çš„è®¾è®¡åŠä¼˜åŒ–è‡³å…³é‡è¦ï¼Œæœ¬æ–‡å°†æ€»ç»“å¸¸ç”¨çš„ç›¸å…³æ–¹æ³•å’Œæ¨¡å‹æ€§èƒ½è¯„ä»·å‡†åˆ™ã€‚ä¸ºäº†ç®€åŒ–ï¼Œæœ¬æ–‡å°†ä¸»è¦é’ˆå¯¹å›å½’é—®é¢˜å’Œåˆ†ç±»é—®é¢˜åˆ†åˆ«äºˆä»¥å½’çº³ï¼Œå…¶å®ƒé—®é¢˜å¯é‡‡å–ç±»ä¼¼çš„æ–¹æ³•åŠæ‰‹æ®µã€‚ @toc è¿‡æ‹Ÿåˆä¸€ç›´æ˜¯æ·±åº¦å­¦ä¹ ç®—æ³•è®­ç»ƒè¿‡ç¨‹ä¸­å¿…é¡»è¦é¢å¯¹çš„ä¸€ä¸ªéš¾é¢˜ï¼Œè€Œæ­£åˆ™åŒ–æ˜¯é™ä½æ¨¡å‹è¿‡æ‹Ÿåˆçš„æœ‰æ•ˆæ‰‹æ®µï¼Œè¿™ç¯‡ç¬”è®°ç”¨äºå½’çº³æ­£åˆ™åŒ–çš„å…³é”®æŠ€æœ¯ã€‚ æ·±åº¦å­¦ä¹ åŸºç¡€ç¯‡å°†ä»å‡ ä¸ªä¸åŒçš„å±‚é¢æ¥æ€»ç»“åœ¨è¿‡å»ä¸€æ®µæ—¶é—´å¯¹äºæ·±åº¦å­¦ä¹ å…³é”®æŠ€æœ¯çš„ç†è§£ï¼Œé€šè¿‡çŸ¥è¯†ä½“ç³»çš„å½’çº³äº†è§£çŸ¥è¯†ä½“ç³»çš„ä¸è¶³ï¼Œæå‡å¯¹æ ¸å¿ƒæŠ€æœ¯ç‚¹çš„è®¤è¯†ã€‚æ‰€æœ‰ç³»åˆ—æ–‡ç« å°†åœ¨æœªæ¥ä¸€æ®µæ—¶é—´å†…å®¹éšç€æŒæ¡äº†è§£çš„æ·±å…¥è¿­ä»£æ›´æ–°ã€‚ç›®å‰ä¸»è¦å¸Œæœ›å¯¹å¦‚ä¸‹å‡ ä¸ªé¢†åŸŸè¿›è¡Œå½’çº³æ±‡æ€»ï¼š é—®é¢˜å®šä¹‰ ç›®æ ‡åŠè¯„ä¼° æ•°æ®å‡†å¤‡ä¸é¢„å¤„ç† æ¿€æ´»å‡½æ•°çš„å½’çº³åŠæ€»ç»“ ä¼˜åŒ–ç®—æ³•çš„å½’çº³åŠæ€»ç»“ æ­£åˆ™åŒ–ä¸æ³›åŒ–æ€§èƒ½ æ¨¡å‹å‹ç¼© æ•°æ®æ‰©å…… ä»æ¬ æ‹Ÿåˆå’Œè¿‡æ‹ŸåˆèŠèµ· é‡è¯» Andrew Wuçš„è¯¾ç¨‹ â€œæ³›åŒ–æŒ‡çš„æ˜¯ä¸€ä¸ªå‡è®¾æ¨¡å‹èƒ½å¤Ÿåº”ç”¨åˆ°æ–°æ ·æœ¬çš„èƒ½åŠ›ã€‚ è§£å†³è¿‡æ‹Ÿåˆæ–¹æ³•ä¸€ï¼šå°½é‡å‡å°‘é€‰å–å˜é‡çš„æ•°é‡ å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬å¯ä»¥äººå·¥æ£€æŸ¥æ¯ä¸€é¡¹å˜é‡ï¼Œå¹¶ä»¥æ­¤æ¥ç¡®å®šå“ªäº›å˜é‡æ›´ä¸ºé‡è¦ï¼Œç„¶åï¼Œä¿ç•™é‚£äº›æ›´ä¸ºé‡è¦çš„ç‰¹å¾å˜é‡ã€‚è‡³äºï¼Œå“ªäº›å˜é‡åº”è¯¥èˆå¼ƒï¼Œæˆ‘ä»¬ä»¥ååœ¨è®¨è®ºï¼Œè¿™ä¼šæ¶‰åŠåˆ°æ¨¡å‹é€‰æ‹©ç®—æ³•ï¼Œè¿™ç§ç®—æ³•æ˜¯å¯ä»¥è‡ªåŠ¨é€‰æ‹©é‡‡ç”¨å“ªäº›ç‰¹å¾å˜é‡ï¼Œè‡ªåŠ¨èˆå¼ƒä¸éœ€è¦çš„å˜é‡ã€‚è¿™ç±»åšæ³•éå¸¸æœ‰æ•ˆï¼Œä½†æ˜¯å…¶ç¼ºç‚¹æ˜¯å½“ä½ èˆå¼ƒä¸€éƒ¨åˆ†ç‰¹å¾å˜é‡æ—¶ï¼Œä½ ä¹Ÿèˆå¼ƒäº†é—®é¢˜ä¸­çš„ä¸€äº›ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œä¹Ÿè®¸æ‰€æœ‰çš„ç‰¹å¾å˜é‡å¯¹äºé¢„æµ‹æˆ¿ä»·éƒ½æ˜¯æœ‰ç”¨çš„ï¼Œæˆ‘ä»¬å®é™…ä¸Šå¹¶ä¸æƒ³èˆå¼ƒä¸€äº›ä¿¡æ¯æˆ–è€…è¯´èˆå¼ƒè¿™äº›ç‰¹å¾å˜é‡ã€‚ æ–¹æ³•äºŒï¼šæ­£åˆ™åŒ– æ­£åˆ™åŒ–ä¸­æˆ‘ä»¬å°†ä¿ç•™æ‰€æœ‰çš„ç‰¹å¾å˜é‡ï¼Œä½†æ˜¯ä¼šå‡å°ç‰¹å¾å˜é‡çš„æ•°é‡çº§ï¼ˆå‚æ•°æ•°å€¼çš„å¤§å°Î¸(j)ï¼‰ã€‚ è¿™ä¸ªæ–¹æ³•éå¸¸æœ‰æ•ˆï¼Œå½“æˆ‘ä»¬æœ‰å¾ˆå¤šç‰¹å¾å˜é‡æ—¶ï¼Œå…¶ä¸­æ¯ä¸€ä¸ªå˜é‡éƒ½èƒ½å¯¹é¢„æµ‹äº§ç”Ÿä¸€ç‚¹å½±å“ã€‚æ­£å¦‚æˆ‘ä»¬åœ¨æˆ¿ä»·é¢„æµ‹çš„ä¾‹å­ä¸­çœ‹åˆ°çš„é‚£æ ·ï¼Œæˆ‘ä»¬å¯ä»¥æœ‰å¾ˆå¤šç‰¹å¾å˜é‡ï¼Œå…¶ä¸­æ¯ä¸€ä¸ªå˜é‡éƒ½æ˜¯æœ‰ç”¨çš„ï¼Œå› æ­¤æˆ‘ä»¬ä¸å¸Œæœ›æŠŠå®ƒä»¬åˆ æ‰ï¼Œè¿™å°±å¯¼è‡´äº†æ­£åˆ™åŒ–æ¦‚å¿µçš„å‘ç”Ÿã€‚ æ‰¹é‡æ­£åˆ™åŒ–ï¼ˆBatch Normalizationï¼‰ \\hat x_i = \\frac{x_i -\\mu_\\beta}{\\sqrt{\\sigma_\\beta^2 + \\epsilon}}å…¶ä¸­ï¼Œ \\mu_\\beta = \\frac{1}{M}\\sum_{i=1}^m{x_i} \\quad \\sigma_\\beta^2=\\frac{1}{m}\\sum_{i=1}^m{(x_i-\\mu_\\beta)^2}æ•°æ®å¢å¼º(Data Augmentation)ç›®çš„ï¼šé€šè¿‡è½»å¾®çš„æ”¹å˜æ ·æœ¬æ•°æ®ï¼Œå¢å¼ºæ¨¡å‹è¾“å…¥æ•°æ®çš„æ³›åŒ–ç‰¹æ€§ï¼Œå¸Œæœ›è®©æ¨¡å‹å­¦åˆ°æ›´åŠ é²æ£’çš„ç‰¹å¾è¡¨è¾¾æ–¹å¼ã€‚ é€šè¿‡ä¸€å®šç¨‹åº¦çš„é™ä½è®­ç»ƒç²¾åº¦ï¼Œæå‡æ³›åŒ–æ€§èƒ½ã€‚ Figure 2.1: Left: A sample of 250 data points that follow a normal distribution exactly. Right: Adding a small amount of random â€œjitterâ€ to the distribution. This type of data augmentation can increase the generalizability of our networks. å¦‚å›¾æ‰€ç¤ºï¼Œç°å®ç”Ÿæ´»ä¸­çš„æ•°æ®åˆ†å¸ƒå¾ˆéš¾åƒæ ‡å‡†æ­£æ€åˆ†å¸ƒä¸€æ ·å®Œç¾ï¼Œå·¦å›¾é€šè¿‡åœ¨æ¯ä¸ªç»´åº¦ä¸Šå¢åŠ ä¸€å®šçš„æŠ–åŠ¨æ¥æå‡ç³»ç»Ÿçš„æ³›åŒ–èƒ½åŠ›ï¼Œå½“å‰ç³»ç»Ÿä»ç„¶è¿‘ä¼¼ç¬¦åˆæ­£æ€åˆ†å¸ƒã€‚ å¸¸ç”¨çš„æ•°æ®æ”¾å¤§æ‰‹æ®µæœ‰ï¼š ä»¿å°„å˜æ¢ï¼› æ—‹è½¬ï¼› ç¼©æ”¾ï¼› è£å‰ªï¼ˆShearingï¼‰,å¦‚random cropï¼šé‡‡ç”¨éšæœºå›¾åƒå·®å€¼æ–¹å¼ï¼Œå¯¹å›¾åƒè¿›è¡Œè£å‰ªã€ç¼©æ”¾ï¼›åŒ…æ‹¬Scale Jitteringæ–¹æ³•ï¼ˆVGGåŠResNetæ¨¡å‹ä½¿ç”¨ï¼‰æˆ–è€…å°ºåº¦å’Œé•¿å®½æ¯”å¢å¼ºå˜æ¢ï¼› æ°´å¹³/å‚ç›´ç¿»è½¬ï¼› å¹³ç§»ï¼› è‰²å½©ç©ºé—´å˜æ¢(Color Jittering): å›¾åƒäº®åº¦ã€é¥±å’Œåº¦ã€å¯¹æ¯”åº¦å˜åŒ–ï¼› PCA Jittering: é¦–å…ˆæŒ‰ç…§RGBä¸‰ä¸ªé¢œè‰²é€šé“è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®ï¼Œå†åœ¨æ•´ä¸ªè®­ç»ƒé›†ä¸Šè®¡ç®—åæ–¹å·®çŸ©é˜µï¼Œè¿›è¡Œç‰¹å¾åˆ†è§£ï¼Œå¾—åˆ°ç‰¹å¾å‘é‡å’Œç‰¹å¾å€¼ï¼Œç”¨æ¥åšPCA Jitteringï¼› å™ªå£°å¤„ç†ï¼Œé«˜æ–¯å™ªå£°ï¼Œæ¨¡ç³Šå¤„ç† Kerasä¸­çš„æ•°æ®å¢å¼ºKerasä¸­æä¾›äº†keras.preprocessing.image.ImageDataGeneratorç”¨äºå¯¹å›¾ç‰‡è¿›è¡Œé¢„å¤„ç†ã€‚ 123456789101112131415161718192021222324252627282930313233# import the necessary packagesfrom keras.preprocessing.image import ImageDataGenerator from keras.preprocessing.image import img_to_array from keras.preprocessing.image import load_img import numpy as np import argparse# load the input image, convert it to a NumPy array, and then # reshape it to have an extra dimension print(\"[INFO] loading example image...\")image = load_img(args[\"image\"]) image = img_to_array(image)image = np.expand_dims(image, axis=0)# construct the image generator for data augmentation then# initialize the total number of images generated thus far aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode=\"nearest\")total = 0# construct the actual Python generator print(\"[INFO] generating images...\")imageGen = aug.flow(image, batch_size=1, save_to_dir=args[\"output\"], save_prefix=args[\"prefix\"], save_format=\"jpg\")# loop over examples from our image data augmentation generator for image in imageGen:# increment our counter total += 1 # if we have reached 10 examples, break from the loop if total == 10: break #Training TimeH = model.fit_generator(aug.flow(trainX, trainY, batch_size=32), validation_data=(testX, testY), steps_per_epoch=len(trainX) // 32, epochs=100, verbose=1) ImageDataGeneratorçš„å¸¸ç”¨å‚æ•°ï¼š rotation_range : éšæœºæ—‹è½¬è§’åº¦ï¼Œæ¯”å¦‚30Â°ï¼› width_shift_rangeå’Œheight_shift_rangeï¼Œæ§åˆ¶å®½åº¦å’Œé«˜åº¦çš„åç§»æ¯”ä¾‹ï¼Œä¾‹å­ä¸­0.1=10%çš„å˜åŠ¨å¹…åº¦ï¼› shear_range: zoom_rangeï¼š[1-zoom_range, 1+zoom_range]èŒƒå›´â€˜ horizontal_flip: flowæ–¹æ³•ï¼šflow(self, X, y, batch_size=32, shuffle=True, seed=None, save_to_dir=None, save_prefix=&#39;&#39;, save_format=&#39;png&#39;), æ¥æ”¶numpyæ•°ç»„å’Œæ ‡ç­¾ä¸ºå‚æ•°ï¼Œç”Ÿæˆç»è¿‡æ•°æ®å¢å¼ºçš„batchæ•°æ®ï¼Œå¹¶åœ¨ä¸€ä¸ªæ— é™å¾ªç¯ä¸­ä¸æ–­çš„è¿”å›batch_sizeçš„æ•°æ® å‚è€ƒ Kerasæ–‡æ¡£ deep learning for computer vision with python Machine Learning Lessons by Andrew","categories":[{"name":"æ·±åº¦å­¦ä¹ ","slug":"æ·±åº¦å­¦ä¹ ","permalink":"http://blog.a-stack.com/categories/æ·±åº¦å­¦ä¹ /"},{"name":"åŸºç¡€çŸ¥è¯†","slug":"æ·±åº¦å­¦ä¹ /åŸºç¡€çŸ¥è¯†","permalink":"http://blog.a-stack.com/categories/æ·±åº¦å­¦ä¹ /åŸºç¡€çŸ¥è¯†/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://blog.a-stack.com/tags/AI/"},{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"æ­£åˆ™åŒ–","slug":"æ­£åˆ™åŒ–","permalink":"http://blog.a-stack.com/tags/æ­£åˆ™åŒ–/"}]},{"title":"Deep Learning for Computer Vision","slug":"Deep-Learning-for-Computer-Vision","date":"2018-03-03T14:12:49.000Z","updated":"2018-05-23T12:44:00.535Z","comments":true,"path":"2018/03/03/Deep-Learning-for-Computer-Vision/","link":"","permalink":"http://blog.a-stack.com/2018/03/03/Deep-Learning-for-Computer-Vision/","excerpt":"","text":"æœ¬æ–‡è®°å½•æ·±åº¦å­¦ä¹ ä¹¦ç±ã€ŠDeep Learning for Computer Vision with Pythonã€‹çš„è¯»ä¹¦ç¬”è®°ã€‚ @toc èƒŒæ™¯ æ·±åº¦å­¦ä¹ æ‹¥æœ‰60å¤šå¹´å†å²ï¼Œè™½ç„¶æ›¾ç»é‡‡ç”¨è¿‡ä¸åŒçš„åç§°å’Œä¸åŒçš„ä¸»å¯¼æŠ€æœ¯ï¼šâ€œdeep learningâ€ has existed since the 1940s undergoing various name changes, including cybernetics, connectionism, and the most familiar, Artificial Neural Networks (ANNs). ç¥ç»ç½‘ç»œçš„æ™®é€‚å®šå¾‹ï¼šFurther research demonstrated that neural networks are universal approximators , capable of approximating any continuous function (but placing no guarantee on whether or not the network can actually learn the parameters required to represent a function). Classic machine learning algorithms for unsupervised learning include Principle Component Analysis (PCA) and k-means clustering. Specific to neural networks, we see Autoencoders, Self-Organizing Maps (SOMs), and Adaptive Resonance Theory applied to unsupervised learning. Popular choices for semisupervised learning include label spreading, label propagation, ladder networks, and co-learning/co-training. Image and Pixels Pixels are represented in two ways: Grayscale: Each pixel is a scalar value between 0 and 255.ï¼ˆ0 for â€œBlackâ€ and 255 for â€œWhiteâ€ï¼‰ï¼Œ0â€”&gt;255 dark â€”&gt; light Color: RGB color space, (R,G,B), Each Red, Green, and Blue channel can have values defined in the range [0,255] for a total of 256 â€œshadesâ€, where 0 indicates no representation and 255 demonstrates full representation. Given that the pixel value only needs to be in the range [0,255], we normally use 8-bit unsigned integers to represent the intensity. Images as Numpy Arrays (height, width, depth) è¡¨ç¤º height æ’ç¬¬ä¸€çš„ä¸»è¦åŸå› æ˜¯ç”±äºçŸ©é˜µè¡¨ç¤ºå½¢å¼ä¸­ï¼Œä¸€èˆ¬æŠŠè¡Œæ”¾åœ¨å‰é¢ï¼Œè€Œå›¾åƒä¸­heightå¤§å°è¡¨å¾äº†è¡Œçš„æ•°ç›®ã€‚ 123456import cv2image = cv2.imread(\"example.png\") print(image.shape)cv2.imshow(\"Image\", image)cv2.waitKey(0)## Access an individual pixel value(b, g, r) = image[20, 100] # accesses pixel at x=100, y=20 å–åƒç´ yåœ¨xå‰é¢ï¼Œè¿˜æ˜¯ç”±äºçŸ©é˜µçš„è¡¨ç¤ºå½¢å¼ï¼› RGBé¡ºåºåçš„ï¼Œè¿™æ˜¯ç”±äºOpenCVå†å²åŸå› å¯¼è‡´çš„è¡¨ç¤ºå½¢å¼å·®å¼‚: Because the BGR ordering was popular among camera manufacturers and other software developers at the time. Othersaspect ratio: the ratio of the width to the height of the image. ç¥ç»ç½‘ç»œæ¨¡å‹ä¸€èˆ¬éƒ½æ˜¯å›ºå®šè¾“å…¥ï¼Œæ¯”å¦‚32Ã—32, 64Ã—64, 224Ã—224, 227Ã—227, 256Ã—256, and 299Ã—299. éœ€è¦å¯¹ä¸åŒå¤§å°çš„å›¾åƒè¿›è¡Œreshapeæ“ä½œï¼ŒFor some datasets you can simply ignore the aspect ratio and squish, distort, and compress your images prior to feeding them through your network. On other datasets, itâ€™s advantageous to preprocess them further by resizing along the shortest dimension and then cropping the center. Image Classificationå›¾åƒåˆ†ç±»å’Œå›¾åƒç†è§£æ˜¯å½“ä»ŠæŠ€æœ¯è§†è§‰é¢†åŸŸæœ€ç«çš„è¯¾é¢˜ã€‚ å®šä¹‰å›¾åƒåˆ†ç±»ï¼š the task of assigning a label to an image from a predefined set ofcategories. å›¾åƒåˆ†ç±»çš„è¿‡ç¨‹æ˜¯å­¦ä¹ å›¾ç‰‡ä¸­çš„â€œunderlying patternsâ€ Semantic Gapï¼š the difference between how a human perceives the contents of an image versus how an image can be represented in a way a computer can understand the process. æŒ‘æˆ˜ æ•°æ®é›†(TODO) MNIST ç›®æ ‡ï¼š å®Œæˆ0-9æ‰‹å†™å­—ç¬¦çš„è¯†åˆ« è¯´æ˜ï¼š NISTä»£è¡¨National Institute ofStandards and Technologyï¼Œ Mä»£è¡¨Modified æ·±åº¦å­¦ä¹ çš„Hello World åŒ…å«60,000è®­ç»ƒæ ·æœ¬ï¼Œ10,000æµ‹è¯•æ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬ä¸º28x28çš„ç°åº¦å›¾åƒ ç›®å‰å‡†ç¡®åº¦ï¼š &gt;99% è·å–åœ°å€ï¼š http://yann.lecun.com/exdb/mnist/ Fashion-MNIST ç›®æ ‡ï¼š å®Œæˆ10ç§ä¸åŒè¡£æœçš„è¯†åˆ« è¯´æ˜ï¼š æ ¹æ®MNISTè®¾è®¡çš„æ–°çš„æ•°æ®é›†ï¼Œéš¾åº¦æ¯”MNISTç•¥é«˜ åŒ…å«60,000è®­ç»ƒæ ·æœ¬ï¼Œ10,000æµ‹è¯•æ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬ä¸º28x28çš„ç°åº¦å›¾åƒ ç›®å‰å‡†ç¡®åº¦ï¼š &gt;95% è·å–åœ°å€ï¼š https://github.com/zalandoresearch/fashion-mnist CIFAR-10 Animalsï¼š Dogsï¼ŒCatï¼Œ Pandas Flowers-17 CALtECH-101 Tiny ImageNet 200 Adience ImageNet è¡¨æƒ…è¯†åˆ«(æ˜¯å¦ç¬‘è„¸) è¯´æ˜ï¼š å…±è®¡13165å¼ ç°åº¦å›¾ç‰‡ï¼Œæ¯å¼ å›¾ç‰‡å¤§å°ä¸º64x64 åˆ†ä¸ºç¬‘è„¸å’Œéç¬‘è„¸ä¸¤ç±»ï¼Œå…¶ä¸­ç¬‘è„¸3690å¼ ï¼Œéç¬‘è„¸9475å¼ ï¼ˆæ•°æ®ä¸å¹³è¡¡ï¼‰ è·å–åœ°å€ï¼šhttps://github.com/hromi/SMILEsmileD å¦å¤–fer2013æä¾›äº†æ›´å¤šè¡¨æƒ…çš„è®­ç»ƒç”¨æ•°æ®é›† æ€§åˆ«å’Œå¹´é¾„æ•°æ®é›† IMDB-WIKI â€“ 500k+ face images with age and gender labels è·å–åœ°å€ï¼š https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/ Indoor CVPR Stanford Cars â€¦ ç¥ç»ç½‘ç»œåŸºç¡€ä¼˜åŒ–ç®—æ³•ï¼ˆTODOï¼Œæ•´åˆåˆ°å•ç‹¬Noteï¼‰ Chapter 8 Regularization (TODO, æ•´åˆåˆ°å•ç‹¬Note) Chapter 9 chapter 10,æ¿€æ´»å‡½æ•°ï¼Œperception ä¸ºä»€ä¹ˆéªŒè¯æŸå¤±å‡½æ•°å€¼æœ‰æ—¶å€™å°äºè®­ç»ƒæŸå¤±å‡½æ•°è¿™å¯èƒ½æ˜¯æœ‰å‡ æ–¹é¢åŸå› å¯¼è‡´çš„ï¼Œæˆ–å¤šæ–¹é¢åŸå› ç»¼åˆä½œç”¨çš„ç»“æœï¼Œä¸»è¦çš„åŸå› åŒ…æ‹¬ï¼š è®­ç»ƒé›†å’ŒéªŒè¯é›†åˆ†å¸ƒä¸å‡ï¼Œå¯¼è‡´è®­ç»ƒé›†æ•°æ®éš¾åº¦å¤§ï¼ŒéªŒè¯é›†ç®€å•æ•°æ®åˆ†å¸ƒæ¯”ä¾‹å¤§ï¼› æ•°æ®æ”¾å¤§æœ¬èº«å½¢æˆäº†ä¸€ç§è§„åˆ™åŒ–ï¼Œé™ä½äº†è®­ç»ƒé›†çš„è®­ç»ƒç»“æœï¼›ï¼ˆè¿™æœ¬èº«æ˜¯è§„åˆ™åŒ–çš„ç›®æ ‡ï¼Œé™ä½åœ¨è®­ç»ƒé›†çš„è¡¨ç°ï¼Œæå‡æ³›åŒ–æ€§èƒ½ï¼‰ è®­ç»ƒæ—¶é—´æˆ–è½®æ•°ä¸å¤Ÿï¼› å…³äºå­¦ä¹ ç‡ kerasä¸­æä¾›äº†decayå‚æ•°æ¥è°ƒèŠ‚å­¦ä¹ ç‡çš„å˜åŒ–æƒ…å†µï¼š 1opt = SGD(lr=0.01, decay=0.01 / 40, momentum=0.9, nesterov=True) ä½¿ç”¨å…¬å¼ï¼š \\alpha_{e+1} = \\alpha_e \\times 1 /(1+\\gamma * e) å¦ä¸€ç§å­¦ä¹ ç‡ä¸ºé˜¶æ¢¯å­¦ä¹ ç‡ï¼šctrl + c Kerasæä¾›ä¸€ä¸ªç±»ï¼šLearningrateScheduleræ¥é…ç½®è‡ªå®šä¹‰çš„å­¦ä¹ ç‡å‡½æ•° æ¯”å¦‚ï¼š \\alpha_{E+1} = \\alpha_1 \\times F^{(1+E)/D}1234567891011121314def step_decay(epoch): # initialize the base initial learning rate, drop factor, and epochs to drop every initAlpha = 0.01 factor = 0.25 dropEvery = 5 # compute learning rate for the current epoch alpha = initAlpha * (factor ** np.floor((1 + epoch) / dropEvery)) # return the learning rate return float(alpha) ##å®šä¹‰callbackcallbacks = [LearningRateScheduler(step_decay)] å½“å®šä¹‰äº†å­¦ä¹ ç‡ä¹‹åï¼ŒSGDä¸­å£°æ˜çš„é…ç½®ä¿¡æ¯å°†è¢«å¿½ç•¥ ç½‘ç»œæ¨¡å‹VGG æ‰€æœ‰çš„å·ç§¯å±‚ä½¿ç”¨åŒä¸€ç§å·ç§¯æ ¸ï¼š3X3 å †ç§¯å¤šä¸ªCONV=&gt;RELUå±‚å†è¿›è¡Œä¸€æ¬¡POOLæ“ä½œ MNISTResearchers tend to use the MNIST dataset as a benchmark to evaluate new classification algorithms. If their methods cannot obtain &gt; 95% classification accuracy, then there is either a flaw in (1) the logic of the algorithm or (2) the implementation itself. Case Study ä½¿ç”¨OpenCVçš„Haar cascade ç®—æ³•è¿›è¡Œäººè„¸æ£€æµ‹ï¼Œæå–äººè„¸çš„ROI(Region of intrest), é€šè¿‡ä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œè¿›è¡Œè¡¨æƒ…è¯†åˆ«ï¼› å¯ä»¥ç»“åˆGithubå¼€æºçš„è¡¨æƒ…è¯†åˆ«ä»£ç ä¸€èµ·ç ”ç©¶ è·¯å¾„å¤„ç† os.path.sepï¼š æå–è·¯å¾„åˆ†éš”ç¬¦ æ•°æ®ä¸å¹³è¡¡çš„å¤„ç†ï¼Œå¯ä»¥è€ƒè™‘ä¸åŒåˆ†ç±»çš„æƒé‡ï¼Œåœ¨è®­ç»ƒæ—¶é€šè¿‡èµ‹æƒè°ƒæ•´å¹³è¡¡æ€§ï¼Œä»£ç å¦‚ä¸‹ï¼š 12345678# Handle data imbalance# account for skew in the labeled dataclassTotals = labels.sum(axis=0)classWeight = classTotals.max() / classTotals## When trainingH = model.fit(trainX, trainY, validation_data=(testX, testY), class_weight=classWeight, batch_size=64, epochs=15, verbose=1) æ‰‹å†™å­—çš„é¢„å¤„ç†1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950def preprocess(image, width, height): #grap the dimensions of the image, then initialize the padding values (h, w) = image.shape[:2] #if width greater than height, resize along the width if w &gt; h: image = imutils.resize(iamge, width=width) else: image = imutils.resize(image, height=height) #padding values for w and h to obtain the target dimensions padW = int((width - image.shape[1])/2.0) padH = int((height - image.shape[0])/2.0) #pad the image then apply one more resizing to handle any rounding issues image = cv2.copyMakeBorder(image, padH, padH, padW, padW, cv2.BORDER_REPLICATE) iamge = cv2.resize(image, (width, height)) return imageimage = cv2.imread(img)gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)gray = cv2.copyMakeBorder(gray, 20,20,20,20, cv2.BORDER_REPLICATE)# threshold the image to reveal the digitsthresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]#find contours in the image, keeping only the four largest onescnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)cnts = cnts[0] if imutils.is_cv2() else cnts[1]cnts = sorted(cnts, key=cv2.contourArea, reverse=True)[:4]cnts = contours.sort_contours(cnts)[0]# initialize the output image as a \"grayscale\" image with 3# channels along with the output predictionsoutput = cv2.merge([gray] * 3)for c in cnts: # compute the bounding box for the contour then extract the # digit (x, y, w, h) = cv2.boundingRect(c) roi = gray[y - 5:y + h + 5, x - 5:x + w + 5] roi = preprocess(roi, 28, 28) roi = np.expand_dims(img_to_array(roi), axis=0) / 255.0 #pred = model.predict(roi).argmax(axis=1)[0] + 1 #predictions.append(str(pred)) # draw the prediction on the output image cv2.rectangle(output, (x - 2, y - 2),(x + w + 4, y + h + 4), (0, 255, 0), 1) #cv2.putText(output, str(pred), (x - 5, y - 5),cv2.FONT_HERSHEY_SIMPLEX, 0.55, (0, 255, 0), 2)# show the output image#print(\"[INFO] captcha: &#123;&#125;\".format(\"\".join(predictions)))plt.imshow(output)#cv2.waitKey() Useful Functionså›¾åƒé¢„å¤„ç†åŠåŠ è½½æ¨¡æ¿123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596'''File1: Preprocessor'''import cv2class SimplePreporcessor: def __init__(self, width, height, inter=cv2.INTER_AREA)ï¼š # store the target image width, height, and interpolation method used when resizing self.width = width self.height = height self.inter = inter def preprocess(self, image): # resize the image to a fixed size, ignoring the aspect ratio return cv2.resize(image, (self.width, self.height), interpolation = self.inter)'''Data Loader'''# import the necessary packages import numpy as np import cv2 import osclass SimpleDatasetLoader: def __init__(self, preprocessors=None): self.preprocessors = preprocessors # if the preprocessors are None, initialize them as an empty list if self.preprocessors is None: self.preprocessors = [] def load(self, imagePaths, verbose =-1): data = [] labels = [] for (i, imagePath) in enumerate(imagePaths): # load the image and extract the class label assuming # # that our path has the following format: # # /path/to/dataset/&#123;class&#125;/&#123;image&#125;.jpg image = cv2.imread(imagePath) label = imagePath.split(os.path.sep)[-2] # check to see if our preprocessors are not None if self.preprocessors is not None: for p in self.preprocessors: image = p.preprocess(image) data.append(image) labels.append(label) # show an update every â€˜verboseâ€˜ images if verbose &gt;0 and i &gt;0 and (i+1)%verbose == 0: print(\"[INFON] process &#123;&#125;/&#123;&#125;\").format(i+1,len(imagePaths)) # return a tuple of the data and labels return (np.array(data), np.array(labels))'''Main'''# import the necessary packagesfrom sklearn.neighbors import KNeighborsClassifier from sklearn.preprocessing import LabelEncoder from sklearn.model_selection import train_test_split from sklearn.metrics import classification_reportfrom imutils import paths import argparse# construct the argument parse and parse the arguments ap = argparse.ArgumentParser()ap.add_argument(\"-d\", \"--dataset\", required=True, help=\"path to input dataset\")ap.add_argument(\"-k\", \"--neighbors\", type=int, default=1, help=\"# of nearest neighbors for classification\") ap.add_argument(\"-j\", \"--jobs\", type=int, default=-1, help=\"# of jobs for k-NN distance (-1 uses all available cores)\")args = vars(ap.parse_args())print(\"[INFO] loading images ...\")imagePaths = list(paths.list_images(args[\"dataset\"]))# initialize the image preprocessor, load the dataset from disk,# and reshape the data matrixsp = SimplePreporcessor(32, 32)sdl = SimpleDatasetLoader(preprocessors=[sp])(data, labels) = sdl.load(imagePaths, verbose=500)#flatten for use in KNNdata = data.reshape((data.shape[0],32*32*3))print(\"[INFO] feature matrix: &#123;:.1f&#125;MB\").format(data.nbytes/(1024*1000.0))# encode the labels as integersle = LabelEncoder()labels = le.fit_transform(labels)(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)# train and evaluate a kNN classifier on raw pixel intensitiesprint(\"[INFO] evaluate kNN classifier ...\")model = KNeighborsClassifier(n_neighbors=args[\"neighbors\"]), n_jobs=args[\"jobs\"])model.fit(trainX, trainY)print(classification_report(testY, model.predict(testX),target_names==le.classes_)) sklearn.metrics.classification_reportsklearnä¸­çš„classification_reportå‡½æ•°ç”¨äºæ˜¾ç¤ºä¸»è¦åˆ†ç±»æŒ‡æ ‡çš„æ–‡æœ¬æŠ¥å‘Šï¼åœ¨æŠ¥å‘Šä¸­æ˜¾ç¤ºæ¯ä¸ªç±»çš„ç²¾ç¡®åº¦ï¼Œå¬å›ç‡ï¼ŒF1å€¼ç­‰ä¿¡æ¯ã€‚ä¸»è¦å‚æ•°: y_trueï¼š1ç»´æ•°ç»„ï¼Œæˆ–æ ‡ç­¾æŒ‡ç¤ºå™¨æ•°ç»„/ç¨€ç–çŸ©é˜µï¼Œç›®æ ‡å€¼ã€‚ y_predï¼š1ç»´æ•°ç»„ï¼Œæˆ–æ ‡ç­¾æŒ‡ç¤ºå™¨æ•°ç»„/ç¨€ç–çŸ©é˜µï¼Œåˆ†ç±»å™¨è¿”å›çš„ä¼°è®¡å€¼ã€‚ labelsï¼šarrayï¼Œshape = [n_labels]ï¼ŒæŠ¥è¡¨ä¸­åŒ…å«çš„æ ‡ç­¾ç´¢å¼•çš„å¯é€‰åˆ—è¡¨ã€‚ target_namesï¼šå­—ç¬¦ä¸²åˆ—è¡¨ï¼Œä¸æ ‡ç­¾åŒ¹é…çš„å¯é€‰æ˜¾ç¤ºåç§°ï¼ˆç›¸åŒé¡ºåºï¼‰ã€‚ sample_weightï¼šç±»ä¼¼äºshape = [n_samples]çš„æ•°ç»„ï¼Œå¯é€‰é¡¹ï¼Œæ ·æœ¬æƒé‡ã€‚ digitsï¼šintï¼Œè¾“å‡ºæµ®ç‚¹å€¼çš„ä½æ•°ï¼ 12345from sklearn.metrics import classification_reporty_true = [0, 1, 2, 2, 2]y_pred = [0, 0, 2, 2, 1]target_names = ['class 0', 'class 1', 'class 2']print(classification_report(y_true, y_pred, target_names=target_names)) opencv ç»™å›¾åƒæ·»åŠ æè¿°123import cv2# draw the label with the highest score on the image as our # predictioncv2.putText(orig, \"Label: &#123;&#125;\".format(labels[np.argmax(scores)]), (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2) Kerasä¸­çš„Checkpointæœºåˆ¶12345678910111213from keras.callbacks import ModelCheckpoint# construct the callback to save only the *best* model to disk# based on the validation lossfname = os.path.sep.join([args[\"weights\"], \"weights-&#123;epoch:03d&#125;-&#123;val_loss:.4f&#125;.hdf5\"])checkpoint = ModelCheckpoint(fname, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1)callbacks = [checkpoint]print(\"[INFO] training network...\")H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, epochs=40, callbacks=callbacks, verbose=2) å‚æ•°ï¼š filenameï¼šå­—ç¬¦ä¸²ï¼Œä¿å­˜æ¨¡å‹çš„è·¯å¾„ monitorï¼šéœ€è¦ç›‘è§†çš„å€¼ verboseï¼šä¿¡æ¯å±•ç¤ºæ¨¡å¼ï¼Œ0æˆ–1 save_best_onlyï¼šå½“è®¾ç½®ä¸ºTrueæ—¶ï¼Œå°†åªä¿å­˜åœ¨éªŒè¯é›†ä¸Šæ€§èƒ½æœ€å¥½çš„æ¨¡å‹ modeï¼šâ€˜autoâ€™ï¼Œâ€˜minâ€™ï¼Œâ€˜maxâ€™ä¹‹ä¸€ï¼Œåœ¨save_best_only=Trueæ—¶å†³å®šæ€§èƒ½æœ€ä½³æ¨¡å‹çš„è¯„åˆ¤å‡†åˆ™ï¼Œä¾‹å¦‚ï¼Œå½“ç›‘æµ‹å€¼ä¸ºval_accæ—¶ï¼Œæ¨¡å¼åº”ä¸ºmaxï¼Œå½“æ£€æµ‹å€¼ä¸ºval_lossæ—¶ï¼Œæ¨¡å¼åº”ä¸ºminã€‚åœ¨autoæ¨¡å¼ä¸‹ï¼Œè¯„ä»·å‡†åˆ™ç”±è¢«ç›‘æµ‹å€¼çš„åå­—è‡ªåŠ¨æ¨æ–­ã€‚ save_weights_onlyï¼šè‹¥è®¾ç½®ä¸ºTrueï¼Œåˆ™åªä¿å­˜æ¨¡å‹æƒé‡ï¼Œå¦åˆ™å°†ä¿å­˜æ•´ä¸ªæ¨¡å‹ï¼ˆåŒ…æ‹¬æ¨¡å‹ç»“æ„ï¼Œé…ç½®ä¿¡æ¯ç­‰ï¼‰ periodï¼šCheckPointä¹‹é—´çš„é—´éš”çš„epochæ•° å¯ä»¥monitor losså€¼ä¹Ÿå¯ä»¥æ˜¯val_accï¼Œtrain_loss, train_acc; æ›´å¤šå†…å®¹å‚è§ï¼šhttp://keras-cn.readthedocs.io/en/latest/other/callbacks/ EarlyStopping1keras.callbacks.EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto') å½“ç›‘æµ‹å€¼ä¸å†æ”¹å–„æ—¶ï¼Œè¯¥å›è°ƒå‡½æ•°å°†ä¸­æ­¢è®­ç»ƒ å‚æ•° monitorï¼šéœ€è¦ç›‘è§†çš„é‡ patienceï¼šå½“early stopè¢«æ¿€æ´»ï¼ˆå¦‚å‘ç°lossç›¸æ¯”ä¸Šä¸€ä¸ªepochè®­ç»ƒæ²¡æœ‰ä¸‹é™ï¼‰ï¼Œåˆ™ç»è¿‡patienceä¸ªepochååœæ­¢è®­ç»ƒã€‚ verboseï¼šä¿¡æ¯å±•ç¤ºæ¨¡å¼ modeï¼šâ€˜autoâ€™ï¼Œâ€˜minâ€™ï¼Œâ€˜maxâ€™ä¹‹ä¸€ï¼Œåœ¨minæ¨¡å¼ä¸‹ï¼Œå¦‚æœæ£€æµ‹å€¼åœæ­¢ä¸‹é™åˆ™ä¸­æ­¢è®­ç»ƒã€‚åœ¨maxæ¨¡å¼ä¸‹ï¼Œå½“æ£€æµ‹å€¼ä¸å†ä¸Šå‡åˆ™åœæ­¢è®­ç»ƒã€‚ åŸºäºkeras callbackå®ç°è®­ç»ƒè¿‡ç¨‹ç›‘æ§1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# import the necessary packagesfrom keras.callbacks import BaseLoggerimport matplotlib.pyplot as pltimport numpy as npimport jsonimport osclass TrainingMonitor(BaseLogger): def __init__(self, figPath, jsonPath=None, startAt=0): # store the output path for the figure, the path to the JSON serialized file, and the starting epoch super(TrainingMonitor, self).__init__() self.figPath = figPath self.jsonPath = jsonPath self.startAt = startAt def on_train_begin(self, logs=&#123;&#125;): # initialize the history dictionary self.H = &#123;&#125; # if the JSON history path exists, load the training history if self.jsonPath is not None: if os.path.exists(self.jsonPath): self.H = json.loads(open(self.jsonPath).read()) # check to see if a starting epoch was supplied if self.startAt &gt; 0: # loop over the entries in the history log and # trim any entries that are past the starting # epoch for k in self.H.keys(): self.H[k] = self.H[k][:self.startAt] def on_epoch_end(self, epoch, logs=&#123;&#125;): # loop over the logs and update the loss, accuracy, etc. # for the entire training process for (k, v) in logs.items(): l = self.H.get(k, []) l.append(v) self.H[k] = l # check to see if the training history should be serialized # to file if self.jsonPath is not None: f = open(self.jsonPath, \"w\") f.write(json.dumps(self.H)) f.close() # ensure at least two epochs have passed before plotting # (epoch starts at zero) if len(self.H[\"loss\"]) &gt; 1: #plot the training loss and accuracy N = np.arange(0, len(self.H[\"loss\"])) plt.style.use(\"ggplot\") plt.figure() plt.plot(N, self.H[\"loss\"], label=\"train_loss\") plt.plot(N, self.H[\"val_loss\"], label=\"val_loss\") plt.plot(N, self.H[\"acc\"], label=\"train_acc\") plt.plot(N, self.H[\"val_acc\"], label=\"val_acc\") plt.title(\"Training Loss and Accuracy [Epoch &#123;&#125;]\".format(len(self.H[\"loss\"]))) plt.xlabel(\"Epoch #\") plt.ylabel(\"Loss/Accuracy\") plt.legend() #save the figure plt.savefig(self.figPath) plt.close() figPath: The path to the output plot that we can use to visualize loss and accuracy over time. jsonPath: An optional path used to serialize the loss and accuracy values as a JSON file. This path is useful if you want to use the training history to create custom plots of your own. startAt: This is the starting epoch that training is resumed at when using ctrl + c training. å‚è€ƒ","categories":[{"name":"è¯»ä¹¦ç¬”è®°","slug":"è¯»ä¹¦ç¬”è®°","permalink":"http://blog.a-stack.com/categories/è¯»ä¹¦ç¬”è®°/"},{"name":"æœºå™¨è§†è§‰","slug":"è¯»ä¹¦ç¬”è®°/æœºå™¨è§†è§‰","permalink":"http://blog.a-stack.com/categories/è¯»ä¹¦ç¬”è®°/æœºå™¨è§†è§‰/"}],"tags":[{"name":"è¯»ä¹¦ç¬”è®°","slug":"è¯»ä¹¦ç¬”è®°","permalink":"http://blog.a-stack.com/tags/è¯»ä¹¦ç¬”è®°/"},{"name":"AI","slug":"AI","permalink":"http://blog.a-stack.com/tags/AI/"},{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"æœºå™¨è§†è§‰","slug":"æœºå™¨è§†è§‰","permalink":"http://blog.a-stack.com/tags/æœºå™¨è§†è§‰/"}]},{"title":"æ·±åº¦å­¦ä¹ åŸºç¡€ä¹‹ç›®æ ‡åŠè¯„ä¼°","slug":"æ·±åº¦å­¦ä¹ åŸºç¡€ä¹‹ç›®æ ‡åŠè¯„ä¼°","date":"2018-03-02T07:35:01.000Z","updated":"2018-06-26T05:47:28.380Z","comments":true,"path":"2018/03/02/æ·±åº¦å­¦ä¹ åŸºç¡€ä¹‹ç›®æ ‡åŠè¯„ä¼°/","link":"","permalink":"http://blog.a-stack.com/2018/03/02/æ·±åº¦å­¦ä¹ åŸºç¡€ä¹‹ç›®æ ‡åŠè¯„ä¼°/","excerpt":"æ˜ç¡®ä»»åŠ¡ç›®æ ‡å’Œè¯„ä»·å‡†åˆ™å¯¹äºæ¨¡å‹çš„è®¾è®¡åŠä¼˜åŒ–è‡³å…³é‡è¦ï¼Œæœ¬æ–‡å°†æ€»ç»“å¸¸ç”¨çš„ç›¸å…³æ–¹æ³•å’Œæ¨¡å‹æ€§èƒ½è¯„ä»·å‡†åˆ™ã€‚ä¸ºäº†ç®€åŒ–ï¼Œæœ¬æ–‡å°†ä¸»è¦é’ˆå¯¹å›å½’é—®é¢˜å’Œåˆ†ç±»é—®é¢˜åˆ†åˆ«äºˆä»¥å½’çº³ï¼Œå…¶å®ƒé—®é¢˜å¯é‡‡å–ç±»ä¼¼çš„æ–¹æ³•åŠæ‰‹æ®µã€‚","text":"æ˜ç¡®ä»»åŠ¡ç›®æ ‡å’Œè¯„ä»·å‡†åˆ™å¯¹äºæ¨¡å‹çš„è®¾è®¡åŠä¼˜åŒ–è‡³å…³é‡è¦ï¼Œæœ¬æ–‡å°†æ€»ç»“å¸¸ç”¨çš„ç›¸å…³æ–¹æ³•å’Œæ¨¡å‹æ€§èƒ½è¯„ä»·å‡†åˆ™ã€‚ä¸ºäº†ç®€åŒ–ï¼Œæœ¬æ–‡å°†ä¸»è¦é’ˆå¯¹å›å½’é—®é¢˜å’Œåˆ†ç±»é—®é¢˜åˆ†åˆ«äºˆä»¥å½’çº³ï¼Œå…¶å®ƒé—®é¢˜å¯é‡‡å–ç±»ä¼¼çš„æ–¹æ³•åŠæ‰‹æ®µã€‚ @toc æ·±åº¦å­¦ä¹ åŸºç¡€ç¯‡å°†ä»å‡ ä¸ªä¸åŒçš„å±‚é¢æ¥æ€»ç»“åœ¨è¿‡å»ä¸€æ®µæ—¶é—´å¯¹äºæ·±åº¦å­¦ä¹ å…³é”®æŠ€æœ¯çš„ç†è§£ï¼Œé€šè¿‡çŸ¥è¯†ä½“ç³»çš„å½’çº³äº†è§£çŸ¥è¯†ä½“ç³»çš„ä¸è¶³ï¼Œæå‡å¯¹æ ¸å¿ƒæŠ€æœ¯ç‚¹çš„è®¤è¯†ã€‚æ‰€æœ‰ç³»åˆ—æ–‡ç« å°†åœ¨æœªæ¥ä¸€æ®µæ—¶é—´å†…å®¹éšç€æŒæ¡äº†è§£çš„æ·±å…¥è¿­ä»£æ›´æ–°ã€‚ç›®å‰ä¸»è¦å¸Œæœ›å¯¹å¦‚ä¸‹å‡ ä¸ªé¢†åŸŸè¿›è¡Œå½’çº³æ±‡æ€»ï¼š é—®é¢˜å®šä¹‰ ç›®æ ‡åŠè¯„ä¼° æ•°æ®å‡†å¤‡ä¸é¢„å¤„ç† æ¿€æ´»å‡½æ•°çš„å½’çº³åŠæ€»ç»“ ä¼˜åŒ–ç®—æ³•çš„å½’çº³åŠæ€»ç»“ æ­£åˆ™åŒ–ä¸æ³›åŒ–æ€§èƒ½ æ¨¡å‹å‹ç¼© æ•°æ®æ‰©å…… æ¦‚è¿°æœºå™¨å­¦ä¹ ä¸­çš„æ‰€æœ‰ç®—æ³•éƒ½ä¾èµ–äºæœ€å°åŒ–æˆ–æœ€å¤§åŒ–æŸä¸€ä¸ªå‡½æ•°ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºâ€œç›®æ ‡å‡½æ•°â€ã€‚æœ€å°åŒ–çš„è¿™ç»„å‡½æ•°è¢«ç§°ä¸ºâ€œæŸå¤±å‡½æ•°â€ã€‚æŸå¤±å‡½æ•°æ˜¯è¡¡é‡é¢„æµ‹æ¨¡å‹é¢„æµ‹æœŸæœ›ç»“æœè¡¨ç°çš„æŒ‡æ ‡ã€‚å¯»æ‰¾å‡½æ•°æœ€å°å€¼çš„æœ€å¸¸ç”¨æ–¹æ³•æ˜¯â€œæ¢¯åº¦ä¸‹é™â€ã€‚æœ¬æ–‡ä¸»è¦å¯¹ç›¸å…³çš„ç›®æ ‡å‡½æ•°/æŸå¤±å‡½æ•°çš„çŸ¥è¯†ç‚¹è¿›è¡Œå½’çº³å’Œæ€»ç»“ã€‚ æ²¡æœ‰ä¸€ä¸ªæŸå¤±å‡½æ•°å¯ä»¥é€‚ç”¨äºæ‰€æœ‰ç±»å‹çš„æ•°æ®ã€‚æŸå¤±å‡½æ•°çš„é€‰æ‹©å–å†³äºè®¸å¤šå› ç´ ï¼ŒåŒ…æ‹¬æ˜¯å¦æœ‰ç¦»ç¾¤ç‚¹ï¼Œæœºå™¨å­¦ä¹ ç®—æ³•çš„é€‰æ‹©ï¼Œè¿è¡Œæ¢¯åº¦ä¸‹é™çš„æ—¶é—´æ•ˆç‡ï¼Œæ˜¯å¦æ˜“äºæ‰¾åˆ°å‡½æ•°çš„å¯¼æ•°ï¼Œä»¥åŠé¢„æµ‹ç»“æœçš„ç½®ä¿¡åº¦ã€‚è¿™ä¸ªåšå®¢çš„ç›®çš„æ˜¯å¸®åŠ©ä½ äº†è§£ä¸åŒçš„æŸå¤±å‡½æ•°ã€‚ æŸå¤±å‡½æ•°å¯ä»¥å¤§è‡´åˆ†ä¸ºä¸¤ç±»ï¼šåˆ†ç±»æŸå¤±ï¼ˆClassificationLossï¼‰å’Œå›å½’æŸå¤±ï¼ˆRegression Lossï¼‰ã€‚ åˆ†ç±»é—®é¢˜åŸºç¡€çŸ¥è¯†åˆ†ç±»é˜ˆå€¼çš„æ¦‚å¿µï¼šå°†é¢„æµ‹ç»“æœåˆ’åˆ†åˆ°æ¯ä¸ªç±»åˆ«çš„åˆ¤å®šé˜ˆå€¼ï¼Œæ¯”å¦‚äºŒåˆ†ç±»é—®é¢˜ä¸­å–ä¸º0.5ã€‚ é˜³æ€§ä¸é˜´æ€§å¦‚ä¸‹å›¾æ‰€ç¤ºçš„æ··æ·†çŸ©é˜µ æ··æ·†çŸ©é˜µ (confusion matrix)ä¸€ç§ NxN è¡¨æ ¼ï¼Œç”¨äºæ€»ç»“åˆ†ç±»æ¨¡å‹çš„é¢„æµ‹æˆæ•ˆï¼›å³æ ‡ç­¾å’Œæ¨¡å‹é¢„æµ‹çš„åˆ†ç±»ä¹‹é—´çš„å…³è”ã€‚åœ¨æ··æ·†çŸ©é˜µä¸­ï¼Œä¸€ä¸ªè½´è¡¨ç¤ºæ¨¡å‹é¢„æµ‹çš„æ ‡ç­¾ï¼Œå¦ä¸€ä¸ªè½´è¡¨ç¤ºå®é™…æ ‡ç­¾ã€‚N è¡¨ç¤ºç±»åˆ«ä¸ªæ•°ã€‚åœ¨äºŒå…ƒåˆ†ç±»é—®é¢˜ä¸­ï¼ŒN=2ã€‚ TP: çœŸæ­£ä¾‹ï¼Œæ˜¯æŒ‡æ¨¡å‹å°†æ­£ç±»åˆ«æ ·æœ¬æ­£ç¡®åœ°é¢„æµ‹ä¸ºæ­£ç±»åˆ«ã€‚ FPï¼šå‡æ­£ä¾‹ï¼Œæ˜¯æŒ‡æ¨¡å‹å°†è´Ÿç±»åˆ«æ ·æœ¬é”™è¯¯åœ°é¢„æµ‹ä¸ºæ­£ç±»åˆ«ï¼Œ FNï¼šå‡è´Ÿä¾‹ï¼Œæ˜¯æŒ‡æ¨¡å‹å°†æ­£ç±»åˆ«æ ·æœ¬é”™è¯¯åœ°é¢„æµ‹ä¸ºè´Ÿç±»åˆ«ã€‚ TNï¼šçœŸè´Ÿä¾‹ï¼Œæ˜¯æŒ‡æ¨¡å‹å°†è´Ÿç±»åˆ«æ ·æœ¬æ­£ç¡®åœ°é¢„æµ‹ä¸ºè´Ÿç±»åˆ«ã€‚ å‡†ç¡®ç‡å‡†ç¡®ç‡æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°åˆ†ç±»æ¨¡å‹çš„æŒ‡æ ‡ã€‚é€šä¿—æ¥è¯´ï¼Œå‡†ç¡®ç‡æ˜¯æŒ‡æˆ‘ä»¬çš„æ¨¡å‹é¢„æµ‹æ­£ç¡®çš„ç»“æœæ‰€å çš„æ¯”ä¾‹ã€‚å‡†ç¡®ç‡çš„å®šä¹‰å¦‚ä¸‹ï¼š Accuracy= \\frac{TP+TN}{TP+FP+TN+FN} ä»è¯†åˆ«ç»“æœçœ‹ï¼Œå…¶ä¸­è¯†åˆ«æ­£ç¡®çš„å æ¯”ä¸ºå¤šå°‘ å½“ä½¿ç”¨åˆ†ç±»ä¸å¹³è¡¡çš„æ•°æ®é›†ï¼ˆæ¯”å¦‚æ­£ç±»åˆ«æ ‡ç­¾å’Œè´Ÿç±»åˆ«æ ‡ç­¾çš„æ•°é‡ä¹‹é—´å­˜åœ¨æ˜æ˜¾å·®å¼‚ï¼‰æ—¶ï¼Œå•å•å‡†ç¡®ç‡ä¸€é¡¹å¹¶ä¸èƒ½åæ˜ å…¨é¢æƒ…å†µã€‚ ç²¾ç¡®ç‡ Precision = \\frac{TP}{TP+FP} åœ¨è¢«è¯†åˆ«ä¸ºæ­£ç±»åˆ«çš„æ ·æœ¬ä¸­ï¼Œç¡®å®ä¸ºæ­£ç±»åˆ«çš„æ¯”ä¾‹æ˜¯å¤šå°‘ï¼Ÿ å¬å›ç‡ Recall = \\frac{TP}{TP+FN} ä»æ‰€æœ‰æ­£ç¡®ç›®æ ‡å€¼çœ‹ï¼Œæœ‰å¤šå°‘ç›®æ ‡è¢«æ­£ç¡®çš„è¯†åˆ«å‡ºæ¥äº† ç²¾ç¡®ç‡å’Œå¬å›ç‡æ˜¯ä¸¤ä¸ªtrade-offçš„æŒ‡æ ‡ã€‚ F1æŒ‡æ ‡ F1 = 2 \\frac{Recall*Precision}{Recall + Precision} =\\frac{TP}{TP+(FN+FP)/2}ROCROC æ›²çº¿ï¼ˆæ¥æ”¶è€…æ“ä½œç‰¹å¾æ›²çº¿ï¼‰æ˜¯ä¸€ç§æ˜¾ç¤ºåˆ†ç±»æ¨¡å‹åœ¨æ‰€æœ‰åˆ†ç±»é˜ˆå€¼ä¸‹çš„æ•ˆæœçš„å›¾è¡¨ã€‚è¯¥æ›²çº¿ç»˜åˆ¶äº†ä»¥ä¸‹ä¸¤ä¸ªå‚æ•°ï¼š çœŸæ­£ä¾‹ç‡ å‡æ­£ä¾‹ç‡ çœŸæ­£ä¾‹ç‡ (TPR) æ˜¯å¬å›ç‡çš„åŒä¹‰è¯ï¼Œå› æ­¤å®šä¹‰å¦‚ä¸‹ï¼š $TPR = \\frac{TP} {TP + FN}$ å‡æ­£ä¾‹ç‡ (FPR) çš„å®šä¹‰å¦‚ä¸‹ï¼š $FPR = \\frac{FP} {FP + TN}$ ROC æ›²çº¿ç”¨äºç»˜åˆ¶é‡‡ç”¨ä¸åŒåˆ†ç±»é˜ˆå€¼æ—¶çš„ TPR ä¸ FPRã€‚é™ä½åˆ†ç±»é˜ˆå€¼ä¼šå¯¼è‡´å°†æ›´å¤šæ ·æœ¬å½’ä¸ºæ­£ç±»åˆ«ï¼Œä»è€Œå¢åŠ å‡æ­£ä¾‹å’ŒçœŸæ­£ä¾‹çš„ä¸ªæ•°ã€‚ä¸‹å›¾æ˜¾ç¤ºäº†ä¸€ä¸ªå…¸å‹çš„ ROC æ›²çº¿ã€‚ æ›²çº¿è¶Šé è¿‘å·¦ä¸Šæ–¹ï¼Œæ•ˆæœçº¦å¥½ï¼Œä»£è¡¨æ­£ç¡®åˆ†ç±»æ¯”ä¾‹è¶Šé«˜ï¼› å››ä¸ªå…³é”®åæ ‡ç‚¹ï¼š (0,0)ï¼š TP=FP=0ï¼Œå…¨éƒ¨é¢„æµ‹ç»“æœä¸ºåä¾‹ï¼› (1,1)ï¼š TN=FN=0, å…¨éƒ¨é¢„æµ‹ç»“æœä¸ºæ­£ä¾‹ï¼› (0,1): FP=FN=0, å…¨éƒ¨æ­£ç¡®åˆ†ç±»æ ·æœ¬ï¼› (1,0): TP=TN=0, å…¨éƒ¨é”™è¯¯åˆ†ç±»æ ·æœ¬ï¼› æ›²çº¿ä¸‹é¢ç§¯ï¼šROC æ›²çº¿ä¸‹é¢ç§¯æ›²çº¿ä¸‹é¢ç§¯è¡¨ç¤ºâ€œROC æ›²çº¿ä¸‹é¢ç§¯â€ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæ›²çº¿ä¸‹é¢ç§¯æµ‹é‡çš„æ˜¯ä» (0,0) åˆ° (1,1) ä¹‹é—´æ•´ä¸ª ROC æ›²çº¿ä»¥ä¸‹çš„æ•´ä¸ªäºŒç»´é¢ç§¯ï¼ˆå‚è€ƒç§¯åˆ†å­¦ï¼‰ã€‚ æ›²çº¿ä¸‹é¢ç§¯å¯¹æ‰€æœ‰å¯èƒ½çš„åˆ†ç±»é˜ˆå€¼çš„æ•ˆæœè¿›è¡Œç»¼åˆè¡¡é‡ã€‚æ›²çº¿ä¸‹é¢ç§¯çš„ä¸€ç§è§£è¯»æ–¹å¼æ˜¯çœ‹ä½œæ¨¡å‹å°†æŸä¸ªéšæœºæ­£ç±»åˆ«æ ·æœ¬æ’åˆ—åœ¨æŸä¸ªéšæœºè´Ÿç±»åˆ«æ ·æœ¬ä¹‹ä¸Šçš„æ¦‚ç‡ã€‚ä»¥ä¸‹é¢çš„æ ·æœ¬ä¸ºä¾‹ï¼Œé€»è¾‘å›å½’é¢„æµ‹ä»å·¦åˆ°å³ä»¥å‡åºæ’åˆ—ã€‚ æ›²çº¿ä¸‹é¢ç§¯è¡¨ç¤ºéšæœºæ­£ç±»åˆ«ï¼ˆç»¿è‰²ï¼‰æ ·æœ¬ä½äºéšæœºè´Ÿç±»åˆ«ï¼ˆçº¢è‰²ï¼‰æ ·æœ¬å³ä¾§çš„æ¦‚ç‡ã€‚ æ›²çº¿ä¸‹é¢ç§¯çš„å–å€¼èŒƒå›´ä¸º 0-1ã€‚é¢„æµ‹ç»“æœ 100% é”™è¯¯çš„æ¨¡å‹çš„æ›²çº¿ä¸‹é¢ç§¯ä¸º 0.0ï¼›è€Œé¢„æµ‹ç»“æœ 100% æ­£ç¡®çš„æ¨¡å‹çš„æ›²çº¿ä¸‹é¢ç§¯ä¸º 1.0ã€‚ æ›²çº¿ä¸‹é¢ç§¯å› ä»¥ä¸‹ä¸¤ä¸ªåŸå› è€Œæ¯”è¾ƒå®ç”¨ï¼š æ›²çº¿ä¸‹é¢ç§¯çš„å°ºåº¦ä¸å˜ã€‚å®ƒæµ‹é‡é¢„æµ‹çš„æ’åæƒ…å†µï¼Œè€Œä¸æ˜¯æµ‹é‡å…¶ç»å¯¹å€¼ã€‚ æ›²çº¿ä¸‹é¢ç§¯çš„åˆ†ç±»é˜ˆå€¼ä¸å˜ã€‚å®ƒæµ‹é‡æ¨¡å‹é¢„æµ‹çš„è´¨é‡ï¼Œè€Œä¸è€ƒè™‘æ‰€é€‰çš„åˆ†ç±»é˜ˆå€¼ã€‚ ä¸è¿‡ï¼Œè¿™ä¸¤ä¸ªåŸå› éƒ½æœ‰å„è‡ªçš„å±€é™æ€§ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´æ›²çº¿ä¸‹é¢ç§¯åœ¨æŸäº›ç”¨ä¾‹ä¸­ä¸å¤ªå®ç”¨ï¼š å¹¶éæ€»æ˜¯å¸Œæœ›å°ºåº¦ä¸å˜ã€‚ ä¾‹å¦‚ï¼Œæœ‰æ—¶æˆ‘ä»¬éå¸¸éœ€è¦è¢«è‰¯å¥½æ ¡å‡†çš„æ¦‚ç‡è¾“å‡ºï¼Œè€Œæ›²çº¿ä¸‹é¢ç§¯æ— æ³•å‘Šè¯‰æˆ‘ä»¬è¿™ä¸€ç»“æœã€‚ å¹¶éæ€»æ˜¯å¸Œæœ›åˆ†ç±»é˜ˆå€¼ä¸å˜ã€‚ åœ¨å‡è´Ÿä¾‹ä¸å‡æ­£ä¾‹çš„ä»£ä»·å­˜åœ¨è¾ƒå¤§å·®å¼‚çš„æƒ…å†µä¸‹ï¼Œå°½é‡å‡å°‘ä¸€ç§ç±»å‹çš„åˆ†ç±»é”™è¯¯å¯èƒ½è‡³å…³é‡è¦ã€‚ä¾‹å¦‚ï¼Œåœ¨è¿›è¡Œåƒåœ¾é‚®ä»¶æ£€æµ‹æ—¶ï¼Œæ‚¨å¯èƒ½å¸Œæœ›ä¼˜å…ˆè€ƒè™‘å°½é‡å‡å°‘å‡æ­£ä¾‹ï¼ˆå³ä½¿è¿™ä¼šå¯¼è‡´å‡è´Ÿä¾‹å¤§å¹…å¢åŠ ï¼‰ã€‚å¯¹äºæ­¤ç±»ä¼˜åŒ–ï¼Œæ›²çº¿ä¸‹é¢ç§¯å¹¶éä¸€ä¸ªå®ç”¨çš„æŒ‡æ ‡ã€‚ é¢„æµ‹åå·®é¢„æµ‹åå·®æŒ‡çš„æ˜¯è¿™ä¸¤ä¸ªå¹³å‡å€¼ä¹‹é—´çš„å·®å€¼ã€‚å³ï¼šé¢„æµ‹åå·®é¢„æµ‹å¹³å‡å€¼æ•°æ®é›†ä¸­ç›¸åº”æ ‡ç­¾çš„å¹³å‡å€¼ é€ æˆé¢„æµ‹åå·®çš„å¯èƒ½åŸå› åŒ…æ‹¬ï¼š ç‰¹å¾é›†ä¸å®Œæ•´ æ•°æ®é›†æ··ä¹± æ¨¡å‹å®ç°æµæ°´çº¿ä¸­æœ‰é”™è¯¯ï¼Ÿ è®­ç»ƒæ ·æœ¬æœ‰åå·® æ­£åˆ™åŒ–è¿‡å¼º å›å½’æŸå¤±å‡½æ•°å‡æ–¹è¯¯å·®ï¼ˆMean Square Errorï¼ŒMSEï¼‰å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰æ˜¯æœ€å¸¸ç”¨çš„å›å½’æŸå¤±å‡½æ•°ï¼Œä¹Ÿå«L2 Lossã€‚MSEæ˜¯ç›®æ ‡å˜é‡ä¸é¢„æµ‹å€¼ä¹‹é—´è·ç¦»å¹³æ–¹ä¹‹å’Œã€‚ MSE = \\frac{\\sum_{i=1}^n (\\hat y - y_{true})^2}{n}ä¸‹é¢æ˜¯ä¸€ä¸ªMSEå‡½æ•°çš„å›¾ï¼Œå…¶ä¸­çœŸå®ç›®æ ‡å€¼ä¸º100ï¼Œé¢„æµ‹å€¼åœ¨-10,000è‡³10,000ä¹‹é—´ã€‚é¢„æµ‹å€¼ï¼ˆXè½´ï¼‰=100æ—¶ï¼ŒMSEæŸå¤±ï¼ˆYè½´ï¼‰è¾¾åˆ°å…¶æœ€å°å€¼ã€‚æŸå¤±èŒƒå›´ä¸º0è‡³âˆã€‚ å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMean Absolute Errorï¼Œ L1 Lossï¼‰å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰æ˜¯å¦ä¸€ç§ç”¨äºå›å½’æ¨¡å‹çš„æŸå¤±å‡½æ•°ï¼Œä¹Ÿå«åšL1 Lossã€‚MAEæ˜¯ç›®æ ‡å˜é‡å’Œé¢„æµ‹å˜é‡ä¹‹é—´å·®å¼‚ç»å¯¹å€¼ä¹‹å’Œã€‚å› æ­¤ï¼Œå®ƒåœ¨ä¸€ç»„é¢„æµ‹ä¸­è¡¡é‡è¯¯å·®çš„å¹³å‡å¤§å°ï¼Œè€Œä¸è€ƒè™‘è¯¯å·®çš„æ–¹å‘ã€‚ï¼ˆå¦‚æœæˆ‘ä»¬ä¹Ÿè€ƒè™‘æ–¹å‘ï¼Œé‚£å°†è¢«ç§°ä¸ºå¹³å‡åå·®ï¼ˆMean Bias Error, MBEï¼‰ï¼Œå®ƒæ˜¯æ®‹å·®æˆ–è¯¯å·®ä¹‹å’Œï¼‰ã€‚æŸå¤±èŒƒå›´ä¹Ÿæ˜¯0åˆ°âˆã€‚ MAE = \\frac{\\sum_{i=1}^n |\\hat y - y_{true}|}{n} MSE vs MAE ç®€è€Œè¨€ä¹‹ï¼Œ ä½¿ç”¨å¹³æ–¹è¯¯å·®æ›´å®¹æ˜“æ±‚è§£ï¼Œä½†ä½¿ç”¨ç»å¯¹è¯¯å·®å¯¹ç¦»ç¾¤ç‚¹æ›´åŠ é²æ£’ã€‚ æ¯å½“æˆ‘ä»¬è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬çš„ç›®æ ‡å°±æ˜¯æ‰¾åˆ°æœ€å°åŒ–æŸå¤±å‡½æ•°çš„ç‚¹ã€‚å½“ç„¶ï¼Œå½“é¢„æµ‹å€¼æ­£å¥½ç­‰äºçœŸå®å€¼æ—¶ï¼Œè¿™ä¸¤ä¸ªæŸå¤±å‡½æ•°éƒ½è¾¾åˆ°æœ€å°å€¼ã€‚ä¸‹é¢è®©æˆ‘ä»¬å¿«é€Ÿè¿‡ä¸€éä¸¤ä¸ªæŸå¤±å‡½æ•°çš„Pythonä»£ç ã€‚æˆ‘ä»¬å¯ä»¥ç¼–å†™è‡ªå·±çš„å‡½æ•°æˆ–ä½¿ç”¨sklearnçš„å†…ç½®åº¦é‡å‡½æ•°ï¼š 1234567891011# trueï¼šçœŸæ­£çš„ç›®æ ‡å˜é‡æ•°ç»„# predï¼šé¢„æµ‹æ•°ç»„def mse(true, pred): return np.sum(((true â€“ pred)**2)) def mae(true, pred): return np.sum(np.abs(true â€“ pred))# ä¹Ÿå¯ä»¥åœ¨sklearnä¸­ä½¿ç”¨from sklearn.metrics import mean_squared_errorfrom sklearn.metrics import mean_absolute_error è®©æˆ‘ä»¬æ¥çœ‹çœ‹ä¸¤ä¸ªä¾‹å­çš„MAEå€¼å’ŒRMSEå€¼ï¼ˆRMSEï¼ŒRoot Mean Square Errorï¼Œå‡æ–¹æ ¹è¯¯å·®ï¼Œå®ƒåªæ˜¯MSEçš„å¹³æ–¹æ ¹ï¼Œä½¿å…¶ä¸MAEçš„æ•°å€¼èŒƒå›´ç›¸åŒï¼‰ã€‚åœ¨ç¬¬ä¸€ä¸ªä¾‹å­ä¸­ï¼Œé¢„æµ‹å€¼æ¥è¿‘çœŸå®å€¼ï¼Œè§‚æµ‹å€¼ä¹‹é—´è¯¯å·®çš„æ–¹å·®è¾ƒå°ã€‚ç¬¬äºŒä¸ªä¾‹å­ä¸­ï¼Œæœ‰ä¸€ä¸ªå¼‚å¸¸è§‚æµ‹å€¼ï¼Œè¯¯å·®å¾ˆé«˜ã€‚ æˆ‘ä»¬ä»ä¸­è§‚å¯Ÿåˆ°ä»€ä¹ˆï¼Ÿæˆ‘ä»¬è¯¥å¦‚ä½•é€‰æ‹©ä½¿ç”¨å“ªç§æŸå¤±å‡½æ•°ï¼Ÿç”±äºMSEå¯¹è¯¯å·®ï¼ˆeï¼‰è¿›è¡Œå¹³æ–¹æ“ä½œï¼ˆy - y_predicted = eï¼‰ï¼Œå¦‚æœe&gt;1ï¼Œè¯¯å·®çš„å€¼ä¼šå¢åŠ å¾ˆå¤šã€‚å¦‚æœæˆ‘ä»¬çš„æ•°æ®ä¸­æœ‰ä¸€ä¸ªç¦»ç¾¤ç‚¹ï¼Œeçš„å€¼å°†ä¼šå¾ˆé«˜ï¼Œå°†ä¼šè¿œè¿œå¤§äº|e|ã€‚è¿™å°†ä½¿å¾—å’Œä»¥MAEä¸ºæŸå¤±çš„æ¨¡å‹ç›¸æ¯”ï¼Œä»¥MSEä¸ºæŸå¤±çš„æ¨¡å‹ä¼šèµ‹äºˆæ›´é«˜çš„æƒé‡ç»™ç¦»ç¾¤ç‚¹ã€‚åœ¨ä¸Šé¢çš„ç¬¬äºŒä¸ªä¾‹å­ä¸­ï¼Œä»¥RMSEä¸ºæŸå¤±çš„æ¨¡å‹å°†è¢«è°ƒæ•´ä»¥æœ€å°åŒ–è¿™ä¸ªç¦»ç¾¤æ•°æ®ç‚¹ï¼Œä½†æ˜¯å´æ˜¯ä»¥ç‰ºç‰²å…¶ä»–æ­£å¸¸æ•°æ®ç‚¹çš„é¢„æµ‹æ•ˆæœä¸ºä»£ä»·ï¼Œè¿™æœ€ç»ˆä¼šé™ä½æ¨¡å‹çš„æ•´ä½“æ€§èƒ½ã€‚ MAEæŸå¤±é€‚ç”¨äºè®­ç»ƒæ•°æ®è¢«ç¦»ç¾¤ç‚¹æŸåçš„æ—¶å€™ï¼ˆå³ï¼Œåœ¨è®­ç»ƒæ•°æ®è€Œéæµ‹è¯•æ•°æ®ä¸­ï¼Œæˆ‘ä»¬é”™è¯¯åœ°è·å¾—äº†ä¸åˆ‡å®é™…çš„è¿‡å¤§æ­£å€¼æˆ–è´Ÿå€¼ï¼‰ã€‚ ç›´è§‚æ¥è¯´ï¼Œæˆ‘ä»¬å¯ä»¥åƒè¿™æ ·è€ƒè™‘ï¼šå¯¹æ‰€æœ‰çš„è§‚æµ‹æ•°æ®ï¼Œå¦‚æœæˆ‘ä»¬åªç»™ä¸€ä¸ªé¢„æµ‹ç»“æœæ¥æœ€å°åŒ–MSEï¼Œé‚£ä¹ˆè¯¥é¢„æµ‹å€¼åº”è¯¥æ˜¯æ‰€æœ‰ç›®æ ‡å€¼çš„å‡å€¼ã€‚ä½†æ˜¯å¦‚æœæˆ‘ä»¬è¯•å›¾æœ€å°åŒ–MAEï¼Œé‚£ä¹ˆè¿™ä¸ªé¢„æµ‹å°±æ˜¯æ‰€æœ‰ç›®æ ‡å€¼çš„ä¸­ä½æ•°ã€‚æˆ‘ä»¬çŸ¥é“ä¸­ä½æ•°å¯¹äºç¦»ç¾¤ç‚¹æ¯”å¹³å‡å€¼æ›´é²æ£’ï¼Œè¿™ä½¿å¾—MAEæ¯”MSEæ›´åŠ é²æ£’ã€‚ ä½¿ç”¨MAEæŸå¤±ï¼ˆç‰¹åˆ«æ˜¯å¯¹äºç¥ç»ç½‘ç»œï¼‰çš„ä¸€ä¸ªå¤§é—®é¢˜æ˜¯å®ƒçš„æ¢¯åº¦å§‹ç»ˆæ˜¯ç›¸åŒçš„ï¼Œè¿™æ„å‘³ç€å³ä½¿å¯¹äºå°çš„æŸå¤±å€¼ï¼Œå…¶æ¢¯åº¦ä¹Ÿæ˜¯å¤§çš„ã€‚è¿™å¯¹æ¨¡å‹çš„å­¦ä¹ å¯ä¸å¥½ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨éšç€æ¥è¿‘æœ€å°å€¼è€Œå‡å°çš„åŠ¨æ€å­¦ä¹ ç‡ã€‚MSEåœ¨è¿™ç§æƒ…å†µä¸‹çš„è¡¨ç°å¾ˆå¥½ï¼Œå³ä½¿é‡‡ç”¨å›ºå®šçš„å­¦ä¹ ç‡ä¹Ÿä¼šæ”¶æ•›ã€‚MSEæŸå¤±çš„æ¢¯åº¦åœ¨æŸå¤±å€¼è¾ƒé«˜æ—¶ä¼šæ¯”è¾ƒå¤§ï¼Œéšç€æŸå¤±æ¥è¿‘0æ—¶è€Œä¸‹é™ï¼Œä»è€Œä½¿å…¶åœ¨è®­ç»ƒç»“æŸæ—¶æ›´åŠ ç²¾ç¡®ï¼ˆå‚è§ä¸‹å›¾ï¼‰ã€‚ å¦‚ä½•é€‰æ‹©ï¼Ÿå¦‚æœç¦»ç¾¤ç‚¹æ˜¯ä¼šå½±å“ä¸šåŠ¡ã€è€Œä¸”æ˜¯åº”è¯¥è¢«æ£€æµ‹åˆ°çš„å¼‚å¸¸å€¼ï¼Œé‚£ä¹ˆæˆ‘ä»¬åº”è¯¥ä½¿ç”¨MSEã€‚å¦ä¸€æ–¹é¢ï¼Œå¦‚æœæˆ‘ä»¬è®¤ä¸ºç¦»ç¾¤ç‚¹ä»…ä»…ä»£è¡¨æ•°æ®æŸåï¼Œé‚£ä¹ˆæˆ‘ä»¬åº”è¯¥é€‰æ‹©MAEä½œä¸ºæŸå¤±ã€‚ L1æŸå¤±å¯¹å¼‚å¸¸å€¼æ›´åŠ ç¨³å¥ï¼Œä½†å…¶å¯¼æ•°å¹¶ä¸è¿ç»­ï¼Œå› æ­¤æ±‚è§£æ•ˆç‡å¾ˆä½ã€‚L2æŸå¤±å¯¹å¼‚å¸¸å€¼æ•æ„Ÿï¼Œä½†ç»™å‡ºäº†æ›´ç¨³å®šçš„é—­å¼è§£ï¼ˆclosedform solutionï¼‰ï¼ˆé€šè¿‡å°†å…¶å¯¼æ•°è®¾ç½®ä¸º0ï¼‰ã€‚ ä¸¤ç§æŸå¤±å‡½æ•°çš„é—®é¢˜ï¼šå¯èƒ½ä¼šå‡ºç°è¿™æ ·çš„æƒ…å†µï¼Œå³ä»»ä½•ä¸€ç§æŸå¤±å‡½æ•°éƒ½ä¸èƒ½ç»™å‡ºç†æƒ³çš„é¢„æµ‹ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æ•°æ®ä¸­90ï¼…çš„è§‚æµ‹æ•°æ®çš„çœŸå®ç›®æ ‡å€¼æ˜¯150ï¼Œå…¶ä½™10ï¼…çš„çœŸå®ç›®æ ‡å€¼åœ¨0-30ä¹‹é—´ã€‚é‚£ä¹ˆï¼Œä¸€ä¸ªä»¥MAEä¸ºæŸå¤±çš„æ¨¡å‹å¯èƒ½å¯¹æ‰€æœ‰è§‚æµ‹æ•°æ®éƒ½é¢„æµ‹ä¸º150ï¼Œè€Œå¿½ç•¥10ï¼…çš„ç¦»ç¾¤æƒ…å†µï¼Œå› ä¸ºå®ƒä¼šå°è¯•å»æ¥è¿‘ä¸­å€¼ã€‚åŒæ ·åœ°ï¼Œä»¥MSEä¸ºæŸå¤±çš„æ¨¡å‹ä¼šç»™å‡ºè®¸å¤šèŒƒå›´åœ¨0åˆ°30çš„é¢„æµ‹ï¼Œå› ä¸ºå®ƒè¢«ç¦»ç¾¤ç‚¹å¼„ç³Šæ¶‚äº†ã€‚è¿™ä¸¤ç§ç»“æœåœ¨è®¸å¤šä¸šåŠ¡ä¸­éƒ½æ˜¯ä¸å¯å–çš„ã€‚ å¹³æ»‘çš„å¹³å‡ç»å¯¹è¯¯å·®å‡½æ•°ï¼ˆHuber Lossï¼‰Huber Losså¯¹æ•°æ®ç¦»ç¾¤ç‚¹çš„æ•æ„Ÿåº¦ä½äºå¹³æ–¹è¯¯å·®æŸå¤±ã€‚å®ƒåœ¨0å¤„ä¹Ÿå¯å¯¼ã€‚åŸºæœ¬ä¸Šå®ƒæ˜¯ç»å¯¹è¯¯å·®ï¼Œå½“è¯¯å·®å¾ˆå°æ—¶ï¼Œè¯¯å·®æ˜¯äºŒæ¬¡å½¢å¼çš„ã€‚è¯¯å·®ä½•æ—¶éœ€è¦å˜æˆäºŒæ¬¡å½¢å¼å–å†³äºä¸€ä¸ªè¶…å‚æ•°ï¼Œ(delta)ï¼Œè¯¥è¶…å‚æ•°å¯ä»¥è¿›è¡Œå¾®è°ƒã€‚å½“ ğ›¿ ~ 0æ—¶ï¼ŒHuber Lossæ¥è¿‘MAEï¼Œå½“ ğ›¿ ~ âˆï¼ˆå¾ˆå¤§çš„æ•°ï¼‰æ—¶ï¼ŒHuber Lossæ¥è¿‘MSEã€‚ deltaçš„é€‰æ‹©éå¸¸é‡è¦ï¼Œå› ä¸ºå®ƒå†³å®šäº†ä½ è®¤ä¸ºä»€ä¹ˆæ•°æ®æ˜¯ç¦»ç¾¤ç‚¹ã€‚å¤§äºdeltaçš„æ®‹å·®ç”¨L1æœ€å°åŒ–ï¼ˆå¯¹è¾ƒå¤§çš„ç¦»ç¾¤ç‚¹è¾ƒä¸æ•æ„Ÿï¼‰ï¼Œè€Œå°äºdeltaçš„æ®‹å·®åˆ™å¯ä»¥â€œå¾ˆåˆé€‚åœ°â€ç”¨L2æœ€å°åŒ–ã€‚ ä¸ºä»€ä¹ˆä½¿ç”¨Huber Lossï¼Ÿä½¿ç”¨MAEè®­ç»ƒç¥ç»ç½‘ç»œçš„ä¸€ä¸ªå¤§é—®é¢˜æ˜¯ç»å¸¸ä¼šé‡åˆ°å¾ˆå¤§çš„æ¢¯åº¦ï¼Œä½¿ç”¨æ¢¯åº¦ä¸‹é™æ—¶å¯èƒ½å¯¼è‡´è®­ç»ƒç»“æŸæ—¶é”™è¿‡æœ€å°å€¼ã€‚å¯¹äºMSEï¼Œæ¢¯åº¦ä¼šéšç€æŸå¤±æ¥è¿‘æœ€å°å€¼è€Œé™ä½ï¼Œä»è€Œä½¿å…¶æ›´åŠ ç²¾ç¡®ã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒHuberLosså¯èƒ½ä¼šéå¸¸æœ‰ç”¨ï¼Œå› ä¸ºå®ƒä¼šä½¿æœ€å°å€¼é™„è¿‘å¼¯æ›²ï¼Œä»è€Œé™ä½æ¢¯åº¦ã€‚å¦å¤–å®ƒæ¯”MSEå¯¹å¼‚å¸¸å€¼æ›´é²æ£’ã€‚å› æ­¤ï¼Œå®ƒç»“åˆäº†MSEå’ŒMAEçš„ä¼˜è‰¯ç‰¹æ€§ã€‚ä½†æ˜¯ï¼ŒHuberLossçš„é—®é¢˜æ˜¯æˆ‘ä»¬å¯èƒ½éœ€è¦è¿­ä»£åœ°è®­ç»ƒè¶…å‚æ•°deltaã€‚ Log-Cosh LossLog-coshæ˜¯ç”¨äºå›å½’ä»»åŠ¡çš„å¦ä¸€ç§æŸå¤±å‡½æ•°ï¼Œå®ƒæ¯”L2æ›´åŠ å¹³æ»‘ã€‚Log-coshæ˜¯é¢„æµ‹è¯¯å·®çš„åŒæ›²ä½™å¼¦çš„å¯¹æ•°ã€‚ L(\\hat y,y_{true}) = \\sum^n_{i=1} log(cosh(y_{true}-\\hat y)) ä¼˜ç‚¹ï¼š log(cosh(x))å¯¹äºå°çš„xæ¥è¯´ï¼Œå…¶å¤§çº¦ç­‰äº (x ** 2) / 2ï¼Œè€Œå¯¹äºå¤§çš„xæ¥è¯´ï¼Œå…¶å¤§çº¦ç­‰äº abs(x) -log(2)ã€‚è¿™æ„å‘³ç€logcoshçš„ä½œç”¨å¤§éƒ¨åˆ†ä¸å‡æ–¹è¯¯å·®ä¸€æ ·ï¼Œä½†ä¸ä¼šå—åˆ°å¶å°”å‡ºç°çš„æç«¯ä¸æ­£ç¡®é¢„æµ‹çš„å¼ºçƒˆå½±å“ã€‚å®ƒå…·æœ‰Huber Lossçš„æ‰€æœ‰ä¼˜ç‚¹ï¼Œå’ŒHuber Lossä¸åŒä¹‹å¤„åœ¨äºï¼Œå…¶å¤„å¤„äºŒæ¬¡å¯å¯¼ã€‚ ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦äºŒé˜¶å¯¼æ•°ï¼Ÿè®¸å¤šæœºå™¨å­¦ä¹ æ¨¡å‹çš„å®ç°ï¼ˆå¦‚XGBoostï¼‰ä½¿ç”¨ç‰›é¡¿æ–¹æ³•æ¥å¯»æ‰¾æœ€ä¼˜è§£ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆéœ€è¦äºŒé˜¶å¯¼æ•°ï¼ˆHessianï¼‰çš„åŸå› ã€‚å¯¹äºåƒXGBoostè¿™æ ·çš„æœºå™¨å­¦ä¹ æ¡†æ¶ï¼ŒäºŒé˜¶å¯å¯¼å‡½æ•°æ›´æœ‰åˆ©ã€‚ ä½†Log-chshLosså¹¶ä¸å®Œç¾ã€‚å®ƒä»ç„¶å­˜åœ¨æ¢¯åº¦å’ŒHessiané—®é¢˜ï¼Œå¯¹äºè¯¯å·®å¾ˆå¤§çš„é¢„æµ‹ï¼Œå…¶æ¢¯åº¦å’Œhessianæ˜¯æ’å®šçš„ã€‚å› æ­¤ä¼šå¯¼è‡´XGBoostä¸­æ²¡æœ‰åˆ†è£‚ã€‚ Huberå’ŒLog-coshæŸå¤±å‡½æ•°çš„Pythonä»£ç ï¼š 12345678910111213def sm_mae(true, pred, delta): \"\"\" true: array of true values pred: array of predicted values returns: smoothed mean absolute error loss \"\"\" loss = np.where(np.abs(true-pred) &lt; delta , 0.5*((true-pred)**2), delta*np.abs(true - pred) - 0.5*(delta**2)) return np.sum(loss)def logcosh(true, pred): loss = np.log(np.cosh(pred - true)) return np.sum(loss) Quantile Loss(åˆ†ä½æ•°æŸå¤±)åœ¨å¤§å¤šæ•°çœŸå®é¢„æµ‹é—®é¢˜ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸æƒ³äº†è§£æˆ‘ä»¬é¢„æµ‹çš„ä¸ç¡®å®šæ€§ã€‚äº†è§£é¢„æµ‹å€¼çš„èŒƒå›´è€Œä¸ä»…ä»…æ˜¯å•ä¸€çš„é¢„æµ‹ç‚¹å¯ä»¥æ˜¾ç€æ”¹å–„è®¸å¤šä¸šåŠ¡é—®é¢˜çš„å†³ç­–è¿‡ç¨‹ã€‚ å½“æˆ‘ä»¬æœ‰å…´è¶£é¢„æµ‹ä¸€ä¸ªåŒºé—´è€Œä¸ä»…ä»…æ˜¯é¢„æµ‹ä¸€ä¸ªç‚¹æ—¶ï¼ŒQuantile Losså‡½æ•°å°±å¾ˆæœ‰ç”¨ã€‚æœ€å°äºŒä¹˜å›å½’çš„é¢„æµ‹åŒºé—´æ˜¯åŸºäºè¿™æ ·ä¸€ä¸ªå‡è®¾ï¼šæ®‹å·®ï¼ˆy -y_hatï¼‰åœ¨ç‹¬ç«‹å˜é‡çš„å€¼ä¹‹é—´å…·æœ‰ä¸å˜çš„æ–¹å·®ã€‚æˆ‘ä»¬ä¸èƒ½ç›¸ä¿¡çº¿æ€§å›å½’æ¨¡å‹ï¼Œå› ä¸ºå®ƒè¿åäº†è¿™ä¸€å‡è®¾ã€‚å½“ç„¶ï¼Œæˆ‘ä»¬ä¹Ÿä¸èƒ½ä»…ä»…è®¤ä¸ºè¿™ç§æƒ…å†µä¸€èˆ¬ä½¿ç”¨éçº¿æ€§å‡½æ•°æˆ–åŸºäºæ ‘çš„æ¨¡å‹å°±å¯ä»¥æ›´å¥½åœ°å»ºæ¨¡ï¼Œè€Œç®€å•åœ°æŠ›å¼ƒæ‹Ÿåˆçº¿æ€§å›å½’æ¨¡å‹ä½œä¸ºåŸºçº¿çš„æƒ³æ³•ã€‚è¿™æ—¶ï¼ŒQuantile Losså°±æ´¾ä¸Šç”¨åœºäº†ã€‚å› ä¸ºåŸºäºQuantile Lossçš„å›å½’æ¨¡å‹å¯ä»¥æä¾›åˆç†çš„é¢„æµ‹åŒºé—´ï¼Œå³ä½¿æ˜¯å¯¹äºå…·æœ‰éå¸¸æ•°æ–¹å·®æˆ–éæ­£æ€åˆ†å¸ƒçš„æ®‹å·®äº¦æ˜¯å¦‚æ­¤ã€‚ è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªæœ‰æ•ˆçš„ä¾‹å­ï¼Œä»¥æ›´å¥½åœ°ç†è§£ä¸ºä»€ä¹ˆåŸºäºQuantileLossçš„å›å½’æ¨¡å‹å¯¹å¼‚æ–¹å·®æ•°æ®è¡¨ç°è‰¯å¥½ã€‚ Quantile å›å½’ vs æ™®é€šæœ€å°äºŒä¹˜ï¼ˆOrdinary Least Square, OLSï¼‰å›å½’ æ©™çº¿è¡¨ç¤ºä¸¤ç§æƒ…å†µä¸‹çš„OLSä¼°è®¡ åŸºäºQuantileå›å½’çš„ç›®çš„æ˜¯ï¼Œåœ¨ç»™å®šé¢„æµ‹å˜é‡çš„æŸäº›å€¼æ—¶ï¼Œä¼°è®¡å› å˜é‡çš„æ¡ä»¶â€œåˆ†ä½æ•°â€ã€‚QuantileLosså®é™…ä¸Šåªæ˜¯MAEçš„æ‰©å±•å½¢å¼ï¼ˆå½“åˆ†ä½æ•°æ˜¯ç¬¬50ä¸ªç™¾åˆ†ä½æ—¶ï¼ŒQuantile Lossé€€åŒ–ä¸ºMAEï¼‰ã€‚ QuantileLossçš„æ€æƒ³æ˜¯æ ¹æ®æˆ‘ä»¬æ˜¯æ‰“ç®—ç»™æ­£è¯¯å·®è¿˜æ˜¯è´Ÿè¯¯å·®æ›´å¤šçš„å€¼æ¥é€‰æ‹©åˆ†ä½æ•°æ•°å€¼ã€‚æŸå¤±å‡½æ•°æ ¹æ®æ‰€é€‰quantile(Î³)çš„å€¼å¯¹é«˜ä¼°å’Œä½ä¼°çš„é¢„æµ‹å€¼ç»™äºˆä¸åŒçš„æƒ©ç½šå€¼ã€‚ä¸¾ä¸ªä¾‹å­ï¼ŒÎ³= 0.25çš„Quantile Losså‡½æ•°ç»™é«˜ä¼°çš„é¢„æµ‹å€¼æ›´å¤šçš„æƒ©ç½šï¼Œå¹¶è¯•å›¾ä½¿é¢„æµ‹å€¼ç•¥ä½äºä¸­ä½æ•°ã€‚ Î³ æ˜¯ç»™å®šçš„åˆ†ä½æ•°ï¼Œå…¶å€¼ä»‹äº0å’Œ1ä¹‹é—´ã€‚ æˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨è¿™ä¸ªæŸå¤±å‡½æ•°æ¥è®¡ç®—ç¥ç»ç½‘ç»œæˆ–åŸºäºæ ‘çš„æ¨¡å‹çš„é¢„æµ‹åŒºé—´ã€‚ä¸‹å›¾æ˜¯sklearnå®ç°çš„æ¢¯åº¦æå‡æ ‘å›å½’ã€‚ ä¸Šå›¾æ˜¾ç¤ºçš„æ˜¯sklearnåº“çš„GradientBoostingRegressionä¸­çš„quantile losså‡½æ•°è®¡ç®—çš„90ï¼…é¢„æµ‹åŒºé—´ã€‚ä¸Šé™çš„è®¡ç®—ä½¿ç”¨äº†Î³ = 0.95ï¼Œä¸‹é™åˆ™æ˜¯ä½¿ç”¨äº†Î³ = 0.05ã€‚ å‡ ç§ç®—æ³•çš„æ¯”è¾ƒâ€œGradient boosting machines, a tutorialâ€ä¸­æä¾›äº†ä¸€ä¸ªå¾ˆå¥½çš„æ¯”è¾ƒç ”ç©¶ã€‚ä¸ºäº†æ¼”ç¤ºä¸Šè¿°æ‰€æœ‰çš„æŸå¤±å‡½æ•°çš„æ€§è´¨ï¼Œç ”ç©¶äººå‘˜åˆ›é€ äº†ä¸€ä¸ªäººå·¥æ•°æ®é›†ï¼Œæ•°æ®é›†ä»sinc(x)å‡½æ•°ä¸­é‡‡æ ·ï¼Œå…¶ä¸­åŠ å…¥äº†ä¸¤ç§äººé€ æ¨¡æ‹Ÿå™ªå£°ï¼šé«˜æ–¯å™ªå£°åˆ†é‡å’Œè„‰å†²å™ªå£°åˆ†é‡ã€‚è„‰å†²å™ªå£°é¡¹æ˜¯ç”¨æ¥å±•ç¤ºç»“æœçš„é²æ£’æ•ˆæœçš„ã€‚ä»¥ä¸‹æ˜¯ä½¿ç”¨ä¸åŒæŸå¤±å‡½æ•°æ¥æ‹Ÿåˆ BMï¼ˆGradient Boosting Machine, æ¢¯åº¦æå‡å›å½’ï¼‰çš„ç»“æœã€‚ ç»“è®º ä»¥MAEä¸ºæŸå¤±çš„æ¨¡å‹é¢„æµ‹è¾ƒå°‘å—åˆ°è„‰å†²å™ªå£°çš„å½±å“ï¼Œè€Œä»¥MSEä¸ºæŸå¤±çš„æ¨¡å‹çš„é¢„æµ‹ç”±äºè„‰å†²å™ªå£°é€ æˆçš„æ•°æ®åç¦»è€Œç•¥æœ‰åå·®ã€‚ ä»¥Huber Lossä¸ºæŸå¤±å‡½æ•°çš„æ¨¡å‹ï¼Œå…¶é¢„æµ‹å¯¹æ‰€é€‰çš„è¶…å‚æ•°ä¸å¤ªæ•æ„Ÿã€‚ Quantile Losså¯¹ç›¸åº”çš„ç½®ä¿¡æ°´å¹³ç»™å‡ºäº†å¾ˆå¥½çš„ä¼°è®¡ã€‚ Rank-1 å’Œ Rank-5æœ€åˆæºè‡ªImagenetä¸­è®¾è®¡çš„ä¸€ä¸ªåˆ†ç±»å‡†ç¡®ç‡çš„è¯„ä»·å‡†åˆ™ã€‚ Rank-1æ¯”è¾ƒå®¹æ˜“ç†è§£ï¼Œå°±æ˜¯ç²¾ç¡®åŒ¹é…ï¼›Rank-5ä¸­ï¼Œå°†æ‰€æœ‰çš„é¢„æµ‹æ¦‚ç‡æ’åºï¼Œåªæœ‰ç›®æ ‡çš„çœŸå®åˆ†ç±»åœ¨Top 5é¢„æµ‹ä¹‹ä¸­å°±ç®—è¯¥æ¬¡åˆ†ç±»æ­£ç¡®é¢„æµ‹äº†åˆ†ç±»ç›®æ ‡ï¼Œä¸»è¦é’ˆå¯¹ç°å®ä¸­æä¾›çš„åˆ†ç±»ç…§ç‰‡ä¸å¤Ÿç†æƒ³ï¼š1ï¼‰æ¯”å¦‚ç…§ç‰‡ä¸­åŒæ—¶å­˜åœ¨å¤šä¸ªç›®æ ‡å¯¹è±¡ï¼›2ï¼‰åˆ†ç±»ç›®æ ‡ç‰¹åˆ«åºå¤§ï¼Œæ¯ä¸ªå¯¹è±¡éƒ½å­˜åœ¨å¤šç§åˆ†ç±»ç›®æ ‡(æ¯”å¦‚ä¸€åªé˜¿é‡Œæ–¯åŠ çŠ¬çš„ç…§ç‰‡ï¼Œæ—¢å¯ä»¥è¢«åˆ†ç±»ä¸ºç‹—ï¼Œä¹Ÿå¯ä»¥è¢«åˆ†ç±»ä¸ºé˜¿æ‹‰æ–¯åŠ )ï¼Œ3ï¼‰åˆ†ç±»ç›®æ ‡ä¸­æ²¡æœ‰ä»»ä½•æ˜ç¡®ä¸å¯¹è±¡ç›¸å…³çš„å†…å®¹ï¼ˆæ¯”å¦‚å›¾åƒä¸ºä¸€å¼ å°æ±½è½¦ç…§ç‰‡ï¼Œæä¾›çš„åˆ†ç±»ä¸ºå¡è½¦ã€é£æœºã€æ‘©æ‰˜è½¦ã€è´§è½¦ã€â€¦ï¼‰ã€‚ 123456789101112131415161718192021222324252627def rank5_accuracy(preds, labels): # initialize the rank-1 and rank-5 accuracies rank1 = 0 rank5 = 0 # loop over the predictions and ground-truth labels for (p, gt) in zip(preds, labels): # sort the probabilities by their index in descending # order so that the more confident guesses are at the # front of the list p = np.argsort(p)[::-1] # check if the ground-truth label is in the top-5 # predictions if gt in p[:5]: rank5 += 1 # check to see if the ground-truth is the #1 prediction if gt == p[0]: rank1 += 1 # compute the final rank-1 and rank-5 accuracies rank1 /= float(len(preds)) rank5 /= float(len(preds)) # return a tuple of the rank-1 and rank-5 accuracies return (rank1, rank5) å‚è€ƒ Kerasæ–‡æ¡£ Google æœºå™¨å­¦ä¹ é€Ÿæˆè¯¾ç¨‹ 5 Regression Loss Functions All Machine Learners Should Know â€‹","categories":[{"name":"æ·±åº¦å­¦ä¹ ","slug":"æ·±åº¦å­¦ä¹ ","permalink":"http://blog.a-stack.com/categories/æ·±åº¦å­¦ä¹ /"},{"name":"åŸºç¡€çŸ¥è¯†","slug":"æ·±åº¦å­¦ä¹ /åŸºç¡€çŸ¥è¯†","permalink":"http://blog.a-stack.com/categories/æ·±åº¦å­¦ä¹ /åŸºç¡€çŸ¥è¯†/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://blog.a-stack.com/tags/AI/"},{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"é¢„å¤„ç†","slug":"é¢„å¤„ç†","permalink":"http://blog.a-stack.com/tags/é¢„å¤„ç†/"}]},{"title":"æ·±åº¦å­¦ä¹ åŸºç¡€ä¹‹æ¨¡å‹å‹ç¼©","slug":"æ·±åº¦å­¦ä¹ åŸºç¡€ä¹‹æ¨¡å‹å‹ç¼©","date":"2018-03-01T08:02:01.000Z","updated":"2018-05-15T09:14:33.792Z","comments":true,"path":"2018/03/01/æ·±åº¦å­¦ä¹ åŸºç¡€ä¹‹æ¨¡å‹å‹ç¼©/","link":"","permalink":"http://blog.a-stack.com/2018/03/01/æ·±åº¦å­¦ä¹ åŸºç¡€ä¹‹æ¨¡å‹å‹ç¼©/","excerpt":"","text":"æ·±åº¦å­¦ä¹ ä¸­æ¨¡å‹å‹ç¼©å…³é”®æŠ€æœ¯æ€»ç»“ã€‚ æ·±åº¦å­¦ä¹ åŸºç¡€ç¯‡å°†ä»å‡ ä¸ªä¸åŒçš„å±‚é¢æ¥æ€»ç»“åœ¨è¿‡å»ä¸€æ®µæ—¶é—´å¯¹äºæ·±åº¦å­¦ä¹ å…³é”®æŠ€æœ¯çš„ç†è§£ï¼Œé€šè¿‡çŸ¥è¯†ä½“ç³»çš„å½’çº³äº†è§£çŸ¥è¯†ä½“ç³»çš„ä¸è¶³ï¼Œæå‡å¯¹æ ¸å¿ƒæŠ€æœ¯ç‚¹çš„è®¤è¯†ã€‚æ‰€æœ‰ç³»åˆ—æ–‡ç« å°†åœ¨æœªæ¥ä¸€æ®µæ—¶é—´å†…å®¹éšç€æŒæ¡äº†è§£çš„æ·±å…¥è¿­ä»£æ›´æ–°ã€‚ç›®å‰ä¸»è¦å¸Œæœ›å¯¹å¦‚ä¸‹å‡ ä¸ªé¢†åŸŸè¿›è¡Œå½’çº³æ±‡æ€»ï¼š é—®é¢˜å®šä¹‰ ç›®æ ‡åŠè¯„ä¼° æ•°æ®å‡†å¤‡ä¸é¢„å¤„ç† æ¿€æ´»å‡½æ•°çš„å½’çº³åŠæ€»ç»“ ä¼˜åŒ–ç®—æ³•çš„å½’çº³åŠæ€»ç»“ æ­£åˆ™åŒ–ä¸æ³›åŒ–æ€§èƒ½ æ¨¡å‹å‹ç¼© æ•°æ®æ‰©å…… ä¸ºäº†å¢åŠ æ·±åº¦å­¦ä¹ æ¨¡å‹çš„å®¹é‡ï¼Œå¾€å¾€åŒ…å«äº†å¤§é‡çš„å¾…è®­ç»ƒå‚æ•°å’Œæ¨¡å‹è§„æ¨¡ï¼Œä»¥VGG-16ä¸ºä¾‹ï¼Œå‚æ•°æ•°ç›®ä¸º1äº¿3åƒä¸‡ï¼Œå ç”¨ç©ºé—´500MBï¼Œå¦‚æœåˆ©ç”¨VGG-16è¿›è¡Œä¸€æ¬¡å›¾ç‰‡è¯†åˆ«ä»»åŠ¡ï¼Œéœ€è¦è¿›è¡Œ309äº¿æ¬¡çš„æµ®ç‚¹è¿ç®—ï¼ˆFLOPsï¼‰ã€‚å¦‚æ­¤å¤§çš„æ¨¡å‹ä½“ç§¯å’Œå¯¹ç®—åŠ›çš„ä¾èµ–ï¼Œä¸ºæ·±åº¦å­¦ä¹ æ¨¡å‹è¿ç§»åˆ°åµŒå…¥å¼è®¾å¤‡æˆ–è€…åˆ©ç”¨CPUè¿›è¡Œæ¨ç†å¸¦æ¥äº†å¾ˆå¤§çš„éš¾åº¦ï¼Œä¸ºæ­¤é€šè¿‡åˆç†çš„æ¨¡å‹å‹ç¼©æŠ€æœ¯åœ¨ä¿è¯æ¨¡å‹æ€§èƒ½æ²¡æœ‰æ˜æ˜¾ä¸‹é™çš„æƒ…å†µä¸‹é™ä½æ¨¡å‹ä½“ç§¯å’Œå‚æ•°æ•°ç›®æˆä¸ºä¸€ä¸ªçƒ­ç‚¹çš„ç ”ç©¶é—®é¢˜ã€‚ åŒæ—¶ï¼Œç ”ç©¶å‘ç°æ·±åº¦ç¥ç»ç½‘ç»œé¢ä¸´ä¸¥å³»çš„è¿‡å‚æ•°åŒ–é—®é¢˜ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™ç§å†—ä½™åœ¨æ¨¡å‹è®­ç»ƒé˜¶æ®µæ˜¯ååˆ†å¿…è¦çš„ã€‚å› ä¸ºæ·±åº¦ç¥ç»ç½‘ç»œé¢ä¸´çš„æ˜¯ä¸€ä¸ªæå…¶å¤æ‚çš„éå‡¸ä¼˜åŒ–é—®é¢˜ï¼Œå¯¹äºç°æœ‰çš„åŸºäºæ¢¯åº¦ä¸‹é™çš„ä¼˜åŒ–ç®—æ³•è€Œè¨€ï¼Œè¿™ç§å‚æ•°ä¸Šçš„å†—ä½™ä¿è¯äº†ç½‘ç»œèƒ½å¤Ÿæ”¶æ•›åˆ°ä¸€ä¸ªæ¯”è¾ƒå¥½çš„æœ€ä¼˜å€¼ã€‚å› è€Œåœ¨ä¸€å®šç¨‹åº¦ä¸Šï¼Œç½‘ç»œè¶Šæ·±ï¼Œå‚æ•°è¶Šå¤šï¼Œæ¨¡å‹è¶Šå¤æ‚ï¼Œå…¶æœ€ç»ˆçš„æ•ˆæœä¹Ÿå¾€å¾€è¶Šå¥½ã€‚ æŒ‰ç…§å‹ç¼©è¿‡ç¨‹å¯¹ç½‘ç»œç»“æ„çš„ç ´åç¨‹åº¦ï¼Œæˆ‘ä»¬å°†æ¨¡å‹å‹ç¼©æŠ€æœ¯åˆ†ä¸ºâ€œå‰ç«¯å‹ç¼©â€ä¸â€œåç«¯å‹ç¼©â€ä¸¤éƒ¨åˆ†ã€‚æ‰€è°“â€œå‰ç«¯å‹ç¼©â€ï¼Œæ˜¯æŒ‡ä¸æ”¹å˜åŸç½‘ç»œç»“æ„çš„å‹ç¼©æŠ€æœ¯ï¼Œä¸»è¦åŒ…æ‹¬çŸ¥è¯†è’¸é¦ã€ç´§å‡‘çš„æ¨¡å‹ç»“æ„è®¾è®¡ä»¥åŠæ»¤æ³¢å™¨å±‚é¢çš„å‰ªæç­‰ï¼›è€Œâ€œåç«¯å‹ç¼©â€åˆ™åŒ…æ‹¬ä½ç§©è¿‘ä¼¼ã€æœªåŠ é™åˆ¶çš„å‰ªæã€å‚æ•°é‡åŒ–ä»¥åŠäºŒå€¼ç½‘ç»œç­‰ï¼Œå…¶ç›®æ ‡åœ¨äºå°½å¯èƒ½åœ°å‡å°‘æ¨¡å‹å¤§å°ï¼Œå› è€Œä¼šå¯¹åŸå§‹ç½‘ç»œç»“æ„é€ æˆæå¤§ç¨‹åº¦çš„æ”¹é€ ã€‚å…¶ä¸­ï¼Œç”±äºâ€œå‰ç«¯å‹ç¼©â€æœªæ”¹å˜åŸæœ‰çš„ç½‘ç»œç»“æ„ï¼Œä»…ä»…åªæ˜¯åœ¨åŸæ¨¡å‹çš„åŸºç¡€ä¸Šå‡å°‘äº†ç½‘ç»œçš„å±‚æ•°æˆ–è€…æ»¤æ³¢å™¨çš„ä¸ªæ•°ï¼Œå…¶æœ€ç»ˆçš„æ¨¡å‹å¯å®Œç¾é€‚é…ç°æœ‰çš„æ·±åº¦å­¦ä¹ åº“ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œâ€œåç«¯å‹ç¼©â€ä¸ºäº†è¿½æ±‚æè‡´çš„å‹ç¼©æ¯”ï¼Œä¸å¾—ä¸å¯¹åŸæœ‰çš„ç½‘ç»œç»“æ„è¿›è¡Œæ”¹é€ ï¼Œå¦‚å¯¹å‚æ•°è¿›è¡Œé‡åŒ–è¡¨ç¤ºç­‰ï¼Œè€Œè¿™æ ·çš„æ”¹é€ å¾€å¾€æ˜¯ä¸å¯é€†çš„ã€‚åŒæ—¶ï¼Œä¸ºäº†è·å¾—ç†æƒ³çš„å‹ç¼©æ•ˆæœï¼Œå¿…é¡»å¼€å‘ç›¸é…å¥—çš„è¿è¡Œåº“ï¼Œç”šè‡³æ˜¯ä¸“é—¨çš„ç¡¬ä»¶è®¾å¤‡ï¼Œå…¶æœ€ç»ˆçš„ç»“æœå¾€å¾€æ˜¯ä¸€ç§å‹ç¼©æŠ€æœ¯å¯¹åº”äºä¸€å¥—è¿è¡Œåº“ï¼Œä»è€Œå¸¦æ¥äº†å·¨å¤§çš„ç»´æŠ¤æˆæœ¬ã€‚ å‰ªæä¸ç¨€ç–çº¦æŸçŸ¥è¯†è’¸é¦å‚æ•°é‡åŒ–äºŒå€¼ç½‘ç»œå‚è€ƒ ã€Šè§£æå·ç§¯ç¥ç»ç½‘ç»œâ€”æ·±åº¦å­¦ä¹ å®è·µæ‰‹å†Œã€‹ Kerasæ–‡æ¡£","categories":[{"name":"æ·±åº¦å­¦ä¹ ","slug":"æ·±åº¦å­¦ä¹ ","permalink":"http://blog.a-stack.com/categories/æ·±åº¦å­¦ä¹ /"},{"name":"åŸºç¡€çŸ¥è¯†","slug":"æ·±åº¦å­¦ä¹ /åŸºç¡€çŸ¥è¯†","permalink":"http://blog.a-stack.com/categories/æ·±åº¦å­¦ä¹ /åŸºç¡€çŸ¥è¯†/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://blog.a-stack.com/tags/AI/"},{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"æ¨¡å‹","slug":"æ¨¡å‹","permalink":"http://blog.a-stack.com/tags/æ¨¡å‹/"},{"name":"ç®—æ³•","slug":"ç®—æ³•","permalink":"http://blog.a-stack.com/tags/ç®—æ³•/"}]},{"title":"æ·±åº¦å­¦ä¹ åŸºç¡€ä¹‹æ•°æ®å‡†å¤‡ä¸é¢„å¤„ç†","slug":"æ·±åº¦å­¦ä¹ åŸºç¡€ä¹‹æ•°æ®é¢„å¤„ç†","date":"2018-03-01T06:35:01.000Z","updated":"2018-05-15T09:14:33.808Z","comments":true,"path":"2018/03/01/æ·±åº¦å­¦ä¹ åŸºç¡€ä¹‹æ•°æ®é¢„å¤„ç†/","link":"","permalink":"http://blog.a-stack.com/2018/03/01/æ·±åº¦å­¦ä¹ åŸºç¡€ä¹‹æ•°æ®é¢„å¤„ç†/","excerpt":"","text":"ç”±äºäººå·¥æ™ºèƒ½é¢å‘çš„åº”ç”¨å’Œåœºæ™¯çš„å¤šæ ·æ€§ï¼Œå¯¼è‡´éœ€è¦åˆ†æçš„æ•°æ®æ— è®ºæ˜¯ä»ç»´åº¦è¿˜æ˜¯æ ¼å¼ä¸Šéƒ½å­˜åœ¨å·¨å¤§å·®å¼‚ï¼Œæ•°æ®å‡†å¤‡é˜¶æ®µéœ€è¦è§£å†³æ•°æ®çš„æ•°å€¼åŒ–ã€å½’ä¸€åŒ–ã€ç‰¹å¾å·¥ç¨‹ç­‰å…±æ€§çš„é—®é¢˜ã€‚ æ·±åº¦å­¦ä¹ åŸºç¡€ç¯‡å°†ä»å‡ ä¸ªä¸åŒçš„å±‚é¢æ¥æ€»ç»“åœ¨è¿‡å»ä¸€æ®µæ—¶é—´å¯¹äºæ·±åº¦å­¦ä¹ å…³é”®æŠ€æœ¯çš„ç†è§£ï¼Œé€šè¿‡çŸ¥è¯†ä½“ç³»çš„å½’çº³äº†è§£çŸ¥è¯†ä½“ç³»çš„ä¸è¶³ï¼Œæå‡å¯¹æ ¸å¿ƒæŠ€æœ¯ç‚¹çš„è®¤è¯†ã€‚æ‰€æœ‰ç³»åˆ—æ–‡ç« å°†åœ¨æœªæ¥ä¸€æ®µæ—¶é—´å†…å®¹éšç€æŒæ¡äº†è§£çš„æ·±å…¥è¿­ä»£æ›´æ–°ã€‚ç›®å‰ä¸»è¦å¸Œæœ›å¯¹å¦‚ä¸‹å‡ ä¸ªé¢†åŸŸè¿›è¡Œå½’çº³æ±‡æ€»ï¼š é—®é¢˜å®šä¹‰ ç›®æ ‡åŠè¯„ä¼° æ•°æ®å‡†å¤‡ä¸é¢„å¤„ç† æ¿€æ´»å‡½æ•°çš„å½’çº³åŠæ€»ç»“ ä¼˜åŒ–ç®—æ³•çš„å½’çº³åŠæ€»ç»“ æ­£åˆ™åŒ–ä¸æ³›åŒ–æ€§èƒ½ æ¨¡å‹å‹ç¼© æ•°æ®æ‰©å…… ç”±äºäººå·¥æ™ºèƒ½é¢å‘çš„åº”ç”¨å’Œåœºæ™¯çš„å¤šæ ·æ€§ï¼Œå¯¼è‡´éœ€è¦åˆ†æçš„æ•°æ®æ— è®ºæ˜¯ä»ç»´åº¦è¿˜æ˜¯æ ¼å¼ä¸Šéƒ½å­˜åœ¨å·¨å¤§å·®å¼‚ï¼Œæ•°æ®å‡†å¤‡é˜¶æ®µéœ€è¦è§£å†³æ•°æ®çš„æ•°å€¼åŒ–ã€å½’ä¸€åŒ–ã€ç‰¹å¾å·¥ç¨‹ç­‰å…±æ€§çš„é—®é¢˜ã€‚ æ·±åº¦å­¦ä¹ çš„ç«¯åˆ°ç«¯å­¦ä¹ èƒ½åŠ›å¹¶ä¸æ„å‘³ç€åœ¨å®é™…çš„ä¸šåŠ¡å¤„ç†ä¸­æŠŠåŸå§‹æ•°æ®ç›´æ¥ä¸¢è¿›ç½‘ç»œæ¨¡å‹ï¼Œä¸ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ æŠ€æœ¯ç±»ä¼¼å¿…è¦çš„æ•°æ®é¢„å¤„ç†å·¥ä½œæ— è®ºæ˜¯å¯¹äºæå‡æ¨¡å‹çš„æ”¶æ•›æ•ˆç‡è¿˜æ˜¯æå‡æ¨¡å‹çš„è®­ç»ƒè´¨é‡éƒ½å…·å¤‡ååˆ†é‡è¦çš„æ„ä¹‰ã€‚ æ•°å€¼åŒ–ç”±äºç¥ç»ç½‘ç»œçš„è¾“å…¥é™å®šä¸ºæ•°å€¼æ•°æ®ï¼Œæ‰€ä»¥å¯¹äºå­—ç¬¦ä¸²æ•°æ®ã€æ–‡æœ¬æ•°æ®ã€ç±»åˆ«æ•°æ®ï¼Œåœ¨å¯¼å…¥ç½‘ç»œæ¨¡å‹ä¹‹å‰éœ€è¦è¿›è¡Œæ•°å€¼åŒ–å¤„ç†ï¼Œè½¬æ¢ä¸ºæ•°å€¼æ•°æ®ã€‚å…¶ä¸­ç±»åˆ«æ•°æ®å¯ä»¥é‡‡ç”¨one-hotç¼–ç ç­‰æ–¹å¼è¿›è¡Œç¼–ç ã€‚ æ•°æ®å½’ä¸€åŒ–æ•°æ®å½’ä¸€åŒ–æ˜¯å±äºé¢„å¤„ç†é˜¶æ®µç»å¸¸é‡‡ç”¨çš„ä¸€ç§æ‰‹æ®µã€‚è™½ç„¶è¿™é‡Œæœ‰ä¸€ç³»åˆ—å¯è¡Œçš„æ–¹æ³•ï¼Œä½†æ˜¯è¿™ä¸€æ­¥é€šå¸¸æ˜¯æ ¹æ®æ•°æ®çš„å…·ä½“æƒ…å†µè€Œæ˜ç¡®é€‰æ‹©çš„ã€‚ç‰¹å¾å½’ä¸€åŒ–å¸¸ç”¨çš„æ–¹æ³•åŒ…å«å¦‚ä¸‹å‡ ç§ï¼š ç®€å•ç¼©æ”¾ é€æ ·æœ¬å‡å€¼æ¶ˆå‡(ä¹Ÿç§°ä¸ºç§»é™¤ç›´æµåˆ†é‡) ç‰¹å¾æ ‡å‡†åŒ–(ä½¿æ•°æ®é›†ä¸­æ‰€æœ‰ç‰¹å¾éƒ½å…·æœ‰é›¶å‡å€¼å’Œå•ä½æ–¹å·®) ç®€å•ç¼©æ”¾åœ¨ç®€å•ç¼©æ”¾ä¸­ï¼Œæˆ‘ä»¬çš„ç›®çš„æ˜¯é€šè¿‡å¯¹æ•°æ®çš„æ¯ä¸€ä¸ªç»´åº¦çš„å€¼è¿›è¡Œé‡æ–°è°ƒèŠ‚ï¼ˆè¿™äº›ç»´åº¦å¯èƒ½æ˜¯ç›¸äº’ç‹¬ç«‹çš„ï¼‰ï¼Œä½¿å¾—æœ€ç»ˆçš„æ•°æ®å‘é‡è½åœ¨ [0,1]æˆ–[ âˆ’ 1,1] çš„åŒºé—´å†…ï¼ˆæ ¹æ®æ•°æ®æƒ…å†µè€Œå®šï¼‰ã€‚è¿™å¯¹åç»­çš„å¤„ç†ååˆ†é‡è¦ï¼Œå› ä¸ºå¾ˆå¤šé»˜è®¤å‚æ•°ï¼ˆå¦‚ PCA-ç™½åŒ–ä¸­çš„ epsilonï¼‰éƒ½å‡å®šæ•°æ®å·²è¢«ç¼©æ”¾åˆ°åˆç†åŒºé—´ã€‚ ä¾‹å­:åœ¨å¤„ç†è‡ªç„¶å›¾åƒæ—¶ï¼Œæˆ‘ä»¬è·å¾—çš„åƒç´ å€¼åœ¨ [0,255] åŒºé—´ä¸­ï¼Œå¸¸ç”¨çš„å¤„ç†æ˜¯å°†è¿™äº›åƒç´ å€¼é™¤ä»¥ 255ï¼Œä½¿å®ƒä»¬ç¼©æ”¾åˆ° [0,1] ä¸­. é€æ ·æœ¬å‡å€¼æ¶ˆå‡å¦‚æœä½ çš„æ•°æ®æ˜¯å¹³ç¨³çš„ï¼ˆå³æ•°æ®æ¯ä¸€ä¸ªç»´åº¦çš„ç»Ÿè®¡éƒ½æœä»ç›¸åŒåˆ†å¸ƒï¼‰ï¼Œé‚£ä¹ˆä½ å¯ä»¥è€ƒè™‘åœ¨æ¯ä¸ªæ ·æœ¬ä¸Šå‡å»æ•°æ®çš„ç»Ÿè®¡å¹³å‡å€¼(é€æ ·æœ¬è®¡ç®—)ã€‚ ä¾‹å­ï¼šå¯¹äºå›¾åƒï¼Œè¿™ç§å½’ä¸€åŒ–å¯ä»¥ç§»é™¤å›¾åƒçš„å¹³å‡äº®åº¦å€¼ (intensity)ã€‚å¾ˆå¤šæƒ…å†µä¸‹æˆ‘ä»¬å¯¹å›¾åƒçš„ç…§åº¦å¹¶ä¸æ„Ÿå…´è¶£ï¼Œè€Œæ›´å¤šåœ°å…³æ³¨å…¶å†…å®¹ï¼Œè¿™æ—¶å¯¹æ¯ä¸ªæ•°æ®ç‚¹ç§»é™¤åƒç´ çš„å‡å€¼æ˜¯æœ‰æ„ä¹‰çš„ã€‚æ³¨æ„ï¼šè™½ç„¶è¯¥æ–¹æ³•å¹¿æ³›åœ°åº”ç”¨äºå›¾åƒï¼Œä½†åœ¨å¤„ç†å½©è‰²å›¾åƒæ—¶éœ€è¦æ ¼å¤–å°å¿ƒï¼Œå…·ä½“æ¥è¯´ï¼Œæ˜¯å› ä¸ºä¸åŒè‰²å½©é€šé“ä¸­çš„åƒç´ å¹¶ä¸éƒ½å­˜åœ¨å¹³ç¨³ç‰¹æ€§ã€‚ ç‰¹å¾æ ‡å‡†åŒ–ç‰¹å¾æ ‡å‡†åŒ–æŒ‡çš„æ˜¯ï¼ˆç‹¬ç«‹åœ°ï¼‰ä½¿å¾—æ•°æ®çš„æ¯ä¸€ä¸ªç»´åº¦å…·æœ‰é›¶å‡å€¼å’Œå•ä½æ–¹å·®ã€‚è¿™æ˜¯å½’ä¸€åŒ–ä¸­æœ€å¸¸è§çš„æ–¹æ³•å¹¶è¢«å¹¿æ³›åœ°ä½¿ç”¨ï¼ˆä¾‹å¦‚ï¼Œåœ¨ä½¿ç”¨æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰æ—¶ï¼Œç‰¹å¾æ ‡å‡†åŒ–å¸¸è¢«å»ºè®®ç”¨ä½œé¢„å¤„ç†çš„ä¸€éƒ¨åˆ†ï¼‰ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œç‰¹å¾æ ‡å‡†åŒ–çš„å…·ä½“åšæ³•æ˜¯ï¼šé¦–å…ˆè®¡ç®—æ¯ä¸€ä¸ªç»´åº¦ä¸Šæ•°æ®çš„å‡å€¼ï¼ˆä½¿ç”¨å…¨ä½“æ•°æ®è®¡ç®—ï¼‰ï¼Œä¹‹ååœ¨æ¯ä¸€ä¸ªç»´åº¦ä¸Šéƒ½å‡å»è¯¥å‡å€¼ã€‚ä¸‹ä¸€æ­¥ä¾¿æ˜¯åœ¨æ•°æ®çš„æ¯ä¸€ç»´åº¦ä¸Šé™¤ä»¥è¯¥ç»´åº¦ä¸Šæ•°æ®çš„æ ‡å‡†å·®ã€‚ ä¾‹å­:å¤„ç†éŸ³é¢‘æ•°æ®æ—¶ï¼Œå¸¸ç”¨ Mel å€’é¢‘ç³»æ•° MFCCs æ¥è¡¨å¾æ•°æ®ã€‚ç„¶è€ŒMFCCç‰¹å¾çš„ç¬¬ä¸€ä¸ªåˆ†é‡ï¼ˆè¡¨ç¤ºç›´æµåˆ†é‡ï¼‰æ•°å€¼å¤ªå¤§ï¼Œå¸¸å¸¸ä¼šæ©ç›–å…¶ä»–åˆ†é‡ã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œä¸ºäº†å¹³è¡¡å„ä¸ªåˆ†é‡çš„å½±å“ï¼Œé€šå¸¸å¯¹ç‰¹å¾çš„æ¯ä¸ªåˆ†é‡ç‹¬ç«‹åœ°ä½¿ç”¨æ ‡å‡†åŒ–å¤„ç†ã€‚ åŸç†ï¼š åœ¨æ¯ä¸ªæ ·æœ¬ä¸­å‡å»æ•°æ®çš„ç»Ÿè®¡å¹³å‡å€¼ï¼Œå¯ä»¥ç§»é™¤æ•°æ®çš„å…±åŒéƒ¨åˆ†ï¼Œå‡¸æ˜¾ä¸ªä½“å·®å¼‚ã€‚ æ³¨æ„ï¼š æ•°æ®å½’ä¸€åŒ–ä¸­é‡‡å–çš„ç»Ÿè®¡å¹³å‡å€¼å’Œå‡æ–¹å·®å€¼éƒ½æ¥æºäºè®­ç»ƒæ•°æ®ï¼Œç”±äºç†è®ºä¸Šä¸åº”è¯¥ä»éªŒè¯é›†å’Œæµ‹è¯•é›†ä¸­è·å–ä¿¡æ¯ï¼Œæ‰€ä»¥å¯¹äºéªŒè¯é›†å’Œæµ‹è¯•é›†çš„å¤„ç†ä¹Ÿä½¿ç”¨è®­ç»ƒé›†çš„ç»“æœã€‚ æ ‡å‡†æµç¨‹åœ¨è¿™ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»å‡ ç§åœ¨ä¸€äº›æ•°æ®é›†ä¸Šæœ‰è‰¯å¥½è¡¨ç°çš„é¢„å¤„ç†æ ‡å‡†æµç¨‹. è‡ªç„¶ç°åº¦å›¾åƒç°åº¦å›¾åƒå…·æœ‰å¹³ç¨³ç‰¹æ€§ï¼Œæˆ‘ä»¬é€šå¸¸åœ¨ç¬¬ä¸€æ­¥å¯¹æ¯ä¸ªæ•°æ®æ ·æœ¬åˆ†åˆ«åšå‡å€¼æ¶ˆå‡ï¼ˆå³å‡å»ç›´æµåˆ†é‡ï¼‰ï¼Œç„¶åé‡‡ç”¨ PCA/ZCA ç™½åŒ–å¤„ç†ï¼Œå…¶ä¸­çš„ epsilon è¦è¶³å¤Ÿå¤§ä»¥è¾¾åˆ°ä½é€šæ»¤æ³¢çš„æ•ˆæœã€‚ å½©è‰²å›¾åƒå¯¹äºå½©è‰²å›¾åƒï¼Œè‰²å½©é€šé“é—´å¹¶ä¸å­˜åœ¨å¹³ç¨³ç‰¹æ€§ã€‚å› æ­¤æˆ‘ä»¬é€šå¸¸é¦–å…ˆå¯¹æ•°æ®è¿›è¡Œç‰¹å¾ç¼©æ”¾ï¼ˆä½¿åƒç´ å€¼ä½äº [0,1] åŒºé—´ï¼‰ï¼Œç„¶åä½¿ç”¨è¶³å¤Ÿå¤§çš„ epsilon æ¥åš PCA/ZCAã€‚æ³¨æ„åœ¨è¿›è¡Œ PCA å˜æ¢å‰éœ€è¦å¯¹ç‰¹å¾è¿›è¡Œåˆ†é‡å‡å€¼å½’é›¶åŒ–ã€‚ éŸ³é¢‘ (MFCC/é¢‘è°±å›¾)å¯¹äºéŸ³é¢‘æ•°æ® (MFCC å’Œé¢‘è°±å›¾)ï¼Œæ¯ä¸€ç»´åº¦çš„å–å€¼èŒƒå›´ï¼ˆæ–¹å·®ï¼‰ä¸åŒã€‚ä¾‹å¦‚ MFCC çš„ç¬¬ä¸€åˆ†é‡æ˜¯ç›´æµåˆ†é‡ï¼Œé€šå¸¸å…¶å¹…åº¦è¿œå¤§äºå…¶ä»–åˆ†é‡ï¼Œå°¤å…¶å½“ç‰¹å¾ä¸­åŒ…å«æ—¶åŸŸå¯¼æ•° (temporal derivatives) æ—¶ï¼ˆè¿™æ˜¯éŸ³é¢‘å¤„ç†ä¸­çš„å¸¸ç”¨æ–¹æ³•ï¼‰æ›´æ˜¯å¦‚æ­¤ã€‚å› æ­¤ï¼Œå¯¹è¿™ç±»æ•°æ®çš„é¢„å¤„ç†é€šå¸¸ä»ç®€å•çš„æ•°æ®æ ‡å‡†åŒ–å¼€å§‹ï¼ˆå³ä½¿å¾—æ•°æ®çš„æ¯ä¸€ç»´åº¦å‡å€¼ä¸ºé›¶ã€æ–¹å·®ä¸º 1ï¼‰ï¼Œç„¶åè¿›è¡Œ PCA/ZCA ç™½åŒ–ï¼ˆä½¿ç”¨åˆé€‚çš„ epsilonï¼‰ã€‚ MNIST æ‰‹å†™æ•°å­—MNIST æ•°æ®é›†çš„åƒç´ å€¼åœ¨ [0,255] åŒºé—´ä¸­ã€‚æˆ‘ä»¬é¦–å…ˆå°†å…¶ç¼©æ”¾åˆ° [0,1] åŒºé—´ã€‚å®é™…ä¸Šï¼Œè¿›è¡Œé€æ ·æœ¬å‡å€¼æ¶ˆå»ä¹Ÿæœ‰åŠ©äºç‰¹å¾å­¦ä¹ ã€‚æ³¨ï¼šä¹Ÿå¯é€‰æ‹©ä»¥å¯¹ MNIST è¿›è¡Œ PCA/ZCA ç™½åŒ–ï¼Œä½†è¿™åœ¨å®è·µä¸­ä¸å¸¸ç”¨ã€‚ å›¾åƒé¢„å¤„ç†Mean Subtraction data normalization ç›®çš„ï¼šå‡å°‘ä¸åŒå›¾ç‰‡å—å…‰ç…§å˜åŒ–çš„å½±å“ã€‚ R = R - \\mu _R G = G - \\mu _G B = B - \\mu _B12345678910111213141516171819202122import cv2class MeanPreprocessor: def __init__(self, rMean, gMean, bMean): # store the Red, Green, and Blue channel averages across a # training set self.rMean = rMean self.gMean = gMean self.bMean = bMean def preprocess(self, image): # split the image into its respective Red, Green, and Blue # channels (B, G, R) = cv2.split(image.astype(\"float32\")) # subtract the means for each channel R -= self.rMean G -= self.gMean B -= self.bMean # merge the channels back together and return the image return cv2.merge([B, G, R]) Patch Extraction ä»åŸå§‹å›¾åƒä¸­éšæœºé‡‡æ ·MxNçš„åŒºåŸŸï¼Œå½“åŸå§‹å›¾åƒçš„ç¨€ç–åº¦è¾ƒé«˜æ—¶å¯ä»¥é‡‡ç”¨è¯¥æ–¹æ³•ã€‚ é™ä½è¿‡æ‹Ÿåˆçš„æ¦‚ç‡ 256x256 ===&gt; 227x227 12345678910111213from sklearn.feature_extraction.image import extract_patches_2dclass PatchPreprocessor: def __init__(self, width, height): # store the target width and height of the image self.width = width self.height = height def preprocess(self, image): # extract a random crop from the image with the target width # and height return extract_patches_2d(image, (self.height, self.width), max_patches=1)[0] Cropping(Over-Sampling) ä½¿ç”¨æ‰£å–æ–¹æ³•å¯ä»¥ä»åŸå§‹å›¾åƒçš„å››ä¸ªè§’+ä¸­å¿ƒä½ç½®è¿›è¡Œæ‰£å–ï¼Œå®éªŒè¯æ˜è¯¥æ–¹æ³•å¯ä»¥æå‡1-2ä¸ªç™¾åˆ†æ¯”çš„åˆ†ç±»ç²¾åº¦ï¼› 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import numpy as npimport cv2class CropPreprocessor: def __init__(self, width, height, horiz=True, inter=cv2.INTER_AREA): # store the target image width, height, whether or not # horizontal flips should be included, along with the # interpolation method used when resizing self.width = width self.height = height self.horiz = horiz self.inter = inter def preprocess(self, image): # initialize the list of crops crops = [] # grab the width and height of the image then use these # dimensions to define the corners of the image based (h, w) = image.shape[:2] coords = [ [0, 0, self.width, self.height], [w - self.width, 0, w, self.height], [w - self.width, h - self.height, w, h], [0, h - self.height, self.width, h]] # compute the center crop of the image as well dW = int(0.5 * (w - self.width)) dH = int(0.5 * (h - self.height)) coords.append([dW, dH, w - dW, h - dH]) # loop over the coordinates, extract each of the crops, # and resize each of them to a fixed size for (startX, startY, endX, endY) in coords: crop = image[startY:endY, startX:endX] crop = cv2.resize(crop, (self.width, self.height), interpolation=self.inter) crops.append(crop) # check to see if the horizontal flips should be taken if self.horiz: # compute the horizontal mirror flips for each crop mirrors = [cv2.flip(c, 1) for c in crops] crops.extend(mirrors) # return the set of crops return np.array(crops) Kerasä¸­çš„æ•°æ®é¢„å¤„ç†åŠŸèƒ½http://keras-cn.readthedocs.io/en/latest/preprocessing/sequence/ A. è®¾ç½®éšæœºç§å­ 1np.random.seed(1337) # for reproducibility B. è¾“å…¥æ•°æ®ç»´åº¦è§„æ ¼åŒ–ï¼Œè¿™é‡Œæ¯ä¸ªæ ·æœ¬åªæ˜¯sizeä¸º784çš„ä¸€ç»´æ•°ç»„ã€‚1X_train = X_train.reshape(60000, 784) å°†ç±»åˆ«æ ‡ç­¾è½¬æ¢ä¸ºone-hot encodingï¼Œ è¿™ä¸€æ­¥å¯¹å¤šåˆ†ç±»æ˜¯å¿…é¡»çš„ 1one_hot_labels = keras.utils.np_utils.to_categorical(labels, num_classes=10) C. è¾“å…¥æ•°æ®ç±»å‹è½¬æ¢ï¼Œæ•°å€¼å½’ä¸€åŒ– 12X_train = X_train.astype('float32')X_train /= 255 åºåˆ—é¢„å¤„ç† æ–‡æœ¬é¢„å¤„ç† å›¾ç‰‡é¢„å¤„ç† æ ·æœ¬æ•°æ®åºåˆ—åŒ–ä¸ºHDF5æ–‡ä»¶ ç›®çš„ï¼šå‡å°‘å¤šæ¬¡IOè¯»å–çš„å»¶æ—¶ å‚è€ƒ ã€Šè§£æå·ç§¯ç¥ç»ç½‘ç»œâ€”æ·±åº¦å­¦ä¹ å®è·µæ‰‹å†Œã€‹ Kerasæ–‡æ¡£ http://deeplearning.stanford.edu/wiki/index.php/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86","categories":[{"name":"æ·±åº¦å­¦ä¹ ","slug":"æ·±åº¦å­¦ä¹ ","permalink":"http://blog.a-stack.com/categories/æ·±åº¦å­¦ä¹ /"},{"name":"åŸºç¡€çŸ¥è¯†","slug":"æ·±åº¦å­¦ä¹ /åŸºç¡€çŸ¥è¯†","permalink":"http://blog.a-stack.com/categories/æ·±åº¦å­¦ä¹ /åŸºç¡€çŸ¥è¯†/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://blog.a-stack.com/tags/AI/"},{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"é¢„å¤„ç†","slug":"é¢„å¤„ç†","permalink":"http://blog.a-stack.com/tags/é¢„å¤„ç†/"}]},{"title":"Tips for Keras","slug":"Tips-for-Keras","date":"2018-02-22T05:20:28.000Z","updated":"2018-05-15T09:14:33.839Z","comments":true,"path":"2018/02/22/Tips-for-Keras/","link":"","permalink":"http://blog.a-stack.com/2018/02/22/Tips-for-Keras/","excerpt":"æ’°å†™ä¸€ç¯‡åšæ–‡ç”¨äºè®°å½•Kerasä½¿ç”¨è¿‡ç¨‹ä¸­çš„ä¸€äº›å…³é”®ç”¨æ³•ï¼Œä»¥æ–¹ä¾¿é€ŸæŸ¥ã€‚","text":"æ’°å†™ä¸€ç¯‡åšæ–‡ç”¨äºè®°å½•Kerasä½¿ç”¨è¿‡ç¨‹ä¸­çš„ä¸€äº›å…³é”®ç”¨æ³•ï¼Œä»¥æ–¹ä¾¿é€ŸæŸ¥ã€‚ æ¨¡å‹å¯è§†åŒ–1keras.utils.vis_utilsæ¨¡å—æä¾›äº†ç”»å‡ºKerasæ¨¡å‹çš„å‡½æ•°ï¼ˆåˆ©ç”¨graphvizï¼‰ è¯¥å‡½æ•°å°†ç”»å‡ºæ¨¡å‹ç»“æ„å›¾ï¼Œå¹¶ä¿å­˜æˆå›¾ç‰‡ï¼š 12from keras.utils import plot_modelplot_model(model, to_file='model.png') plot_modelæ¥æ”¶ä¸¤ä¸ªå¯é€‰å‚æ•°ï¼š show_shapesï¼šæŒ‡å®šæ˜¯å¦æ˜¾ç¤ºè¾“å‡ºæ•°æ®çš„å½¢çŠ¶ï¼Œé»˜è®¤ä¸ºFalse show_layer_names:æŒ‡å®šæ˜¯å¦æ˜¾ç¤ºå±‚åç§°,é»˜è®¤ä¸ºTrue æˆ‘ä»¬ä¹Ÿå¯ä»¥ç›´æ¥è·å–ä¸€ä¸ªpydot.Graphå¯¹è±¡ï¼Œç„¶åæŒ‰ç…§è‡ªå·±çš„éœ€è¦é…ç½®å®ƒï¼Œä¾‹å¦‚ï¼Œå¦‚æœè¦åœ¨ipythonä¸­å±•ç¤ºå›¾ç‰‡ 1234from IPython.display import SVGfrom keras.utils.vis_utils import model_to_dotSVG(model_to_dot(model).create(prog='dot', format='svg')) ã€Tipsã€‘ä¾èµ– pydot-ng å’Œ graphvizï¼Œè‹¥å‡ºç°é”™è¯¯ï¼Œç”¨å‘½ä»¤è¡Œè¾“å…¥ pip install pydot-ng &amp; brew install graphviz å‚è€ƒ 1. http://keras-cn.readthedocs.io/en/latest/other/visualization/ &#8617;","categories":[{"name":"å·¥å…·","slug":"å·¥å…·","permalink":"http://blog.a-stack.com/categories/å·¥å…·/"},{"name":"Keras","slug":"å·¥å…·/Keras","permalink":"http://blog.a-stack.com/categories/å·¥å…·/Keras/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://blog.a-stack.com/tags/AI/"},{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"http://blog.a-stack.com/tags/äººå·¥æ™ºèƒ½/"},{"name":"Keras","slug":"Keras","permalink":"http://blog.a-stack.com/tags/Keras/"},{"name":"æŠ€å·§","slug":"æŠ€å·§","permalink":"http://blog.a-stack.com/tags/æŠ€å·§/"}]},{"title":"åšå®¢ç›¸å…³é…ç½®","slug":"hexo_config","date":"2018-02-19T16:00:00.000Z","updated":"2018-05-23T12:45:41.660Z","comments":true,"path":"2018/02/20/hexo_config/","link":"","permalink":"http://blog.a-stack.com/2018/02/20/hexo_config/","excerpt":"2018å¹´2æœˆ20æ—¥ï¼Œé‡æ–°å¯ç”¨ä¸ªäººblogç³»ç»Ÿï¼Œç”¨äºæ•´ç†æŠ€æœ¯æ–‡æ¡£å¹¶è¿›è¡ŒæŠ€æœ¯åˆ†äº«ï¼Œä¸»è¦å›´ç»•äººå·¥æ™ºèƒ½ç›¸å…³æŠ€æœ¯æœ€æ–°æŠ€æœ¯è¿›å±•å’ŒåŠ¨æ€ã€‚ æ¦‚è¿°2018å¹´2æœˆ20æ—¥ï¼Œé‡æ–°å¯ç”¨ä¸ªäººblogç³»ç»Ÿï¼Œç”¨äºæ•´ç†æŠ€æœ¯æ–‡æ¡£å¹¶è¿›è¡ŒæŠ€æœ¯åˆ†äº«ï¼Œä¸»è¦å›´ç»•äººå·¥æ™ºèƒ½ç›¸å…³æŠ€æœ¯æœ€æ–°æŠ€æœ¯è¿›å±•å’ŒåŠ¨æ€ã€‚ ä½¿ç”¨æ¡†æ¶ï¼š hexo(v1.0.4) ä¸»é¢˜ï¼š hexo-theme-melody ç›¸å…³ä¾èµ–: hexo-renderer-jade hexo-renderer-stylus hexo-algoliasearch hexo-wordcount hexo-deployer-git hexo-generator-searchdbâ€‹","text":"2018å¹´2æœˆ20æ—¥ï¼Œé‡æ–°å¯ç”¨ä¸ªäººblogç³»ç»Ÿï¼Œç”¨äºæ•´ç†æŠ€æœ¯æ–‡æ¡£å¹¶è¿›è¡ŒæŠ€æœ¯åˆ†äº«ï¼Œä¸»è¦å›´ç»•äººå·¥æ™ºèƒ½ç›¸å…³æŠ€æœ¯æœ€æ–°æŠ€æœ¯è¿›å±•å’ŒåŠ¨æ€ã€‚ æ¦‚è¿°2018å¹´2æœˆ20æ—¥ï¼Œé‡æ–°å¯ç”¨ä¸ªäººblogç³»ç»Ÿï¼Œç”¨äºæ•´ç†æŠ€æœ¯æ–‡æ¡£å¹¶è¿›è¡ŒæŠ€æœ¯åˆ†äº«ï¼Œä¸»è¦å›´ç»•äººå·¥æ™ºèƒ½ç›¸å…³æŠ€æœ¯æœ€æ–°æŠ€æœ¯è¿›å±•å’ŒåŠ¨æ€ã€‚ ä½¿ç”¨æ¡†æ¶ï¼š hexo(v1.0.4) ä¸»é¢˜ï¼š hexo-theme-melody ç›¸å…³ä¾èµ–: hexo-renderer-jade hexo-renderer-stylus hexo-algoliasearch hexo-wordcount hexo-deployer-git hexo-generator-searchdbâ€‹ å®‰è£…éƒ¨ç½² Hexo Serverçš„éƒ¨ç½² git submodule è®¾ç½® é¢å¤–ä¿®æ”¹é…ç½®DaoVoice é¦–å…ˆåœ¨ daovoice æ³¨å†Œè´¦å·,é‚€è¯·ç æ˜¯0f81ff2fï¼Œæ³¨å†Œå®Œæˆåä¼šå¾—åˆ°ä¸€ä¸ª app_idï¼› åœ¨head.pugæ–‡ä»¶æ’å…¥å¦‚ä¸‹ä»£ç ï¼š 1234567if theme.daovoice script. (function(i,s,o,g,r,a,m)&#123;i[\"DaoVoiceObject\"]=r;i[r]=i[r]||function()&#123;(i[r].q=i[r].q||[]).push(arguments)&#125;,i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset=\"utf-8\";m.parentNode.insertBefore(a,m)&#125;)(window,document,\"script\",('https:' == document.location.protocol ? 'https:' : 'http:') + \"//widget.daovoice.io/widget/d29c876c.js\",\"daovoice\") daovoice('init', &#123; app_id: '!&#123;theme.daovoice_app_id&#125;' &#125;); daovoice('update'); åœ¨_config.ymlæ–‡ä»¶ä¸­å¢åŠ å¦‚ä¸‹å†…å®¹ï¼š 123# Online contact daovoice: truedaovoice_app_id: è¿™é‡Œå¡«ä½ çš„åˆšæ‰è·å¾—çš„ app_id ä¿®æ”¹æ ‡é¢˜å­—ä½“æ˜¾ç¤ºæ ·å¼pos.stylæ–‡ä»¶ å…¶å®ƒbLF will be replacedWindows æäº¤å‘½ä»¤çš„æ—¶å€™å‡ºç° warning: LF will be replaced by CRLF in XXXXXXXXXXXXXX çš„è­¦å‘Šã€‚è¾“å…¥å‘½ä»¤ï¼š è§£å†³åŠæ³• 1git config --global core.autocrlf false To-Do List CDN SOE hexo-theme-doc é›†æˆ â€‹","categories":[{"name":"å·¥å…·","slug":"å·¥å…·","permalink":"http://blog.a-stack.com/categories/å·¥å…·/"}],"tags":[{"name":"åšå®¢","slug":"åšå®¢","permalink":"http://blog.a-stack.com/tags/åšå®¢/"},{"name":"é…ç½®","slug":"é…ç½®","permalink":"http://blog.a-stack.com/tags/é…ç½®/"}]},{"title":"Markdown Formats","slug":"Markdown_Reference","date":"2017-12-31T16:00:00.000Z","updated":"2018-05-23T12:45:14.341Z","comments":true,"path":"2018/01/01/Markdown_Reference/","link":"","permalink":"http://blog.a-stack.com/2018/01/01/Markdown_Reference/","excerpt":"Markdownç›¸å…³è¯­æ³•æ€»ç»“","text":"Markdownç›¸å…³è¯­æ³•æ€»ç»“ Markdown ä¸»è¦æ ¼å¼åŠæ•ˆæœOverviewMarkdown is created by Daring Fireball, the original guideline is here. Its syntax, however, varies between different parsers or editors. Typora is using GitHub Flavored Markdown. Please note that HTML fragments in markdown source will be recognized but not parsed or rendered. Also, there may be small reformatting on the original markdown source code after saving. æ•°å­¦å…¬å¼åŸºæœ¬ è¡Œå†…å…¬å¼ 1$...$ å±…ä¸­æ˜¾ç¤ºï¼š 1$$...$$ â€‹ \\mathbf{V}_1 \\times \\mathbf{V}_2 = \\begin{vmatrix} \\mathbf{i} & \\mathbf{j} & \\mathbf{k} \\\\ \\frac{\\partial X}{\\partial u} & \\frac{\\partial Y}{\\partial u} & 0 \\\\ \\frac{\\partial X}{\\partial v} & \\frac{\\partial Y}{\\partial v} & 0 \\\\ \\end{vmatrix} In markdown source file, math block is LaTeX expression wrapped by â€˜$$â€™ mark: 1234567$$\\mathbf&#123;V&#125;_1 \\times \\mathbf&#123;V&#125;_2 = \\begin&#123;vmatrix&#125; \\mathbf&#123;i&#125; &amp; \\mathbf&#123;j&#125; &amp; \\mathbf&#123;k&#125; \\\\\\frac&#123;\\partial X&#125;&#123;\\partial u&#125; &amp; \\frac&#123;\\partial Y&#125;&#123;\\partial u&#125; &amp; 0 \\\\\\frac&#123;\\partial X&#125;&#123;\\partial v&#125; &amp; \\frac&#123;\\partial Y&#125;&#123;\\partial v&#125; &amp; 0 \\\\\\end&#123;vmatrix&#125;$$ å¸Œè…Šå­—æ¯ æ˜¾ç¤º å‘½ä»¤ æ˜¾ç¤º å‘½ä»¤ Î± \\alpha Î² \\beta Î³ \\gamma Î´ \\delta Îµ \\epsilon Î¶ \\zeta Î· \\eta Î¸ \\theta Î¹ \\iota Îº \\kappa Î» \\lambda Î¼ \\mu Î½ \\nu Î¾ \\xi Ï€ \\pi Ï \\rho Ïƒ \\sigma Ï„ \\tau Ï… \\upsilon Ï† \\phi Ï‡ \\chi Ïˆ \\psi Ï‰ \\omega è‹¥å¤§å†™å­—æ¯ï¼Œå‘½ä»¤é¦–å­—æ¯å¤§å†™å³å¯ï¼š$\\Omega$,çš„ä»£ç ä¸º\\Omega è‹¥éœ€è¦æ–œä½“ï¼Œå‘½ä»¤å‰æ·»åŠ varå‰ç¼€ï¼š$\\varOmega$,ä»£ç ä¸º\\varOmega ä¿®é¥°ç¬¦ ä¸Šä¸‹æ ‡ ä¸Šæ ‡ä½¿ç”¨ï¼š^ ä¸‹æ ‡ä½¿ç”¨ï¼š_ ä¸¾ä¾‹ï¼š x_{n} ^2 çŸ¢é‡ \\vec a : $\\vec a$ \\overrightarrow {xy}: $\\overrightarrow {xy}$ å­—ä½“ Typewriterï¼š \\mathtt {A}: $ \\mathtt {ABCDEFGHIJKLMNOPQRSTUVWXYZ}$ Blackbloard Bold: \\mathbb {A}: $\\mathbb {ABCDEFGHIJKLMNOPQRSTUVWXY}$ SansSerif: \\mathsf {A}: $\\mathsf {ABCDEFGHIJKLMNOPQRSTUVWXY}$ åˆ†ç»„æ˜¾ç¤º {...} æ‹¬å· () [] \\langle, \\rangle: $\\langle â€¦ \\rangle$ æ±‚å’Œã€æé™ä¸ç§¯åˆ† æ±‚å’Œï¼š \\sum $\\sum_{i=1}^n{a_i}$ æé™ï¼š \\lim_{x\\to 0} $\\lim_{x\\to 0}$ ç§¯åˆ†ï¼š \\int_0^\\infty{x}dx $\\int_0^\\infty{x}dx$ åˆ†å¼ä¸æ ¹å· åˆ†å¼ï¼š\\frac{åˆ†å­}{åˆ†æ¯} $\\frac{åˆ†å­}{åˆ†æ¯}$ æ ¹å¼ï¼š \\sqrt[x]{y} $\\sqrt[x]{y}$ ç‰¹æ®Šå‡½æ•° \\sin x \\ln x \\max(A,B,C) $\\sin x$ ,$\\ln x$, $max(A,B,C)$ ç‰¹æ®Šç¬¦å· æ˜¾ç¤º å‘½ä»¤ æ˜¾ç¤º å‘½ä»¤ æ˜¾ç¤º å‘½ä»¤ $\\lt$ \\lt $\\cup$ \\cup $\\to$ \\to $\\gt$ \\gt $\\cap$ \\cap $\\forall$ \\forall $\\le$ \\le $\\setminus$ \\setminus $\\exists$ \\exists $\\ge$ \\ge $\\subset$ \\subset $\\lnot$ lnot $\\neq$ \\neq $\\subseteq$ \\subseteq $\\nabla$ \\nabla $\\not$ not $\\subsetneq$ \\subsetneq $\\partial$ \\partial $\\times$ times $\\supset$ \\supset $\\approx$ \\approx $\\div$ div $\\in$ \\in $\\ldots$ \\ldots $\\pm$ pm $\\notin$ \\notin $\\bullet$ \\bullet $\\cdot$ cdot $\\emptyset$ \\emptyset $\\circ$ \\circ ç©ºæ ¼ å°ç©ºæ ¼ï¼š a\\ b 4ç©ºæ ¼ï¼š a\\quad b å¤šè¡Œå…¬å¼ 1234567891011$$sign(x)=\\begin&#123;equation&#125; \\left\\&#123; \\begin&#123;array&#125;&#123;lr&#125; +1, &amp; x \\ge 0\\\\ -1, &amp; x \\lt 0 \\end&#123;array&#125; \\right. \\end&#123;equation&#125; $$ sign(x)= \\begin{equation} \\left\\{ \\begin{array}{lr} +1, & x \\ge 0\\\\ -1, & x \\lt 0 \\end{array} \\right. \\end{equation} å…¬å¼ç¼–å· 123$$\\begin&#123;equation&#125; h_\\theta (x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\theta_3 x_3 + \\cdots + \\theta_n x_n = \\theta ^T x \\tag&#123;1.a&#125; \\end&#123;equation&#125;$$ \\begin{equation} h_\\theta (x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\theta_3 x_3 + \\cdots + \\theta_n x_n = \\theta ^T x \\tag{1.a} \\end{equation}å‚è€ƒ MathJax Baisic Tutorial https://www.jianshu.com/p/a0aa94ef8ab2 Block ElementsParagraph and line breaksA paragraph is simply one or more consecutive lines of text. In markdown source code, paragraphs are separated by more than one blank lines. In Typora, you only need to press Return to create a new paragraph. Press Shift + Return to create a single line break. However, most markdown parser will ignore single line break, to make other markdown parsers recognize your line break, you can leave two whitespace at the end of the line, or insert &lt;br/&gt;. HeadersHeaders use 1-6 hash characters at the start of the line, corresponding to header levels 1-6. For example: 12345# This is an H1## This is an H2###### This is an H6 In typora, input â€˜#â€™s followed by title content, and press Return key will create a header. BlockquotesMarkdown uses email-style &gt; characters for block quoting. They are presented as: 1234567&gt; This is a blockquote with two paragraphs. This is first paragraph.&gt;&gt; This is second pragraph.Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus.&gt; This is another blockquote with one paragraph. There is three empty line to seperate two blockquote. In typora, just input â€˜&gt;â€™ followed by quote contents a block quote is generated. Typora will insert proper â€˜&gt;â€™ or line break for you. Block quote inside anther block quote is allowed by adding additional levels of â€˜&gt;â€™. ListsInput * list item 1 will create an un-ordered list, the * symbol can be replace with + or -. Input 1. list item 1 will create an ordered list, their markdown source code is like: 123456789## un-ordered list* Red* Green* Blue## ordered list1. Red2. Green3. Blue Task ListTask lists are lists with items marked as either [ ] or [x] (incomplete or complete). For example: 12345- [ ] a task list item- [ ] list syntax required- [ ] normal **formatting**, @mentions, #1234 refs- [ ] incomplete- [x] completed You can change the complete/incomplete state by click the checkbox before the item. (Fenced) Code BlocksTypora only support fences in Github Flavored Markdown. Original code blocks in markdown is not supported. Using fences is easy: Input ``` and press return. Add an optional language identifier after ``` and weâ€™ll run it through syntax highlighting: 123Here&apos;s an example:â€‹ function test() { console.log(â€œnotice the blank line before this function?â€);}â€‹1234567syntax highlighting:â€‹```rubyrequire 'redcarpet'markdown = Redcarpet.new(\"Hello World!\")puts markdown.to_htmlâ€‹ 12345678910111213141516### TablesInput `| First Header | Second Header |` and press `return` key will create a table with two column.After table is created, focus on that table will pop up a toolbar for table, where you can resize, align, or delete table. You can also use context menu to copy and add/delete column/row.Following descriptions can be skipped, as markdown source code for tables are generated by typora automatically.In markdown source code, they look like:``` markdown| First Header | Second Header || ------------- | ------------- || Content Cell | Content Cell || Content Cell | Content Cell | You can also include inline Markdown such as links, bold, italics, or strikethrough. Finally, by including colons : within the header row, you can define text to be left-aligned, right-aligned, or center-aligned: 12345| Left-Aligned | Center Aligned | Right Aligned || :------------ |:---------------:| -----:|| col 3 is | some wordy text | $1600 || col 2 is | centered | $12 || zebra stripes | are neat | $1 | A colon on the left-most side indicates a left-aligned column; a colon on the right-most side indicates a right-aligned column; a colon on both sides indicates a center-aligned column. Footnotes123You can create footnotes like this[^footnote].[^footnote]: Here is the *text* of the **footnote**. will produce: You can create footnotes like thisfootnote. footnote. Here is the text of the footnote. &#8617; Mouse on the â€˜footnoteâ€™ superscript to see content of the footnote. Horizontal RulesInput *** or --- on a blank line and press return will draw a horizontal line. YAML Front MatterTypora support YAML Front Matter now. Input --- at the top of the article and then press Enter will introduce one. Or insert one metadata block from the menu. Table of Contents (TOC)Input [toc] then press Return key will create a section for â€œTable of Contentsâ€ extracting all headers from oneâ€™s writing, its contents will be updated automatically. Diagrams (Sequence, Flowchart and Mermaid)Typora supports, sequence, flowchart and mermaid, after this feature is enabled from preference panel. See this document for detail. Span ElementsSpan elements will be parsed and rendered right after your typing. Moving cursor in middle of those span elements will expand those elements into markdown source. Following will explain the syntax of those span element. LinksMarkdown supports two style of links: inline and reference. In both styles, the link text is delimited by [square brackets]. To create an inline link, use a set of regular parentheses immediately after the link textâ€™s closing square bracket. Inside the parentheses, put the URL where you want the link to point, along with an optional title for the link, surrounded in quotes. For example: 123This is [an example](http://example.com/ \"Title\") inline link.[This link](http://example.net/) has no title attribute. will produce: This is an example inline link. (&lt;p&gt;This is &lt;a href=&quot;http://example.com/&quot; title=&quot;Title&quot;&gt;) This link has no title attribute. (&lt;p&gt;&lt;a href=&quot;http://example.net/&quot;&gt;This link&lt;/a&gt; has no) Internal LinksYou can set the href to headers, which will create a bookmark that allow you to jump to that section after clicking. For example: Command(on Windows: Ctrl) + Click This link will jump to header Block Elements. To see how to write that, please move cursor or click that link with âŒ˜ key pressed to expand the element into markdown source. Reference LinksReference-style links use a second set of square brackets, inside which you place a label of your choosing to identify the link: 12345This is [an example][id] reference-style link.Then, anywhere in the document, you define your link label like this, on a line by itself:[id]: http://example.com/ \"Optional Title Here\" In typora, they will be rendered like: This is an example reference-style link. The implicit link name shortcut allows you to omit the name of the link, in which case the link text itself is used as the name. Just use an empty set of square brackets â€” e.g., to link the word â€œGoogleâ€ to the google.com web site, you could simply write: 1234[Google][]And then define the link:[Google]: http://google.com/ In typora click link will expand it for editing, command+click will open the hyperlink in web browser. URLsTypora allows you to insert urls as links, wrapped by &lt;brackets&gt;. &lt;i@typora.io&gt; becomes &#105;&#x40;&#x74;&#121;&#x70;&#x6f;&#x72;&#97;&#46;&#105;&#111;. Typora will aslo auto link standard URLs. e.g: www.google.com. ImagesImage looks similar with links, but it requires an additional ! char before the start of link. Image syntax looks like this: 123![Alt text](/path/to/img.jpg)![Alt text](/path/to/img.jpg \"Optional title\") You are able to use drag &amp; drop to insert image from image file or we browser. And modify the markdown source code by clicking on the image. Relative path will be used if image is in same directory or sub-directory with current editing document when drag &amp; drop. For more tips on images, please read http://support.typora.io//Images/ EmphasisMarkdown treats asterisks (*) and underscores (_) as indicators of emphasis. Text wrapped with one * or _ will be wrapped with an HTML &lt;em&gt; tag. E.g: 123*single asterisks*_single underscores_ output: single asterisks single underscores GFM will ignores underscores in words, which is commonly used in code and names, like this: wow_great_stuff do_this_and_do_that_and_another_thing. To produce a literal asterisk or underscore at a position where it would otherwise be used as an emphasis delimiter, you can backslash escape it: 1\\*this text is surrounded by literal asterisks\\* Typora recommends to use * symbol. Strongdouble *â€™s or _â€™s will be wrapped with an HTML &lt;strong&gt; tag, e.g: 123**double asterisks**__double underscores__ output: double asterisks double underscores Typora recommends to use ** symbol. CodeTo indicate a span of code, wrap it with backtick quotes (`). Unlike a pre-formatted code block, a code span indicates code within a normal paragraph. For example: 1Use the `printf()` function. will produce: Use the printf() function. StrikethroughGFM adds syntax to create strikethrough text, which is missing from standard Markdown. ~~Mistaken text.~~ becomes Mistaken text. UnderlineUnderline is powered by raw HTML. &lt;u&gt;Underline&lt;/u&gt; becomes Underline. Emoji :happy:Input emoji with syntax :smile:. User can trigger auto-complete suggestions for emoji by pressing ESC key, or trigger it automatically after enable it on preference panel. Also, input UTF8 emoji char directly from Edit -&gt; Emoji &amp; Symbols from menu bar is also supported. HTMLTypora cannot render html fragments. But typora can parse and render very limited HTML fragments, as an extension of Markdown, including: Underline: &lt;u&gt;underline&lt;/u&gt; Image: &lt;img src=&quot;http://www.w3.org/html/logo/img/mark-word-icon.png&quot; width=&quot;200px&quot; /&gt; (And width, height attribute in HTML tag, and width, height, zoom style in style attribute will be applied.) Comments: &lt;!-- This is some comments --&gt; Hyperlink: &lt;a href=&quot;http://typora.io&quot; target=&quot;_blank&quot;&gt;link&lt;/a&gt;. Most of their attributes, styles, or classes will be ignored. For other tags, typora will render them as raw HTML snippets. But those HTML will be exported on print or export. SubscriptTo use this feature, first, please enable it in Preference Panel -&gt; Markdown Tab. Then use ~ to wrap subscript content, for example: H~2~O, X~long\\ text~/ SuperscriptTo use this feature, first, please enable it in Preference Panel -&gt; Markdown Tab. Then use ^ to wrap superscript content, for example: X^2^. HighlightTo use this feature, first, please enable it in Preference Panel -&gt; Markdown Tab. Then use == to wrap superscript content, for example: ==highlight==.","categories":[{"name":"å·¥å…·","slug":"å·¥å…·","permalink":"http://blog.a-stack.com/categories/å·¥å…·/"},{"name":"MarkDown","slug":"å·¥å…·/MarkDown","permalink":"http://blog.a-stack.com/categories/å·¥å…·/MarkDown/"}],"tags":[{"name":"æŠ€å·§","slug":"æŠ€å·§","permalink":"http://blog.a-stack.com/tags/æŠ€å·§/"},{"name":"æ€»ç»“","slug":"æ€»ç»“","permalink":"http://blog.a-stack.com/tags/æ€»ç»“/"},{"name":"Markdown","slug":"Markdown","permalink":"http://blog.a-stack.com/tags/Markdown/"}]},{"title":"è¯»ä¹¦ç¬”è®°-<è…¾è®¯ä¼ ï¼šä¸­å›½äº’è”ç½‘å…¬å¸è¿›åŒ–è®º>","slug":"è¯»ä¹¦ç¬”è®°-è…¾è®¯ä¼ ","date":"2017-02-02T07:33:43.000Z","updated":"2018-05-15T13:32:58.866Z","comments":true,"path":"2017/02/02/è¯»ä¹¦ç¬”è®°-è…¾è®¯ä¼ /","link":"","permalink":"http://blog.a-stack.com/2017/02/02/è¯»ä¹¦ç¬”è®°-è…¾è®¯ä¼ /","excerpt":"2017å¹´1æœˆä»½ï¼Œæ•´ç†äº†ä¸€å †è®¡åˆ’åœ¨2017å¹´é˜…è¯»çš„ä¹¦ç±æ¸…å•ï¼Œå…¶ä¸­åŒ…æ‹¬ä¸€äº›è¯»è¿‡å¤šéçš„è€ä¹¦ï¼Œä¹Ÿæœ‰ä¸€äº›åˆšåˆšé—®ä¸–çš„æ–°ä¹¦ã€‚å¸Œæœ›é€šè¿‡ä¸€è½®å…¨æ–°çš„é˜…è¯»èƒ½èƒ½å¤Ÿè·å¾—æ›´å¤šçš„æ„Ÿæ‚Ÿã€‚å…¶ä¸­ã€Šè…¾è®¯ä¼ ï¼šä¸­å›½äº’è”ç½‘å…¬å¸è¿›åŒ–è®ºã€‹åœ¨2016å¹´12æœˆåˆšåˆšå‡ºç‰ˆï¼Œåˆæ˜¯å…³äºBATå·¨å¤´çš„å…¨æ–°è‘—ä½œï¼Œä¸å…å…ˆç¹ä¸ºå¿«ã€‚","text":"2017å¹´1æœˆä»½ï¼Œæ•´ç†äº†ä¸€å †è®¡åˆ’åœ¨2017å¹´é˜…è¯»çš„ä¹¦ç±æ¸…å•ï¼Œå…¶ä¸­åŒ…æ‹¬ä¸€äº›è¯»è¿‡å¤šéçš„è€ä¹¦ï¼Œä¹Ÿæœ‰ä¸€äº›åˆšåˆšé—®ä¸–çš„æ–°ä¹¦ã€‚å¸Œæœ›é€šè¿‡ä¸€è½®å…¨æ–°çš„é˜…è¯»èƒ½èƒ½å¤Ÿè·å¾—æ›´å¤šçš„æ„Ÿæ‚Ÿã€‚å…¶ä¸­ã€Šè…¾è®¯ä¼ ï¼šä¸­å›½äº’è”ç½‘å…¬å¸è¿›åŒ–è®ºã€‹åœ¨2016å¹´12æœˆåˆšåˆšå‡ºç‰ˆï¼Œåˆæ˜¯å…³äºBATå·¨å¤´çš„å…¨æ–°è‘—ä½œï¼Œä¸å…å…ˆç¹ä¸ºå¿«ã€‚ å†™åœ¨å‰é¢ â€‹ å…³äºè¿™æœ¬ä¹¦ï¼Œå®˜æ–¹ï¼ˆå‡ºç‰ˆç¤¾åŠç½‘ç»œå®£ä¼ æ–¹ï¼‰ç»™å‡ºçš„å®£ä¼ è¯­ä¸ºï¼š è…¾è®¯å®˜æ–¹å”¯ä¸€æˆæƒçš„æƒå¨ä¼ è®° è‘—åè´¢ç»ä½œå®¶å´æ™“æ³¢å€¾åŠ›ä¹‹ä½œ å½“å¸‚å€¼æœ€é«˜çš„ä¸­å›½äº’è”ç½‘å…¬å¸ï¼Œé‡ä¸Šä¸­å›½è´¢ç»ç•Œæœ€å†·é™çš„ä¸€åŒçœ¼ç› è¯»æ‡‚è…¾è®¯ï¼Œè¯»æ‡‚ä¸­å›½äº’è”ç½‘ â€‹ è±†ç“£è¯»ä¹¦ä¸Š,æˆ‘åˆšå¼€å§‹è¯»çš„æ—¶å€™ä¹Ÿç»™å‡ºäº†æ¥è¿‘9åˆ†çš„é«˜è¯„åˆ†ï¼Œå½“ç„¶éšç€æ—¶é—´çš„æ¨ç§»ï¼Œè¶Šæ¥è¶Šæ¥çš„è¯»è€…æ¥å…¥ï¼Œè¯„åˆ†é€æ¸å›è½åˆ°äº†8åˆ†å·¦å³ã€‚ â€‹ æ®è¯´ï¼Œä¸ºäº†å†™è¿™æœ¬ä¹¦ï¼Œå´æ™“æ³¢èŠ±äº†äº”å¹´æ—¶é—´æ•´ç†ææ–™ï¼Œä¸å…è®©äººæƒ³èµ·ï¼Œå½“å¹´è‘—åä½œå®¶æ²ƒå°”ç‰¹Â·è‰¾è¨å…‹æ£®ï¼ˆWalter Isaacsonï¼‰åœ¨2009å¹´èŠ±äº†ä¸¤å¹´ä¸ä¹”å¸ƒæ–¯é¢å¯¹é¢äº¤æµ40å¤šæ¬¡ã€å¯¹ä¹”å¸ƒæ–¯100å¤šä½å®¶åº­æˆå‘˜ã€æœ‹å‹ã€ç«äº‰å¯¹æ‰‹å’ŒåŒäº‹çš„é‡‡è®¿çš„åŸºç¡€ä¸Šæ’°å†™è€Œæˆã€Šå²è’‚å¤«Â·ä¹”å¸ƒæ–¯ä¼ ã€‹ã€‚ å…ˆåæ§½ä¸ºå¿«â€‹ åŸºäºå†™åœ¨å‰é¢éƒ¨åˆ†æåˆ°çš„ä¸‰ç‚¹ï¼Œæˆ‘å¯¹è¿™éƒ¨è‘—ä½œå……æ»¡äº†æœŸå¾…ï¼ŒæœŸæœ›ä¸­å›½ä¹Ÿèƒ½æœ‰ä¸ªå¯ä»¥å°†ä¸­å›½ç§‘æŠ€å·¨å¤´å®Œç¾å‘ˆç°çš„ä½œå®¶ã€‚ä½†å®é™…ä¸Šï¼Œè®©ä¸€ä¸ªè´¢ç»è®°è€…ä¸ºä¸­å›½ç§‘æŠ€ç•ŒæŠŠè„‰è¿˜æ˜¯æœ‰äº›å‹‰å¼ºã€‚ä¸­å›½ç¼ºå°‘è¿™ä¹ˆä¸€ä¸ªèƒ½æŠŠç§‘æŠ€ç•Œçš„äº‹æƒ…è®²æ˜ç™½çš„æ–‡äººã€‚ä½†æœŸå¾…ç§‘æŠ€åœˆå¤–é¢çš„äººèƒ½å¤ŸæŠŠæœ‰äº›å†…å®¹è®²æ¸…æ¥šå´ç»™åˆ«äººè®²ä¸æ¸…æ¥šè‡ªå·±åšçš„å†…å®¹ï¼Œæˆ‘ä»¬å¾€å¾€å–„äºå»åˆ›é€ ç§‘æŠ€æˆæœï¼Œå´æå°‘æ€»ç»“ã€ç§¯ç´¯è¿™äº›æˆæœã€‚æ‰€ä»¥å´æ™“æ³¢åœ¨å¼€ç¯‡å°±å¼ºè°ƒï¼Œè‡ªå·±æœŸæœ›å®Œæˆä¸€éƒ¨å·¨è‘—ï¼Œä½†ç°å®ååˆ†æ®‹å¿ï¼Œè…¾è®¯è¿™å®¶å…¬å¸æ²¡æœ‰è¶³å¤Ÿçš„å²æ–™ç§¯ç´¯ï¼Œå“ªæ€•ä¸€äº›é‡è¦ä¼šè®®çš„ä¼šè®®çºªè¦éƒ½æ²¡æœ‰æ²‰æ·€åœ¨æ–‡å­—ä¸Šã€‚æ‰€ä»¥ä»–é™¤äº†è®¿è°ˆè®©å…³é”®äººç‰©å»å›å¿†ï¼Œç„¶åä¸åœçš„å»éªŒè¯å›å¿†çš„æ­£ç¡®æ€§ï¼Œåªèƒ½é€šè¿‡è¢«æœ‰é™å…¬å¼€çš„è…¾è®¯å†…éƒ¨é‚®ä»¶ä¸­æ”«å–ä¸€äº›ä¿¡æ¯ã€‚ â€‹ æœ€ç»ˆçš„ç»“æœå°±æ˜¯ï¼Œã€Šè…¾è®¯ä¼ ã€‹æˆä¸ºäº†ä¸€éƒ¨å¤§é‡äº’è”ç½‘ä¸Šå…¬å¼€ä¿¡æ¯çš„æ•´ç†ï¼Œé€šè¿‡æ—¶é—´æµæ°´è´¦çš„å½¢å¼å±•ç¤ºäº†å‡ºæ¥ï¼ŒåŠæ—¶å¶å°”åŠ è½½å…¶ä¸­çš„å“ªäº›å¥‡é—»å¼‚äº‹ä¹Ÿå¤§å¤šè¢«æˆ‘ä»¬åš¼è¿‡äº†ï¼Œå¤šå¤šå°‘å°‘æœ‰äº›å¤±æœ›ã€‚ â€‹ å¦ä¸€æ–¹é¢ï¼Œäºã€Šè…¾è®¯ä¼ ã€‹è€Œè¨€ï¼Œå´æ™“æ³¢ä¿¨ç„¶æˆä¸ºäº†è…¾è®¯çš„å®˜æ–¹å‘è¨€äººï¼Œä»–æ˜æ˜¾æ²¡æœ‰ä»ä¸€ä¸ªä¸­ç«‹ä½œå®¶çš„èº«ä»½å»è¯„ä»·å‘ç”Ÿåœ¨ç‰¹å®šå†å²æ—¶æœŸçš„è…¾è®¯äº‹ä»¶ã€‚è‡³å°‘åœ¨ã€Šä¹”å¸ƒæ–¯ä¼ ã€‹ä¸Šï¼Œæ²ƒå°”ç‰¹å¯¹ä¹”å¸ƒæ–¯é™¤äº†æº¢ç¾ä¹‹è¯å¤–ä¹Ÿå¸¸å¸¸èƒ½å¤Ÿçœ‹åˆ°å¯¹ä¹”å¸ƒæ–¯çš„ä¸­æ€§æ‰¹åˆ¤ï¼Œè¿™äº›ä»å®¢è§‚è§’åº¦çš„åæ€å’Œæ‰¹åˆ¤ç»™äº†è¯»è€…å¾ˆå¤šåæ€å’Œæ€æƒ³ç¢°æ’ã€‚è¯šç„¶ï¼Œè…¾è®¯èƒ½å¤Ÿåœ¨å‡ æ¬¡ITå˜è¿ä¹‹åèƒ½å¤Ÿç”Ÿå­˜å’Œå‘å±•æœ‰å…¶å†å²å¿…ç„¶ï¼Œè€Œä¸å•å•æ˜¯è¿æ°”é‚£ä¹ˆç®€å•ï¼Œä½†ã€Šè…¾è®¯ä¼ ã€‹è¿™ç§æ‹¼å‘½ä¼å›¾æ´—ç™½çš„æ–¹å¼ï¼Œå¤šå°‘è®©äººè§‰å¾—ä¸å¤Ÿå®¢è§‚ï¼Œè€Œä¸”å¯¹ä¸€äº›å†å²äº‹ä»¶ï¼ˆ3Qå¤§æˆ˜ï¼Œå°ç±³ ç±³èŠäºå¾®ä¿¡çš„ç§»åŠ¨å®¢æˆ·ç«¯ä¹‹äº‰ï¼‰åªèƒ½å¤Ÿç®€å•çš„é™ˆè¿°ï¼Œè€Œæˆ‘æ‰€æœŸå¾…çš„æ ¹æœ¬æ€§åˆ†ææ˜æ˜¾è¿˜ä¸å¤Ÿé€å½»ã€‚ â€‹ å½“ç„¶ï¼Œæ•´ä½“è€Œè¨€ï¼Œå´æ™“æ³¢è¿˜æ˜¯å¾ˆç”¨å¿ƒçš„åœ¨æ„é€ ä¸­å›½äº’è”ç½‘çš„å‘å±•æ¼”è¿›å†å²å’Œè¶‹åŠ¿æ¼”è¿›ï¼Œæ‰€ä»¥åæ§½å½’åæ§½ï¼Œæˆ‘å°†ç”¨æ›´å¤šçš„ç¯‡å¹…æ¥æè¿°è¿™æœ¬è‘—ä½œç»™æˆ‘çš„æ„Ÿæ‚Ÿã€‚ ä¸­å›½äº’è”ç½‘çš„æ¼”è¿›é©¬åŒ–è…¾çš„äº§å“ç»ç†æ€ç»´å…³äºäº’è”ç½‘+çš„æ€è€ƒ","categories":[{"name":"è¯»ä¹¦ç¬”è®°","slug":"è¯»ä¹¦ç¬”è®°","permalink":"http://blog.a-stack.com/categories/è¯»ä¹¦ç¬”è®°/"}],"tags":[{"name":"æŠ€æœ¯","slug":"æŠ€æœ¯","permalink":"http://blog.a-stack.com/tags/æŠ€æœ¯/"},{"name":"è¯»ä¹¦ç¬”è®°","slug":"è¯»ä¹¦ç¬”è®°","permalink":"http://blog.a-stack.com/tags/è¯»ä¹¦ç¬”è®°/"}]},{"title":"Gitä½¿ç”¨æ€»ç»“","slug":"è¯»ä¹¦ç¬”è®°-Pro-Git","date":"2017-02-02T04:45:13.000Z","updated":"2018-05-15T09:14:33.908Z","comments":false,"path":"2017/02/02/è¯»ä¹¦ç¬”è®°-Pro-Git/","link":"","permalink":"http://blog.a-stack.com/2017/02/02/è¯»ä¹¦ç¬”è®°-Pro-Git/","excerpt":"ä¸€ç›´åœ¨ç”¨Gitä½œä¸ºä»£ç ç‰ˆæœ¬æ§åˆ¶å·¥å…·ï¼Œä¸€èˆ¬éƒ½æ˜¯ç°æŸ¥ç°ç”¨ï¼Œéš¾å¾—æŠŠä¸€æœ¬ä¸“é—¨ä»‹ç»gitçš„ä¹¦ä»å¤´è¯»åˆ°å°¾ã€‚åšä¸ªç¬”è®°ï¼Œè®°å½•ä»¥ä¸‹æ–°Getåˆ°çš„ä¸€äº›æŠ€èƒ½ï¼Œä»¥å¤‡ä»¥åå¿«é€ŸæŸ¥çœ‹ã€‚","text":"ä¸€ç›´åœ¨ç”¨Gitä½œä¸ºä»£ç ç‰ˆæœ¬æ§åˆ¶å·¥å…·ï¼Œä¸€èˆ¬éƒ½æ˜¯ç°æŸ¥ç°ç”¨ï¼Œéš¾å¾—æŠŠä¸€æœ¬ä¸“é—¨ä»‹ç»gitçš„ä¹¦ä»å¤´è¯»åˆ°å°¾ã€‚åšä¸ªç¬”è®°ï¼Œè®°å½•ä»¥ä¸‹æ–°Getåˆ°çš„ä¸€äº›æŠ€èƒ½ï¼Œä»¥å¤‡ä»¥åå¿«é€ŸæŸ¥çœ‹ã€‚ å†™åœ¨å‰é¢â€‹ ã€ŠPro Gitã€‹ç”±GitHubå‘˜å·¥Scott Chaconå’Œå¦ä¸€ä½çˆ±å¥½è€…Ben Straubå…±åŒç¼–å†™ï¼Œä¸»è¦ä»‹ç»äº†Gitä½¿ç”¨åŸºç¡€å’ŒåŸç†ï¼Œé€‚åˆGitçˆ±å¥½è€…å’Œåˆå­¦è€…å‚è€ƒã€‚ The entire Pro Git book, written by Scott Chacon and Ben Straub and published by Apress, is available here. All content is licensed under the Creative Commons Attribution Non Commercial Share Alike 3.0 license. Print versions of the book are available on Amazon.com. å¯é€šè¿‡å¦‚ä¸‹åœ°å€è·å–ï¼ˆå¦å¤–æœ¬æ–‡æœ«å°¾æä¾›äº†ä¸åŒæ ¼å¼ä¸‹è½½çš„åœ°å€ï¼‰ï¼š å®˜ç½‘ï¼šhttp://git-scm.com/book/en/v2ï¼ˆç¬¬äºŒç‰ˆï¼‰ ä¸­æ–‡ç¿»è¯‘ï¼šhttps://git-scm.com/book/zh/v2ï¼ˆç¬¬äºŒç‰ˆï¼‰â€‹ Take a Note for Reading è¿™æ¬¡ç¬”è®°æ•´ç†æˆ‘å°†ä»¥2014å¹´çš„ç¬¬äºŒç‰ˆè‹±æ–‡ç‰ˆä¸ºåŸºç¡€ï¼Œè®°å½•è¿™ä¸ªè¿‡ç¨‹ä¸­æ‰€è·å¾—çš„æ–°çš„æŠ€èƒ½ç‚¹ã€‚ åŒç±»å·¥å…· Subversion Perforce Bazaar Gitç‰¹ç‚¹ æ•°æ®å­˜å‚¨æ–¹å¼â€”-ã€‹a stream of snapshots ç¦»çº¿å¤„ç†å’Œç¼–è¾‘ Checksum ç®—æ³•ï¼šSHA-1 hash 0. ç¯å¢ƒé…ç½® Gitå…¨å±€é…ç½®æ–‡ä»¶çš„æ”¹å†™é€šè¿‡æ·»åŠ --globalå®ç°Gitçš„é…ç½®æ–‡ä»¶ï¼ˆæ­¤å¤„ä»…é’ˆå¯¹æŸä¸ªrepoï¼‰ä½ç½®ä¸º.git/config åŸºæœ¬ä¿¡æ¯é…ç½® 1234567$ git config --global user.name \"John Doe\"$ git config --global user.email johndoe@example.com$ git config --global pull.rebase true$ git config --global core.editor emacs$ git config --global color.ui true# Windowsç¯å¢ƒä¸‹ï¼Œç¼–è¾‘å™¨çš„é…ç½®å¦‚ä¸‹$ git config --global core.editor \"'C:/Program Files (x86)/Notepad++/notepad++.exe' -multiInst é…ç½®å®Œæˆä¹‹åï¼Œå¯ä»¥é€šè¿‡å¦‚ä¸‹å‘½ä»¤æ£€æŸ¥é…ç½®æƒ…å†µï¼š 1$ git config --list åˆ«åè®¾ç½® 123$ git config --global alias.unstage 'reset HEAD --'$ git config --global alias.last 'log -1 HEAD'... 1. GitåŸºç¡€â€‹ ä¸‹å›¾æè¿°äº†gitå¤„ç†æ–‡ä»¶çš„ç”Ÿå‘½å‘¨æœŸ å…³äº.gitignoreæ–‡ä»¶â€‹ æ–‡ä»¶ .gitignore çš„æ ¼å¼è§„èŒƒå¦‚ä¸‹ï¼š æ‰€æœ‰ç©ºè¡Œæˆ–è€…ä»¥ ï¼ƒ å¼€å¤´çš„è¡Œéƒ½ä¼šè¢« Git å¿½ç•¥ã€‚ å¯ä»¥ä½¿ç”¨æ ‡å‡†çš„ glob æ¨¡å¼åŒ¹é…ã€‚ åŒ¹é…æ¨¡å¼å¯ä»¥ä»¥/å¼€å¤´é˜²æ­¢é€’å½’ã€‚ åŒ¹é…æ¨¡å¼å¯ä»¥ä»¥/ç»“å°¾æŒ‡å®šç›®å½•ã€‚ è¦å¿½ç•¥æŒ‡å®šæ¨¡å¼ä»¥å¤–çš„æ–‡ä»¶æˆ–ç›®å½•ï¼Œå¯ä»¥åœ¨æ¨¡å¼å‰åŠ ä¸ŠæƒŠå¹å·!å–åã€‚ æ‰€è°“çš„ glob æ¨¡å¼æ˜¯æŒ‡ shell æ‰€ä½¿ç”¨çš„ç®€åŒ–äº†çš„æ­£åˆ™è¡¨è¾¾å¼ã€‚ æ˜Ÿå·*åŒ¹é…é›¶ä¸ªæˆ–å¤šä¸ªä»»æ„å­—ç¬¦ï¼›[abc] åŒ¹é…ä»»ä½•ä¸€ä¸ªåˆ—åœ¨æ–¹æ‹¬å·ä¸­çš„å­—ç¬¦ï¼ˆè¿™ä¸ªä¾‹å­è¦ä¹ˆåŒ¹é…ä¸€ä¸ª aï¼Œè¦ä¹ˆåŒ¹é…ä¸€ä¸ª bï¼Œè¦ä¹ˆåŒ¹é…ä¸€ä¸ª cï¼‰ï¼›é—®å·?åªåŒ¹é…ä¸€ä¸ªä»»æ„å­—ç¬¦ï¼›å¦‚æœåœ¨æ–¹æ‹¬å·ä¸­ä½¿ç”¨çŸ­åˆ’çº¿åˆ†éš”ä¸¤ä¸ªå­—ç¬¦ï¼Œè¡¨ç¤ºæ‰€æœ‰åœ¨è¿™ä¸¤ä¸ªå­—ç¬¦èŒƒå›´å†…çš„éƒ½å¯ä»¥åŒ¹é…ï¼ˆæ¯”å¦‚[0-9]è¡¨ç¤ºåŒ¹é…æ‰€æœ‰ 0 åˆ° 9 çš„æ•°å­—ï¼‰ã€‚ ä½¿ç”¨ä¸¤ä¸ªæ˜Ÿå·** è¡¨ç¤ºåŒ¹é…ä»»æ„ä¸­é—´ç›®å½•ï¼Œæ¯”å¦‚a/**/z å¯ä»¥åŒ¹é… a/z, a/b/z æˆ– a/b/c/zç­‰ã€‚æ›´å¤šå†…å®¹è¯·å‚è€ƒï¼šhttps://github.com/github/gitignore â€‹ ä¸¾ä¸ªğŸŒ°[æ —å­]ï¼š1234567891011121314151617# no .a files*.a# but do track lib.a, even though you're ignoring .a files above!lib.a# only ignore the TODO file in the current directory, not subdir/TODO/TODO# ignore all files in the build/ directorybuild/# ignore doc/notes.txt, but not doc/server/arch.txtdoc/*.txt# ignore all .pdf files in the doc/ directorydoc/**/*.pdf git rmâ€‹ æˆ‘ä»¬æƒ³æŠŠæ–‡ä»¶ä» Git ä»“åº“ä¸­åˆ é™¤ï¼ˆäº¦å³ä»æš‚å­˜åŒºåŸŸç§»é™¤ï¼‰ï¼Œä½†ä»ç„¶å¸Œæœ›ä¿ç•™åœ¨å½“å‰å·¥ä½œç›®å½•ä¸­ã€‚ æ¢å¥è¯è¯´ï¼Œä½ æƒ³è®©æ–‡ä»¶ä¿ç•™åœ¨ç£ç›˜ï¼Œä½†æ˜¯å¹¶ä¸æƒ³è®© Git ç»§ç»­è·Ÿè¸ªã€‚ å½“ä½ å¿˜è®°æ·»åŠ  .gitignore æ–‡ä»¶ï¼Œä¸å°å¿ƒæŠŠä¸€ä¸ªå¾ˆå¤§çš„æ—¥å¿—æ–‡ä»¶æˆ–ä¸€å † .aè¿™æ ·çš„ç¼–è¯‘ç”Ÿæˆæ–‡ä»¶æ·»åŠ åˆ°æš‚å­˜åŒºæ—¶ï¼Œè¿™ä¸€åšæ³•å°¤å…¶æœ‰ç”¨ã€‚ ä¸ºè¾¾åˆ°è¿™ä¸€ç›®çš„ï¼Œä½¿ç”¨â€”cached é€‰é¡¹ï¼š1$ git rm --cached README â€‹ git rmå‘½ä»¤åé¢å¯ä»¥åˆ—å‡ºæ–‡ä»¶æˆ–è€…ç›®å½•çš„åå­—ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ glob æ¨¡å¼ã€‚ æ¯”æ–¹è¯´ï¼š1$ git rm log/*.log â€‹ æ³¨æ„åˆ°æ˜Ÿå· * ä¹‹å‰çš„åæ–œæ \\ï¼Œ å› ä¸º Git æœ‰å®ƒè‡ªå·±çš„æ–‡ä»¶æ¨¡å¼æ‰©å±•åŒ¹é…æ–¹å¼ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸ç”¨ shell æ¥å¸®å¿™å±•å¼€ã€‚ æ­¤å‘½ä»¤åˆ é™¤ log/ ç›®å½•ä¸‹æ‰©å±•åä¸º .log çš„æ‰€æœ‰æ–‡ä»¶ã€‚ ç±»ä¼¼çš„æ¯”å¦‚ï¼š1$ git rm *~ â€‹ è¯¥å‘½ä»¤ä¸ºåˆ é™¤ä»¥ ~ ç»“å°¾çš„æ‰€æœ‰æ–‡ä»¶ã€‚ git logâ€‹ git log æœ‰è®¸å¤šé€‰é¡¹å¯ä»¥å¸®åŠ©ä½ æœå¯»ä½ æ‰€è¦æ‰¾çš„æäº¤ã€‚ ä¸€ä¸ªå¸¸ç”¨çš„é€‰é¡¹æ˜¯-pï¼Œç”¨æ¥æ˜¾ç¤ºæ¯æ¬¡æäº¤çš„å†…å®¹å·®å¼‚ã€‚ ä½ ä¹Ÿå¯ä»¥åŠ ä¸Š-2 æ¥ä»…æ˜¾ç¤ºæœ€è¿‘ä¸¤æ¬¡æäº¤ï¼š 1$ git log -p -2 å¦‚æœä½ æƒ³çœ‹åˆ°æ¯æ¬¡æäº¤çš„ç®€ç•¥çš„ç»Ÿè®¡ä¿¡æ¯ï¼Œä½ å¯ä»¥ä½¿ç”¨ â€”stat é€‰é¡¹ï¼š 123456789101112131415161718EbbyMandeMBP:blog 520XM$ git log --statcommit 1a158fd41bece4caed80210526e8700dae73a527Author: ddebby &lt;ebby.dd@gmail.com&gt;Date: Thu Feb 2 19:02:31 2017 +0800 æ–°å¢ä¸¤ç¯‡è¯»ä¹¦ç¬”è®° Signed-off-by: ddebby &lt;ebby.dd@gmail.com&gt; ...344\\271\\246\\347\\254\\224\\350\\256\\260-Pro-Git.md\" | 79 +++++++++++++++++++++ ...56\\260-\\350\\205\\276\\350\\256\\257\\344\\274\\240.md\" | 65 +++++++++++++++++ source/images/blog/Pro Git Version 2.jpg | Bin 0 -&gt; 134581 bytes source/images/blog/pro-git-cover.jpeg | Bin 0 -&gt; 21289 bytes ...56\\257\\344\\274\\240\\345\\260\\201\\351\\235\\242.jpg\" | Bin 0 -&gt; 12898 bytes ...0\\206-\\350\\205\\276\\350\\256\\257\\344\\274\\240.PNG\" | Bin 0 -&gt; 24520 bytes themes/next/source/css/_custom/custom.styl | 3 +- themes/next/source/css/_variables/custom.styl | 12 ++-- 8 files changed, 152 insertions(+), 7 deletions(-) è¿˜å¯ä»¥ç»™å‡ºè‹¥å¹²æœç´¢æ¡ä»¶ï¼Œåˆ—å‡ºç¬¦åˆçš„æäº¤ã€‚ ç”¨ --author é€‰é¡¹æ˜¾ç¤ºæŒ‡å®šä½œè€…çš„æäº¤ï¼Œç”¨ --grep é€‰é¡¹æœç´¢æäº¤è¯´æ˜ä¸­çš„å…³é”®å­—ã€‚ ï¼ˆè¯·æ³¨æ„ï¼Œå¦‚æœè¦å¾—åˆ°åŒæ—¶æ»¡è¶³è¿™ä¸¤ä¸ªé€‰é¡¹æœç´¢æ¡ä»¶çš„æäº¤ï¼Œå°±å¿…é¡»ç”¨ --all-matché€‰é¡¹ã€‚å¦åˆ™ï¼Œæ»¡è¶³ä»»æ„ä¸€ä¸ªæ¡ä»¶çš„æäº¤éƒ½ä¼šè¢«åŒ¹é…å‡ºæ¥ï¼‰ å¦ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„ç­›é€‰é€‰é¡¹æ˜¯ -Sï¼Œå¯ä»¥åˆ—å‡ºé‚£äº›æ·»åŠ æˆ–ç§»é™¤äº†æŸäº›å­—ç¬¦ä¸²çš„æäº¤ã€‚ æ¯”å¦‚è¯´ï¼Œä½ æƒ³æ‰¾å‡ºæ·»åŠ æˆ–ç§»é™¤äº†æŸä¸€ä¸ªç‰¹å®šå‡½æ•°çš„å¼•ç”¨çš„æäº¤ï¼Œä½ å¯ä»¥è¿™æ ·ä½¿ç”¨ï¼š 1$ git log -S function_name æœ€åä¸€ä¸ªå¾ˆå®ç”¨çš„ git log é€‰é¡¹æ˜¯è·¯å¾„ï¼ˆpathï¼‰ï¼Œ å¦‚æœåªå…³å¿ƒæŸäº›æ–‡ä»¶æˆ–è€…ç›®å½•çš„å†å²æäº¤ï¼Œå¯ä»¥åœ¨ git log é€‰é¡¹çš„æœ€åæŒ‡å®šå®ƒä»¬çš„è·¯å¾„ã€‚ å› ä¸ºæ˜¯æ”¾åœ¨æœ€åä½ç½®ä¸Šçš„é€‰é¡¹ï¼Œæ‰€ä»¥ç”¨ä¸¤ä¸ªçŸ­åˆ’çº¿ï¼ˆâ€”ï¼‰éš”å¼€ä¹‹å‰çš„é€‰é¡¹å’Œåé¢é™å®šçš„è·¯å¾„åã€‚ é€‰é¡¹ è¯´æ˜ -(n) ä»…æ˜¾ç¤ºæœ€è¿‘çš„ n æ¡æäº¤ â€”since, â€”after ä»…æ˜¾ç¤ºæŒ‡å®šæ—¶é—´ä¹‹åçš„æäº¤ã€‚ â€”until, â€”before ä»…æ˜¾ç¤ºæŒ‡å®šæ—¶é—´ä¹‹å‰çš„æäº¤ã€‚ â€”author ä»…æ˜¾ç¤ºæŒ‡å®šä½œè€…ç›¸å…³çš„æäº¤ã€‚ â€”committer ä»…æ˜¾ç¤ºæŒ‡å®šæäº¤è€…ç›¸å…³çš„æäº¤ã€‚ â€”grep ä»…æ˜¾ç¤ºå«æŒ‡å®šå…³é”®å­—çš„æäº¤ -S ä»…æ˜¾ç¤ºæ·»åŠ æˆ–ç§»é™¤äº†æŸä¸ªå…³é”®å­—çš„æäº¤ git diff Git æä¾›äº†ä¸€ç§æ¯”è¾ƒä¾¿æ·çš„æ–¹å¼ï¼šä¸‰ç‚¹è¯­æ³•ã€‚ å¯¹äº diff å‘½ä»¤æ¥è¯´ï¼Œä½ å¯ä»¥é€šè¿‡æŠŠ ... ç½®äºå¦ä¸€ä¸ªåˆ†æ”¯ååæ¥å¯¹è¯¥åˆ†æ”¯çš„æœ€æ–°æäº¤ä¸ä¸¤ä¸ªåˆ†æ”¯çš„å…±åŒç¥–å…ˆè¿›è¡Œæ¯”è¾ƒï¼š 1$ git diff master...contrib è¯¥å‘½ä»¤ä»…ä¼šæ˜¾ç¤ºè‡ªå½“å‰ç‰¹æ€§åˆ†æ”¯ä¸ master åˆ†æ”¯çš„å…±åŒç¥–å…ˆèµ·ï¼Œè¯¥åˆ†æ”¯ä¸­çš„å·¥ä½œã€‚ è¿™ä¸ªè¯­æ³•å¾ˆæœ‰ç”¨ï¼Œåº”è¯¥ç‰¢è®°ã€‚ è¿œç¨‹ä»“åº“æ·»åŠ è¿œç¨‹ä»“åº“â€‹ æˆ‘åœ¨ä¹‹å‰çš„ç« èŠ‚ä¸­å·²ç»æåˆ°å¹¶å±•ç¤ºäº†å¦‚ä½•æ·»åŠ è¿œç¨‹ä»“åº“çš„ç¤ºä¾‹ï¼Œä¸è¿‡è¿™é‡Œå°†å‘Šè¯‰ä½ å¦‚ä½•æ˜ç¡®åœ°åšåˆ°è¿™ä¸€ç‚¹ã€‚ è¿è¡Œ git remote add &lt;shortname&gt; &lt;url&gt; æ·»åŠ ä¸€ä¸ªæ–°çš„è¿œç¨‹ Git ä»“åº“ã€‚ä»è¿œç¨‹ä»“åº“ä¸­æŠ“å–ä¸æ‹‰å–â€‹ å¦‚æœä½ æƒ³æ‹‰å–è¿œç¨‹ä»“åº“ä¸­æœ‰ä½†ä½ æ²¡æœ‰çš„ä¿¡æ¯ï¼Œå¯ä»¥è¿è¡Œï¼š1$ git fetch [remote-name] â€‹ å¿…é¡»æ³¨æ„ git fetch å‘½ä»¤ä¼šå°†æ•°æ®æ‹‰å–åˆ°ä½ çš„æœ¬åœ°ä»“åº“ - å®ƒå¹¶ä¸ä¼šè‡ªåŠ¨åˆå¹¶æˆ–ä¿®æ”¹ä½ å½“å‰çš„å·¥ä½œã€‚ å½“å‡†å¤‡å¥½æ—¶ä½ å¿…é¡»æ‰‹åŠ¨å°†å…¶åˆå¹¶å…¥ä½ çš„å·¥ä½œã€‚ æ ‡ç­¾é™„æ³¨æ ‡ç­¾åœ¨ Git ä¸­åˆ›å»ºä¸€ä¸ªé™„æ³¨æ ‡ç­¾æ˜¯å¾ˆç®€å•çš„ã€‚ æœ€ç®€å•çš„æ–¹å¼æ˜¯å½“ä½ åœ¨è¿è¡Œ tag å‘½ä»¤æ—¶æŒ‡å®š-a é€‰é¡¹ï¼š123456$ git tag -a v1.4 -m 'my version 1.4'$ git tagv0.1v1.3v1.4 â€‹ -mé€‰é¡¹æŒ‡å®šäº†ä¸€æ¡å°†ä¼šå­˜å‚¨åœ¨æ ‡ç­¾ä¸­çš„ä¿¡æ¯ã€‚ å¦‚æœæ²¡æœ‰ä¸ºé™„æ³¨æ ‡ç­¾æŒ‡å®šä¸€æ¡ä¿¡æ¯ï¼ŒGit ä¼šè¿è¡Œç¼–è¾‘å™¨è¦æ±‚ä½ è¾“å…¥ä¿¡æ¯ã€‚ åæœŸæ‰“æ ‡ç­¾ è¦åœ¨é‚£ä¸ªæäº¤ä¸Šæ‰“æ ‡ç­¾ï¼Œä½ éœ€è¦åœ¨å‘½ä»¤çš„æœ«å°¾æŒ‡å®šæäº¤çš„æ ¡éªŒå’Œï¼ˆæˆ–éƒ¨åˆ†æ ¡éªŒå’Œï¼‰:1$ git tag -a v1.2 9fceb02 å…±äº«æ ‡ç­¾â€‹ é»˜è®¤æƒ…å†µä¸‹ï¼Œgit push å‘½ä»¤å¹¶ä¸ä¼šä¼ é€æ ‡ç­¾åˆ°è¿œç¨‹ä»“åº“æœåŠ¡å™¨ä¸Šã€‚ åœ¨åˆ›å»ºå®Œæ ‡ç­¾åä½ å¿…é¡»æ˜¾å¼åœ°æ¨é€æ ‡ç­¾åˆ°å…±äº«æœåŠ¡å™¨ä¸Šã€‚ è¿™ä¸ªè¿‡ç¨‹å°±åƒå…±äº«è¿œç¨‹åˆ†æ”¯ä¸€æ · - ä½ å¯ä»¥è¿è¡Œ123$ git push origin [tagname] # or$ git push origin --tags æ£€å‡ºæ ‡ç­¾â€‹ åœ¨ Git ä¸­ä½ å¹¶ä¸èƒ½çœŸçš„æ£€å‡ºä¸€ä¸ªæ ‡ç­¾ï¼Œå› ä¸ºå®ƒä»¬å¹¶ä¸èƒ½åƒåˆ†æ”¯ä¸€æ ·æ¥å›ç§»åŠ¨ã€‚ å¦‚æœä½ æƒ³è¦å·¥ä½œç›®å½•ä¸ä»“åº“ä¸­ç‰¹å®šçš„æ ‡ç­¾ç‰ˆæœ¬å®Œå…¨ä¸€æ ·ï¼Œå¯ä»¥ä½¿ç”¨ git checkout -b [branchname][tagname]åœ¨ç‰¹å®šçš„æ ‡ç­¾ä¸Šåˆ›å»ºä¸€ä¸ªæ–°åˆ†æ”¯ï¼š12$ git checkout -b version2 v2.0.0Switched to a new branch 'version2' åˆ†æ”¯ç®¡ç† git branchâ€‹ å¦‚æœéœ€è¦æŸ¥çœ‹æ¯ä¸€ä¸ªåˆ†æ”¯çš„æœ€åä¸€æ¬¡æäº¤ï¼Œå¯ä»¥è¿è¡Œ git branch -vå‘½ä»¤ï¼š123$ git branch -v* dev 1a158fd æ–°å¢ä¸¤ç¯‡è¯»ä¹¦ç¬”è®° master f8f05fb Accept Merge Request #1 Merge Resource branch to Master branch : (resource -&gt; master) â€‹ â€”merged ä¸ --no-merged è¿™ä¸¤ä¸ªæœ‰ç”¨çš„é€‰é¡¹å¯ä»¥è¿‡æ»¤è¿™ä¸ªåˆ—è¡¨ä¸­å·²ç»åˆå¹¶æˆ–å°šæœªåˆå¹¶åˆ°å½“å‰åˆ†æ”¯çš„åˆ†æ”¯ã€‚ å¦‚æœè¦æŸ¥çœ‹å“ªäº›åˆ†æ”¯å·²ç»åˆå¹¶åˆ°å½“å‰åˆ†æ”¯ï¼Œå¯ä»¥è¿è¡Œï¼š123$ git branch --merged iss53* master â€‹ å› ä¸ºä¹‹å‰å·²ç»åˆå¹¶äº† iss53 åˆ†æ”¯ï¼Œæ‰€ä»¥ç°åœ¨çœ‹åˆ°å®ƒåœ¨åˆ—è¡¨ä¸­ã€‚ åœ¨è¿™ä¸ªåˆ—è¡¨ä¸­åˆ†æ”¯åå­—å‰æ²¡æœ‰ * å·çš„åˆ†æ”¯é€šå¸¸å¯ä»¥ä½¿ç”¨ git branch -d åˆ é™¤æ‰ï¼›ä½ å·²ç»å°†å®ƒä»¬çš„å·¥ä½œæ•´åˆåˆ°äº†å¦ä¸€ä¸ªåˆ†æ”¯ï¼Œæ‰€ä»¥å¹¶ä¸ä¼šå¤±å»ä»»ä½•ä¸œè¥¿ã€‚â€‹ æŸ¥çœ‹æ‰€æœ‰åŒ…å«æœªåˆå¹¶å·¥ä½œçš„åˆ†æ”¯ï¼Œå¯ä»¥è¿è¡Œï¼š12$ git branch --no-merged testing â€‹ è¿™é‡Œæ˜¾ç¤ºäº†å…¶ä»–åˆ†æ”¯ã€‚ æœªè¢«åˆå¹¶çš„åˆ†æ”¯é»˜è®¤æ˜¯æ— æ³•è¢«åˆ é™¤ï¼Œä¸è¿‡å¯ä»¥é€šè¿‡git branch -D &lt;branch_name&gt;æ¥å¼ºåˆ¶åˆ é™¤ã€‚ æ‹‰å–è¿œç¨‹åˆ†æ”¯ï¼š 1$ git checkout -b [branch] [remotename]/[branch] å¦‚æœæƒ³è¦æŸ¥çœ‹è®¾ç½®çš„æ‰€æœ‰è·Ÿè¸ªåˆ†æ”¯ï¼Œå¯ä»¥ä½¿ç”¨ git branch çš„ -vv é€‰é¡¹ã€‚ è¿™ä¼šå°†æ‰€æœ‰çš„æœ¬åœ°åˆ†æ”¯åˆ—å‡ºæ¥å¹¶ä¸”åŒ…å«æ›´å¤šçš„ä¿¡æ¯ï¼Œå¦‚æ¯ä¸€ä¸ªåˆ†æ”¯æ­£åœ¨è·Ÿè¸ªå“ªä¸ªè¿œç¨‹åˆ†æ”¯ä¸æœ¬åœ°åˆ†æ”¯æ˜¯å¦æ˜¯é¢†å…ˆã€è½åæˆ–æ˜¯éƒ½æœ‰ã€‚ 12345$ git branch -vv iss53 7e424c3 [origin/iss53: ahead 2] forgot the brackets master 1ae2a45 [origin/master] deploying index fix* serverfix f8674d9 [teamone/server-fix-good: ahead 3, behind 1] this should do it testing 5ea463a trying something new åˆ é™¤è¿œç¨‹æœåŠ¡å™¨çš„åˆ†æ”¯ 123$ git push origin --delete serverfixTo https://github.com/schacon/simplegit - [deleted] serverfix git mergeä¸git rebase æ€»çš„åŸåˆ™æ˜¯ï¼Œåªå¯¹å°šæœªæ¨é€æˆ–åˆ†äº«ç»™åˆ«äººçš„æœ¬åœ°ä¿®æ”¹æ‰§è¡Œå˜åŸºæ“ä½œæ¸…ç†å†å²ï¼Œä»ä¸å¯¹å·²æ¨é€è‡³åˆ«å¤„çš„æäº¤æ‰§è¡Œå˜åŸºæ“ä½œï¼Œè¿™æ ·ï¼Œä½ æ‰èƒ½äº«å—åˆ°ä¸¤ç§æ–¹å¼å¸¦æ¥çš„ä¾¿åˆ©ã€‚è¯¦æƒ…å‚è€ƒï¼šhttps://git-scm.com/book/zh/v2/Git-åˆ†æ”¯-å˜åŸº å°†å½“å‰åˆ†æ”¯æ¨é€ä¸ºè¿œç¨‹æ–°åˆ†æ”¯ 1git push origin local_branch:remote_branch git stashå‚¨è—ä¸æ¸…ç† åœ¨ä¸€ä¸ªåˆ†æ”¯ä¸Šåšäº†ä¸€äº›ä¿®æ”¹ï¼Œåœ¨ä¸æƒ³commitçš„æƒ…å†µä¸‹ï¼Œåˆ‡æ¢åˆ†æ”¯ï¼Œéœ€è¦å°†ä¿®æ”¹çš„å†…å®¹å­˜å‚¨èµ·æ¥ï¼Œä½¿ç”¨å¦‚ä¸‹å‘½ä»¤ï¼š 12345git stash | git stash savegit stash listgit stash apply# ç§»é™¤æŸä¸ªstachå†…å®¹git stach drop stach@&#123;0&#125; 2. Git æœåŠ¡å™¨ ç”Ÿæˆè£¸ä»“åº“â€‹åœ¨å¼€å§‹æ¶è®¾ Git æœåŠ¡å™¨å‰ï¼Œéœ€è¦æŠŠç°æœ‰ä»“åº“å¯¼å‡ºä¸ºè£¸ä»“åº“â€”â€”å³ä¸€ä¸ªä¸åŒ…å«å½“å‰å·¥ä½œç›®å½•çš„ä»“åº“ã€‚ è¿™é€šå¸¸æ˜¯å¾ˆç®€å•çš„ã€‚ ä¸ºäº†é€šè¿‡å…‹éš†ä½ çš„ä»“åº“æ¥åˆ›å»ºä¸€ä¸ªæ–°çš„è£¸ä»“åº“ï¼Œä½ éœ€è¦åœ¨å…‹éš†å‘½ä»¤ååŠ ä¸Š --bareé€‰é¡¹ æŒ‰ç…§æƒ¯ä¾‹ï¼Œè£¸ä»“åº“ç›®å½•åä»¥ .git ç»“å°¾ï¼Œå°±åƒè¿™æ ·ï¼š123$ git clone --bare my_project my_project.gitCloning into bare repository 'my_project.git'...done. ç°åœ¨ï¼Œä½ çš„ my_project.git ç›®å½•ä¸­åº”è¯¥æœ‰ Git ç›®å½•çš„å‰¯æœ¬äº†ã€‚ æŠŠè£¸ä»“åº“æ”¾åˆ°æœåŠ¡å™¨ä¸Šåªéœ€è¦å°†ä¸Šè¿°my_project.gitå¤åˆ¶åˆ°æŸä¸ªç›®å½•ä¸‹å³å¯é€šè¿‡å¦‚ä¸‹å‘½ä»¤è®¿é—®ï¼š1$ git clone user@git.example.com:/opt/git/my_project.git â€‹ å¦‚æœåˆ°è¯¥é¡¹ç›®ç›®å½•ä¸­è¿è¡Œ git init å‘½ä»¤ï¼Œå¹¶åŠ ä¸Š --sharedé€‰é¡¹ï¼Œé‚£ä¹ˆ Git ä¼šè‡ªåŠ¨ä¿®æ”¹è¯¥ä»“åº“ç›®å½•çš„ç»„æƒé™ä¸ºå¯å†™ã€‚123$ ssh user@git.example.com$ cd /opt/git/my_project.git$ git init --bare --shared åŸºäºä»¥ä¸Šç®€å•é…ç½®çš„ç®€å•æƒé™ç®¡ç†ç­–ç•¥ï¼š ä¸»æœºä¸Šå»ºç«‹ä¸€ä¸ª git è´¦æˆ·ï¼Œè®©æ¯ä¸ªéœ€è¦å†™æƒé™çš„äººå‘é€ä¸€ä¸ª SSH å…¬é’¥ï¼Œç„¶åå°†å…¶åŠ å…¥ git è´¦æˆ·çš„ ~/.ssh/authorized_keys æ–‡ä»¶ã€‚ è¿™æ ·ä¸€æ¥ï¼Œæ‰€æœ‰äººéƒ½å°†é€šè¿‡ git è´¦æˆ·è®¿é—®ä¸»æœºã€‚ è¿™ä¸€ç‚¹ä¹Ÿä¸ä¼šå½±å“æäº¤çš„æ•°æ®â€”â€”è®¿é—®ä¸»æœºç”¨çš„èº«ä»½ä¸ä¼šå½±å“æäº¤å¯¹è±¡çš„æäº¤è€…ä¿¡æ¯ã€‚ å¦ä¸€ä¸ªåŠæ³•æ˜¯è®© SSH æœåŠ¡å™¨é€šè¿‡æŸä¸ª LDAP æœåŠ¡ï¼Œæˆ–è€…å…¶ä»–å·²ç»è®¾å®šå¥½çš„é›†ä¸­æˆæƒæœºåˆ¶ï¼Œæ¥è¿›è¡Œæˆæƒã€‚ åªè¦æ¯ä¸ªç”¨æˆ·å¯ä»¥è·å¾—ä¸»æœºçš„ shell è®¿é—®æƒé™ï¼Œä»»ä½• SSH æˆæƒæœºåˆ¶ä½ éƒ½å¯è§†ä¸ºæ˜¯æœ‰æ•ˆçš„ã€‚ ç»´æŠ¤é¡¹ç›®ä½¿ç”¨format-patchç”Ÿæˆè¡¥ä¸ é€‚ç”¨äºé‚®ä»¶é€šçŸ¥é¡¹ç›®ç®¡ç†è€…åˆå¹¶è¡¥ä¸å†…å®¹ ä½¿ç”¨ apply å‘½ä»¤åº”ç”¨è¡¥ä¸ â€‹ å¦‚æœä½ æ”¶åˆ°äº†ä¸€ä¸ªä½¿ç”¨ git diff æˆ– Unix diff å‘½ä»¤ï¼ˆä¸æ¨èä½¿ç”¨è¿™ç§æ–¹å¼ï¼Œå…·ä½“è§ä¸‹ä¸€èŠ‚ï¼‰åˆ›å»ºçš„è¡¥ä¸ï¼Œå¯ä»¥ä½¿ç”¨ git apply å‘½ä»¤æ¥åº”ç”¨ã€‚ å‡è®¾ä½ å°†è¡¥ä¸ä¿å­˜åœ¨äº† /tmp/patch-ruby-client.patch ä¸­ï¼Œå¯ä»¥è¿™æ ·åº”ç”¨è¡¥ä¸ï¼š 1$ git apply /tmp/patch-ruby-client.patch è¿™ä¼šä¿®æ”¹å·¥ä½œç›®å½•ä¸­çš„æ–‡ä»¶ã€‚ å®ƒä¸è¿è¡Œ patch -p1 å‘½ä»¤æ¥åº”ç”¨è¡¥ä¸å‡ ä¹æ˜¯ç­‰æ•ˆçš„ï¼Œä½†æ˜¯è¿™ç§æ–¹å¼æ›´åŠ ä¸¥æ ¼ï¼Œç›¸å¯¹äº patch æ¥è¯´ï¼Œå®ƒèƒ½å¤Ÿæ¥å—çš„æ¨¡ç³ŠåŒ¹é…æ›´å°‘ã€‚ åœ¨å®é™…åº”ç”¨è¡¥ä¸å‰ï¼Œä½ è¿˜å¯ä»¥ä½¿ç”¨ git apply æ¥æ£€æŸ¥è¡¥ä¸æ˜¯å¦å¯ä»¥é¡ºåˆ©åº”ç”¨â€”â€”å³å¯¹è¡¥ä¸è¿è¡Œ git apply --check å‘½ä»¤ï¼š 123$ git apply --check 0001-seeing-if-this-helps-the-gem.patcherror: patch failed: ticgit.gemspec:1error: ticgit.gemspec: patch does not apply å¦‚æœæ²¡æœ‰äº§ç”Ÿè¾“å‡ºï¼Œåˆ™è¯¥è¡¥ä¸å¯ä»¥é¡ºåˆ©åº”ç”¨ã€‚ å¦‚æœæ£€æŸ¥å¤±è´¥äº†ï¼Œè¯¥å‘½ä»¤è¿˜ä¼šä»¥ä¸€ä¸ªéé›¶çš„çŠ¶æ€é€€å‡ºï¼Œæ‰€ä»¥éœ€è¦æ—¶ä½ ä¹Ÿå¯ä»¥åœ¨è„šæœ¬ä¸­ä½¿ç”¨å®ƒã€‚ å‡†å¤‡ä¸€æ¬¡å‘å¸ƒç°åœ¨ä½ å¯ä»¥å‘å¸ƒä¸€ä¸ªæ„å»ºäº†ã€‚ å…¶ä¸­ä¸€ä»¶äº‹æƒ…å°±æ˜¯ä¸ºé‚£äº›ä¸ä½¿ç”¨ Git çš„å¯æ€œåŒ…ä»¬åˆ›å»ºä¸€ä¸ªæœ€æ–°çš„å¿«ç…§å½’æ¡£ã€‚ ä½¿ç”¨ git archive å‘½ä»¤å®Œæˆæ­¤å·¥ä½œï¼š 123$ git archive master --prefix='project/' | gzip &gt; `git describe master`.tar.gz$ ls *.tar.gzv1.6.2-rc1-20-g8c5b85c.tar.gz å¦‚æœæœ‰äººå°†è¿™ä¸ªå‹ç¼©åŒ…è§£å‹ï¼Œä»–å°±å¯ä»¥å¾—åˆ°ä½ çš„é¡¹ç›®æ–‡ä»¶å¤¹çš„æœ€æ–°å¿«ç…§ã€‚ ä½ ä¹Ÿå¯ä»¥ä»¥ç±»ä¼¼çš„æ–¹å¼åˆ›å»ºä¸€ä¸ª zip å‹ç¼©åŒ…ï¼Œä½†æ­¤æ—¶ä½ åº”è¯¥å‘ git archive å‘½ä»¤ä¼ é€’ --format=zip é€‰é¡¹ï¼š 1$ git archive master --prefix='project/' --format=zip &gt; `git describe master`.zip ç°åœ¨ä½ æœ‰äº†æœ¬æ¬¡å‘å¸ƒçš„ä¸€ä¸ª tar åŒ…å’Œä¸€ä¸ª zip åŒ…ï¼Œå¯ä»¥å°†å…¶ä¸Šä¼ åˆ°ç½‘ç«™æˆ–ä»¥ç”µå­é‚®ä»¶çš„å½¢å¼å‘é€ç»™äººä»¬ã€‚ åˆ¶ä½œæäº¤ç®€æŠ¥ç°åœ¨æ˜¯æ—¶å€™é€šçŸ¥é‚®ä»¶åˆ—è¡¨é‡Œé‚£äº›å¥½å¥‡ä½ çš„é¡¹ç›®å‘ç”Ÿäº†ä»€ä¹ˆçš„äººäº†ã€‚ ä½¿ç”¨ git shortlog å‘½ä»¤å¯ä»¥å¿«é€Ÿç”Ÿæˆä¸€ä»½åŒ…å«ä»ä¸Šæ¬¡å‘å¸ƒä¹‹åé¡¹ç›®æ–°å¢å†…å®¹çš„ä¿®æ”¹æ—¥å¿—ï¼ˆchangelogï¼‰ç±»æ–‡æ¡£ã€‚ å®ƒä¼šå¯¹ä½ ç»™å®šèŒƒå›´å†…çš„æ‰€æœ‰æäº¤è¿›è¡Œæ€»ç»“ï¼›æ¯”å¦‚ï¼Œä½ çš„ä¸Šä¸€æ¬¡å‘å¸ƒåç§°æ˜¯ v1.0.1ï¼Œé‚£ä¹ˆä¸‹é¢çš„å‘½ä»¤å¯ä»¥ç»™å‡ºä¸Šæ¬¡å‘å¸ƒä»¥æ¥æ‰€æœ‰æäº¤çš„æ€»ç»“ï¼š 1234567891011121314$ git shortlog --no-merges master --not v1.0.1Chris Wanstrath (8): Add support for annotated tags to Grit::Tag Add packed-refs annotated tag support. Add Grit::Commit#to_patch Update version and History.txt Remove stray `puts` Make ls_tree ignore nilsTom Preston-Werner (4): fix dates in history dynamic version method Version bump to 1.0.2 Regenerated gemspec for version 1.0.2 è¿™ä»½æ•´æ´çš„æ€»ç»“åŒ…æ‹¬äº†è‡ª v1.0.1 ä»¥æ¥çš„æ‰€æœ‰æäº¤ï¼Œå¹¶ä¸”å·²ç»æŒ‰ç…§ä½œè€…åˆ†å¥½ç»„ï¼Œä½ å¯ä»¥é€šè¿‡ç”µå­é‚®ä»¶å°†å…¶ç›´æ¥å‘é€åˆ°åˆ—è¡¨ä¸­ã€‚ Gitå·¥å…·åŒç‚¹æœ€å¸¸ç”¨çš„æŒ‡æ˜æäº¤åŒºé—´è¯­æ³•æ˜¯åŒç‚¹ã€‚ è¿™ç§è¯­æ³•å¯ä»¥è®© Git é€‰å‡ºåœ¨ä¸€ä¸ªåˆ†æ”¯ä¸­è€Œä¸åœ¨å¦ä¸€ä¸ªåˆ†æ”¯ä¸­çš„æäº¤ã€‚ä½ æƒ³è¦æŸ¥çœ‹ experiment åˆ†æ”¯ä¸­è¿˜æœ‰å“ªäº›æäº¤å°šæœªè¢«åˆå¹¶å…¥ master åˆ†æ”¯ã€‚ ä½ å¯ä»¥ä½¿ç”¨ master..experiment æ¥è®© Git æ˜¾ç¤ºè¿™äº›æäº¤ã€‚ä¹Ÿå°±æ˜¯ â€œåœ¨ experiment åˆ†æ”¯ä¸­è€Œä¸åœ¨ master åˆ†æ”¯ä¸­çš„æäº¤â€ï¼š 1$ git log master..experiment åè¿‡æ¥ï¼Œå¦‚æœä½ æƒ³æŸ¥çœ‹åœ¨ master åˆ†æ”¯ä¸­è€Œä¸åœ¨ experiment åˆ†æ”¯ä¸­çš„æäº¤ï¼Œä½ åªè¦äº¤æ¢åˆ†æ”¯åå³å¯ã€‚experiment..master ä¼šæ˜¾ç¤ºåœ¨ master åˆ†æ”¯ä¸­è€Œä¸åœ¨ experiment åˆ†æ”¯ä¸­çš„æäº¤ï¼š 1$ git log experiment..master è¿™å¯ä»¥è®©ä½ ä¿æŒ experiment åˆ†æ”¯è·Ÿéšæœ€æ–°çš„è¿›åº¦ä»¥åŠæŸ¥çœ‹ä½ å³å°†åˆå¹¶çš„å†…å®¹ã€‚ å¦ä¸€ä¸ªå¸¸ç”¨çš„åœºæ™¯æ˜¯æŸ¥çœ‹ä½ å³å°†æ¨é€åˆ°è¿œç«¯çš„å†…å®¹ï¼š 1$ git log origin/master..HEAD è¿™ä¸ªå‘½ä»¤ä¼šè¾“å‡ºåœ¨ä½ å½“å‰åˆ†æ”¯ä¸­è€Œä¸åœ¨è¿œç¨‹ origin ä¸­çš„æäº¤ã€‚ å¦‚æœä½ æ‰§è¡Œäº† git push å¹¶ä¸”ä½ çš„å½“å‰åˆ†æ”¯æ­£åœ¨è·Ÿè¸ª origin/masterï¼Œgit log origin/master..HEAD æ‰€è¾“å‡ºçš„æäº¤å°†ä¼šè¢«ä¼ è¾“åˆ°è¿œç«¯æœåŠ¡å™¨ã€‚ å¦‚æœä½ ç•™ç©ºäº†å…¶ä¸­çš„ä¸€è¾¹ï¼Œ Git ä¼šé»˜è®¤ä¸º HEADã€‚ ä¾‹å¦‚ï¼Œ git log origin/master.. å°†ä¼šè¾“å‡ºä¸ä¹‹å‰ä¾‹å­ç›¸åŒçš„ç»“æœ â€”â€” Git ä½¿ç”¨ HEAD æ¥ä»£æ›¿ç•™ç©ºçš„ä¸€è¾¹ã€‚ å¤šç‚¹åŒç‚¹è¯­æ³•å¾ˆå¥½ç”¨ï¼Œä½†æœ‰æ—¶å€™ä½ å¯èƒ½éœ€è¦ä¸¤ä¸ªä»¥ä¸Šçš„åˆ†æ”¯æ‰èƒ½ç¡®å®šä½ æ‰€éœ€è¦çš„ä¿®è®¢ï¼Œæ¯”å¦‚æŸ¥çœ‹å“ªäº›æäº¤æ˜¯è¢«åŒ…å«åœ¨æŸäº›åˆ†æ”¯ä¸­çš„ä¸€ä¸ªï¼Œä½†æ˜¯ä¸åœ¨ä½ å½“å‰çš„åˆ†æ”¯ä¸Šã€‚ Git å…è®¸ä½ åœ¨ä»»æ„å¼•ç”¨å‰åŠ ä¸Š ^ å­—ç¬¦æˆ–è€… --notæ¥æŒ‡æ˜ä½ ä¸å¸Œæœ›æäº¤è¢«åŒ…å«å…¶ä¸­çš„åˆ†æ”¯ã€‚ å› æ­¤ä¸‹åˆ—3ä¸ªå‘½ä»¤æ˜¯ç­‰ä»·çš„ï¼š 123$ git log refA..refB$ git log ^refA refB$ git log refB --not refA è¿™ä¸ªè¯­æ³•å¾ˆå¥½ç”¨ï¼Œå› ä¸ºä½ å¯ä»¥åœ¨æŸ¥è¯¢ä¸­æŒ‡å®šè¶…è¿‡ä¸¤ä¸ªçš„å¼•ç”¨ï¼Œè¿™æ˜¯åŒç‚¹è¯­æ³•æ— æ³•å®ç°çš„ã€‚ æ¯”å¦‚ï¼Œä½ æƒ³æŸ¥çœ‹æ‰€æœ‰è¢« refA æˆ– refB åŒ…å«çš„ä½†æ˜¯ä¸è¢« refC åŒ…å«çš„æäº¤ï¼Œä½ å¯ä»¥è¾“å…¥ä¸‹é¢ä¸­çš„ä»»æ„ä¸€ä¸ªå‘½ä»¤ 12$ git log refA refB ^refC$ git log refA refB --not refC è¿™å°±æ„æˆäº†ä¸€ä¸ªååˆ†å¼ºå¤§çš„ä¿®è®¢æŸ¥è¯¢ç³»ç»Ÿï¼Œä½ å¯ä»¥é€šè¿‡å®ƒæ¥æŸ¥çœ‹ä½ çš„åˆ†æ”¯é‡ŒåŒ…å«äº†å“ªäº›ä¸œè¥¿ã€‚ æœç´¢ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æƒ³æ‰¾åˆ° ZLIB_BUF_MAX å¸¸é‡æ˜¯ä»€ä¹ˆæ—¶å€™å¼•å…¥çš„ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ -S é€‰é¡¹æ¥æ˜¾ç¤ºæ–°å¢å’Œåˆ é™¤è¯¥å­—ç¬¦ä¸²çš„æäº¤ã€‚ 123$ git log -SZLIB_BUF_MAX --onelinee01503b zlib: allow feeding more than 4GB in one goef49a7a zlib: zlib can only process 4GB at a time å¦‚æœæˆ‘ä»¬æŸ¥çœ‹è¿™äº›æäº¤çš„ diffï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°åœ¨ ef49a7a è¿™ä¸ªæäº¤å¼•å…¥äº†å¸¸é‡ï¼Œå¹¶ä¸”åœ¨ e01503b è¿™ä¸ªæäº¤ä¸­è¢«ä¿®æ”¹äº†ã€‚ è¡Œæ—¥å¿—æœç´¢è¡Œæ—¥å¿—æœç´¢æ˜¯å¦ä¸€ä¸ªç›¸å½“é«˜çº§å¹¶ä¸”æœ‰ç”¨çš„æ—¥å¿—æœç´¢åŠŸèƒ½ã€‚ è¿™æ˜¯ä¸€ä¸ªæœ€è¿‘æ–°å¢çš„ä¸å¤ªçŸ¥åçš„åŠŸèƒ½ï¼Œä½†å´æ˜¯ååˆ†æœ‰ç”¨ã€‚ åœ¨ git log ååŠ ä¸Š -L é€‰é¡¹å³å¯è°ƒç”¨ï¼Œå®ƒå¯ä»¥å±•ç¤ºä»£ç ä¸­ä¸€è¡Œæˆ–è€…ä¸€ä¸ªå‡½æ•°çš„å†å²ã€‚ ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬æƒ³æŸ¥çœ‹ zlib.c æ–‡ä»¶ä¸­git_deflate_bound å‡½æ•°çš„æ¯ä¸€æ¬¡å˜æ›´ï¼Œæˆ‘ä»¬å¯ä»¥æ‰§è¡Œ git log -L :git_deflate_bound:zlib.cã€‚ Git ä¼šå°è¯•æ‰¾å‡ºè¿™ä¸ªå‡½æ•°çš„èŒƒå›´ï¼Œç„¶åæŸ¥æ‰¾å†å²è®°å½•ï¼Œå¹¶ä¸”æ˜¾ç¤ºä»å‡½æ•°åˆ›å»ºä¹‹åä¸€ç³»åˆ—å˜æ›´å¯¹åº”çš„è¡¥ä¸ã€‚ å‹ç¼©æäº¤ä»¥ä¸‹å‘½ä»¤å°†HEADè°ƒå›åˆ°ä¸¤æ¬¡æäº¤ä¹‹å‰ï¼Œåšä¸€æ¬¡å‹ç¼©æäº¤ã€‚æ›´å¤šå†…å®¹è¯¦è§ï¼šPro Gitä¸­çš„è¯´æ˜ 1git reset --soft HEAD~2 è¿˜åŸæäº¤å¦‚æœç§»åŠ¨åˆ†æ”¯æŒ‡é’ˆå¹¶ä¸é€‚åˆä½ ï¼ŒGit ç»™ä½ ä¸€ä¸ªç”Ÿæˆä¸€ä¸ªæ–°æäº¤çš„é€‰é¡¹ï¼Œæäº¤å°†ä¼šæ’¤æ¶ˆä¸€ä¸ªå·²å­˜åœ¨æäº¤çš„æ‰€æœ‰ä¿®æ”¹ã€‚ Git ç§°è¿™ä¸ªæ“ä½œä¸º â€œè¿˜åŸâ€ï¼Œåœ¨è¿™ä¸ªç‰¹å®šçš„åœºæ™¯ä¸‹ï¼Œä½ å¯ä»¥åƒè¿™æ ·è°ƒç”¨å®ƒï¼š 12$ git revert -m 1 HEAD[master b1d8379] Revert \"Merge branch 'topic'\" -m 1 æ ‡è®°æŒ‡å‡º â€œmainlineâ€ éœ€è¦è¢«ä¿ç•™ä¸‹æ¥çš„çˆ¶ç»“ç‚¹ã€‚ å½“ä½ å¼•å…¥ä¸€ä¸ªåˆå¹¶åˆ° HEADï¼ˆgit merge topicï¼‰ï¼Œæ–°æäº¤æœ‰ä¸¤ä¸ªçˆ¶ç»“ç‚¹ï¼šç¬¬ä¸€ä¸ªæ˜¯ HEADï¼ˆC6ï¼‰ï¼Œç¬¬äºŒä¸ªæ˜¯å°†è¦åˆå¹¶å…¥åˆ†æ”¯çš„æœ€æ–°æäº¤ï¼ˆC4ï¼‰ã€‚ åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬æƒ³è¦æ’¤æ¶ˆæ‰€æœ‰ç”±çˆ¶ç»“ç‚¹ #2ï¼ˆC4ï¼‰åˆå¹¶å¼•å…¥çš„ä¿®æ”¹ï¼ŒåŒæ—¶ä¿ç•™ä»çˆ¶ç»“ç‚¹ #1ï¼ˆC4ï¼‰å¼€å§‹çš„æ‰€æœ‰å†…å®¹ã€‚ æ’¤é”€æäº¤å¦‚æœè¿™ä¸ªä¸æƒ³è¦çš„åˆå¹¶æäº¤åªå­˜åœ¨äºä½ çš„æœ¬åœ°ä»“åº“ä¸­ï¼Œæœ€ç®€å•ä¸”æœ€å¥½çš„è§£å†³æ–¹æ¡ˆæ˜¯ç§»åŠ¨åˆ†æ”¯åˆ°ä½ æƒ³è¦å®ƒæŒ‡å‘çš„åœ°æ–¹ã€‚ å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œå¦‚æœä½ åœ¨é”™è¯¯çš„ git merge åè¿è¡Œ git reset --hard HEAD~ï¼Œè¿™ä¼šé‡ç½®åˆ†æ”¯æŒ‡å‘ã€‚ è¿™ä¸ªæ–¹æ³•çš„ç¼ºç‚¹æ˜¯å®ƒä¼šé‡å†™å†å²ï¼Œåœ¨ä¸€ä¸ªå…±äº«çš„ä»“åº“ä¸­è¿™ä¼šé€ æˆé—®é¢˜çš„ã€‚ æŸ¥é˜… å˜åŸºçš„é£é™© æ¥äº†è§£æ›´å¤šå¯èƒ½å‘ç”Ÿçš„äº‹æƒ…ï¼›ç”¨ç®€å•çš„è¯è¯´å°±æ˜¯å¦‚æœå…¶ä»–äººå·²ç»æœ‰ä½ å°†è¦é‡å†™çš„æäº¤ï¼Œä½ åº”å½“é¿å…ä½¿ç”¨ resetã€‚ å¦‚æœæœ‰ä»»ä½•å…¶ä»–æäº¤åœ¨åˆå¹¶ä¹‹ååˆ›å»ºäº†ï¼Œé‚£ä¹ˆè¿™ä¸ªæ–¹æ³•ä¹Ÿä¼šæ— æ•ˆï¼›ç§»åŠ¨å¼•ç”¨å®é™…ä¸Šä¼šä¸¢å¤±é‚£äº›æ”¹åŠ¨ã€‚ GitHubçš„é…ç½®åŠåŸºæœ¬æµ‹è¯• ssh keyçš„åˆ›å»º 1$ ssh-keygen -t rsa -C \"your_email@youremail.com\" ä¸Šä¼ id_rsa.pub åˆ°githubé…ç½® æµ‹è¯• 1$ ssh -T git@github.com æ­£ç¡®çš„è¿”å›ç»“æœ 123456gaoc@DataScience:/data2/ml-cousera$ ssh -T git@github.comThe authenticity of host 'github.com (52.74.223.119)' can't be established.RSA key fingerprint is SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added 'github.com,52.74.223.119' (RSA) to the list of known hosts.Hi ddebby! You've successfully authenticated, but GitHub does not provide shell access. æ·»åŠ originæº 1$ git remote add origin git@github.com:yourName/yourRepo.git ä¸è¦ç›´æ¥ä½¿ç”¨httpsçš„é“¾æ¥åœ°å€ï¼Œè¿˜éœ€è¦ä¸åœçš„è¾“å…¥ç”¨æˆ·å/å¯†ç éªŒè¯ TO-DOå…³äºä¹¦ä¸­ç¬¬åç« Gitå†…éƒ¨åŸç†éƒ¨åˆ†ï¼Œç›®å‰è¿˜æ²¡æœ‰æ—¶é—´ç ”è¯»ï¼Œç•™ä½œåé¢ä½œä¸šã€‚é™äºæœ¬æ–‡ç¯‡å¹…ï¼Œè¿™éƒ¨åˆ†å†…å®¹å°†æ–°å»ºä¸€ç¯‡åšæ–‡ï¼Œæ­¤å¤„æ’å…¥é“¾æ¥å³å¯ã€‚ è·å–ä¸åŒç‰ˆæœ¬çš„ç”µå­ä¹¦ PDFæ ¼å¼ Epubæ ¼å¼ Mobiæ ¼å¼ HTMLåœ¨çº¿é˜…è¯»","categories":[{"name":"å·¥å…·","slug":"å·¥å…·","permalink":"http://blog.a-stack.com/categories/å·¥å…·/"}],"tags":[{"name":"æŠ€æœ¯","slug":"æŠ€æœ¯","permalink":"http://blog.a-stack.com/tags/æŠ€æœ¯/"},{"name":"è¯»ä¹¦ç¬”è®°","slug":"è¯»ä¹¦ç¬”è®°","permalink":"http://blog.a-stack.com/tags/è¯»ä¹¦ç¬”è®°/"},{"name":"Git","slug":"Git","permalink":"http://blog.a-stack.com/tags/Git/"}]}]}