<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Ebby&#39;s Notes</title>
  
  <subtitle>=Blog for AI Learning=</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://blog.a-stack.com/"/>
  <updated>2021-01-28T07:46:43.219Z</updated>
  <id>http://blog.a-stack.com/</id>
  
  <author>
    <name>Ebby DD</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Reinforcement Learning:Tips and Tricks</title>
    <link href="http://blog.a-stack.com/2021/01/28/Reinforcement-Learning-Tips-and-Tricks/"/>
    <id>http://blog.a-stack.com/2021/01/28/Reinforcement-Learning-Tips-and-Tricks/</id>
    <published>2021-01-28T02:56:30.000Z</published>
    <updated>2021-01-28T07:46:43.219Z</updated>
    
    <content type="html"><![CDATA[<p><strong>摘要：</strong> 本篇博文记录强化学习过程中的一些最佳实践的总结，持续更新ing …</p><a id="more"></a><h2 id="Current-Limitations-of-RL"><a href="#Current-Limitations-of-RL" class="headerlink" title="Current Limitations of RL"></a>Current Limitations of RL</h2><h3 id="Sample-inefficient"><a href="#Sample-inefficient" class="headerlink" title="Sample inefficient"></a>Sample inefficient</h3><ul><li>他们需要大量样本（有时需要数百万次交互）才能学到有用的东西。 这就是为什么RL的大部分成功都是通过游戏或模拟获得的。</li><li><p>作为一般建议，为了获得更好的性能，您应该增加Agent的预算（训练时间步数）。</p></li><li><p>计划谬误说，完成某件事通常比您想象的要花费更长的时间。强化学习有其自身的计划谬误-学习策略通常需要比您想象的更多的样本。</p></li><li>理论上，强化学习可以适用于任何事物，包括不了解世界模型的环境。但是，这种普遍性是有代价的：很难利用任何可能有助于学习的特定于问题的信息，这迫使您使用大量样本来学习本来可以进行硬编码的内容。</li></ul><p><img src="/2021/01/28/Reinforcement-Learning-Tips-and-Tricks/rainbow_dqn.png" style="zoom:50%;"></p><blockquote><p>The y-axis is “median human-normalized score”. This is computed by training 57 DQNs, one for each Atari game, normalizing the score of each agent such that human performance is 100%, then plotting the median performance across the 57 games. RainbowDQN passes the 100% threshold at about <em>18 million</em> frames. This corresponds to about 83 hours of play experience, plus however long it takes to train the model. A lot of time, for an Atari game that most humans pick up within a few minutes.</p><p>Mind you, 18 million frames is actually pretty good, when you consider that the previous record (<a href="https://arxiv.org/pdf/1707.06887.pdf">Distributional DQN (Bellemare et al, 2017)</a>) needed 70 million frames to hit 100% median performance, which is about 4x more time. As for the <a href="https://www.nature.com/articles/nature14236">Nature DQN (Mnih et al, 2015)</a>, it never hits 100% median performance, even after 200 million frames of experience.</p></blockquote><h3 id="Reward函数的设计哲学不是所有人都可以掌握（RewArt）"><a href="#Reward函数的设计哲学不是所有人都可以掌握（RewArt）" class="headerlink" title="Reward函数的设计哲学不是所有人都可以掌握（RewArt）"></a>Reward函数的设计哲学不是所有人都可以掌握（RewArt）</h3><ol><li>Atari游戏天生有reward，你不需要为此额外担心，但现实场景却往往并非如此；</li><li>设计一个合理的Reward函数不难，难在如何设计一个函数既能实现你的目标又能让算法很好的学到？<ol><li>打个OpenAI的比方，做一个电动艇竞赛类游戏，优先到达目的地获胜，为了获胜要收集途中的能量块；</li><li>悬崖的复杂版本，可能选择自杀是最有效的方式；</li></ol></li><li>即使你有一个好的reward函数，逃离局部最优仍然是一件困难的事情；</li></ol><h3 id="稳定性与泛化性能"><a href="#稳定性与泛化性能" class="headerlink" title="稳定性与泛化性能"></a>稳定性与泛化性能</h3><ol><li>Overfitting 影响了泛化性能；</li><li>训练结果的稳定性没有定论；<ol><li>比如Pong的Case，不同开局结果往往不一样，波动比较严重；</li><li>RL对您的初始化和培训过程的动态非常敏感，因为您的数据始终是在线收集的，并且您获得的唯一监督就是单个标量来获得奖励。</li></ol></li></ol><blockquote><p><strong>When your training algorithm is both sample inefficient and unstable, it heavily slows down your rate of productive research.</strong> Maybe it only takes 1 million steps. But when you multiply that by 5 random seeds, and then multiply that with hyperparam tuning, you need an exploding amount of compute to test hypotheses effectively.</p></blockquote><h2 id="What’s-important-in-RL"><a href="#What’s-important-in-RL" class="headerlink" title="!!What’s important in RL"></a>!!What’s important in RL</h2><ol><li><p>在强化学习领域，数据仍然是最重要的一环，我们需要重点考虑的问题是：如何保证在环境交互中获取数据的质量？</p><blockquote><ol><li>比如这些过程中，如果存在一些<code>Trajectories</code>存在零回报；</li><li>对于强化学习的训练来说，最耗时的部分是和环境交互获取数据的部分，所以从这个意义上讲，经验回放机制对训练效率提升有一定的价值，很多并行训练的机制也在于保障这个环节性能的提升；</li><li>RL的优化目标是一个<code>Trajectories</code>中的累积汇报最大，但中间某些bad case会被放大，解决这个问题也有助于提升算法收敛效率；</li></ol></blockquote></li><li><p>超参数优化同样十分重要</p><blockquote><ol><li>不要奢望使用默认参数就可以轻易解决你自己环境的问题；</li><li>So 如何高效优化超参数是必须掌握的技能</li></ol></blockquote></li><li><p>仿真环境的构建</p><blockquote><p>尤其是Reward机制的设计，是玄学的玄学 …</p></blockquote></li></ol><h2 id="仿真环境构建"><a href="#仿真环境构建" class="headerlink" title="仿真环境构建"></a>仿真环境构建</h2><h3 id="初始阶段："><a href="#初始阶段：" class="headerlink" title="初始阶段："></a>初始阶段：</h3><ul><li><strong>不要一步到位，先写一个简化版的训练环境</strong>。把任务难度降到最低，确保一定能正常训练。</li><li>记下这个正常训练的智能体的分数，<strong>与随机动作、传统算法得到的分数做比较</strong>。DRL算法的分数应该明显高于随机动作（随机执行动作）。DRL算法不应该低于传统算法的分数。如果没有传统算法，那么也需要自己写一个局部最优的算法（就算只比随机动作的算法高一点点都可以，有能力的情况下，要尽量写好）。</li><li>评估策略的性能: 大部分情况下，可以直接是对Reward Function 给出的reward 进行求和得到的每轮收益episode return作为策略评分。有时候可以需要直接拿策略的实际分数作为评分（移动速度/股票收益/目标完成情况 等）。</li><li>需要保证这个简化版的代码：高效、简洁、可拓展</li></ul><h3 id="改进阶段："><a href="#改进阶段：" class="headerlink" title="改进阶段："></a>改进阶段：</h3><ul><li><strong>让任务难度逐步提高</strong>，对训练环境env 进行缓慢的修改，时刻保存旧版本的代码</li><li><strong>同步微调 Reward Function</strong>，可以直接代入自己的人类视角，为某些行为添加正负奖励。注意奖励的平衡（有正有负）。注意不要为Reward Function 添加太多额外规则，时常回过头取消一些规则，避免过度矫正。</li><li><strong>同步微调 DRL算法，只建议微调超参数</strong>，但不建议对算法核心进行修改。因为任务变困难了，所以需要调整超参数让训练变快。同时摸清楚在这个训练环境下，算法对哪几个超参数是敏感的。有时候为了节省时间，甚至可以为 off-policy 算法保存一些典型的 trajectory（不建议在最终验证阶段使用）。</li><li>每一次修改，都需要跑一下记录不同方法的分数，确保：<strong>随机动作 &lt; 传统方法 &lt; DRL算法</strong>。这样才能及时发现代码逻辑上的错误。要极力避免代码中出现复数个的错误，因为极难排查。</li></ul><h2 id="收尾阶段："><a href="#收尾阶段：" class="headerlink" title="收尾阶段："></a>收尾阶段：</h2><ul><li>尝试慢慢删掉Reward Function 中一些比较复杂的东西，删不掉就算了。</li><li>选择高低两组超参数再跑一次，确认没有优化空间。</li></ul><h2 id="算法设计"><a href="#算法设计" class="headerlink" title="算法设计"></a>算法设计</h2><ol><li>快速开始实验</li><li>超参数优化</li><li>可视化、可解释性分析</li><li>处理过拟合问题</li><li>选择难度适中的baseline（Pong？）</li></ol><blockquote><p>算法选择：</p><ol><li>状态空间、动作空间的连续/离散性；</li><li>是否支持分布式并行运算？</li></ol></blockquote><div class="table-container"><table><thead><tr><th>算法名称</th><th>类型</th><th>动作空间</th><th>备注</th></tr></thead><tbody><tr><td>Q-learning（1992）</td><td>Value Based(Classical)</td><td>离散</td><td></td></tr><tr><td>Deep Q-Network(DQN)（2015）</td><td>Value Based</td><td>离散</td><td></td></tr><tr><td>Dueling DQN（2015）</td><td>Value Based</td><td>离散</td><td></td></tr><tr><td>Double DQN（2016）</td><td>Value Based</td><td>离散</td><td></td></tr><tr><td>REINFORCE（Policy Gradient）（2011）</td><td>Policy Based</td><td>离散/连续</td><td></td></tr><tr><td>TRPO（Trust Region Policy Optimization）（2015）</td><td>Policy Based</td><td>离散/连续</td><td></td></tr><tr><td>PPO（Proximal Policy Optimization）（2017）</td><td>Policy Based</td><td>离散/连续</td><td></td></tr><tr><td>Actor-Critic（AC）(2000)</td><td>Actor-Crtic</td><td>离散/连续</td><td></td></tr><tr><td>Asynchronous Advantage Actor-Critic(A3C)</td><td>Actor-Crtic</td><td>离散/连续</td><td></td></tr><tr><td>DDPG(2018)</td><td>Actor-Crtic</td><td>离散/连续</td><td></td></tr><tr><td>TD3(2018)</td><td>Actor-Crtic</td><td>离散/连续</td></tr></tbody></table></div><h2 id="调参"><a href="#调参" class="headerlink" title="调参"></a>调参</h2><h3 id="off-policy"><a href="#off-policy" class="headerlink" title="off-policy"></a>off-policy</h3><ol><li><p>【<strong>网络宽度、网络层数】</strong>越复杂的函数就需要越大容量的神经网络去拟合。在需要训练1e6步的任务中，我一般选择 宽度128、256，层数小于8的网络；</p></li><li><p><strong>过大、过深的神经网络不适合DRL</strong>，因为：</p><ul><li>深度学习可以在整个训练结束后再使用训练好的模型。而强化学习需要在几秒钟的训练后马上使用刚训好的模型。这导致DRL只能用比较浅的网络来保证<strong>快速拟合</strong>（10层以下）</li><li>并且强化学习的训练数据不如有监督学习那么稳定，无法划分出训练集测试集去避免过拟合，因此DRL也不能用太宽的网络（超过1024），避免参数过度冗余导致<strong>过拟合</strong>。</li></ul></li><li><p><strong>【记忆容量】</strong>经验回放缓存 experimence replay buffer 的最大容量 max capacity，如果超过容量限制，它就会删掉最早的记忆。在简单的任务中（训练步数小于1e6），对于探索能力强的DRL算法，通常在缓存被放满前就训练到收敛了，<strong>不需要删除任何记忆</strong>。然而，过大的记忆也会拖慢训练速度，我一般会先从默认值 2 <strong> 17 ~ 2 </strong> 20 开始尝试，如果环境的随机因素大，我会同步增加记忆容量 与 batch size、网络更新次数，直到逼近服务器的内存、显存上限（放在显存训练更快）</p></li><li><p><strong>【批次大小、更新次数】</strong>一般我会选择与网络宽度相同、或略大的批次大小batch size。我一般从128、256 开始尝试这些2的N次方。</p></li><li><p><strong>【折扣因子】</strong>discount factor（或者叫 discount-rate parameter），gamma 。这个值很容易确定，请回答“你希望你的智能体每做出一步，至少需要考虑接下来多少步的reward？”如果是t 步：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">gamma ** t = <span class="number">0.1</span>  <span class="comment"># 0.1 对于当前这一步来说，t步后的reward的权重</span></span><br><span class="line">gamma = <span class="number">0.1</span> ** (<span class="number">1</span>/t)</span><br><span class="line"></span><br><span class="line"><span class="number">0.93</span>  ~= <span class="number">0.1</span> ** (<span class="number">1</span>/<span class="number">32</span>)</span><br><span class="line"><span class="number">0.98</span>  ~= <span class="number">0.1</span> ** (<span class="number">1</span>/<span class="number">128</span>)</span><br><span class="line"><span class="number">0.99</span>  ~= <span class="number">0.1</span> ** (<span class="number">1</span>/<span class="number">256</span>) </span><br><span class="line"><span class="number">0.995</span> ~= <span class="number">0.1</span> ** (<span class="number">1</span>/<span class="number">512</span>)</span><br><span class="line"></span><br><span class="line">可以看到 <span class="number">0.93</span>, <span class="number">0.98</span>, <span class="number">0.99</span>, <span class="number">0.995</span> 的gamma值</span><br><span class="line">分别对应   <span class="number">32</span>,  <span class="number">128</span>,  <span class="number">256</span>,   <span class="number">512</span> 的步数</span><br></pre></td></tr></table></figure></li></ol><h3 id="on-policy"><a href="#on-policy" class="headerlink" title="on-policy"></a>on-policy</h3><ol><li><strong>【记忆容量】</strong>on-policy 算法每轮更新后都需要删除“用过的数据”，所以on-policy的记忆容量应该大于等于【单轮更新的采样步数】</li><li><strong>【批次大小】</strong>on-policy 算法比off-policy更像深度学习，它可以采用稍大一点的学习率（2e-4）。</li></ol><h2 id="建议"><a href="#建议" class="headerlink" title="建议"></a>建议</h2><h3 id="选择RL来实现你的问题需要慎重考虑，并非只有RL才可以解决序列决策问题；"><a href="#选择RL来实现你的问题需要慎重考虑，并非只有RL才可以解决序列决策问题；" class="headerlink" title="选择RL来实现你的问题需要慎重考虑，并非只有RL才可以解决序列决策问题；"></a>选择RL来实现你的问题需要慎重考虑，并非只有RL才可以解决序列决策问题；</h3><ol><li><p>经验法则是，除极少数情况外，特定领域的算法比强化学习更快，更好。</p></li><li><p>Boston Dynamics并非使用RL？</p><ol><li><p><a href="https://dspace.mit.edu/openaccess-disseminate/1721.1/110533">time-varying LQR, QP solvers, and convex optimization</a></p><iframe width="560" height="315" src="https://www.youtube.com/embed/fRj34o4hN4I" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></li></ol></li></ol><h3 id="如果选择强化学习，该满足什么样的要求？"><a href="#如果选择强化学习，该满足什么样的要求？" class="headerlink" title="如果选择强化学习，该满足什么样的要求？"></a>如果选择强化学习，该满足什么样的要求？</h3><ol><li>场景很容易产生几乎无限的经验数据。</li><li>该问题被简化为更简单的形式。<ul><li>由极简的问题开始逐步处理，检查可行性；</li></ul></li><li>有一种方法可以将自我游戏引入学习中。<ul><li>So far, that setting seems to have the most stable and well-performing behavior.</li></ul></li><li>有一种干净的方法来定义可学习，而非游戏的奖励。</li><li>如果必须确定奖励，它至少应该是丰富的（尽量多的及时奖励）。</li></ol><h3 id="如果从事RL研究，可以再如下领域多些想象力："><a href="#如果从事RL研究，可以再如下领域多些想象力：" class="headerlink" title="如果从事RL研究，可以再如下领域多些想象力："></a>如果从事RL研究，可以再如下领域多些想象力：</h3><ol><li>RL其实不需要遍历或者推理出最优的策略，只要是一个比人类更优的近优策略就足够了！</li><li>期待硬件水平的增速，抹平一切对算法的需求；</li><li>Model Based + Model Free + Deep Learning</li><li>像AlphaGo那样使用RL，RL只是其中的一个环节，解决的是fine-tune的问题；</li><li>设计Reward函数太难，设计一个学习reward函数的算法生成reward，比如imitation learning/inverse learning</li><li>什么时候可以像使用迁移学习一样使用RL？</li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="http://joschu.net/docs/nuts-and-bolts.pdf">The Nuts and Bolts of Deep RL Research</a></li><li><a href="https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html">stable baseline3</a></li><li><a href="https://www.alexirpan.com/2018/02/14/rl-hard.html">Deep Reinforcement Learning Doesn’t Work Yet</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 本篇博文记录强化学习过程中的一些最佳实践的总结，持续更新ing …&lt;/p&gt;
    
    </summary>
    
      <category term="强化学习" scheme="http://blog.a-stack.com/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="强化学习" scheme="http://blog.a-stack.com/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="心得体会" scheme="http://blog.a-stack.com/tags/%E5%BF%83%E5%BE%97%E4%BD%93%E4%BC%9A/"/>
    
  </entry>
  
  <entry>
    <title>pytorch模型的导出与部署</title>
    <link href="http://blog.a-stack.com/2020/11/19/pytorch%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AF%BC%E5%87%BA%E4%B8%8E%E9%83%A8%E7%BD%B2/"/>
    <id>http://blog.a-stack.com/2020/11/19/pytorch模型的导出与部署/</id>
    <published>2020-11-19T05:00:18.000Z</published>
    <updated>2020-11-27T05:33:41.838Z</updated>
    
    <content type="html"><![CDATA[<p><strong>摘要：</strong></p><a id="more"></a><h2 id="pytorch模型的导出"><a href="#pytorch模型的导出" class="headerlink" title="pytorch模型的导出"></a>pytorch模型的导出</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存网络结构和参数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法1：保存网络结构和参数</span></span><br><span class="line">PATH = <span class="string">'./cifar_net.pth'</span></span><br><span class="line">torch.save(net, PATH)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法2：保存网络参数</span></span><br><span class="line">PATH = <span class="string">'./cifar_net.pth'</span></span><br><span class="line">torch.save(net.state_dict(), PATH)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法3：导出网络到ONNX</span></span><br><span class="line">dummy_input = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>).to(device)</span><br><span class="line">torch.onnx.export(net, dummy_input, <span class="string">"torch.onnx"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法4：保存网络位TORCHSCRIPT</span></span><br><span class="line">dummy_input = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>).to(device)</span><br><span class="line">traced_cell = torch.jit.trace(net, dummy_input)</span><br><span class="line">traced_cell.save(<span class="string">"tests.pth"</span>)</span><br></pre></td></tr></table></figure><h3 id="导出模型的检测"><a href="#导出模型的检测" class="headerlink" title="导出模型的检测"></a>导出模型的检测</h3><blockquote><p>But before verifying the model’s output with ONNX Runtime, we will check the ONNX model with ONNX’s API. First, <code>onnx.load(&quot;super_resolution.onnx&quot;)</code> will load the saved model and will output a onnx.ModelProto structure (a top-level file/container format for bundling a ML model. For more information <a href="https://github.com/onnx/onnx/blob/master/onnx/onnx.proto">onnx.proto documentation</a>.). Then, <code>onnx.checker.check_model(onnx_model)</code> will verify the model’s structure and confirm that the model has a valid schema. The validity of the ONNX graph is verified by checking the model’s version, the graph’s structure, as well as the nodes and their inputs and outputs.</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> onnx</span><br><span class="line"></span><br><span class="line">onnx_model = onnx.load(<span class="string">"super_resolution.onnx"</span>)</span><br><span class="line">onnx.checker.check_model(onnx_model)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> onnxruntime</span><br><span class="line"></span><br><span class="line">ort_session = onnxruntime.InferenceSession(<span class="string">"super_resolution.onnx"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Input to the model</span></span><br><span class="line">batch_size = <span class="number">1</span></span><br><span class="line">x = torch.randn(batch_size, <span class="number">3</span>, <span class="number">512</span>, <span class="number">512</span>, requires_grad=<span class="keyword">True</span>)</span><br><span class="line">torch_out = learn.model(x)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">to_numpy</span><span class="params">(tensor)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tensor.detach().cpu().numpy() <span class="keyword">if</span> tensor.requires_grad <span class="keyword">else</span> tensor.cpu().numpy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># compute ONNX Runtime output prediction</span></span><br><span class="line">ort_inputs = &#123;ort_session.get_inputs()[<span class="number">0</span>].name: to_numpy(x)&#125;</span><br><span class="line">ort_outs = ort_session.run(<span class="keyword">None</span>, ort_inputs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># compare ONNX Runtime and PyTorch results</span></span><br><span class="line">np.testing.assert_allclose(to_numpy(torch_out), ort_outs[<span class="number">0</span>], rtol=<span class="number">1e-03</span>, atol=<span class="number">1e-05</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Exported model has been tested with ONNXRuntime, and the result looks good!"</span>)</span><br></pre></td></tr></table></figure><h2 id="模型加载"><a href="#模型加载" class="headerlink" title="模型加载"></a>模型加载</h2><h3 id="使用opencv加载ONNX模型"><a href="#使用opencv加载ONNX模型" class="headerlink" title="使用opencv加载ONNX模型"></a>使用opencv加载ONNX模型</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/highgui.hpp&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv::dnn;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstdlib&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    String modelFile = <span class="string">"D://fastai.onnx"</span>;</span><br><span class="line">    String imageFile = <span class="string">"D://1.jpg"</span>;</span><br><span class="line"></span><br><span class="line">    dnn::Net net = cv::dnn::readNetFromONNX(modelFile); <span class="comment">//读取网络和参数</span></span><br><span class="line">   </span><br><span class="line">    Mat image = imread(imageFile); <span class="comment">// 读取测试图片</span></span><br><span class="line">    cv::cvtColor(image, image, cv::COLOR_BGR2RGB);</span><br><span class="line">    image.convertTo(image, CV_32FC3, <span class="number">1.0f</span> / <span class="number">255.0f</span>);</span><br><span class="line"> </span><br><span class="line">    Mat inputBolb = blobFromImage(image, <span class="number">0.00390625f</span>, Size(<span class="number">512</span>, <span class="number">512</span>), Scalar(), <span class="literal">false</span>, <span class="literal">false</span>); <span class="comment">//将图像转化为正确输入格式</span></span><br><span class="line"></span><br><span class="line">    net.setInput(inputBolb); <span class="comment">//输入图像</span></span><br><span class="line"></span><br><span class="line">    Mat result = net.forward(); <span class="comment">//前向计算</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; result &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">char</span> j;</span><br><span class="line">    <span class="built_in">cin</span> &gt;&gt; j;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="使用libtorch"><a href="#使用libtorch" class="headerlink" title="使用libtorch"></a>使用libtorch</h3><ol><li>libtorch下载</li><li>opencv下载</li><li>visual studio环境准备</li><li>测试</li></ol><h3 id="DLL的生成与测试"><a href="#DLL的生成与测试" class="headerlink" title="DLL的生成与测试"></a>DLL的生成与测试</h3><h4 id="解决cuda不识别的问题"><a href="#解决cuda不识别的问题" class="headerlink" title="解决cuda不识别的问题"></a>解决cuda不识别的问题</h4><p>Windows10系统下使用LibTorch 1.5.0，使用Visual Studio进行C++开发时，</p><p>Torch::cuda::is_available()返回值为False的解决办法：</p><p>在<code>链接器中 -&gt; 命令行 -&gt; 其他选项</code>:</p><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/INCLUDE:?<span class="symbol">warp_size@</span><span class="symbol">cuda@</span><span class="symbol">at@</span><span class="meta">@YAHXZ</span></span><br></pre></td></tr></table></figure><h2 id="Visual-Studio配置"><a href="#Visual-Studio配置" class="headerlink" title="Visual Studio配置"></a>Visual Studio配置</h2><h4 id="1-附加包含目录的配置"><a href="#1-附加包含目录的配置" class="headerlink" title="1. 附加包含目录的配置"></a>1. 附加包含目录的配置</h4><p><code>项目属性</code>—<code>c/c++</code>—<code>附加包含目录</code>,添加如下信息：</p><figure class="highlight taggerscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">D:<span class="symbol">\6</span>6.code<span class="symbol">\9</span>09.torchScript<span class="symbol">\l</span>ibtorchCuda<span class="symbol">\l</span>ibtorch<span class="symbol">\i</span>nclude           D:<span class="symbol">\6</span>6.code<span class="symbol">\9</span>09.torchScript<span class="symbol">\l</span>ibtorchCuda<span class="symbol">\l</span>ibtorch<span class="symbol">\i</span>nclude<span class="symbol">\t</span>orch<span class="symbol">\c</span>src<span class="symbol">\a</span>pi<span class="symbol">\i</span>nclude</span><br><span class="line">D:<span class="symbol">\6</span>6.code<span class="symbol">\9</span>09.torchScript<span class="symbol">\o</span>pencv<span class="symbol">\b</span>uild<span class="symbol">\i</span>nclude</span><br></pre></td></tr></table></figure><p><img src="/2020/11/19/pytorch模型的导出与部署/Tue, 24 Nov 2020 104414.png" alt="兰 0  的 的 00 到  D:\&quot;code\909.torchScript\ex•mpIe•app\Iibtorch\incIud• ： D:\66.code\909.torchScript\opencv\build\incIude  过 它 0 膣 式  支 仅 俄 启 代 码 涯 过  公 虐 叾 运 行 时 查  0 亍 扈 动 版 权 吓  等 3VW3 ）  鞯 吉 视 为 0  習 雪 所 事  列 億 息 知 i 四 n 。 “ （ 豳  是 VsdD  SDL 到  启 用 尥 址 蓀 景 铳 （ 逾 性 ）  0 入 的 IOL  ndo 元 數  加 包 含 目  指 定 一 个 多 个 要 添 加 到 0 路 径 半 的 目 录 ： 当 到 录 不 止 一 省 对 。 用 分 分 儀 ．  伊 憮 径 勇  XM L 立 生 器 "></p><h4 id="2-链接器配置"><a href="#2-链接器配置" class="headerlink" title="2. 链接器配置"></a>2. 链接器配置</h4><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">D:</span>\<span class="number">66</span>.code\<span class="number">909</span>.torchScript\opencv\build\x64\vc15\<span class="class"><span class="keyword">lib</span>;</span></span><br><span class="line"><span class="symbol">D:</span>\<span class="number">66</span>.code\<span class="number">909</span>.torchScript\libtorchCuda\libtorch\<span class="class"><span class="keyword">lib</span>;</span></span><br></pre></td></tr></table></figure><p><img src="/2020/11/19/pytorch模型的导出与部署/config-link.png" alt="0 人 的 IOL  0d0 、 “ 元 如  》 工 且  》 讽 ML 立 档 生 藏  鮁 出 立  是 示 启 动 版 权 标 志  0 苤 导 入  河 目 景  使 甲 过 阪 项 的 入  上 011 孬  强 制 仁 出  创 津 可 那 修 峡 0  / OUT 笾 0 可 虫 写 逆 创 过 的 程 序 的 默 认 0 0 苤 ．  OutDir) 地 3 四 阝 四 e 还  占 VINCREMENTAL•NO)  0G0  D:Wcode\909.torchScript\opencv\build\x64\vc1S\Iib;D:Wcode\909.torchScript\example-•pp\libtord&#39;\lib; "></p><p><code>链接器</code> —<code>输入</code>:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">opencv_world450.lib</span><br><span class="line">asmjit.lib</span><br><span class="line">c10.lib</span><br><span class="line">c10_cuda.lib</span><br><span class="line">caffe2_detectron_ops_gpu.lib</span><br><span class="line">caffe2_module_test_dynamic.lib</span><br><span class="line">caffe2_nvrtc.lib</span><br><span class="line">clog.lib</span><br><span class="line">cpuinfo.lib</span><br><span class="line">fbgemm.lib</span><br><span class="line">libprotobuf.lib</span><br><span class="line">libprotobuf-lite.lib</span><br><span class="line">libprotoc.lib</span><br><span class="line">mkldnn.lib</span><br><span class="line">torch_cpu.lib</span><br><span class="line">torch_cuda.lib</span><br><span class="line">torch.lib</span><br></pre></td></tr></table></figure><p><strong>测试代码</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;torch/torch.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">torch::Tensor tensor = torch::eye(<span class="number">3</span>);</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; tensor.cuda() &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="技巧"><a href="#技巧" class="headerlink" title="技巧"></a>技巧</h2><ol><li><p>使用<code>dumpbin</code>进行依赖的查看</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dumpbin /dependents xxx.dll 或者 xxx.exe</span><br></pre></td></tr></table></figure></li></ol><p>   <img src="/2020/11/19/pytorch模型的导出与部署/image-20201119144802243.png" alt="image-20201119144802243"></p><p><img src="/2020/11/19/pytorch模型的导出与部署/image-20201119145027954.png" alt="image-20201119145027954"></p><ol><li><p>通过配置环境变量，减少复制<code>dll</code>的空间成本</p><p>属性页—配置属性—调试—环境</p><p>设置dll文件的环境变量，</p><p><code>PATH=D:\software\gnsoftware\pyTorch\libtorch-win-shared-with-deps-debug-1.5.0\libtorch\lib;%PATH%</code></p><p>（之前我一般是把那一堆dll文件拷贝到生成的exe文件所在目录，导致这些dll文件会复制很多份，占据很大空间，这里通过设置依赖于项目的环境变量，少了大量拷贝，还不影响其他变量）</p></li></ol><h2 id="C-调用C-DLL"><a href="#C-调用C-DLL" class="headerlink" title="C#调用C++ DLL"></a>C#调用C++ DLL</h2><blockquote><p>项目需求利用C#调用C++封装好的DLL库，进行了一番调研与试错，此部分进行一些详实的记录，有些问题仍待进一步验证。</p><p>以下经验来自网友的分享：<a href="https://www.cnblogs.com/neverstop/p/5901652.html">https://www.cnblogs.com/neverstop/p/5901652.html</a></p></blockquote><h3 id="c-与c-的类型对照问题"><a href="#c-与c-的类型对照问题" class="headerlink" title="c# 与c++的类型对照问题"></a>c# 与c++的类型对照问题</h3><p>c#调用c++方法时，首先要在类中定义一个与c++方法对应的外部方法，因为该方法是用C#语言定义的，那么肯定要弄清楚C#类型与c++类型如何对应，否则会导致调用失败。可以使用工具，自动根据c++方法签名生成对应的C# import方法签名，参考<a href="http://www.cnblogs.com/lbq1221119/archive/2008/01/16/1040958.html">P/Invoke Interop Assistant</a>。不过有一个问题还是要注意的，在x86模式下c#中的int对应c++中的int，而在x64模式下C#中的int是对应c++中的long，就这么一个小小的变量类型，在不经意间可能就会导致c++代码出错。</p><p>还有一个问题是：<code>托管的 PInvoke 签名与非托管的目标签名不匹配</code>，可以在C#代码的方法特性上加上<code>CallingConvention.Cdecl</code>。如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DllImport(&quot;dllname.dll&quot;, CharSet = CharSet.Ansi, EntryPoint = &quot;methodname&quot;, CallingConvention = CallingConvention.Cdecl)]</span><br></pre></td></tr></table></figure><h3 id="内存释放"><a href="#内存释放" class="headerlink" title="内存释放"></a>内存释放</h3><p>哪里调用哪里释放，需要做大量测试检测。</p><h3 id="版本问题"><a href="#版本问题" class="headerlink" title="版本问题"></a>版本问题</h3><p>版本不匹配的话，在调试时会提示<code>正在加载格式不正确的dll</code>，如果使用的是32位的c++版dll，需要把C#项目的编译平台设置为x86，如果使用的是64位的c++版dll，则设置为any cpu和x64都可以。</p><h3 id="编译问题-静态编译与动态编译"><a href="#编译问题-静态编译与动态编译" class="headerlink" title="编译问题(静态编译与动态编译)"></a>编译问题(静态编译与动态编译)</h3><p>这个问题在运行时有时候会提示dll加载不成功，这个问题在不同的电脑上会有不同的体现，有的存在这个问题，有的就运行正常。而我本机就属于正常的，部署的服务器属于出问题的。出现这个问题后，在确认代码无误后，我用<code>depends.exe</code>这个工具查看了一下导致问题的那个c++版的dll都依赖什么程序集，在出问题的机器上会提示有一些依赖的dll不存在，而这些dll在运行正常的机器上是存在的。下图红色框中的为某些机器上可能会缺少的dll：</p><p><img src="/2020/11/19/pytorch模型的导出与部署/206282-20160923224910559-38712457.png" alt="img"></p><p>如果缺少相关dll，该条目的左边会显示出一个黄色的问号。这个问题可以采用静态编译进行解决，关于什么是<a href="http://baike.baidu.com/link?url=ZveglEz7YJNWNoKN5pKfGJbu_pijrEoP2yIA7h99VNEAYAcPwl-8jwWEzVoFDwDhlVS5EoqALwxoJejI7Kpj9a">静态编译</a>可以自行百度，总之就是将程序所依赖的dll编译到程序集中，这样即使其他机器不存在这些dll也可以正常运行了，静态编译可以在vs的项目属性中进行设置</p><p><img src="/2020/11/19/pytorch模型的导出与部署/206282-20160923224957981-1888139544.png" alt="img"></p><p>默认是<code>多线程 DLL(/MD)</code>，即：<strong>动态编译</strong>，这里更改为 <code>多线程（/MT）</code>，即：静态编译。</p><p>刚才的配置只能解决缺少MSVCP120.DLL和MSVCR120.DLL这一类问题，对于缺少MFC相关的dll，还要经过下面的配置：</p><p><img src="/2020/11/19/pytorch模型的导出与部署/206282-20160923225012371-1331717166-1606185369311.png" alt="img"></p><h3 id="异常捕获与问题定位"><a href="#异常捕获与问题定位" class="headerlink" title="异常捕获与问题定位"></a>异常捕获与问题定位</h3><p>很多时候在c#代码中是捕获不到c++的异常的，虽然在方法中添加了特性<code>HandleProcessCorruptedStateExceptions</code>与<code>SecurityCritical</code>但还是捕获不到c++中的异常，原因可能是c++在遇到某些异常时会造成程序直接退出，这样在C#中就自然捕获不到了，所以还是尽量保证c++代码的健壮性。 如果在c#中调用了多个c++版dll中的方法，因为有时捕获不到异常，很难通过常规方法找到问题的原因，c++方法中一旦出现异常可能会直接导致进程退出了，这时可以借助操作系统中的事件查看器来找出异常是来自哪个dll，同时在原有代码中注释掉那段调用该c++方法的代码，或者mock一个方法调用，保证该段代码无异常，然后再进行测试，如果无异常，那么只要解决了那个c++方法的问题即可，如果还有异常那么就是其他dll的问题，然后可以编写测试代码单独测试曾经出问题的dll中的方法。<code>异常捕获+事件查看器+日志</code>可以帮助开发者发现程序的大部分问题与原因。</p><h3 id="c-与-c-互传文件代码"><a href="#c-与-c-互传文件代码" class="headerlink" title="c# 与 c++互传文件代码"></a>c# 与 c++互传文件代码</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">public static BitmapInfo GetImagePixel(Bitmap Source)</span><br><span class="line">        &#123;</span><br><span class="line">            byte[] result;</span><br><span class="line">            int step;</span><br><span class="line">            int iWidth = Source.Width;</span><br><span class="line">            int iHeight = Source.Height;</span><br><span class="line">            //</span><br><span class="line">            if (iWidth %4!=0)</span><br><span class="line">            &#123;</span><br><span class="line">                iWidth = iWidth - (iWidth % 4);</span><br><span class="line">            &#125;</span><br><span class="line">            Rectangle rect = new Rectangle(0, 0, iWidth, iHeight);</span><br><span class="line">            System.Drawing.Imaging.BitmapData bmpData = Source.LockBits(rect,</span><br><span class="line">                System.Drawing.Imaging.ImageLockMode.ReadWrite, Source.PixelFormat);</span><br><span class="line">            IntPtr iPtr = bmpData.Scan0;</span><br><span class="line">            //int iBytes = iWidth * iHeight * 3;</span><br><span class="line">            step = bmpData.Stride/iWidth;</span><br><span class="line">            int iBytes = iWidth * iHeight * step;</span><br><span class="line">            byte[] PixelValues = new byte[iBytes];</span><br><span class="line">            System.Runtime.InteropServices.Marshal.Copy(iPtr, PixelValues, 0, iBytes);</span><br><span class="line">            Source.UnlockBits(bmpData);</span><br><span class="line">            result = PixelValues;</span><br><span class="line">            BitmapInfo bi = new BitmapInfo &#123; Result = result, Channels = step, width =iWidth, height = iHeight&#125;;</span><br><span class="line">            return bi;</span><br><span class="line">        &#125;</span><br><span class="line">     </span><br><span class="line">public class BitmapInfo</span><br><span class="line">    &#123;</span><br><span class="line">        public byte[] Result &#123; get; set; &#125;</span><br><span class="line">        public int Channels &#123; get; set; &#125;</span><br><span class="line">        public int width &#123; get; set; &#125;</span><br><span class="line">        public int height &#123; get; set; &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><h3 id="关于libtorch与pytorch输出结果的不一致性"><a href="#关于libtorch与pytorch输出结果的不一致性" class="headerlink" title="关于libtorch与pytorch输出结果的不一致性"></a>关于libtorch与pytorch输出结果的不一致性</h3><ol><li><p>pre-processing过程导致的结果差异</p><ol><li><p>pre-processing阶段关注两个问题：<code>resize</code>的方法是否一致；<code>normalization</code>的方法是否一致;</p></li><li><p>当统一的相关方法之后仍然发现存在不一致性，进一步分析发现：<code>图像库 PIL的计算浮点数，与opencv计算的不一致。</code></p><blockquote><p>参见：<a href="https://zhuanlan.zhihu.com/p/141401062?from_voters_page=true">https://zhuanlan.zhihu.com/p/141401062?from_voters_page=true</a></p><ol><li>torchvision transforms 默认使用 PIL 预处理图片。</li><li>c++ libtorch 使用opencv预处理图片，所以建议python训练模型的数据增强，使用 opencv 处理数据增强，评估也使用opencv 处理数据增强。</li></ol></blockquote><p>使用libtorch进行预处理代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"torch/script.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"torch/torch.h"</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// opencv 头文件</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/highgui/highgui.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/imgproc/imgproc.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;memory&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    torch::jit::script::Module <span class="keyword">module</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">module</span> = torch::jit::load(<span class="string">"mobilenetv2-trace.pt"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">catch</span> (<span class="keyword">const</span> c10::Error&amp; ) &#123;</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">cerr</span> &lt;&lt; <span class="string">"error loading the model\n"</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 之前的版本 module-&gt;to , 1.4版本以上用 module.to();</span></span><br><span class="line">    <span class="keyword">module</span>.to(at::kCUDA);</span><br><span class="line"></span><br><span class="line">    cv::Mat input_image;</span><br><span class="line">    cv::Mat read_image = cv::imread(<span class="string">"cat.png"</span>);</span><br><span class="line">    <span class="keyword">if</span> (read_image.empty() || !read_image.data)</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"read image fail"</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">    cv::cvtColor(read_image, input_image, cv::COLOR_BGR2RGB);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// resize(256)</span></span><br><span class="line">    cv::<span class="function">Size <span class="title">scale</span><span class="params">(<span class="number">256</span>, <span class="number">256</span>)</span></span>;</span><br><span class="line">    cv::resize(input_image, input_image, scale, <span class="number">0</span>, <span class="number">0</span>, cv::INTER_LINEAR);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// centerSizeCrop(224)</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> cropSize = <span class="number">224</span>;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> offsetW = <span class="built_in">std</span>::round((input_image.cols - cropSize) / <span class="number">2.0</span>);</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> offsetH = <span class="built_in">std</span>::round((input_image.rows - cropSize) / <span class="number">2.0</span>);</span><br><span class="line">    <span class="keyword">const</span> cv::<span class="function">Rect <span class="title">roi</span><span class="params">(offsetW, offsetH, cropSize, cropSize)</span></span>;</span><br><span class="line">    input_image = input_image(roi).clone();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 转换 [unsigned int] to [float]</span></span><br><span class="line">    input_image.convertTo(input_image, CV_32FC3, <span class="number">1.0</span> / <span class="number">255.0</span>);</span><br><span class="line">    torch::Tensor tensor_image = torch::from_blob(input_image.data, &#123;<span class="number">1</span>, input_image.rows, input_image.cols,<span class="number">3</span>&#125;);</span><br><span class="line">    tensor_image = tensor_image.permute(&#123;<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>&#125;);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// transforms.Normalize(mean=[0.485, 0.456, 0.406],</span></span><br><span class="line">    <span class="comment">//                    std=[0.229, 0.224, 0.225])</span></span><br><span class="line">    tensor_image[<span class="number">0</span>][<span class="number">0</span>] = tensor_image[<span class="number">0</span>][<span class="number">0</span>].sub_(<span class="number">0.485</span>).div_(<span class="number">0.229</span>);</span><br><span class="line">    tensor_image[<span class="number">0</span>][<span class="number">1</span>] = tensor_image[<span class="number">0</span>][<span class="number">1</span>].sub_(<span class="number">0.456</span>).div_(<span class="number">0.224</span>);</span><br><span class="line">    tensor_image[<span class="number">0</span>][<span class="number">2</span>] = tensor_image[<span class="number">0</span>][<span class="number">2</span>].sub_(<span class="number">0.406</span>).div_(<span class="number">0.225</span>);</span><br><span class="line">    tensor_image = tensor_image.to(torch::kCUDA);</span><br><span class="line">    torch::Tensor output = <span class="keyword">module</span>.forward(&#123;tensor_image&#125;).toTensor();</span><br><span class="line"></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; output.slice(<span class="comment">/*dim=*/</span><span class="number">1</span>, <span class="comment">/*start=*/</span><span class="number">0</span>, <span class="comment">/*end=*/</span><span class="number">5</span>) &lt;&lt; <span class="string">'\n'</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>为了和libtorch中一致，pytorch中建议使用的策略：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms </span><br><span class="line"><span class="comment">#from PIL import Image</span></span><br><span class="line">val_transform = transforms.Compose([</span><br><span class="line">    <span class="comment">#transforms.Resize(512),</span></span><br><span class="line">    <span class="comment">#transforms.CenterCrop(512),</span></span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>],</span><br><span class="line">                        std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">    ]</span><br><span class="line">)  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">centerSizeCrop</span><span class="params">(image, crop_size)</span>:</span></span><br><span class="line">    rows, cols = image.shape[:<span class="number">2</span>]</span><br><span class="line">    x = round((cols - crop_size) / <span class="number">2.0</span>)</span><br><span class="line">    y = round((rows - crop_size) / <span class="number">2.0</span>)</span><br><span class="line">    img = image[y:y+crop_size, x:x+crop_size]</span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">"xxxxx.bmp"</span>)</span><br><span class="line">img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class="line">img = cv2.resize(img, (<span class="number">1024</span>,<span class="number">1024</span>))</span><br><span class="line">img = centerSizeCrop(img, <span class="number">512</span>)</span><br><span class="line">img = val_transform(img)</span><br><span class="line">img = img.unsqueeze(<span class="number">0</span>)</span><br><span class="line">img = img.cuda()</span><br><span class="line">output = model(img)</span><br></pre></td></tr></table></figure></li></ol></li><li><p>计算精度损失导致的差异</p></li></ol><h3 id="C-调用C-类的实现-如下内容待测试"><a href="#C-调用C-类的实现-如下内容待测试" class="headerlink" title="C# 调用C++类的实现(如下内容待测试)"></a>C# 调用C++类的实现(如下内容待测试)</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line">Marshal C++ Class <span class="keyword">and</span> use the PInvoke</span><br><span class="line">C++ Code ,ClassName.h</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> __<span class="title">declspec</span>(<span class="title">dllexport</span>) <span class="title">CClassName</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">    CClassName();</span><br><span class="line">    ~CClassName();</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">function</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line">C++ Code, ClassName.cpp</span><br><span class="line"></span><br><span class="line">CClassName::CClassName()</span><br><span class="line">&#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">CClassName::~CClassName()</span><br><span class="line">&#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> CClassName::function()</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"Bla bla bla"</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">C++ Code, ClassNameCaller.h file <span class="keyword">for</span> the caller function</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"ClassName.h"</span>      </span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> __cplusplus</span></span><br><span class="line"><span class="keyword">extern</span> <span class="string">"C"</span> &#123;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">extern</span> __declspec(dllexport) <span class="function">CClassName* <span class="title">CreateClassName</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">extern</span> __declspec(dllexport) <span class="function"><span class="keyword">void</span> <span class="title">DisposeClassName</span><span class="params">(CClassName* a_pObject)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">extern</span> __declspec(dllexport) <span class="function"><span class="keyword">void</span> <span class="title">function</span><span class="params">(CClassName* a_pObject)</span></span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> __cplusplus</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">C++ Code, ClassNameCaller.cpp file <span class="keyword">for</span> the caller function</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"ClassNameCaller.h"</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function">CClassName* <span class="title">CreateClassName</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> CClassName();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">DisposeClassName</span><span class="params">(CClassName* a_pObject)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(a_pObject!= <span class="literal">NULL</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">delete</span> a_pObject;</span><br><span class="line">        a_pObject= <span class="literal">NULL</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">function</span><span class="params">(CClassName* a_pObject)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(a_pObject!= <span class="literal">NULL</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        a_pObject-&gt;function();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">-------------------------------------------------------------------------</span><br><span class="line">C<span class="meta"># code</span></span><br><span class="line"></span><br><span class="line">[DllImport(<span class="string">"ClassNameDll.dll"</span>)]</span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">public</span> <span class="keyword">extern</span> IntPtr <span class="title">CreateClassName</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">[DllImport(<span class="string">"ClassNameDll.dll"</span>)]</span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">public</span> <span class="keyword">extern</span> <span class="keyword">void</span> <span class="title">DisposeClassName</span><span class="params">(IntPtr pClassNameObject)</span></span>;</span><br><span class="line"></span><br><span class="line">[DllImport(<span class="string">"ClassNameDll.dll"</span>)]</span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">public</span> <span class="keyword">extern</span> <span class="keyword">void</span> <span class="title">CallFunction</span><span class="params">(IntPtr pClassNameObject)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//use the functions</span></span><br><span class="line">IntPtr pClassName = CreateClassName();</span><br><span class="line"></span><br><span class="line">CallFunction(pClassName);</span><br><span class="line">DisposeClassName(pClassName);</span><br><span class="line">pClassName = IntPtr.Zero;</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://www.cnblogs.com/neverstop/p/5901652.html">https://www.cnblogs.com/neverstop/p/5901652.html</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://blog.a-stack.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
  </entry>
  
  <entry>
    <title>读书笔记-《神经网络与深度学习》</title>
    <link href="http://blog.a-stack.com/2020/05/04/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E3%80%8A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%8B/"/>
    <id>http://blog.a-stack.com/2020/05/04/读书笔记-《神经网络与深度学习》/</id>
    <published>2020-05-04T13:50:21.000Z</published>
    <updated>2021-01-14T11:04:47.898Z</updated>
    
    <content type="html"><![CDATA[<p><strong>摘要：</strong> 借着读邱锡鹏老师新书《神经网络与深度学习》，把深度学习的基础知识再详细梳理一遍。</p><a id="more"></a><h2 id="前馈神经网络"><a href="#前馈神经网络" class="headerlink" title="前馈神经网络"></a>前馈神经网络</h2><p>人工神经网络最初是作为连接主义的重要阵地。</p><blockquote><p>连接主义强调连接的重要性，比如记忆和知识是存储在连接之中，改变连接之间的强度来更新知识。</p></blockquote><p><img src="/2020/05/04/读书笔记-《神经网络与深度学习》/image-20200506222213551.png" alt="典型的神经元结构" style="zoom:80%;"></p><p><strong>激活函数</strong>需要具备以下几点性质： </p><ol><li>连续并可导（允许少数点上不可导）的非线性函数．可导的激活函数 可以直接利用数值优化的方法来学习网络参数．</li><li>激活函数及其导函数要尽可能的简单，有利于提高网络计算效率．</li><li>激活函数的导函数的值域要在一个合适的区间内，不能太大也不能太小，否则会影响训练的效率和稳定性．</li></ol><blockquote><p>特别地，认识一下 <code>Swish</code> 激活函数：</p><p>$f(x) = x<em>sigmod(\beta</em>x)$ </p></blockquote><p><img src="/2020/05/04/读书笔记-《神经网络与深度学习》/image-20200507120117476.png" alt="多层前馈神经网络"></p><h2 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h2><p>权重共享 + 局部连接 + 汇聚</p><p>在深度学习中，使用的卷积是不进行卷积核反转的操作，称作<code>互相关</code>。</p><p><strong>局部连接</strong>：在卷积层（假设是第𝑙层）中的每一个神经元都只和下一层（第𝑙 − 1 层）中某个局部窗口内的神经元相连，构成一个局部连接网络．（由原来的$M<em>l X M</em>{l-1}$ 个变为$M_l X K$）</p><p><strong>权重共享</strong>： 作为参数的卷积核𝒘(𝑙) 对于第𝑙层的所有的神经元都是相同的；</p><p><strong>汇聚：</strong> 本质上是一种下采样操作。</p><p><img src="/2020/05/04/读书笔记-《神经网络与深度学习》/image-20200509145807980.png" alt="全连接层 vs 卷积层"></p><p>卷积层的作用是提取局部特征，不同卷积核相当于不同的特征提取器。</p><p><a href="https://nndl.github.io/v/cnn-conv-more">https://nndl.github.io/v/cnn-conv-more</a></p><h3 id="特殊的卷积"><a href="#特殊的卷积" class="headerlink" title="特殊的卷积"></a>特殊的卷积</h3><ol><li><p>转置卷积/反卷积： 补零操作；</p><p><img src="/2020/05/04/读书笔记-《神经网络与深度学习》/cnn-no_padding_no_strides_transposed.gif" alt="转置卷积"></p></li><li><p>微步卷积： 通过在输入特征之间插入零；</p><p><img src="/2020/05/04/读书笔记-《神经网络与深度学习》/cnn-no_padding_strides_transposed.gif" alt="img"></p></li><li><p>空洞卷积/膨胀卷积：给卷积核增加“空洞”，提高感受野。</p><p><img src="/2020/05/04/读书笔记-《神经网络与深度学习》/cnn-dilation-in_7_out_3.gif" alt="空洞卷积"></p></li></ol><h2 id="Everything-About-RNN"><a href="#Everything-About-RNN" class="headerlink" title="Everything About RNN"></a>Everything About RNN</h2><blockquote><p>前馈神经网络中，信息的传递是单向的，，这种限制虽然使得网络变得更容易学习，但在一定程度上也减弱了神经网络模型的能力．</p><p>很多现实任务中，网络的输出不仅和当前时刻输入相关，也和过去一段时间的输出相关。比如 视频、语音、文本等时序数据，输入长度不确定。</p></blockquote><h3 id="如何让网络有记忆力"><a href="#如何让网络有记忆力" class="headerlink" title="如何让网络有记忆力"></a>如何让网络有记忆力</h3><ul><li>延时神经网络<ul><li>增加延时器，记录近期活性值</li></ul></li><li>有外部输入的非线性自回归模型</li><li>RNN</li></ul><p><img src="/2020/05/04/读书笔记-《神经网络与深度学习》/20170228155156825.png" alt="img"></p><blockquote><p> 理论上，循环神经网络可以近似任意的非线性动力系统.前馈神经网络可以模拟任何连续函数，而循环神经网络可以模拟任何程序．</p></blockquote><h3 id="Vanilla-RNN"><a href="#Vanilla-RNN" class="headerlink" title="Vanilla RNN"></a>Vanilla RNN</h3><p><img src="/2020/05/04/读书笔记-《神经网络与深度学习》/1_xn5kA92_J5KLaKcP7BMRLA.gif" alt="img"></p><h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><p><img src="/2020/05/04/读书笔记-《神经网络与深度学习》/1_goJVQs-p9kgLODFNyhl9zA.gif" alt="img"></p><blockquote><p>引入了cell结构，来维护较长期状态；</p><p>三个门控：遗忘门、输入门、输出门</p></blockquote><h3 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h3><p><img src="/2020/05/04/读书笔记-《神经网络与深度学习》/1_FpRS0C3EHQnELVaWRvb8bg.gif" alt="img"></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://nndl.github.io/">书籍主页地址</a></li><li>《神经网络与深度学习》3小时课程概要 <a href="https://nndl.github.io/ppt/神经网络与深度学习-3小时.pptx">ppt</a>(72M) <a href="https://nndl.github.io/ppt/神经网络与深度学习-3小时.pdf">pdf</a> (12M)</li><li>RCNN<ol><li><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a></li><li><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">http://karpathy.github.io/2015/05/21/rnn-effectiveness/</a></li><li><a href="https://distill.pub/2016/augmented-rnns/">Attention</a></li><li></li></ol></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 借着读邱锡鹏老师新书《神经网络与深度学习》，把深度学习的基础知识再详细梳理一遍。&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://blog.a-stack.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="读书笔记" scheme="http://blog.a-stack.com/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
  </entry>
  
  <entry>
    <title>计算机视觉目标检测研究札记</title>
    <link href="http://blog.a-stack.com/2020/04/19/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6%E6%9C%AD%E8%AE%B0/"/>
    <id>http://blog.a-stack.com/2020/04/19/计算机视觉目标检测研究札记/</id>
    <published>2020-04-19T07:10:45.000Z</published>
    <updated>2020-04-25T13:25:48.225Z</updated>
    
    <content type="html"><![CDATA[<p><strong>摘要：</strong> 写一篇小结，记录目标检测算法近期的学习笔记。</p><a id="more"></a><h2 id="一、背景知识"><a href="#一、背景知识" class="headerlink" title="一、背景知识"></a>一、背景知识</h2><p><img src="/2020/04/19/计算机视觉目标检测研究札记/deep_learning_architecture600pixels.png" alt="层次特征提取"></p><h2 id="二、目标检测问题"><a href="#二、目标检测问题" class="headerlink" title="二、目标检测问题"></a>二、目标检测问题</h2><blockquote><p>目标检测 = 目标定位 + 目标识别</p></blockquote><p><img src="/2020/04/19/计算机视觉目标检测研究札记/objectdetectionInyears.png" alt="PASCAL VOC object detection"></p><h3 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h3><blockquote><p>Region with CNN features</p><p>一句话： 使用CNN从2000个候选区域的图像中进行特征提取，然后交给分类和回归网络执行</p></blockquote><p><img src="/2020/04/19/计算机视觉目标检测研究札记/R-CNN.jpg" alt="R-CNN"></p><ol><li><strong>候选区域选择</strong> 使用了Selective Search算法，一个通过贪婪搜索来寻找Region的算法：<ol><li>自底向上，基于如下特征从一张图像中搜寻相似的像素：<ol><li>颜色</li><li>纹理</li><li>大小</li><li>形状兼容性</li></ol></li><li>将相似的像素进行组合，并通过加权算法形成相似表征结果；</li><li>重复1和2，直到结果稳定</li></ol></li></ol><p><img src="/2020/04/19/计算机视觉目标检测研究札记/image.png" alt="Selective Search"></p><ol><li>特征提取部分，生成一个2000x4096的特征矩阵（feature map）</li><li>论文中分类使用SVM（每个类别一个SVM线性分类器），回归定义了一个最小二乘损失函数，同时对坐标值的映射关系做了重新定义。</li></ol><h3 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h3><p><img src="/2020/04/19/计算机视觉目标检测研究札记/1_ATyBsAsDQNqT4GYKLrO81w.png" alt="1*ATyBsAsDQNqT4GYKLrO81w"></p><h4 id="ROI-Pooling"><a href="#ROI-Pooling" class="headerlink" title="ROI Pooling"></a>ROI Pooling</h4><p>使用了修改过的SPP中空间金字塔pooling的概念；</p><p><img src="/2020/04/19/计算机视觉目标检测研究札记/1_0BJEv0i2OCptYL0PWZve7g.png" alt="1*0BJEv0i2OCptYL0PWZve7g"></p><h2 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h2><p>更多内容详见以前的<a href="http://blog.a-stack.com/2018/04/13/Object-Detection-Faster-RCNN/">博文</a></p><p><img src="/2020/04/19/计算机视觉目标检测研究札记/1_NXWE7BHug0i-FQlHo5xa7w.png" alt="1*NXWE7BHug0i-FQlHo5xa7w"></p><p>提出了新的RPN算法。</p><h3 id="RPN"><a href="#RPN" class="headerlink" title="RPN"></a>RPN</h3><p><img src="/2020/04/19/计算机视觉目标检测研究札记/1_Z4FFgjKMCNkPbkR0mccbyg.png" alt="1*Z4FFgjKMCNkPbkR0mccbyg"></p><h3 id="NMS：-非极大抑制"><a href="#NMS：-非极大抑制" class="headerlink" title="NMS： 非极大抑制"></a>NMS： 非极大抑制</h3><p>​    搜索局部极大值，抑制非极大值元素；</p><ol><li>Select the box that has the highest score.</li><li>Compute its overlap with all other boxes, and remove boxes that overlap it more than the IOU threshold</li><li>Go back to step 1 and iterate until there’s no more boxes with a lower score than the current selected box.</li></ol><h4 id="Soft-NMS"><a href="#Soft-NMS" class="headerlink" title="Soft NMS"></a>Soft NMS</h4><p>​    不要盲目删框，万一两个物体接近，检测两个物体的框有可能重贴区域大；和最大得分框IoU大于阈值的，不直接删除，而是降低得分；</p><h2 id="FPN的研究"><a href="#FPN的研究" class="headerlink" title="FPN的研究"></a>FPN的研究</h2><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="[https://www.alegion.com/object-detection-part-2?hsCtaTracking=ffec2678-3e07-4dbf-a497-31d7baa30d44%7C3ea279e9-75d4-4f87-bbc8-0376dbb15995](https://www.alegion.com/object-detection-part-2?hsCtaTracking=ffec2678-3e07-4dbf-a497-31d7baa30d44|3ea279e9-75d4-4f87-bbc8-0376dbb15995">Deep Learning For Object Detection Part II</a>)</li><li><a href="[https://www.alegion.com/faster-r-cnn?hsCtaTracking=14d0108f-d07f-4e74-9757-63542dc3a883%7Cee0bc84a-eb7c-4804-b336-829f64b40190](https://www.alegion.com/faster-r-cnn?hsCtaTracking=14d0108f-d07f-4e74-9757-63542dc3a883|ee0bc84a-eb7c-4804-b336-829f64b40190">Faster R-CNN</a>)</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 写一篇小结，记录目标检测算法近期的学习笔记。&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://blog.a-stack.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
  </entry>
  
  <entry>
    <title>目标检测中的Anchor与感受野</title>
    <link href="http://blog.a-stack.com/2020/03/30/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%AD%E7%9A%84Anchor%E4%B8%8E%E6%84%9F%E5%8F%97%E9%87%8E/"/>
    <id>http://blog.a-stack.com/2020/03/30/目标检测中的Anchor与感受野/</id>
    <published>2020-03-30T13:14:50.000Z</published>
    <updated>2020-03-31T04:19:47.018Z</updated>
    
    <content type="html"><![CDATA[<p><strong>摘要：</strong> Anchor的设置对于目标检测来说作用的重要性不言而喻，本文主要整理了相关技巧和背后的逻辑原理解读，不断更新完善。</p><a id="more"></a><p>在Faster RCNN的RPN网络部分，anchor为三个尺度{128, 256, 512}，三个比例{1:1, 1:2, 2:1}，所以一共9组anchor。</p><p>通过标记样本聚类，来了解该如何设计Anchor Box的size：</p><p><img src="/2020/03/30/目标检测中的Anchor与感受野/v2-455d4dd1430f426d323fc6a889dadbb4_1440w.jpg" alt="img"></p><blockquote><p>参考实现：<a href="https://github.com/AIZOOTech/object-detection-anchors">object-detection-anchors</a></p></blockquote><h3 id="Pytorch中计算感受野的工具"><a href="#Pytorch中计算感受野的工具" class="headerlink" title="Pytorch中计算感受野的工具"></a>Pytorch中计算感受野的工具</h3><p><a href="https://github.com/Fangyh09/pytorch-receptive-field">https://github.com/Fangyh09/pytorch-receptive-field</a></p><h3 id="常用backbone网络的感受野"><a href="#常用backbone网络的感受野" class="headerlink" title="常用backbone网络的感受野"></a>常用backbone网络的感受野</h3><p><img src="/2020/03/30/目标检测中的Anchor与感受野/v2-5a27b73f03e36e0c1494323a4950523a_720w.jpg" alt="img"></p><blockquote><p>待完善 &gt;&gt;&gt;&gt;&gt;&gt;</p></blockquote><p>目标检测的目标：<code>What objects are where?</code></p><p><img src="/2020/03/30/目标检测中的Anchor与感受野/Object Detection Milestones.png" alt="image-20200330232026807"></p><blockquote><p>Picture from Ref 3</p></blockquote><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://zhuanlan.zhihu.com/p/112574936">新手也能彻底搞懂的目标检测Anchor是什么？怎么科学设置？</a></li><li><a href="https://zhuanlan.zhihu.com/p/55824651">目标检测中的Anchor-YaqiLYU</a></li><li><a href="https://arxiv.org/abs/1905.05055">Object Detection in 20 Years: A Survey</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; Anchor的设置对于目标检测来说作用的重要性不言而喻，本文主要整理了相关技巧和背后的逻辑原理解读，不断更新完善。&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://blog.a-stack.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="计算机视觉" scheme="http://blog.a-stack.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="目标检测" scheme="http://blog.a-stack.com/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>2019年总结：来自19年的工作感悟</title>
    <link href="http://blog.a-stack.com/2020/03/22/2019%E5%B9%B4%E6%80%BB%E7%BB%93%EF%BC%9A%E6%9D%A5%E8%87%AA19%E5%B9%B4%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%84%9F%E6%82%9F/"/>
    <id>http://blog.a-stack.com/2020/03/22/2019年总结：来自19年的工作感悟/</id>
    <published>2020-03-22T07:31:47.000Z</published>
    <updated>2020-03-22T07:50:36.530Z</updated>
    
    <content type="html"><![CDATA[<p><strong>摘要：</strong> 这是一份迟到的总结，2019年底现场工作分享已经结束近三个月，在新冠疫情即将消亡的时刻，重新整理出来，对过去的回顾为了明天更加精彩。</p><a id="more"></a><blockquote><p>这是我在2020年年度工作会议上代表人工智能团队的讲话内容，总结了19年团队工作过程中的几点感悟。</p></blockquote><p>很荣幸今天有机会代表人工智能团队和大家分享一下2019年的一些工作感悟。</p><h2 id="知识"><a href="#知识" class="headerlink" title="知识"></a>知识</h2><p><img src="/2020/03/22/2019年总结：来自19年的工作感悟/image-20200322153844024.png" alt=""></p><p>2019年，人工智能让我对知识的力量有了更加深刻的认识。</p><p>整个2019年是人工智能的爆发期，人工智能领域发展日新月异，新的算法层出不穷，后浪把各种前浪拍死在沙滩上。</p><p>算法的研究已经变成了海量金钱+海量数据+大量技术才能支撑起一项工作。</p><p>其实就算你真的搞出什么新算法可以充当技术壁垒，可能两三个月之后就又有人做出了更强的结果。</p><p>在高速变化的领域是很难形成壁垒的。</p><p>带着这个疑问，在2019年里，我们微软亚洲研究院专家、科大讯飞人工智能专家经过多次交流与探讨，人工智能未来的发展路径必然从数据驱动 ===》 知识驱动转变。</p><p>在人工智能技术如火如荼的今天，我们在技术交流和培训时经常被问到：什么样的工作不容易被替代？</p><p><img src="/2020/03/22/2019年总结：来自19年的工作感悟/image-20200322154014565.png" alt=""></p><p>一要有热情，而要有内涵。</p><p> <img src="/2020/03/22/2019年总结：来自19年的工作感悟/image-20200322154127317.png" alt=""></p><p>【知识驱动的人工智能技术研发】 —-&gt;这也是今年在和科大讯飞的联合实验室中，我们一起探索领域知识库建设的原因。</p><h2 id="传播"><a href="#传播" class="headerlink" title="传播"></a>传播</h2><p> <img src="/2020/03/22/2019年总结：来自19年的工作感悟/image-20200322154222813.png" alt=""></p><p>去年的此时，我们曾分享过，对人工智能算法工程师的要求，不但写的了算法还要认得清场景。2019年的实践验证了我们的看法。拿智能制造领域的人工智能应用来说，客户在车间现场通常需要一个开箱即用的产品，而大多数AI类场景需要足够多的时间去打磨。</p><p>在去年缺陷检测场景中，在很多行业里，很多问题不是算法难以设计，而是沟通这个需求和目标，比如检测标准的制定：如何定义检测工人所说的协调..?</p><p> <img src="/2020/03/22/2019年总结：来自19年的工作感悟/AI001.jpg" alt=""></p><p>如何做有意义的技术研发？</p><p>人工智能团队2020年的能力建设，从四方面入手： 连接—生产—传播—赋能</p><p> <img src="/2020/03/22/2019年总结：来自19年的工作感悟/image-20200322154330587.png" alt=""></p><ul><li><p>连接解决的问题：不要重复造轮子；</p></li><li><p>生产解决的问题：针对具体问题，能够对症下药；</p></li><li><p>传播解决的问题：让更多人的人认识我们；</p></li><li><p>赋能解决的问题：价值在哪里？技术竞争力何在? 找准点</p></li></ul><p>整个2019年里，我们不再闭门造车、关起门来搞研发，而更多的走了出去，参加比赛、组织培训、参加技术论坛和技术交流活动，让别人了解你， 你也更了解别人。</p><p> <img src="/2020/03/22/2019年总结：来自19年的工作感悟/image-20200322154350920.png" alt=""></p><h2 id="团队"><a href="#团队" class="headerlink" title="团队"></a>团队</h2><p><img src="/2020/03/22/2019年总结：来自19年的工作感悟/image-20200322154508163.png" alt=""></p><p><strong>高：</strong>以前有句话，叫做“火车跑得快，全靠车头带”，这说的是前动车时代。动车和高铁为什么比传统的火车速度更快？根本原因是：大多数车厢都能提供动力。在新技术领域，往往如此，学习和交流一直是我们团队努力进行的。我也借此机会，和大家分享，在过去一年中，团队成员的成长感悟：</p><p><strong>HF：</strong> 在过去的一年中，我们看到很多领域人工智能算法在学术上达到甚至超越了人类水平，但这是否代表相关算法/模型可以完全替代人类落地应用呢？</p><p>于此同时，我们也看到很多算法，准确率明明还没有达到人类水平，却已经开始普及应用了。比如自然场景下身份证识别，反面识别的准确率还不足九成。</p><p>这也是在过去一年的工程实践中，我们逐步发现学术成绩和工程落地之间存在很大的差别，我们无法提供百分百可靠的算法，但在工程领域讲究的是够用就行，我们可以在环境约束、实现路径、用户体验上来弥补算法的不足。（张会峰如是说）</p><p><strong>DL：</strong> 在机器学习领域有个经典的理论，叫做没有免费的午餐。它讲的是没有一个算法在所有场景下都表现最优，所以根据场景需求进行算法的选择尤为重要，在众如繁星的算法空间中，挑中最闪亮的那一个，不但需要足够的技术功底掌握算法特性，更应该敏锐的洞察业务场景，没有最好的，只有最适合的。这是刘建志潜移默化影响团队的格言。</p><p> <img src="/2020/03/22/2019年总结：来自19年的工作感悟/image-20200322154635575.png" alt=""></p><p>在过去一年的多个项目对接中，技术人员总是自觉不自觉的沉寂在自己技术领域之中，和客户分享着算法的优势、模型的特点，然而往往事倍功半。如何把模型和算法的魅力用更直观、更亲切的可视化方式和别人分享，是团队<strong>YY</strong>在过去一年努力追求的方向。</p><p>感谢集团领导给我们的耐心，给予我们宽松的环境从事技术研发，感谢研究院领导在过去一年中，帮我们牵线搭桥促进合作交流，2020年我们有信心，不负所托，争创佳绩。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 这是一份迟到的总结，2019年底现场工作分享已经结束近三个月，在新冠疫情即将消亡的时刻，重新整理出来，对过去的回顾为了明天更加精彩。&lt;/p&gt;
    
    </summary>
    
      <category term="工作总结" scheme="http://blog.a-stack.com/categories/%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="总结" scheme="http://blog.a-stack.com/tags/%E6%80%BB%E7%BB%93/"/>
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="感悟" scheme="http://blog.a-stack.com/tags/%E6%84%9F%E6%82%9F/"/>
    
  </entry>
  
  <entry>
    <title>图像数据标注工具推荐-CVAT</title>
    <link href="http://blog.a-stack.com/2020/03/21/%E5%9B%BE%E5%83%8F%E6%95%B0%E6%8D%AE%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E6%8E%A8%E8%8D%90-CVAT/"/>
    <id>http://blog.a-stack.com/2020/03/21/图像数据标注工具推荐-CVAT/</id>
    <published>2020-03-21T13:23:49.000Z</published>
    <updated>2021-01-28T07:11:18.596Z</updated>
    
    <content type="html"><![CDATA[<p><strong>摘要：</strong> 从事深度学习研究开始，尝试过很多不同类型，不同功能的数据标注工具，尤其是图像标注工具，包括自己写的简单工具，都不能很好的满足任务的需求，近期突然使用了CVAT，感觉似乎可能成为未来工具包中的常备系列，写此一文，记录使用过程。</p><a id="more"></a><blockquote><p>Computer Vision Annotation Tool (CVAT) is a web-based tool which helps to annotate videos and images for Computer Vision algorithms. It was inspired by <a href="http://carlvondrick.com/vatic/">Vatic</a> free, online, interactive video annotation tool. CVAT has many powerful features: <em>interpolation of bounding boxes between key frames, automatic annotation using deep learning models, shortcuts for most of critical actions, dashboard with a list of annotation tasks, LDAP and basic authorization, etc…</em> It was created for and used by a professional data annotation team. UX and UI were optimized especially for computer vision tasks developed by our team.</p></blockquote><h2 id="安装部署与配置"><a href="#安装部署与配置" class="headerlink" title="安装部署与配置"></a>安装部署与配置</h2><p>部署过程参考官方文档：<a href="https://github.com/opencv/cvat/blob/develop/cvat/apps/documentation/installation.md">CVAT 部署文档</a>，写的极为详细，基本没有太多坑🕳。</p><p>由于本身的需求，需要使用一些特定功能，具体如下：</p><h3 id="1-配置外网访问"><a href="#1-配置外网访问" class="headerlink" title="1. 配置外网访问"></a>1. 配置外网访问</h3><p>构建YAML文件：<code>docker-compose.add-on.yml</code>:</p><figure class="highlight yaml"><figcaption><span>&gt;folded</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">"2.3"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line"><span class="attr">  cvat_proxy:</span></span><br><span class="line"><span class="attr">    environment:</span></span><br><span class="line"><span class="attr">      CVAT_HOST:</span> <span class="string">.example.com</span></span><br></pre></td></tr></table></figure><h3 id="2-配置挂载图像存储目录"><a href="#2-配置挂载图像存储目录" class="headerlink" title="2. 配置挂载图像存储目录"></a>2. 配置挂载图像存储目录</h3><blockquote><p>替换{}中目录位置</p></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">"2.3"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line"><span class="attr">  cvat:</span></span><br><span class="line"><span class="attr">    environment:</span></span><br><span class="line"><span class="attr">      CVAT_SHARE_URL:</span> <span class="string">"Mounted from /mnt/share host directory"</span></span><br><span class="line"><span class="attr">    volumes:</span></span><br><span class="line"><span class="attr">      - cvat_share:</span><span class="string">/home/django/share:ro</span></span><br><span class="line"></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line"><span class="attr">  cvat_share:</span></span><br><span class="line"><span class="attr">    driver_opts:</span></span><br><span class="line"><span class="attr">      type:</span> <span class="string">none</span></span><br><span class="line"><span class="attr">      device:</span> <span class="string">&#123;/mnt/share&#125;</span></span><br><span class="line"><span class="attr">      o:</span> <span class="string">bind</span></span><br></pre></td></tr></table></figure><p>完成上述配置，重新执行<code>build</code>过程：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose -f docker-compose.yml -f docker-compose.add-on.yml up -d --build</span><br></pre></td></tr></table></figure><h3 id="3-开启CUDA-OpenVINO-support-分析组件"><a href="#3-开启CUDA-OpenVINO-support-分析组件" class="headerlink" title="3. 开启CUDA/OpenVINO support | 分析组件"></a>3. 开启CUDA/OpenVINO support | 分析组件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Build and run containers with CUDA and OpenVINO support</span></span><br><span class="line"><span class="comment"># IMPORTANT: need to download OpenVINO package before running the command</span></span><br><span class="line">docker-compose -f docker-compose.yml -f components/cuda/docker-compose.cuda.yml -f components/openvino/docker-compose.openvino.yml up -d --build</span><br><span class="line"></span><br><span class="line"><span class="comment"># Build and run containers with Analytics component support:</span></span><br><span class="line">docker-compose -f docker-compose.yml -f components/analytics/docker-compose.analytics.yml up -d --build</span><br></pre></td></tr></table></figure><h3 id="4-配置访问命令"><a href="#4-配置访问命令" class="headerlink" title="4. 配置访问命令"></a>4. 配置访问命令</h3><blockquote><p> How to make unassigned tasks not visible to all users</p><p>Set <a href="https://github.com/opencv/cvat/blob/develop/cvat/settings/base.py#L424">reduce_task_visibility</a> variable to <code>True</code>.</p><p>cvat/<a href="https://github.com/opencv/cvat/tree/develop/cvat">cvat</a>/<a href="https://github.com/opencv/cvat/tree/develop/cvat/settings">settings</a>/<strong>base.py</strong> </p></blockquote><h3 id="5-修改logo"><a href="#5-修改logo" class="headerlink" title="5. 修改logo"></a>5. 修改logo</h3><blockquote><p><code>cvat/cvat-ui/src/assets/cvat-logo.svg</code></p></blockquote><h3 id="其它命令"><a href="#其它命令" class="headerlink" title="其它命令"></a>其它命令</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># stops and removes containers, networks, volumes, and images</span></span><br><span class="line">docker-compose down</span><br></pre></td></tr></table></figure><h2 id="使用技巧"><a href="#使用技巧" class="headerlink" title="使用技巧"></a>使用技巧</h2><h3 id="相关地址"><a href="#相关地址" class="headerlink" title="相关地址"></a>相关地址</h3><div class="table-container"><table><thead><tr><th style="text-align:left">功能</th><th style="text-align:center">地址</th></tr></thead><tbody><tr><td style="text-align:left">主页</td><td style="text-align:center"><cvat_origin></cvat_origin></td></tr><tr><td style="text-align:left">用户管理</td><td style="text-align:center"><cvat_origin>/admiin</cvat_origin></td></tr><tr><td style="text-align:left">REST API</td><td style="text-align:center"><cvat_origin>/api/swagger</cvat_origin></td></tr></tbody></table></div><h3 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h3><p>每个数据集的标注工作都作为一项任务；</p><p>支持两种工作模式：</p><ul><li>interpolation task (video sequence)</li><li>annotation task (independent images)</li></ul><h3 id="快捷键"><a href="#快捷键" class="headerlink" title="快捷键"></a>快捷键</h3><p><strong>常用快捷键：</strong></p><ul><li>N：快速创建BOX标记工具；</li><li>Crtl + S: 随时保存</li><li>D： 上一张</li><li>F： 下一张</li><li>CRTL + #N（标签序号）</li></ul><div class="table-container"><table><thead><tr><th>Shortcut</th><th>Common</th></tr></thead><tbody><tr><td><code>F1</code></td><td>open help</td></tr><tr><td><code>F1</code> in dashboard</td><td>open page with documentation</td></tr><tr><td><code>F2</code></td><td>open settings</td></tr><tr><td><code>L</code></td><td>lock/unlock an active shape</td></tr><tr><td><code>L+T</code></td><td>lock/unlock all shapes on the current frame</td></tr><tr><td><code>Q</code> or <code>Num/</code></td><td>set occluded property for an active shape</td></tr><tr><td><code>N</code></td><td>start/stop draw mode</td></tr><tr><td><code>Esc</code></td><td>close draw mode without create</td></tr><tr><td><code>Ctrl+</code></td><td>change type of an active shape</td></tr><tr><td><code>Shift+</code></td><td>change type of new shape by default</td></tr><tr><td><code>Alt + &gt;</code></td><td>switch next default shape type</td></tr><tr><td><code>Alt + &lt;</code></td><td>switch previous default shape type</td></tr><tr><td><code>Enter</code></td><td>change color of active shape</td></tr><tr><td><code>H</code></td><td>hide active shape</td></tr><tr><td><code>T+H</code></td><td>hide all shapes</td></tr><tr><td><code>J</code></td><td>hide labels with attributes on every frame</td></tr><tr><td><code>Delete</code></td><td>delete an active shape</td></tr><tr><td><code>Shift+Delete</code></td><td>delete an active shape even if it is locked</td></tr><tr><td><code>F</code></td><td>go to next frame</td></tr><tr><td><code>D</code></td><td>go to previous frame</td></tr><tr><td><code>V</code></td><td>go forward with a predefined step</td></tr><tr><td><code>C</code></td><td>go backward with a predefined step</td></tr><tr><td><code>~</code></td><td>focus to <code>go to frame</code> element</td></tr><tr><td><code>Ctrl + R</code></td><td>clockwise image rotation</td></tr><tr><td><code>Ctrl + Shift + R</code></td><td>counter clockwise image rotation</td></tr><tr><td><code>Ctrl+C</code></td><td>copy an active shape</td></tr><tr><td><code>Ctrl+V</code></td><td>insert a copied shape</td></tr><tr><td><code>Ctrl+Z</code></td><td>undo previous action</td></tr><tr><td><code>Ctrl+Shift+Z</code>/<code>Ctrl+Y</code></td><td>redo previous action</td></tr><tr><td><code>Shift+B</code>/<code>Alt+B</code></td><td>increase/decrease brightness on an image</td></tr><tr><td><code>Shift+C</code>/<code>Alt+C</code></td><td>increase/decrease contrast on an image</td></tr><tr><td><code>Shift+S</code>/<code>Alt+S</code></td><td>increase/decrease saturation on an image</td></tr><tr><td><code>Alt + G + &#39;+&#39;, Alt + G + &#39;-&#39;</code></td><td>increase/decrease grid opacity</td></tr><tr><td><code>Alt + G + Enter</code></td><td>change grid color</td></tr><tr><td><code>Ctrl+S</code></td><td>save job</td></tr><tr><td><code>Ctrl+B</code></td><td>propagate active shape</td></tr><tr><td><code>+</code>/<code>-</code></td><td>change relative order of highlighted box (if Z-Order is enabled)</td></tr><tr><td></td><td><strong>Interpolation</strong></td></tr><tr><td><code>M</code></td><td>enter/apply merge mode</td></tr><tr><td><code>Esc</code></td><td>close merge mode without apply the merge</td></tr><tr><td><code>R</code></td><td>go to the next key frame of an active shape</td></tr><tr><td><code>E</code></td><td>go to the previous key frame of an active shape</td></tr><tr><td><code>O</code></td><td>change attribute of an active shape to “Outside the frame”</td></tr><tr><td><code>K</code></td><td>mark current frame as key frame on an active shape</td></tr><tr><td></td><td><strong>Attribute annotation mode</strong></td></tr><tr><td><code>Shift+Enter</code></td><td>enter/leave Attribute Annotation mode</td></tr><tr><td><code>Up Arrow</code></td><td>go to the next attribute (up)</td></tr><tr><td><code>Down Arrow</code></td><td>go to the next attribute (down)</td></tr><tr><td><code>Tab</code></td><td>go to the next annotated object</td></tr><tr><td><code>Shift+Tab</code></td><td>go to the previous annotated object</td></tr><tr><td>``</td><td>assign a corresponding value to the current attribute</td></tr><tr><td></td><td><strong>Grouping</strong></td></tr><tr><td><code>G</code></td><td>switch group mode</td></tr><tr><td><code>Esc</code></td><td>close group mode</td></tr><tr><td><code>Shift+G</code></td><td>reset group for selected shapes</td></tr><tr><td></td><td><strong>Filter</strong></td></tr><tr><td><code>Left Arrow</code></td><td>go to the previous frame which corresponds to the specified filter value</td></tr><tr><td><code>Right Arrow</code></td><td>go to the next frame which corresponds to the specified filter value</td></tr></tbody></table></div><blockquote><p><strong>Hints:</strong></p><p>Hold <code>Mouse Wheel</code> to move frame (for example, while drawing)</p><p>Hold <code>Ctrl</code> when shape is active and fix it.</p><p>Hold <code>Ctrl</code> when paste shape from buffer for multiple pasting.</p></blockquote><h2 id="半监督标记与模型"><a href="#半监督标记与模型" class="headerlink" title="半监督标记与模型"></a>半监督标记与模型</h2><blockquote><p><strong>To-Do</strong></p><ul><li><a href="https://github.com/opencv/cvat/blob/develop/cvat/apps/auto_annotation/README.md">Auto annotation using DL models in OpenVINO toolkit format</a></li><li><a href="https://github.com/opencv/cvat/blob/develop/components/analytics/README.md">Analytics: management and monitoring of data annotation team</a></li><li><a href="https://github.com/opencv/cvat/blob/develop/components/tf_annotation/README.md">TF Object Detection API: auto annotation</a></li><li><a href="https://github.com/opencv/cvat/blob/develop/components/cuda/README.md">Support for NVIDIA GPUs</a></li><li><a href="https://github.com/opencv/cvat/blob/develop/cvat/apps/dextr_segmentation/README.md">Semi-automatic segmentation with Deep Extreme Cut</a></li><li><a href="https://github.com/opencv/cvat/blob/develop/components/auto_segmentation/README.md">Auto segmentation: Keras+Tensorflow Mask R-CNN Segmentation</a></li></ul></blockquote><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://github.com/opencv/cvat">CVAT Github</a></li><li><a href="https://github.com/opencv/cvat/blob/develop/cvat/apps/documentation/installation.md">CVAT 部署文档</a></li><li><a href="https://github.com/opencv/cvat/blob/develop/cvat/apps/documentation/user_guide.md">CVAT 用户文档</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 从事深度学习研究开始，尝试过很多不同类型，不同功能的数据标注工具，尤其是图像标注工具，包括自己写的简单工具，都不能很好的满足任务的需求，近期突然使用了CVAT，感觉似乎可能成为未来工具包中的常备系列，写此一文，记录使用过程。&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://blog.a-stack.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="数据" scheme="http://blog.a-stack.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
      <category term="数据标注" scheme="http://blog.a-stack.com/tags/%E6%95%B0%E6%8D%AE%E6%A0%87%E6%B3%A8/"/>
    
      <category term="计算机视觉" scheme="http://blog.a-stack.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
  </entry>
  
  <entry>
    <title>Pathlib--Python的路径管理库</title>
    <link href="http://blog.a-stack.com/2019/05/07/Pathlib-Python%E7%9A%84%E8%B7%AF%E5%BE%84%E7%AE%A1%E7%90%86%E5%BA%93/"/>
    <id>http://blog.a-stack.com/2019/05/07/Pathlib-Python的路径管理库/</id>
    <published>2019-05-07T08:53:05.000Z</published>
    <updated>2020-03-21T06:32:25.109Z</updated>
    
    <content type="html"><![CDATA[<p><strong>摘要：</strong> 整理了Pathlib的使用方法，便于速查。</p><a id="more"></a><h2 id="Pathlib使用方法归纳"><a href="#Pathlib使用方法归纳" class="headerlink" title="Pathlib使用方法归纳"></a>Pathlib使用方法归纳</h2><h3 id="常用操作"><a href="#常用操作" class="headerlink" title="常用操作"></a>常用操作</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p1 = Path()</span><br><span class="line">print(p1)</span><br></pre></td></tr></table></figure><pre><code>.</code></pre><h4 id="路径"><a href="#路径" class="headerlink" title="路径"></a>路径</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p1.cwd()</span><br></pre></td></tr></table></figure><pre><code>PosixPath(&#39;/data/home/gaoc/data/1.fast.ai/nbs/dl1&#39;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 返回一个新的路径，这个新路径就是当前Path对象的绝对路径</span></span><br><span class="line">p1.resolve()</span><br></pre></td></tr></table></figure><pre><code>PosixPath(&#39;/data/home/gaoc/data/1.fast.ai/nbs/dl1&#39;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 也可以获取绝对路径，但是推荐使用resolve()</span></span><br><span class="line">p1.absolute()</span><br></pre></td></tr></table></figure><pre><code>PosixPath(&#39;/data/home/gaoc/data/1.fast.ai/nbs/dl1&#39;)</code></pre><h4 id="获取文件名，文件后缀，文件目录"><a href="#获取文件名，文件后缀，文件目录" class="headerlink" title="获取文件名，文件后缀，文件目录"></a>获取文件名，文件后缀，文件目录</h4><ul><li>name: 目录的最后一个部分</li><li>suffix:目录中最后一个部分的扩展名</li><li>stem：目录最后一个部分，没有后缀</li><li>suffixes：返回多个扩展名列表</li><li>with_suffix(suffix)：补充扩展名到尾部，扩展名存在无效</li><li>with_name(name)：替换目录最后一个部分并返回一个新的路径</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p2 = Path(<span class="string">'/data/home/gaoc/data/99.test/Untitled.ipynb.test'</span>)</span><br><span class="line">p2.name</span><br></pre></td></tr></table></figure><pre><code>&#39;Untitled.ipynb&#39;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p2.stem</span><br></pre></td></tr></table></figure><pre><code>&#39;Untitled&#39;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p2.suffix</span><br></pre></td></tr></table></figure><pre><code>&#39;.ipynb&#39;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p2.suffixes</span><br></pre></td></tr></table></figure><pre><code>[&#39;.ipynb&#39;, &#39;.test&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p2.parent</span><br></pre></td></tr></table></figure><pre><code>PosixPath(&#39;/data/home/gaoc/data/99.test&#39;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 返回一个iterable, 包含所有父目录</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> p2.parents:</span><br><span class="line">    print(i)</span><br></pre></td></tr></table></figure><pre><code>/data/home/gaoc/data/99.test/data/home/gaoc/data/data/home/gaoc/data/home/data/</code></pre><h3 id="拼接、检查与分解"><a href="#拼接、检查与分解" class="headerlink" title="拼接、检查与分解"></a>拼接、检查与分解</h3><p>操作符：/<br>Path对象 / Path对象</p><p>Path对象 / 字符串 或者 字符串 / Path对象</p><p>分解：<br>parts 属性, 可以返回路径中的每一个部分</p><p>joinpath：</p><p>joinpath(*other) 连接多个字符串到Path对象中</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p3 = Path(p2.parent, <span class="string">'test.txt'</span>)</span><br><span class="line">p3</span><br></pre></td></tr></table></figure><pre><code>PosixPath(&#39;/data/home/gaoc/data/99.test/test.txt&#39;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p3 = p2.parent / <span class="string">'test2.txt'</span></span><br><span class="line">p3</span><br></pre></td></tr></table></figure><pre><code>PosixPath(&#39;/data/home/gaoc/data/99.test/test2.txt&#39;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p3 = p2.parent.joinpath(<span class="string">'etc'</span>, <span class="string">'init.d'</span>, Path(<span class="string">'abc'</span>))</span><br><span class="line">p3</span><br></pre></td></tr></table></figure><pre><code>PosixPath(&#39;/data/home/gaoc/data/99.test/etc/init.d/abc&#39;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p3.exists()</span><br></pre></td></tr></table></figure><pre><code>False</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p3.is_file()</span><br></pre></td></tr></table></figure><pre><code>False</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p3.is_dir()</span><br></pre></td></tr></table></figure><pre><code>False</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将路径通过分隔符分割成一个元组</span></span><br><span class="line">p2.parts</span><br></pre></td></tr></table></figure><pre><code>(&#39;/&#39;, &#39;data&#39;, &#39;home&#39;, &#39;gaoc&#39;, &#39;data&#39;, &#39;99.test&#39;, &#39;Untitled.ipynb.test&#39;)</code></pre><h3 id="遍历文件夹"><a href="#遍历文件夹" class="headerlink" title="遍历文件夹"></a>遍历文件夹</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p4 = p2.parent</span><br><span class="line">p4.iterdir()</span><br></pre></td></tr></table></figure><pre><code>&lt;generator object Path.iterdir at 0x7f6dfc0fbeb8&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 相当于os.listdir</span></span><br><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> p4.iterdir():</span><br><span class="line">    print(file)</span><br></pre></td></tr></table></figure><pre><code>/data/home/gaoc/data/99.test/.ipynb_checkpoints/data/home/gaoc/data/99.test/data-science/data/home/gaoc/data/99.test/Untitled.ipynb</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">list(p4.iterdir())</span><br></pre></td></tr></table></figure><pre><code>[PosixPath(&#39;/data/home/gaoc/data/99.test/.ipynb_checkpoints&#39;), PosixPath(&#39;/data/home/gaoc/data/99.test/test&#39;), PosixPath(&#39;/data/home/gaoc/data/99.test/data-science&#39;), PosixPath(&#39;/data/home/gaoc/data/99.test/Untitled.ipynb&#39;)]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 相当于os.listdir, 但是可以添加匹配条件</span></span><br><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> p4.glob(<span class="string">"*.ipynb"</span>):</span><br><span class="line">    print(file)</span><br></pre></td></tr></table></figure><pre><code>/data/home/gaoc/data/99.test/Untitled.ipynb</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">list(p4.glob(<span class="string">"*.ipynb"</span>))</span><br></pre></td></tr></table></figure><pre><code>[PosixPath(&#39;/data/home/gaoc/data/99.test/Untitled.ipynb&#39;)]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 相当于os.walk, 也可以添加匹配条件</span></span><br><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> p4.rglob(<span class="string">"*.ipynb"</span>):</span><br><span class="line">    print(file)</span><br></pre></td></tr></table></figure><pre><code>/data/home/gaoc/data/99.test/Untitled.ipynb/data/home/gaoc/data/99.test/.ipynb_checkpoints/Untitled-checkpoint.ipynb</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">list(p4.rglob(<span class="string">"*.ipynb"</span>))</span><br></pre></td></tr></table></figure><pre><code>[PosixPath(&#39;/data/home/gaoc/data/99.test/Untitled.ipynb&#39;), PosixPath(&#39;/data/home/gaoc/data/99.test/.ipynb_checkpoints/Untitled-checkpoint.ipynb&#39;)]</code></pre><h3 id="创建文件夹"><a href="#创建文件夹" class="headerlink" title="创建文件夹"></a>创建文件夹</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p5 = Path(p4,<span class="string">'test'</span>)</span><br><span class="line">p5.mkdir(exist_ok=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p5</span><br></pre></td></tr></table></figure><pre><code>PosixPath(&#39;/data/home/gaoc/data/99.test/test&#39;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p5.mkdir((exist_ok=<span class="keyword">True</span>, parents=<span class="keyword">True</span>) <span class="comment"># 递归创建文件目录</span></span><br></pre></td></tr></table></figure><h3 id="查看文件信息"><a href="#查看文件信息" class="headerlink" title="查看文件信息"></a>查看文件信息</h3><h4 id="获取详细信息"><a href="#获取详细信息" class="headerlink" title="获取详细信息"></a>获取详细信息</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p6 = Path(<span class="string">'/data/home/gaoc/data/99.test/Untitled.ipynb'</span>)</span><br><span class="line">p6.stat()</span><br></pre></td></tr></table></figure><pre><code>os.stat_result(st_mode=33204, st_ino=57147394, st_dev=2096, st_nlink=1, st_uid=1003, st_gid=1003, st_size=636, st_atime=1555927128, st_mtime=1555926338, st_ctime=1555926338)</code></pre><h4 id="文件大小"><a href="#文件大小" class="headerlink" title="文件大小"></a>文件大小</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p6.stat().st_size</span><br></pre></td></tr></table></figure><pre><code>636</code></pre><h4 id="创建时间"><a href="#创建时间" class="headerlink" title="创建时间"></a>创建时间</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p6.stat().st_atime</span><br></pre></td></tr></table></figure><pre><code>1555927128.4478571</code></pre><h4 id="修改时间"><a href="#修改时间" class="headerlink" title="修改时间"></a>修改时间</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p6.stat().st_mtime</span><br></pre></td></tr></table></figure><pre><code>1555926338.8676176</code></pre><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://www.jianshu.com/p/a820038e65c3">https://www.jianshu.com/p/a820038e65c3</a></li><li><a href="https://www.cnblogs.com/hkcs/p/7773484.html">https://www.cnblogs.com/hkcs/p/7773484.html</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 整理了Pathlib的使用方法，便于速查。&lt;/p&gt;
    
    </summary>
    
      <category term="工具" scheme="http://blog.a-stack.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="Python" scheme="http://blog.a-stack.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>从头训练一个图像分类器</title>
    <link href="http://blog.a-stack.com/2019/02/01/%E4%BB%8E%E5%A4%B4%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AA%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E5%99%A8/"/>
    <id>http://blog.a-stack.com/2019/02/01/从头训练一个图像分类器/</id>
    <published>2019-02-01T02:16:46.000Z</published>
    <updated>2020-03-21T06:07:35.476Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/qnsource/banner/08.jpg" alt="Test Picture"></p><p><strong>摘要：</strong> 本文记录了利用fast.ai快速构建一个图像识别（图像分类器）的方法。</p><a id="more"></a><p>Fast.ai是一个基于Pytorch的深度学习计算框架，就像keras基于tensorflow，目的在于简化深度学习网络设计、训练过程中的复杂逻辑，简化设计时间。2019年第三个版的课程配合pytorch 1.0版本进行了全面更新，相关链接见文末参考。</p><h2 id="基本的环境配置"><a href="#基本的环境配置" class="headerlink" title="基本的环境配置"></a>基本的环境配置</h2><p>我是使用一台Azure的GPU云主机进行的实验，Azure的DSVM云主机提供了扩展包来迅速部署fast.ai所需的相关库，也可以参见 <a href="https://course.fast.ai/start_azure.html">https://course.fast.ai/start_azure.html</a> 进行环境安装。安装的bash脚本如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#安装相关基本软件包</span></span></span><br><span class="line">/anaconda/bin/conda create -y -n fastai python=3.6</span><br><span class="line">source /anaconda/bin/activate fastai</span><br><span class="line">pip install dataclasses</span><br><span class="line">/anaconda/bin/conda install  -y -c pytorch pytorch torchvision</span><br><span class="line">/anaconda/bin/conda install  -y -c fastai fastai</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 在JupyterNotebook中增加fast.ai的kernel</span></span></span><br><span class="line">/anaconda/bin/conda install  -y ipykernel</span><br><span class="line">python -m ipykernel install --name 'fastai' --display-name 'Python (fastai)'</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Script to update Notbook metadata</span></span><br><span class="line">cat &lt;&lt; EOF &gt; /tmp/changenbmeta.py</span><br><span class="line"><span class="meta">#</span><span class="bash">!/usr/bin/python</span></span><br><span class="line">import json,sys</span><br><span class="line"></span><br><span class="line">if len(sys.argv) &lt; 2 :</span><br><span class="line">        print "Usage: python changenbmeta.py &lt;filename&gt;"</span><br><span class="line">        exit()</span><br><span class="line">with open(sys.argv[1], "r") as jsonFile:</span><br><span class="line">    data = json.load(jsonFile)</span><br><span class="line"></span><br><span class="line">data["metadata"]["kernelspec"]["display_name"] = "Python (fastai)"</span><br><span class="line">data["metadata"]["kernelspec"]["name"] = "fastai"</span><br><span class="line"></span><br><span class="line">with open(sys.argv[1], "w") as jsonFile:</span><br><span class="line">    json.dump(data, jsonFile)</span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 下载课程</span></span></span><br><span class="line">cd ~/home/courses</span><br><span class="line">git clone https://github.com/fastai/course-v3</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Change metadata on notebook to match kernel name <span class="keyword">in</span> the fast.ai notebooks</span></span><br><span class="line">find . -name \*.ipynb -exec /usr/bin/python /tmp/changenbmeta.py &#123;&#125; \;</span><br></pre></td></tr></table></figure><h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><p>Fast.ai课程给出了一种可以利用Google Image快速收集图片的流程，值得借鉴。在本例中，我想了半天该识别点啥呢？ 做个自行车、电瓶车、摩托车的识别分类器吧！</p><h3 id="准备图片"><a href="#准备图片" class="headerlink" title="准备图片"></a>准备图片</h3><ol><li><p>打开<a href="https://images.google.com/?gws_rd=ssl">Google Image</a>,搜索并浏览需要的图片，往下滚动，直到有差不多数目的图像被加载（搜索越多，无关照片越多，尽量控制搜索条件，保证搜索质量）；</p></li><li><p>使用命令<code>Ctrl+Shift+J</code>打开控制台，填入如下命令并敲回车，将所有图片保持为<code>urls_xxx.txt</code></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">urls = <span class="built_in">Array</span>.from(<span class="built_in">document</span>.querySelectorAll(<span class="string">'.rg_di .rg_meta'</span>)).map(<span class="function"><span class="params">el</span>=&gt;</span><span class="built_in">JSON</span>.parse(el.textContent).ou);</span><br><span class="line"><span class="built_in">window</span>.open(<span class="string">'data:text/csv;charset=utf-8,'</span> + <span class="built_in">escape</span>(urls.join(<span class="string">'\n'</span>)));</span><br></pre></td></tr></table></figure></li><li><p>准备图片存储目录并下载图片，对于每个类别（注意改变类别名）分别使用如下命令：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> fastai.vision <span class="keyword">import</span> *</span><br><span class="line">path = Path(<span class="string">'/home/gaoc/data/1.Courses/3.fastai/data/bicycles'</span>)</span><br><span class="line"></span><br><span class="line">file1 = <span class="string">'urls_bike.txt'</span></span><br><span class="line"></span><br><span class="line">dest1 = path/<span class="string">'bike'</span></span><br><span class="line">dest1.mkdir(parents=<span class="keyword">True</span>, exist_ok=<span class="keyword">True</span>)</span><br><span class="line">dest2 = path/<span class="string">'battery'</span></span><br><span class="line">dest2.mkdir(parents=<span class="keyword">True</span>, exist_ok=<span class="keyword">True</span>)</span><br><span class="line">dest3 = path/<span class="string">'motorcycle'</span></span><br><span class="line">dest3.mkdir(parents=<span class="keyword">True</span>, exist_ok=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure></li><li><p>下载图片</p><p>将存储的<code>urls_xxx.txt</code>文件放于<code>path</code>目录下，执行如下命令：</p><blockquote><p>其中使用了fast.ai.vision.data的<a href="https://docs.fast.ai/vision.data.html#download_images"><code>download_images</code></a>,指定url文件的位置，存放图片的目的文件夹，最大的图片数目，最大处理线程数目</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">download_images(path/file1, dest1, max_pics=<span class="number">200</span>)</span><br><span class="line">download_images(path/file2, dest2, max_pics=<span class="number">200</span>)</span><br><span class="line">download_images(path/file3, dest3, max_pics=<span class="number">200</span>)</span><br></pre></td></tr></table></figure></li></ol><h3 id="数据清理"><a href="#数据清理" class="headerlink" title="数据清理"></a>数据清理</h3><ol><li><p>下载下来的图片，格式（jpeg、png、gift等）、大小都不一致，需要进行一波清理，fast.ai提供了一个<code>verify_images</code>的工具，可以对图像进行基本的清理操作：</p><blockquote><p><a href="https://docs.fast.ai/vision.data.html#verify_images">verify_images</a> 是一个很有用的函数，会查看该图片是否损坏、是否使用合适的channel数目，是否需要调整到指定大小或超过了限定大小</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">classes = [<span class="string">'bike'</span>,<span class="string">'battery'</span>,<span class="string">'motorcycle'</span>]</span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> classes:</span><br><span class="line">    print(c)</span><br><span class="line">    verify_images(path/c, delete=<span class="keyword">True</span>, max_size=<span class="number">500</span>)</span><br></pre></td></tr></table></figure></li><li><p>虽然图片格式清理完毕， 但由于搜索引擎本身搜索质量的问题，还存在很多归类错误的照片，需要手动调整，fast.ai 提供了一个<code>fastai.widgets</code>的<code>ImageCleaner</code>工具，可以在JupyterNotebook中交互式的进行图片清理。一般而言，为了降低工作量都是从错分的数据中进行数据清理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> fastai.widgets <span class="keyword">import</span> *</span><br><span class="line">ds, idxs = DatasetFormatter().from_toplosses(learn, ds_type=DatasetType.Valid)</span><br><span class="line">ImageCleaner(ds, idxs,path=path)</span><br></pre></td></tr></table></figure></li></ol><p><img src="/2019/02/01/从头训练一个图像分类器/check data.png" alt="check data"></p><p>查找并删除重复图片</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ds, idxs = DatasetFormatter().from_similars(learn, ds_type=DatasetType.Valid)</span><br></pre></td></tr></table></figure><p><img src="/2019/02/01/从头训练一个图像分类器/similar data.png" alt="similar data"></p><h3 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h3><p>fast.ai通过类<code>ImageDataBunch</code>进行数据的组织，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">42</span>)</span><br><span class="line">data = ImageDataBunch.from_folder(path, train=<span class="string">"."</span>, valid_pct=<span class="number">0.2</span>,</span><br><span class="line">        ds_tfms=get_transforms(), size=<span class="number">224</span>, num_workers=<span class="number">4</span>).normalize(imagenet_stats)</span><br></pre></td></tr></table></figure><p>如果从清理过的图像中导入数据，执行如下命令</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">42</span>)</span><br><span class="line">data = ImageDataBunch.from_csv(<span class="string">"."</span>, folder=<span class="string">"."</span>, valid_pct=<span class="number">0.2</span>, csv_labels=path/<span class="string">'cleaned.csv'</span>,</span><br><span class="line">        ds_tfms=get_transforms(), size=<span class="number">224</span>, num_workers=<span class="number">4</span>).normalize(imagenet_stats)</span><br></pre></td></tr></table></figure><p>可以通过如下命令，查看相关类别情况</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.classes, data.c, len(data.train_ds), len(data.valid_ds)</span><br></pre></td></tr></table></figure><p>可以随机查看一组数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.show_batch(rows=<span class="number">3</span>, figsize=(<span class="number">7</span>,<span class="number">8</span>))</span><br></pre></td></tr></table></figure><p><img src="/2019/02/01/从头训练一个图像分类器/data_show.png" alt="data_show"></p><h2 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h2><ol><li><p>使用预训练模型resnet34进行迁移学习：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">learn = create_cnn(data,arch=models.resnet34, metrics=error_rate)</span><br><span class="line">learn.fit_one_cycle(<span class="number">4</span>)</span><br><span class="line">learn.save(<span class="string">'stage-1'</span>)</span><br></pre></td></tr></table></figure><p>结果</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Total time: 00:11</span><br><span class="line">epochtrain_lossvalid_losserror_rate</span><br><span class="line">11.0837250.6011550.250000</span><br><span class="line">20.6813580.6146700.220000</span><br><span class="line">30.5183870.5018600.110000</span><br><span class="line">40.4154230.4752730.100000</span><br></pre></td></tr></table></figure></li><li><p>解冻模型，修改学习率，再训练几轮：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">learn.unfreeze()</span><br><span class="line">learn.lr_find()</span><br><span class="line">learn.recorder.plot()</span><br></pre></td></tr></table></figure><p><img src="/2019/02/01/从头训练一个图像分类器/lr_find.png" alt="lr_find"></p></li><li><p>调整学习率继续学习</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">learn.fit_one_cycle(<span class="number">2</span>,max_lr=slice(<span class="number">1e-4</span>,<span class="number">3e-4</span>))</span><br><span class="line">learn.save(<span class="string">'stage-2'</span>)</span><br></pre></td></tr></table></figure><blockquote><p>这个步骤中学习率的控制很重要，后续更新</p></blockquote><p>结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Total time: <span class="number">00</span>:<span class="number">05</span></span><br><span class="line">epochtrain_lossvalid_losserror_rate</span><br><span class="line"><span class="number">1</span><span class="number">0.139484</span><span class="number">0.459167</span><span class="number">0.120000</span></span><br><span class="line"><span class="number">2</span><span class="number">0.118735</span><span class="number">0.434948</span><span class="number">0.080000</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="模型结果分析"><a href="#模型结果分析" class="headerlink" title="模型结果分析"></a>模型结果分析</h2><p>fast.ai提供了<code>ClassificationInterpretation</code>能够从结果中高效的进行分析</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">interp = ClassificationInterpretation.from_learner(learn)</span><br><span class="line">interp.plot_confusion_matrix()</span><br></pre></td></tr></table></figure><p><img src="/2019/02/01/从头训练一个图像分类器/confusion_matrix.png" alt="confusion_matrix"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">interp.plot_top_losses(<span class="number">9</span>)</span><br></pre></td></tr></table></figure><p><img src="/2019/02/01/从头训练一个图像分类器/top losses.png" alt="top losses"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">interp.most_confused(<span class="number">1</span>)</span><br><span class="line">&gt; [(<span class="string">'battery'</span>, <span class="string">'motorcycle'</span>, <span class="number">4</span>), (<span class="string">'battery'</span>, <span class="string">'bike'</span>, <span class="number">2</span>)]</span><br></pre></td></tr></table></figure><p>可以看处模型容易搞混电动车和摩托车。</p><h2 id="Next"><a href="#Next" class="headerlink" title="Next"></a>Next</h2><p>手动修正数据之后，再重复训练，错误率会降低至1%</p><h2 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 执行如下命令，生成1个84M的export.pkl文件</span></span><br><span class="line">learn.export()</span><br><span class="line">learn = load_learner(path)</span><br><span class="line">pred_class,pred_idx,outputs = learn.predict(img)</span><br></pre></td></tr></table></figure><h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><h3 id="关于Google-Image的图像下载"><a href="#关于Google-Image的图像下载" class="headerlink" title="关于Google Image的图像下载"></a>关于Google Image的图像下载</h3><p>GitHub项目 <a href="https://github.com/toffebjorkskog/ml-tools/blob/master/gi2ds.md"><strong>ml-tools</strong></a> 提供了一种更加便捷的下载方案, 可以在搜索的时候选择是否存储相关照片，只需要把如下代码粘贴在控制台中：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">(<span class="function"><span class="keyword">function</span>(<span class="params">e, s</span>) </span>&#123;</span><br><span class="line">    e.src = s;</span><br><span class="line">    e.onload = <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">        jQuery.noConflict();</span><br><span class="line">        jQuery(<span class="string">'&lt;style type="text/css"&gt; .remove &#123; opacity:0.3;&#125;\n .urlmodal &#123;padding: 10px; background-color: #eee; position: fixed; bottom: 0; right: 0; height: 100px; width: 300px; z-index: 1000;&#125; .urlmodal textarea &#123;width: 100%; height: 250px;&#125;&lt;/style&gt;'</span>).appendTo(<span class="string">'head'</span>);</span><br><span class="line">        jQuery(<span class="string">'&lt;div class="urlmodal"&gt;&lt;h3&gt;Let\'s create a dataset&lt;/h3&gt;&lt;textarea&gt;Scoll all the way down\nClick "Show more images"\nScroll more\nClick on the images you want to remove from the dataset\nThe urls will appear in this box for you to copy.&lt;/textarea&gt;&lt;/div&gt;'</span>).appendTo(<span class="string">'body'</span>);</span><br><span class="line"></span><br><span class="line">        jQuery(<span class="string">'#rg'</span>).on(<span class="string">'click'</span>, <span class="string">'.rg_di'</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">            jQuery(<span class="keyword">this</span>).toggleClass(<span class="string">'remove'</span>);</span><br><span class="line">            updateUrls();</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;);</span><br><span class="line">        jQuery(<span class="built_in">window</span>).scroll(updateUrls);</span><br><span class="line">        jQuery(<span class="string">'.urlmodal textarea'</span>).focus(<span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;updateUrls(); setTimeout(selectText, <span class="number">100</span>)&#125;).mouseup(<span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;<span class="keyword">return</span> <span class="literal">false</span>;&#125;);</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">function</span> <span class="title">updateUrls</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">            <span class="keyword">var</span> urls = <span class="built_in">Array</span>.from(<span class="built_in">document</span>.querySelectorAll(<span class="string">'.rg_di:not(.remove) .rg_meta'</span>)).map(<span class="function"><span class="params">el</span>=&gt;</span><span class="built_in">JSON</span>.parse(el.textContent).ou);</span><br><span class="line">            <span class="keyword">var</span> search_term = jQuery(<span class="string">'.gsfi'</span>).val();</span><br><span class="line">            jQuery(<span class="string">'.urlmodal textarea'</span>).val(urls.join(<span class="string">"\n"</span>));</span><br><span class="line">            jQuery(<span class="string">'.urlmodal h3'</span>).html(search_term + <span class="string">": "</span> + urls.length);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">function</span> <span class="title">selectText</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">            jQuery(<span class="string">'.urlmodal textarea'</span>).select();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">document</span>.head.appendChild(e);</span><br><span class="line">&#125;)(<span class="built_in">document</span>.createElement(<span class="string">'script'</span>), <span class="string">'//code.jquery.com/jquery-latest.min.js'</span>);</span><br></pre></td></tr></table></figure><h3 id="数据清理工具-fastclass"><a href="#数据清理工具-fastclass" class="headerlink" title="数据清理工具 fastclass"></a>数据清理工具 fastclass</h3><blockquote><p><a href="https://github.com/cwerner/fastclass">https://github.com/cwerner/fastclass</a></p><p><a href="https://www.christianwerner.net/tech/Build-your-image-dataset-faster/#">https://www.christianwerner.net/tech/Build-your-image-dataset-faster/#</a></p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install git+https://github.com/cwerner/fastclass.git<span class="comment">#egg=fastclass</span></span><br></pre></td></tr></table></figure><p>使用方法：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">1. 创建一个csv文件用于声明要下载的图片的关键字，比如：</span><br><span class="line">head -n 3 example/guitars.csv</span><br><span class="line">searchterm,exclude</span><br><span class="line">guitar gibson les paul,guitar</span><br><span class="line">guitar gibson SG,guitar</span><br><span class="line"></span><br><span class="line">2. 下载（ALL=Google+Bing+Baidu）</span><br><span class="line">fcd -c ALL -k -o guitars example/guitars.csv </span><br><span class="line"></span><br><span class="line">3. 清理（使用[1]-[9]分类，D删除，X退出）</span><br><span class="line">fcc guitars/gibson_les_paul</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://course.fast.ai/">Fast.ai课程v3</a></li><li><a href="https://docs.fast.ai/">Fast.ai文档</a></li><li><a href="https://40.73.66.75:8000/user/gaoc/notebooks/1.Courses/3.fastai/course-v3/nbs/dl-ebby/lesson2-download.ipynb">JupyterNotebook</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/qnsource/banner/08.jpg&quot; alt=&quot;Test Picture&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 本文记录了利用fast.ai快速构建一个图像识别（图像分类器）的方法。&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://blog.a-stack.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="Fast.ai" scheme="http://blog.a-stack.com/tags/Fast-ai/"/>
    
  </entry>
  
  <entry>
    <title>2018年总结：来自18年的工作感悟</title>
    <link href="http://blog.a-stack.com/2019/01/24/2018%E5%B9%B4%E6%80%BB%E7%BB%93%EF%BC%9A%E6%9D%A5%E8%87%AA18%E5%B9%B4%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%84%9F%E6%82%9F/"/>
    <id>http://blog.a-stack.com/2019/01/24/2018年总结：来自18年的工作感悟/</id>
    <published>2019-01-24T06:50:22.000Z</published>
    <updated>2020-03-22T07:32:36.767Z</updated>
    
    <content type="html"><![CDATA[<p><strong>摘要：</strong> 2018年在从事人工智能工作过程中，有着诸多的感悟，记录下来激励自己2019年不要放松要求。</p><a id="more"></a><blockquote><p>这是我在2019年年度工作会议上代表人工智能团队的讲话内容，总结了18年团队工作过程中的几点感悟。</p></blockquote><h2 id="安而不忘危，存而不忘亡，治而不忘乱"><a href="#安而不忘危，存而不忘亡，治而不忘乱" class="headerlink" title="安而不忘危，存而不忘亡，治而不忘乱"></a>安而不忘危，存而不忘亡，治而不忘乱</h2><p>第一个感悟，我引用了《周易》中的一段话：</p><blockquote><p>安而不忘危，存而不忘亡，治而不忘乱。——《周易》       </p><p> 原话内容是：“安而不忘危、存而不忘亡、治而不忘乱、富而不忘贫、乐而不忘忧、顺而不忘逆、甘而不忘苦、福而不忘祸“。</p></blockquote><p>其实三句话都在讲述同一个道理，要有忧患意识，懂得居安思危。我之所以有这样的感悟，来自于18年几次人工智能交流活动，让我对所从事的工作充满了紧迫感：</p><ol><li><p>今年下半年，我们去云智科技调研，这曾经是一家在传统视频图像分析领域很领先的公司，随着这波深度学习技术兴起，他们在技术转型上慢了一小步，便被抛下了，很难在智能安防这个市场下占有一席之地；逆境求生存，他们只能在一些边缘行业寻找机会，比如参与了航天员的训练监控项目、音频分析等特质化的业务场景；云智是众多拥有一定技术的人工智能小公司的真实写照；这也是人工智能对传统行业的冲击；</p></li><li><p>10月份，我们去塞嘉电子正在驻场的一家客户——杭州卷烟厂进行实地调研，塞嘉在烟厂落地了一个烟包检测的人工智能的小项目，项目虽小，但为了推动后续合作，专门在现场设了驻场人员，一点一点的从客户身上挖需求，这让我真切感受到了人工智能外部项目落地的艰辛。跟赛嘉驻场人员沟通时，我问：你们觉得在实现客户需求有什么技术困难么？他说其实我们最终技术实现也没用什么深度学习技术，更多是在用传统的机器视觉分析，与技术比起来更头痛的是，烟厂更看重人工智能项目的学术价值，让我们帮他们发几篇SCI论文；</p></li><li><p>同样在10月，微软亚洲研究院副院长，自然语言处理领域的权威周明博士来公司做了一次交流，会上我问道了如何能够在人工智能领域跟的上？ 周院长笑了笑，说这是个开放的问题，我是做理论研究的，光我所从事的领域每天就更新几十篇重要论文，我休个假回来就需要补好久。我只能给你提供一些高效的工具。</p></li></ol><p>这些只是18年发生在身边众多感触的一小部分，在外部环境风起云涌，技术飞速发展的今天，一方面请珍惜xx给予了我们相对稳定、宽松的研发环境，但更重要的是安而不忘危，存而不忘亡，治而不忘乱。需要提升紧迫感和危机意识。没有压力就没有动力，去年这个时候我曾经开玩笑说唯一让我睡不着觉的恐怕是牛总在熬夜学习人工智能技术给我的压迫感，今年让我紧迫的可不止牛总一个了。</p><h2 id="学如逆水行舟，不进则退；心似平原纵马，易放难收"><a href="#学如逆水行舟，不进则退；心似平原纵马，易放难收" class="headerlink" title="学如逆水行舟，不进则退；心似平原纵马，易放难收"></a>学如逆水行舟，不进则退；心似平原纵马，易放难收</h2><p>2018年给我们的第二个感悟： </p><blockquote><p>学如逆水行舟，不进则退；心似平原纵马，易放难收。——《增广贤文》</p></blockquote><p>在过去的一年里，团队在技术跟进和项目研发过程中面临了很多全新的技术内容，在人工智能领域，技术上跟的上对我们团队是个很大的无形压力。我们一起啃论文、扣算法、业余充电。</p><p>在此，我要感谢团队这过去一年的辛勤付出，让技能时刻更新，让项目如期完成：</p><ul><li><p>…</p></li><li><p>对我而言，18年是我整体规划、系统学习的一年，迫于压力，在过去的一年来我读了二十四本书；拿了30门课程认证证书，花了400个学时来补技术短板；</p><p><img src="/2019/01/24/2018年总结：来自18年的工作感悟/感悟二.png" alt="感悟二"></p></li><li><p>在人工智能技术影响越来越多行业领域今天，它作为一项技能不再单是人工智能工程师一个角色的事情，我们即将迎来的是个全民AI时代，就像程序员都需要学习并使用一门编程语言一样，大家也应该尝试了解一两个机器学习算法，说不定对你手头工作大有裨益。</p><h2 id="路逢剑客须呈剑，不是诗人莫献诗"><a href="#路逢剑客须呈剑，不是诗人莫献诗" class="headerlink" title="路逢剑客须呈剑，不是诗人莫献诗"></a>路逢剑客须呈剑，不是诗人莫献诗</h2></li></ul><p>我的第三个感悟：</p><blockquote><p>“路逢剑客须呈剑，不是诗人莫献诗。”———《庄子》</p></blockquote><p>在过去的一年里，我们技术上对接过来自集团内外不同背景、不同需求、不用业务条线的很多人。每次我都怀着一个技术人员的执念，跟他们介绍什么是人工智能，什么是这个技术能做的，人工智能不是万能，没有什么是100%准确的。但每次都感觉收效甚微。</p><p>经历了几次碰壁，我去好好思考了这个问题，结论见图：</p><blockquote><p>你以为你给别人呈现的未必是别人以为你能给别人呈现的内容。</p></blockquote><p><img src="/2019/01/24/2018年总结：来自18年的工作感悟/不同人眼中的人工智能工程师2.jpg" alt="不同人眼中的人工智能工程师2"></p><p>我们人工智能的工作是每天都在想如何把这些数学模型做好，再通过计算机程序实现。当然在这期间我们也做了不少艺术化的工作，比如一直尝试把饼图画得更圆一点、哪种配色展示效果更好，这似乎是我们唯一的艺术追求，但实际上我们的追求还是要更大一点的。我觉得一个技术人员除了内修技术之外，还要在艺术上有所作为，做好一个演员。</p><p><img src="/2019/01/24/2018年总结：来自18年的工作感悟/感悟三.png" alt="感悟三"></p><p>我一直觉得，在人工智能领域奇缺一类人才，我姑且叫他们“人工智能需求转化工程师”。他们一方面具备快速了解客户业务场景的能力，另一方面需要明白人工智能技术的边界，当然更为关键的是懂得如何与客户沟通，要能迅速入戏，成为他们期待你成为的样子，知道该呈剑，还是献诗。只有如此才能将业务需求很好的和对应的人工智能技术衔接。</p><p>在18年，为了更好的让别人了解我们在做什么，更好的展现研发的技术，团队成员一起利用空余时间搭建了研究院的人工智能AI实验室平台，将一些可视化的技术成果和培训课程移值了上去，同时一起为集团进行了人工智能的技术分享，（我们在演员的道路上走出了第一步）；台上一分钟，台下十年功，18年只是一个开始，19年人工智能大戏，我们已经准备好粉墨登场。</p><p>2018年一代武侠大师金庸先生驾鹤西去，但19年技术武学仍要刻苦修炼，留本武林秘籍，供大家参悟：</p><blockquote><p>“知识是内功，执行是外功，经验是心法，领悟是贯通。”</p></blockquote><p>祝大家19年工作顺利！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 2018年在从事人工智能工作过程中，有着诸多的感悟，记录下来激励自己2019年不要放松要求。&lt;/p&gt;
    
    </summary>
    
      <category term="工作总结" scheme="http://blog.a-stack.com/categories/%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="总结" scheme="http://blog.a-stack.com/tags/%E6%80%BB%E7%BB%93/"/>
    
      <category term="感悟" scheme="http://blog.a-stack.com/tags/%E6%84%9F%E6%82%9F/"/>
    
  </entry>
  
  <entry>
    <title>Batch-Normalization(批量归一化)</title>
    <link href="http://blog.a-stack.com/2019/01/12/Batch-Normalization-%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96/"/>
    <id>http://blog.a-stack.com/2019/01/12/Batch-Normalization-批量归一化/</id>
    <published>2019-01-12T14:45:29.000Z</published>
    <updated>2020-03-21T06:08:31.497Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/qnsource/banner/07.jpg" alt="BN不得不了解的深度学习技术~"></p><p><strong>摘要：</strong> 借重读论文的机会，重新整理一下Batch Normalization的关键技术。</p><a id="more"></a><blockquote><p>近期在重新做CS231n作业的时候，再次被Batch Normalization给困住，无奈从论文和资料重新开始查阅，这次尽量把相关技术研究透，整理以备速查。</p><p>CS231n中关于Batch Normalization的作业出在Assignment 2的第二个作业，可通过该<a href="https://github.com/ddebby/cs231n/blob/master/assignment2/BatchNormalization.ipynb">链接</a>访问。</p></blockquote><h2 id="为什么需要Batch-Normalization"><a href="#为什么需要Batch-Normalization" class="headerlink" title="为什么需要Batch Normalization"></a>为什么需要Batch Normalization</h2><p>BN是由Google于2015年提出，这是一个深度神经网络训练的技巧，它不仅可以加快了模型的收敛速度，而且更重要的是在一定程度缓解了深层网络中“梯度弥散”的问题，从而使得训练深层网络模型更加容易和稳定。所以目前BN已经成为几乎所有卷积神经网络的标配技巧了。</p><p>在机器学习算法中，一般都假设所有输入特征符合独立同分布的特性，所以将输入数据归一化为单位高斯分布有利于提升模型的训练效果。这也是白化对于提升模型训练起的良好效果的原因。在深度神经网络中，我们通过对输入数据的约束，已经可以实现在输入层的激活可以保证数据的独立同分布，但随着网络传播过程，非线性激活函数的作用，导致数据的分布不断变化，数据的独立性（层的数据之间存在不同程度的相关性）被破坏。数据不再是零均值或者单位方差。同时随着梯度的更新，每层数据分布也在产生不同程度的偏移。</p><h2 id="Batch-Normalization的思想及实现"><a href="#Batch-Normalization的思想及实现" class="headerlink" title="Batch Normalization的思想及实现"></a>Batch Normalization的思想及实现</h2><p>模型训练阶段，BN层通过估计mini-batch中数据的均值和方差，将数据进行归一化。同时这些估计结果的滑动均值被记录下来，用于推理阶段。</p><p>Batch Normalization的计算</p><script type="math/tex; mode=display">\begin{align}\mu_i = \frac{1}{m} \sum_{k \in S_i} x_k\\\sigma_i = \sqrt{\frac{1}{m}\sum_{k\in S_i} (x_k-\mu_i)^2 + \epsilon}\\\hat x_i = \frac{x_i - \mu_i}{\sigma_i}\\y_i = \lambda \hat x_i + \beta\end{align}</script><blockquote><p>公式（4）是为了保证被BN层处理之后的数据仍具备一定的非线性特征而进行的恢复操作，不然网络所有层都是线性变换，无法进行模型参数更新。</p></blockquote><h3 id="前向传播的实现"><a href="#前向传播的实现" class="headerlink" title="前向传播的实现"></a>前向传播的实现</h3><p>参考BN作者论文的思路如下：</p><p><img src="/2019/01/12/Batch-Normalization-批量归一化/BN_Forward.PNG" alt="BN_Forward"></p><p>代码实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batchnorm_forward</span><span class="params">(x, gamma, beta, bn_param)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Forward pass for batch normalization.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    During training the sample mean and (uncorrected) sample variance are</span></span><br><span class="line"><span class="string">    computed from minibatch statistics and used to normalize the incoming data.</span></span><br><span class="line"><span class="string">    During training we also keep an exponentially decaying running mean of the</span></span><br><span class="line"><span class="string">    mean and variance of each feature, and these averages are used to normalize</span></span><br><span class="line"><span class="string">    data at test-time.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    At each timestep we update the running averages for mean and variance using</span></span><br><span class="line"><span class="string">    an exponential decay based on the momentum parameter:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    running_mean = momentum * running_mean + (1 - momentum) * sample_mean</span></span><br><span class="line"><span class="string">    running_var = momentum * running_var + (1 - momentum) * sample_var</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Note that the batch normalization paper suggests a different test-time</span></span><br><span class="line"><span class="string">    behavior: they compute sample mean and variance for each feature using a</span></span><br><span class="line"><span class="string">    large number of training images rather than using a running average. For</span></span><br><span class="line"><span class="string">    this implementation we have chosen to use running averages instead since</span></span><br><span class="line"><span class="string">    they do not require an additional estimation step; the torch7</span></span><br><span class="line"><span class="string">    implementation of batch normalization also uses running averages.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">    - x: Data of shape (N, D)</span></span><br><span class="line"><span class="string">    - gamma: Scale parameter of shape (D,)</span></span><br><span class="line"><span class="string">    - beta: Shift paremeter of shape (D,)</span></span><br><span class="line"><span class="string">    - bn_param: Dictionary with the following keys:</span></span><br><span class="line"><span class="string">      - mode: 'train' or 'test'; required</span></span><br><span class="line"><span class="string">      - eps: Constant for numeric stability</span></span><br><span class="line"><span class="string">      - momentum: Constant for running mean / variance.</span></span><br><span class="line"><span class="string">      - running_mean: Array of shape (D,) giving running mean of features</span></span><br><span class="line"><span class="string">      - running_var Array of shape (D,) giving running variance of features</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - out: of shape (N, D)</span></span><br><span class="line"><span class="string">    - cache: A tuple of values needed in the backward pass</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    mode = bn_param[<span class="string">'mode'</span>]</span><br><span class="line">    eps = bn_param.get(<span class="string">'eps'</span>, <span class="number">1e-5</span>)</span><br><span class="line">    momentum = bn_param.get(<span class="string">'momentum'</span>, <span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line">    N, D = x.shape</span><br><span class="line">    running_mean = bn_param.get(<span class="string">'running_mean'</span>, np.zeros(D, dtype=x.dtype))</span><br><span class="line">    running_var = bn_param.get(<span class="string">'running_var'</span>, np.zeros(D, dtype=x.dtype))</span><br><span class="line"></span><br><span class="line">    out, cache = <span class="keyword">None</span>, <span class="keyword">None</span></span><br><span class="line">    <span class="keyword">if</span> mode == <span class="string">'train'</span>:</span><br><span class="line">        <span class="comment">#######################################################################</span></span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span> Implement the training-time forward pass for batch norm.      #</span></span><br><span class="line">        <span class="comment"># Use minibatch statistics to compute the mean and variance, use      #</span></span><br><span class="line">        <span class="comment"># these statistics to normalize the incoming data, and scale and      #</span></span><br><span class="line">        <span class="comment"># shift the normalized data using gamma and beta.                     #</span></span><br><span class="line">        <span class="comment">#                                                                     #</span></span><br><span class="line">        <span class="comment"># You should store the output in the variable out. Any intermediates  #</span></span><br><span class="line">        <span class="comment"># that you need for the backward pass should be stored in the cache   #</span></span><br><span class="line">        <span class="comment"># variable.                                                           #</span></span><br><span class="line">        <span class="comment">#                                                                     #</span></span><br><span class="line">        <span class="comment"># You should also use your computed sample mean and variance together #</span></span><br><span class="line">        <span class="comment"># with the momentum variable to update the running mean and running   #</span></span><br><span class="line">        <span class="comment"># variance, storing your result in the running_mean and running_var   #</span></span><br><span class="line">        <span class="comment"># variables.                                                          #</span></span><br><span class="line">        <span class="comment">#                                                                     #</span></span><br><span class="line">        <span class="comment"># Note that though you should be keeping track of the running         #</span></span><br><span class="line">        <span class="comment"># variance, you should normalize the data based on the standard       #</span></span><br><span class="line">        <span class="comment"># deviation (square root of variance) instead!                        # </span></span><br><span class="line">        <span class="comment"># Referencing the original paper (https://arxiv.org/abs/1502.03167)   #</span></span><br><span class="line">        <span class="comment"># might prove to be helpful.                                          #</span></span><br><span class="line">        <span class="comment">#######################################################################</span></span><br><span class="line">        <span class="comment">#pass</span></span><br><span class="line">        sample_mean = np.mean(x,axis=<span class="number">0</span>)</span><br><span class="line">        sample_var = np.var(x,axis=<span class="number">0</span>)</span><br><span class="line">        running_mean = momentum * running_mean + (<span class="number">1</span> - momentum) * sample_mean</span><br><span class="line">        running_var = momentum * running_var + (<span class="number">1</span> - momentum) * sample_var</span><br><span class="line">        x_hat = (x - sample_mean)/np.sqrt(sample_var + eps)</span><br><span class="line">        out = gamma * x_hat  + beta</span><br><span class="line"></span><br><span class="line">        cache =(x, x_hat, gamma, beta,eps,sample_mean, sample_var)</span><br><span class="line">        <span class="comment">#######################################################################</span></span><br><span class="line">        <span class="comment">#                           END OF YOUR CODE                          #</span></span><br><span class="line">        <span class="comment">#######################################################################</span></span><br><span class="line">    <span class="keyword">elif</span> mode == <span class="string">'test'</span>:</span><br><span class="line">        <span class="comment">#######################################################################</span></span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span> Implement the test-time forward pass for batch normalization. #</span></span><br><span class="line">        <span class="comment"># Use the running mean and variance to normalize the incoming data,   #</span></span><br><span class="line">        <span class="comment"># then scale and shift the normalized data using gamma and beta.      #</span></span><br><span class="line">        <span class="comment"># Store the result in the out variable.                               #</span></span><br><span class="line">        <span class="comment">#######################################################################</span></span><br><span class="line">        <span class="comment">#pass</span></span><br><span class="line">        x_hat = (x - running_mean)/np.sqrt(running_var + eps)</span><br><span class="line">        out = gamma * x_hat  + beta</span><br><span class="line">        cache =(x,x_hat, gamma, beta, eps, running_mean, running_var)</span><br><span class="line">        <span class="comment">#######################################################################</span></span><br><span class="line">        <span class="comment">#                          END OF YOUR CODE                           #</span></span><br><span class="line">        <span class="comment">#######################################################################</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">'Invalid forward batchnorm mode "%s"'</span> % mode)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Store the updated running means back into bn_param</span></span><br><span class="line">    bn_param[<span class="string">'running_mean'</span>] = running_mean</span><br><span class="line">    bn_param[<span class="string">'running_var'</span>] = running_var</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> out, cache</span><br></pre></td></tr></table></figure><h3 id="反向传播的实现"><a href="#反向传播的实现" class="headerlink" title="反向传播的实现"></a>反向传播的实现</h3><p><img src="/2019/01/12/Batch-Normalization-批量归一化/BN_Backward.PNG" alt="BN_Backward"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batchnorm_backward_alt</span><span class="params">(dout, cache)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Alternative backward pass for batch normalization.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    For this implementation you should work out the derivatives for the batch</span></span><br><span class="line"><span class="string">    normalizaton backward pass on paper and simplify as much as possible. You</span></span><br><span class="line"><span class="string">    should be able to derive a simple expression for the backward pass. </span></span><br><span class="line"><span class="string">    See the jupyter notebook for more hints.</span></span><br><span class="line"><span class="string">     </span></span><br><span class="line"><span class="string">    Note: This implementation should expect to receive the same cache variable</span></span><br><span class="line"><span class="string">    as batchnorm_backward, but might not use all of the values in the cache.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs / outputs: Same as batchnorm_backward</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    dx, dgamma, dbeta = <span class="keyword">None</span>, <span class="keyword">None</span>, <span class="keyword">None</span></span><br><span class="line">    <span class="comment">###########################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> Implement the backward pass for batch normalization. Store the    #</span></span><br><span class="line">    <span class="comment"># results in the dx, dgamma, and dbeta variables.                         #</span></span><br><span class="line">    <span class="comment">#                                                                         #</span></span><br><span class="line">    <span class="comment"># After computing the gradient with respect to the centered inputs, you   #</span></span><br><span class="line">    <span class="comment"># should be able to compute gradients with respect to the inputs in a     #</span></span><br><span class="line">    <span class="comment"># single statement; our implementation fits on a single 80-character line.#</span></span><br><span class="line">    <span class="comment">###########################################################################    </span></span><br><span class="line">    x, x_hat, gamma, beta, eps, mean, var = cache</span><br><span class="line"></span><br><span class="line">    dgamma = np.sum(dout*x_hat,axis=<span class="number">0</span>)</span><br><span class="line">    dbeta = np.sum(dout, axis=<span class="number">0</span>)</span><br><span class="line">    dx_hat = dout * gamma</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># temp vars</span></span><br><span class="line">    xmu = x - mean</span><br><span class="line">    istd = <span class="number">1</span>/np.sqrt(var + eps)</span><br><span class="line">    m = x.shape[<span class="number">0</span>]   </span><br><span class="line">    </span><br><span class="line">    dvar = np.sum(dx_hat*xmu*(<span class="number">-0.5</span>)*np.power((var+eps),<span class="number">-1.5</span>),axis=<span class="number">0</span>)</span><br><span class="line">    dmean = np.sum(dx_hat*(<span class="number">-1</span>)*istd,axis=<span class="number">0</span>) + np.sum(<span class="number">-2</span>*xmu*dvar,axis=<span class="number">0</span>)/m</span><br><span class="line">    dx = dx_hat*istd + dvar*<span class="number">2</span>*xmu/m + dmean/m    </span><br><span class="line"></span><br><span class="line">    <span class="comment">###########################################################################</span></span><br><span class="line">    <span class="comment">#                             END OF YOUR CODE                            #</span></span><br><span class="line">    <span class="comment">###########################################################################</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dx, dgamma, dbeta</span><br></pre></td></tr></table></figure><h3 id="BN层参数的学习过程中"><a href="#BN层参数的学习过程中" class="headerlink" title="BN层参数的学习过程中"></a>BN层参数的学习过程中</h3><p>在每个BN层，除了w和b之外，还需要学习<code>gamma</code>和<code>beta</code>两个额外的参数。</p><h2 id="Batch-Normalization带来的好处"><a href="#Batch-Normalization带来的好处" class="headerlink" title="Batch Normalization带来的好处"></a>Batch Normalization带来的好处</h2><ol><li>不仅极大的提升了训练速度，收敛过程也大大的加快了；</li><li>增强分类效果，一种解释是这是类似于Dropout的一种防止过拟合的正则化表达方式，所以不用Dropout也能达到相当的效果；</li><li>使用了BN层之后，进一步减少了在处理过拟合过程中对Dropout的依赖；</li><li>对于网络的参数初始化要求降低，不再担心网络初始化没控制好导致网络难以训练的问题（尤其是深层次网络）</li></ol><h2 id="其它的归一化方法"><a href="#其它的归一化方法" class="headerlink" title="其它的归一化方法"></a>其它的归一化方法</h2><p>由于BN会受到batch size大小的影响，如果batch size太小，算出的均值和方差就会不准确，太大存储可能不够用。所以衍生出了几种优化表达。</p><p><img src="/2019/01/12/Batch-Normalization-批量归一化/BN_error_with_small_batch_size.png" alt="BN_error_with_small_batch_size"></p><p><img src="/qnsource/images/2018-04-28-cs231n-notes/normalization_methods.png" alt="normalization_methods"></p><ul><li>BatchNorm： batch方向做归一化，计算 <code>H*W*C</code> 的均值；</li><li>LayerNorm： channel方向做归一化，计算<code>N*H*W</code> 的均值；</li><li>InstanceNorm： 一个channel内做归一化，计算<code>H*W</code>的均值；</li><li>GroupNorm： 将Channel方向分为Group，然后每个Group内做归一化，计算<code>(C//G)*H*W</code>的均值</li></ul><blockquote><p>当G=C时，GroupNorm为LayerNorm，当G=1时，GroupNorm为InstanceNorm</p></blockquote><p>其中，GourpNorm的启发来源于图像的手工特征提取器（比如HOG，SIFT）发现很多不同类型的特征都是成组出现的，利用成组封装的方式进行特征均值、方差提取可能更能反映特征的真实情况，尤其在小批量BN效果下降的情况下作为BN的一个替代品。</p><p>但实际上，在使用过程中还是优先选用BN，只有在批量实在很小，如视频分析、图像分割等场景，每个批次只有一两张图像的情况下，选用GroupNorm作为替代。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://arxiv.org/abs/1502.03167">Sergey Ioffe and Christian Szegedy, “Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift”, ICML 2015.</a></li><li><a href="https://arxiv.org/abs/1803.08494">Wu, Yuxin, and Kaiming He. “Group Normalization.” arXiv preprint arXiv:1803.08494 (2018).</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/qnsource/banner/07.jpg&quot; alt=&quot;BN不得不了解的深度学习技术~&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 借重读论文的机会，重新整理一下Batch Normalization的关键技术。&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://blog.a-stack.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
  </entry>
  
  <entry>
    <title>数据科学工具——Pandas</title>
    <link href="http://blog.a-stack.com/2019/01/02/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%B7%A5%E5%85%B7%E2%80%94%E2%80%94Pandas/"/>
    <id>http://blog.a-stack.com/2019/01/02/数据科学工具——Pandas/</id>
    <published>2019-01-02T08:54:58.000Z</published>
    <updated>2020-03-21T06:16:43.864Z</updated>
    
    <content type="html"><![CDATA[<p><strong>摘要：</strong>工欲善其事必先利其器，数据科学工具的整理是个循序渐进的过程，开个头立个Flag🏁，慢慢积累工具的使用方法，便于以后速查。主要涉及工具包括：Ipython，Numpy，Pandas，Scikit-Learn等。</p><a id="more"></a><h2 id="Series"><a href="#Series" class="headerlink" title="Series"></a>Series</h2><p><strong>Index + Values</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data = pd.Series([<span class="number">0.25</span>, <span class="number">0.5</span>, <span class="number">0.75</span>, <span class="number">1.0</span>], index=[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>])</span><br><span class="line"></span><br><span class="line">repeat_constent_value = pd.Series(<span class="number">5</span>, index=[<span class="number">100</span>,<span class="number">200</span>,<span class="number">300</span>])</span><br></pre></td></tr></table></figure><blockquote><p>Series是Python字典和Numpy的有机结合，集成了字典引用的便捷性，同时也实现了narray结构的灵活性。</p></blockquote><h2 id="DataFrame"><a href="#DataFrame" class="headerlink" title="DataFrame"></a>DataFrame</h2><ul><li><p>可以通过Series生成；</p></li><li><p>通过一组python字典变量生成；</p></li><li><p>通过二维的Numpy Array生成</p></li></ul><h2 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h2><ul><li><code>loc</code>: 实际的index值: <code>data.loc[data.density &gt; 100, [&#39;pop&#39;, &#39;density&#39;]]</code></li><li><code>iloc</code>: index的编号值： <code>data.iloc[:3, :2]</code></li><li><code>ix</code>: 以上两者的组合： `data.ix[:3, :’column2’]</li></ul><blockquote><ol><li>First, while indexing refers to columns, slicing refers to rows.</li><li>Similarly, direct masking operations are also interpreted row-wise rather than column-wise.</li></ol></blockquote><h2 id="数据操作"><a href="#数据操作" class="headerlink" title="数据操作"></a>数据操作</h2><p>`</p><h2 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h2><p><code>NaN</code>是浮点标记，可参与运算；结果都是<code>NaN</code></p><ul><li><p><code>isunll()</code>与<code>notnull</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[data.notnull()]</span><br></pre></td></tr></table></figure></li><li><p><code>dropna()</code></p><ul><li>将丢弃存在至少一个null数值的行；</li><li>也可以通过命令<code>dropna(axis=&#39;columns&#39;)</code>丢弃列;</li><li>也可以通过参数控制丢弃的门限(至少有几个非空元素)：<code>df.dropna(axis=&#39;rows&#39;, thresh=3)</code></li></ul></li><li><p><code>fillna()</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data.fillna(<span class="number">0</span>)</span><br><span class="line"><span class="comment"># forward-fill</span></span><br><span class="line">data.fillna(method=<span class="string">'ffill'</span>)</span><br><span class="line"><span class="comment"># back-fill </span></span><br><span class="line">data.fillna(method=<span class="string">'bfill'</span>)</span><br></pre></td></tr></table></figure></li></ul><h2 id="时序数据处理"><a href="#时序数据处理" class="headerlink" title="时序数据处理"></a>时序数据处理</h2><h3 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h3><ul><li>Time Stamps：Pandas中提供<code>Timestamp</code>类型</li><li>Time Intervals/Periods: Pandas中提供<code>Period</code>类型</li><li>Time delta/Durations: Pandas中提供<code>Timedelta</code>类型</li><li>python中处理时间的库有<code>datetime</code>和<code>dateutil</code></li><li>Numpy中处理时间数据的类型：<code>datetime64</code></li></ul><h3 id="Pandas中的主要相关函数"><a href="#Pandas中的主要相关函数" class="headerlink" title="Pandas中的主要相关函数"></a>Pandas中的主要相关函数</h3><p><code>pd.to_datetime()</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">date = pd.to_datetime(<span class="string">"4th of July, 2015"</span>)</span><br><span class="line"></span><br><span class="line">date + pd.to_timedelta(np.arange(<span class="number">12</span>), <span class="string">'D'</span>)</span><br><span class="line">date2 = pd.to_datetime([datetime(<span class="number">2015</span>, <span class="number">7</span>, <span class="number">3</span>), <span class="string">'4th of July, 2015'</span>,</span><br><span class="line">                       <span class="string">'2015-Jul-6'</span>, <span class="string">'07-07-2015'</span>, <span class="string">'20150708'</span>])</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">DatetimeIndex([<span class="string">'2015-07-04'</span>, <span class="string">'2015-07-05'</span>, <span class="string">'2015-07-06'</span>, <span class="string">'2015-07-07'</span>,</span><br><span class="line">               <span class="string">'2015-07-08'</span>, <span class="string">'2015-07-09'</span>, <span class="string">'2015-07-10'</span>, <span class="string">'2015-07-11'</span>,</span><br><span class="line">               <span class="string">'2015-07-12'</span>, <span class="string">'2015-07-13'</span>, <span class="string">'2015-07-14'</span>, <span class="string">'2015-07-15'</span>],</span><br><span class="line">              dtype=<span class="string">'datetime64[ns]'</span>, freq=None)</span><br></pre></td></tr></table></figure><p>Pandas中时间序列分析的强大之处在于当时间变量作为Index时，通过对Index的操作来体现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">index = pd.DatetimeIndex([<span class="string">'2014-07-04'</span>, <span class="string">'2014-08-04'</span>,</span><br><span class="line">                          <span class="string">'2015-07-04'</span>, <span class="string">'2015-08-04'</span>])</span><br><span class="line">data = pd.Series([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], index=index)</span><br><span class="line">data[<span class="string">'2015'</span>]</span><br><span class="line">data[<span class="string">'2014'</span>:<span class="string">'2015'</span>]</span><br></pre></td></tr></table></figure><p><code>pd.date_range</code>,产生从起始时间开始的一段时间信息</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pd.date_range(<span class="string">'2015-07-03'</span>, <span class="string">'2015-07-10'</span>)</span><br><span class="line">pd.date_range(<span class="string">'2015-07-03'</span>, periods=<span class="number">8</span>)</span><br><span class="line">pd.date_range(<span class="string">'2015-07-03'</span>, periods=<span class="number">8</span>, freq=<span class="string">'H'</span>)</span><br></pre></td></tr></table></figure><h3 id="重采样"><a href="#重采样" class="headerlink" title="重采样"></a>重采样</h3><ul><li><code>resample()</code>: 聚合采样；</li><li><code>asfreq()</code>: 选择抽样；</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#降采样</span></span><br><span class="line">data.resample(<span class="string">'BA'</span>).mean()</span><br><span class="line">data.asfreq(<span class="string">'BA'</span>)</span><br><span class="line"><span class="comment">#升采样</span></span><br><span class="line">data.asfreq(<span class="string">'D'</span>, method=<span class="string">'bfill'</span>)</span><br><span class="line">data.asfreq(<span class="string">'D'</span>, method=<span class="string">'ffill'</span>)</span><br></pre></td></tr></table></figure><h3 id="数据偏移"><a href="#数据偏移" class="headerlink" title="数据偏移"></a>数据偏移</h3><blockquote><p>用于比较不同时间数据差异</p></blockquote><ul><li><code>tshift()</code></li><li><code>shift()</code></li></ul><h3 id="滑动平均：Rolling"><a href="#滑动平均：Rolling" class="headerlink" title="滑动平均：Rolling"></a>滑动平均：<code>Rolling</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data = data.rolling(<span class="number">365</span>, center=<span class="keyword">True</span>)</span><br><span class="line">data.rolling.mean()</span><br><span class="line">data.rolling.std()</span><br></pre></td></tr></table></figure><h3 id="※时序数据分析举例"><a href="#※时序数据分析举例" class="headerlink" title="※时序数据分析举例"></a>※时序数据分析举例</h3><blockquote><p>数据：西雅图自行车计数，<a href="https://data.seattle.gov/Transportation/Fremont-Bridge-Hourly-Bicycle-Counts-by-Month-Octo/65db-xm6k">Link</a></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">'FremontBridge.csv'</span>, index_col=<span class="string">'Date'</span>, parse_dates=<span class="keyword">True</span>)</span><br><span class="line">data.columns = [<span class="string">'West'</span>, <span class="string">'East'</span>]</span><br><span class="line">data[<span class="string">'Total'</span>] = data.eval(<span class="string">'West + East'</span>)</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure><div class="table-container"><table><thead><tr><th></th><th>West</th><th>East</th><th>Total</th></tr></thead><tbody><tr><td>Date</td><td></td><td></td><td></td></tr><tr><td>2012-10-03 00:00:00</td><td>9.0</td><td>4.0</td><td>13.0</td></tr><tr><td>2012-10-03 01:00:00</td><td>6.0</td><td>4.0</td><td>10.0</td></tr><tr><td>2012-10-03 02:00:00</td><td>1.0</td><td>1.0</td><td>2.0</td></tr><tr><td>2012-10-03 03:00:00</td><td>3.0</td><td>2.0</td><td>5.0</td></tr><tr><td>2012-10-03 04:00:00</td><td>1.0</td><td>6.0</td><td>7.0</td></tr></tbody></table></div><p>由于数据每小时记录一个数值，直接画图，数据点过密：</p><p><img src="/2019/01/02/数据科学工具——Pandas/timeseries_1.png" alt="timeseries_1"></p><ol><li><p>通过降采样，方便显示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">weekly = data.resample(<span class="string">'W'</span>).sum()</span><br><span class="line">weekly.plot(style=[<span class="string">':'</span>, <span class="string">'--'</span>, <span class="string">'-'</span>])</span><br><span class="line">plt.ylabel(<span class="string">'Weekly bicycle count'</span>);</span><br></pre></td></tr></table></figure><p><img src="/2019/01/02/数据科学工具——Pandas/timeseries_weekly.png" alt="timeseries_weekly"></p></li><li><p>通过滑动平均处理每天为单位的数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">daily = data.resample(<span class="string">'D'</span>).sum()</span><br><span class="line">daily.rolling(<span class="number">30</span>, center=<span class="keyword">True</span>).sum().plot(style=[<span class="string">':'</span>, <span class="string">'--'</span>, <span class="string">'-'</span>])</span><br><span class="line">plt.ylabel(<span class="string">'mean hourly count'</span>);</span><br></pre></td></tr></table></figure><p><img src="/2019/01/02/数据科学工具——Pandas/timeseries_daily.png" alt="timeseries_daily"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">daily.rolling(<span class="number">50</span>, center=<span class="keyword">True</span>,</span><br><span class="line">              win_type=<span class="string">'gaussian'</span>).sum(std=<span class="number">10</span>).plot(style=[<span class="string">':'</span>, <span class="string">'--'</span>, <span class="string">'-'</span>]);</span><br></pre></td></tr></table></figure><p><img src="/2019/01/02/数据科学工具——Pandas/timeseries_daily2.png" alt="timeseries_daily2"></p></li><li><p>通过数据分组查看每年、每周或每天的数据规律</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">by_time = data.groupby(data.index.time).mean()</span><br><span class="line">hourly_ticks = <span class="number">4</span> * <span class="number">60</span> * <span class="number">60</span> * np.arange(<span class="number">6</span>)</span><br><span class="line">by_time.plot(xticks=hourly_ticks, style=[<span class="string">':'</span>, <span class="string">'--'</span>, <span class="string">'-'</span>]);</span><br></pre></td></tr></table></figure><p><img src="/2019/01/02/数据科学工具——Pandas/data_in_one_day.png" alt="data_in_one_day"></p></li><li><p>进一步查看周末与周中数据区别</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">by_weekday = data.groupby(data.index.dayofweek).mean()</span><br><span class="line">by_weekday.index = [<span class="string">'Mon'</span>, <span class="string">'Tues'</span>, <span class="string">'Wed'</span>, <span class="string">'Thurs'</span>, <span class="string">'Fri'</span>, <span class="string">'Sat'</span>, <span class="string">'Sun'</span>]</span><br><span class="line">by_weekday.plot(style=[<span class="string">':'</span>, <span class="string">'--'</span>, <span class="string">'-'</span>]);</span><br></pre></td></tr></table></figure><p><img src="/2019/01/02/数据科学工具——Pandas/data_in_one_week.png" alt="data_in_one_week"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">weekend = np.where(data.index.weekday &lt; <span class="number">5</span>, <span class="string">'Weekday'</span>, <span class="string">'Weekend'</span>)</span><br><span class="line">by_time = data.groupby([weekend, data.index.time]).mean()</span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">14</span>, <span class="number">5</span>))</span><br><span class="line">by_time.ix[<span class="string">'Weekday'</span>].plot(ax=ax[<span class="number">0</span>], title=<span class="string">'Weekdays'</span>,</span><br><span class="line">                           xticks=hourly_ticks, style=[<span class="string">':'</span>, <span class="string">'--'</span>, <span class="string">'-'</span>])</span><br><span class="line">by_time.ix[<span class="string">'Weekend'</span>].plot(ax=ax[<span class="number">1</span>], title=<span class="string">'Weekends'</span>,</span><br><span class="line">                           xticks=hourly_ticks, style=[<span class="string">':'</span>, <span class="string">'--'</span>, <span class="string">'-'</span>]);</span><br></pre></td></tr></table></figure><p><img src="/2019/01/02/数据科学工具——Pandas/week+OneDay.png" alt="week+OneDay"></p></li></ol><h3 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h3><div class="table-container"><table><thead><tr><th>Code</th><th>Description</th><th>Code</th><th>Description</th></tr></thead><tbody><tr><td><code>D</code></td><td>Calendar day</td><td><code>B</code></td><td>Business day</td></tr><tr><td><code>W</code></td><td>Weekly</td><td>\</td><td></td><td></td></tr><tr><td><code>M</code></td><td>Month end</td><td><code>BM</code></td><td>Business month end</td></tr><tr><td><code>Q</code></td><td>Quarter end</td><td><code>BQ</code></td><td>Business quarter end</td></tr><tr><td><code>A</code></td><td>Year end</td><td><code>BA</code></td><td>Business year end</td></tr><tr><td><code>H</code></td><td>Hours</td><td><code>BH</code></td><td>Business hours</td></tr><tr><td><code>T</code></td><td>Minutes</td><td>\</td><td></td><td></td></tr><tr><td><code>S</code></td><td>Seconds</td><td>\</td><td></td><td></td></tr><tr><td><code>L</code></td><td>Milliseonds</td><td>\</td><td></td><td></td></tr><tr><td><code>U</code></td><td>Microseconds</td><td>\</td><td></td><td></td></tr><tr><td><code>N</code></td><td>nanoseconds</td><td>\</td><td></td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>Directive</th><th>Meaning</th><th>Example</th><th>Notes</th></tr></thead><tbody><tr><td><code>%a</code></td><td>Weekday as locale’s abbreviated name.</td><td>Sun, Mon, …, Sat (en_US);So, Mo, …, Sa (de_DE)</td><td>(1)</td></tr><tr><td><code>%A</code></td><td>Weekday as locale’s full name.</td><td>Sunday, Monday, …, Saturday (en_US);Sonntag, Montag, …, Samstag (de_DE)</td><td>(1)</td></tr><tr><td><code>%w</code></td><td>Weekday as a decimal number, where 0 is Sunday and 6 is Saturday.</td><td>0, 1, …, 6</td><td></td></tr><tr><td><code>%d</code></td><td>Day of the month as a zero-padded decimal number.</td><td>01, 02, …, 31</td><td></td></tr><tr><td><code>%b</code></td><td>Month as locale’s abbreviated name.</td><td>Jan, Feb, …, Dec (en_US);Jan, Feb, …, Dez (de_DE)</td><td>(1)</td></tr><tr><td><code>%B</code></td><td>Month as locale’s full name.</td><td>January, February, …, December (en_US);Januar, Februar, …, Dezember (de_DE)</td><td>(1)</td></tr><tr><td><code>%m</code></td><td>Month as a zero-padded decimal number.</td><td>01, 02, …, 12</td><td></td></tr><tr><td><code>%y</code></td><td>Year without century as a zero-padded decimal number.</td><td>00, 01, …, 99</td><td></td></tr><tr><td><code>%Y</code></td><td>Year with century as a decimal number.</td><td>0001, 0002, …, 2013, 2014, …, 9998, 9999</td><td>(2)</td></tr><tr><td><code>%H</code></td><td>Hour (24-hour clock) as a zero-padded decimal number.</td><td>00, 01, …, 23</td><td></td></tr><tr><td><code>%I</code></td><td>Hour (12-hour clock) as a zero-padded decimal number.</td><td>01, 02, …, 12</td><td></td></tr><tr><td><code>%p</code></td><td>Locale’s equivalent of either AM or PM.</td><td>AM, PM (en_US);am, pm (de_DE)</td><td>(1), (3)</td></tr><tr><td><code>%M</code></td><td>Minute as a zero-padded decimal number.</td><td>00, 01, …, 59</td><td></td></tr><tr><td><code>%S</code></td><td>Second as a zero-padded decimal number.</td><td>00, 01, …, 59</td><td>(4)</td></tr><tr><td><code>%f</code></td><td>Microsecond as a decimal number, zero-padded on the left.</td><td>000000, 000001, …, 999999</td><td>(5)</td></tr><tr><td><code>%z</code></td><td>UTC offset in the form ±HHMM[SS[.ffffff]] (empty string if the object is naive).</td><td>(empty), +0000, -0400, +1030, +063415, -030712.345216</td><td>(6)</td></tr><tr><td><code>%Z</code></td><td>Time zone name (empty string if the object is naive).</td><td>(empty), UTC, EST, CST</td><td></td></tr><tr><td><code>%j</code></td><td>Day of the year as a zero-padded decimal number.</td><td>001, 002, …, 366</td><td></td></tr><tr><td><code>%U</code></td><td>Week number of the year (Sunday as the first day of the week) as a zero padded decimal number. All days in a new year preceding the first Sunday are considered to be in week 0.</td><td>00, 01, …, 53</td><td>(7)</td></tr><tr><td><code>%W</code></td><td>Week number of the year (Monday as the first day of the week) as a decimal number. All days in a new year preceding the first Monday are considered to be in week 0.</td><td>00, 01, …, 53</td><td>(7)</td></tr><tr><td><code>%c</code></td><td>Locale’s appropriate date and time representation.</td><td>Tue Aug 16 21:30:00 1988 (en_US);Di 16 Aug 21:30:00 1988 (de_DE)</td><td>(1)</td></tr><tr><td><code>%x</code></td><td>Locale’s appropriate date representation.</td><td>08/16/88 (None);08/16/1988 (en_US);16.08.1988 (de_DE)</td><td>(1)</td></tr><tr><td><code>%X</code></td><td>Locale’s appropriate time representation.</td><td>21:30:00 (en_US);21:30:00 (de_DE)</td><td>(1)</td></tr><tr><td><code>%%</code></td><td>A literal <code>&#39;%&#39;</code> character.</td><td>%</td></tr></tbody></table></div><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li>Book《Python Data Science Handbook》](<a href="https://jakevdp.github.io/PythonDataScienceHandbook/">https://jakevdp.github.io/PythonDataScienceHandbook/</a>)</li><li><a href="https://github.com/jakevdp/PythonDataScienceHandbook">https://github.com/jakevdp/PythonDataScienceHandbook</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt;工欲善其事必先利其器，数据科学工具的整理是个循序渐进的过程，开个头立个Flag🏁，慢慢积累工具的使用方法，便于以后速查。主要涉及工具包括：Ipython，Numpy，Pandas，Scikit-Learn等。&lt;/p&gt;
    
    </summary>
    
      <category term="工具" scheme="http://blog.a-stack.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="时序数据" scheme="http://blog.a-stack.com/tags/%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Pandas" scheme="http://blog.a-stack.com/tags/Pandas/"/>
    
      <category term="工具使用" scheme="http://blog.a-stack.com/tags/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/"/>
    
  </entry>
  
  <entry>
    <title>数据科学工具——Numpy</title>
    <link href="http://blog.a-stack.com/2018/12/30/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%B7%A5%E5%85%B7%E2%80%94%E2%80%94Numpy/"/>
    <id>http://blog.a-stack.com/2018/12/30/数据科学工具——Numpy/</id>
    <published>2018-12-30T08:54:48.000Z</published>
    <updated>2018-12-30T14:11:41.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/2018/12/30/数据科学工具——Numpy/Numpy.png" alt="Numpy"></p><p><strong>摘要：</strong>工欲善其事必先利其器，数据科学工具的整理是个循序渐进的过程，开个头立个Flag🏁，慢慢积累工具的使用方法，便于以后速查。主要涉及工具包括：Ipython，Numpy，Pandas，Scikit-Learn等。</p><a id="more"></a><h2 id="Numpy"><a href="#Numpy" class="headerlink" title="Numpy"></a>Numpy</h2><ul><li>Python List and Numpy</li><li>一个Numpy矩阵中的所有元素类型必须相同；</li><li>矩阵slicing操作，返回的是对原矩阵的引用而非复制，所以对其操作将影响原矩阵；</li></ul><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a 3x5 array filled with 3.14 </span></span><br><span class="line">np.full((<span class="number">3</span>, <span class="number">5</span>), <span class="number">3.14</span>)</span><br><span class="line"><span class="comment"># Create an array filled with a linear sequence # Starting at 0, ending at 20, stepping by 2 # (this is similar to the built-in range() function) </span></span><br><span class="line">np.arange(<span class="number">0</span>, <span class="number">20</span>, <span class="number">2</span>)</span><br><span class="line"><span class="comment">#&gt;&gt; array([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18])</span></span><br><span class="line"><span class="comment"># Create an array of five values evenly spaced between 0 and 1 </span></span><br><span class="line">np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>)</span><br><span class="line"><span class="comment">#&gt;&gt; array([0.  , 0.25, 0.5 , 0.75, 1.  ])</span></span><br></pre></td></tr></table></figure><h2 id="矩阵组合：-np-concatenate-np-vstack-np-hstack"><a href="#矩阵组合：-np-concatenate-np-vstack-np-hstack" class="headerlink" title="矩阵组合： np.concatenate,np.vstack,np.hstack"></a>矩阵组合： <code>np.concatenate</code>,<code>np.vstack</code>,<code>np.hstack</code></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># concatenate along the second axis (zero-indexed) </span></span><br><span class="line">np.concatenate([grid, grid], axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h2 id="np-random"><a href="#np-random" class="headerlink" title="np.random"></a><code>np.random</code></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a 3x3 array of uniformly distributed # random values between 0 and 1  </span></span><br><span class="line">  np.random.random((<span class="number">3</span>, <span class="number">3</span>)) </span><br><span class="line">Out[<span class="number">17</span>]: array([[ <span class="number">0.99844933</span>, <span class="number">0.52183819</span>, <span class="number">0.22421193</span>], [ <span class="number">0.08007488</span>, <span class="number">0.45429293</span>, <span class="number">0.20941444</span>], [ <span class="number">0.14360941</span>, <span class="number">0.96910973</span>, <span class="number">0.946117</span> ]])</span><br><span class="line">In[<span class="number">18</span>]: <span class="comment"># Create a 3x3 array of normally distributed random values # with mean 0 and standard deviation 1 </span></span><br><span class="line">  np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">Out[<span class="number">18</span>]: array([[ <span class="number">1.51772646</span>, <span class="number">0.39614948</span>, <span class="number">-0.10634696</span>], [ <span class="number">0.25671348</span>, <span class="number">0.00732722</span>, <span class="number">0.37783601</span>], [ <span class="number">0.68446945</span>, <span class="number">0.15926039</span>, <span class="number">-0.70744073</span>]])</span><br><span class="line">In[<span class="number">19</span>]: <span class="comment"># Create a 3x3 array of random integers in the interval [0, 10) </span></span><br><span class="line">  np.random.randint(<span class="number">0</span>, <span class="number">10</span>, (<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">Out[<span class="number">19</span>]: array([[<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">7</span>, <span class="number">8</span>], [<span class="number">0</span>, <span class="number">5</span>, <span class="number">0</span>]])</span><br></pre></td></tr></table></figure><h2 id="技巧"><a href="#技巧" class="headerlink" title="技巧"></a>技巧</h2><ol><li><p>矩阵元素反置</p><p>x是一维矩阵</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x[::<span class="number">-1</span>]</span><br></pre></td></tr></table></figure></li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li>Book《Python Data Science Handbook》](<a href="https://jakevdp.github.io/PythonDataScienceHandbook/">https://jakevdp.github.io/PythonDataScienceHandbook/</a>)</li><li><a href="https://github.com/jakevdp/PythonDataScienceHandbook">https://github.com/jakevdp/PythonDataScienceHandbook</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/2018/12/30/数据科学工具——Numpy/Numpy.png&quot; alt=&quot;Numpy&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt;工欲善其事必先利其器，数据科学工具的整理是个循序渐进的过程，开个头立个Flag🏁，慢慢积累工具的使用方法，便于以后速查。主要涉及工具包括：Ipython，Numpy，Pandas，Scikit-Learn等。&lt;/p&gt;
    
    </summary>
    
      <category term="工具" scheme="http://blog.a-stack.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="教学" scheme="http://blog.a-stack.com/tags/%E6%95%99%E5%AD%A6/"/>
    
      <category term="工具使用" scheme="http://blog.a-stack.com/tags/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/"/>
    
      <category term="Numpy" scheme="http://blog.a-stack.com/tags/Numpy/"/>
    
  </entry>
  
  <entry>
    <title>数据科学工具——Ipython</title>
    <link href="http://blog.a-stack.com/2018/12/29/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%B7%A5%E5%85%B7%E2%80%94%E2%80%94Ipython/"/>
    <id>http://blog.a-stack.com/2018/12/29/数据科学工具——Ipython/</id>
    <published>2018-12-29T08:13:36.000Z</published>
    <updated>2018-12-30T08:54:09.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/2018/12/29/数据科学工具——Ipython/Jupyter Notebook.png" alt="Jupyter Notebook"></p><p><strong>摘要：</strong> 工欲善其事必先利其器，数据科学工具的整理是个循序渐进的过程，开个头立个Flag🏁，慢慢积累工具的使用方法，便于以后速查。主要涉及工具包括：Ipython，Numpy，Pandas，Scikit-Learn等。</p><a id="more"></a><h2 id="数据科学的定义"><a href="#数据科学的定义" class="headerlink" title="数据科学的定义"></a>数据科学的定义</h2><blockquote><p>Data science comprises three distinct and overlapping areas: the skills of a <em>statistician</em> who knows how to model and summarize datasets (which are growing ever larger); the skills of a <em>computer scientist</em> who can design and use algorithms to efficiently store, process, and visualize this data; and the <em>domain expertise</em>—what we might think of as “classical” training in a subject—necessary both to formulate the right questions and to put their answers in context.</p></blockquote><h2 id="技巧"><a href="#技巧" class="headerlink" title="技巧"></a>技巧</h2><ol><li><p>Accessing Documentation with <code>?</code> | Accessing Source Code with <code>??</code></p></li><li><p><code>+ &lt;TAB&gt;</code> 的使用</p></li><li><p>查找命令的通配符匹配策略： <code>*</code> + <code>?</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">*Warning?</span><br><span class="line"></span><br><span class="line">str.*find*?</span><br><span class="line">  str.find</span><br><span class="line">  str.rfind</span><br></pre></td></tr></table></figure></li><li><p>在Notebook中可以使用<code>automagic</code>,直接通过<code>cd</code>命令切换目录；</p><ol><li>其它还有<code>%cat,%cp,%env,%ls,%man,%mkdir,%more,%mv, %pwd, %rm, and %rmdir</code></li></ol></li><li></li></ol><h2 id="魔法字符"><a href="#魔法字符" class="headerlink" title="魔法字符%"></a>魔法字符<code>%</code></h2><ol><li><p><code>%run</code></p><p>运行<code>.py</code>文件,同时把文件中的上下文环境加载到当前环境中</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%run xxx.py</span><br></pre></td></tr></table></figure></li><li><p><code>%timeit</code>，<code>%time</code>,<code>%%time</code></p></li><li><p><code>%history -n 1-4</code></p></li></ol><h2 id="Debug"><a href="#Debug" class="headerlink" title="Debug"></a>Debug</h2><p><code>ipdb</code>:Ipython Debugger</p><p><code>%debug</code> 进入调试模式，<code>quit</code>命令退出；</p><ul><li><code>up</code>和<code>down</code>可以控制代码执行位置；</li></ul><p>命令<code>%pdb on</code>可以开启自动调试模式，每次出异常自动触发调试；</p><p>其它相关调试命令见下表：</p><div class="table-container"><table><thead><tr><th>命令</th><th>描述</th></tr></thead><tbody><tr><td><code>list</code></td><td>显示当前异常在文件中的位置</td></tr><tr><td><code>h(elp)</code></td><td>查看帮助文件</td></tr><tr><td><code>q(uit)</code></td><td>退出调试模式</td></tr><tr><td><code>c(ontinue)</code></td><td>中断调试，继续执行程序</td></tr><tr><td><code>n(ext)</code></td><td>继续程序下一步</td></tr><tr><td><code>&lt;enter&gt;</code></td><td>重复上一个命令</td></tr><tr><td><code>p(rint)</code></td><td>打印变量</td></tr><tr><td><code>s(tep)</code></td><td>进入子程序</td></tr><tr><td><code>r(etrun)</code></td><td>返回子程序</td></tr></tbody></table></div><h2 id="快捷键"><a href="#快捷键" class="headerlink" title="快捷键"></a>快捷键</h2><h4 id="命令行模式-按-Esc-生效-编辑快捷键"><a href="#命令行模式-按-Esc-生效-编辑快捷键" class="headerlink" title="命令行模式(按 Esc 生效)编辑快捷键"></a>命令行模式(按 Esc 生效)编辑快捷键</h4><p>F: 查找并且替换</p><p>Enter: 进入编辑模式</p><p>P: 打开命令配置</p><p>Shift-Enter: 运行代码块, 选择下面的代码块</p><p>Ctrl-Enter: 运行选中的代码块</p><p>Alt-Enter: 运行代码块并且插入下面</p><p><strong>Y: 把代码块变成代码</strong></p><p><strong>M: 把代码块变成标签</strong></p><p><strong>R: 清除代码块格式</strong></p><p>1: 把代码块变成heading 1</p><p>2: 把代码块变成heading 2</p><p>3: 把代码块变成heading 3</p><p>4: 把代码块变成heading 4</p><p>5: 把代码块变成heading 5</p><p>6: 把代码块变成heading 6</p><p>K: 选择上面的代码块</p><p>J: 选择下面的代码块</p><p>Shift-K: 扩展上面选择的代码块</p><p>Shift-上: 扩展上面选择的代码块</p><p>Shift-下: 扩展下面选择的代码块</p><p>Shift-J: 扩展下面选择的代码块</p><p><strong>A: 在上面插入代码块</strong></p><p><strong>B: 在下面插入代码块</strong></p><p>X: 剪切选择的代码块</p><p>C: 复制选择的代码块</p><p>Shift-V: 粘贴到上面</p><p>V: 粘贴到下面</p><p>Z: 撤销删除</p><p>D,D: 删除选中单元格</p><p><strong>Shift-M: 合并选中单元格, 如果只有一个单元格被选中</strong></p><p>Ctrl-S: 保存并检查</p><p>L: 切换行号</p><p>O: 选择单元格的输出</p><p>Shift-O: 切换选定单元的输出滚动</p><p>H: 显示快捷键</p><p>I,I: 中断服务</p><p>0,0: 重启服务(带窗口)</p><p>Esc: 关闭页面</p><p>Q: 关闭页面</p><p>Shift-L: 在所有单元格中切换行号，并保持设置</p><p>Shift-空格: 向上滚动</p><p>空格: 向下滚动</p><h4 id="编辑模式-按-Enter-生效"><a href="#编辑模式-按-Enter-生效" class="headerlink" title="编辑模式(按 Enter 生效)"></a>编辑模式(按 Enter 生效)</h4><p>Tab: 代码完成或缩进</p><p><strong>Shift-Tab: 工具提示</strong></p><p>Ctrl-]: 缩进</p><p>Ctrl-[: 取消缩进</p><p>Ctrl-A: 全选</p><p>Ctrl-Z: 撤销</p><p><strong>Ctrl-/: 注释代码</strong></p><p>Ctrl-D: 删除整行</p><p>Ctrl-U: 撤销选择</p><p>Insert: 切换 重写标志</p><p>Ctrl-Home: 跳到单元格起始处</p><p>Ctrl-上: 跳到单元格起始处</p><p>Ctrl-End: 跳到单元格最后</p><p>Ctrl-下: 跳到单元格最后</p><p>Ctrl-左: 跳到单词左边</p><p>Ctrl-右: 跳到单词右边</p><p>Ctrl-删除: 删除前面的单词</p><p>Ctrl-Delete: 删除后面的单词</p><p>Ctrl-Y: 重做</p><p>Alt-U: 重新选择</p><p>Ctrl-M: 进入命令行模式</p><p>Ctrl-Shift-F: 打开命令配置</p><p>Ctrl-Shift-P: 打开命令配置</p><p>Esc: 进入命令行模式</p><p>Shift-Enter: 运行代码块, 选择下面的代码块</p><p>Ctrl-Enter: 运行选中的代码块</p><p>Alt-Enter: 运行代码块并且插入下面</p><p>Ctrl-Shift-Minus: 在鼠标出分割代码块</p><p>Ctrl-S: 保存并检查</p><p>下: 光标下移</p><p>上: 光标上移</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://jakevdp.github.io/PythonDataScienceHandbook/">Book《Python Data Science Handbook》</a></li><li><a href="https://github.com/jakevdp/PythonDataScienceHandbook">https://github.com/jakevdp/PythonDataScienceHandbook</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/2018/12/29/数据科学工具——Ipython/Jupyter Notebook.png&quot; alt=&quot;Jupyter Notebook&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 工欲善其事必先利其器，数据科学工具的整理是个循序渐进的过程，开个头立个Flag🏁，慢慢积累工具的使用方法，便于以后速查。主要涉及工具包括：Ipython，Numpy，Pandas，Scikit-Learn等。&lt;/p&gt;
    
    </summary>
    
      <category term="工具" scheme="http://blog.a-stack.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="教学" scheme="http://blog.a-stack.com/tags/%E6%95%99%E5%AD%A6/"/>
    
      <category term="JupyterNotebook" scheme="http://blog.a-stack.com/tags/JupyterNotebook/"/>
    
      <category term="Ipython" scheme="http://blog.a-stack.com/tags/Ipython/"/>
    
  </entry>
  
  <entry>
    <title>深度学习资源调度平台OpenPAI部署</title>
    <link href="http://blog.a-stack.com/2018/12/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%BA%90%E8%B0%83%E5%BA%A6%E5%B9%B3%E5%8F%B0OpenPAI%E9%83%A8%E7%BD%B2/"/>
    <id>http://blog.a-stack.com/2018/12/26/深度学习资源调度平台OpenPAI部署/</id>
    <published>2018-12-26T10:42:53.000Z</published>
    <updated>2019-03-14T04:53:43.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/2018/12/26/深度学习资源调度平台OpenPAI部署/sysarch.png" alt="OpenPAI"></p><a id="more"></a><blockquote><p>date: 2018-12-26</p><p>Version: 0.8.3</p><p>操作系统：Ubuntu 16.04</p><p>GitHub: <a href="https://github.com/Microsoft/pai">https://github.com/Microsoft/pai</a></p><p>All-in-One部署</p></blockquote><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><h3 id="1-环境要求"><a href="#1-环境要求" class="headerlink" title="1. 环境要求"></a>1. 环境要求</h3><ul><li>一组集群主机，PC或服务器均可；</li><li>所有节点全新安装<strong>Ubuntu Server 16.04</strong>，不需安装GPU驱动及CUDA；</li><li>各节点具有统一的登录账户及密码，此账户不需要root账户角色，但<strong>必须具有sudo权限</strong>；</li><li>各节点具有静态IP地址；</li><li>各节点均可访问互联网；</li><li>各节点间可互访；</li><li>各节点时间一致，即<strong>ntp</strong>功能可用；</li></ul><h3 id="2-依赖包安装"><a href="#2-依赖包安装" class="headerlink" title="2. 依赖包安装"></a>2. 依赖包安装</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 0.1</span></span><br><span class="line">gaoc@openpaiTest03:~$ sudo apt-get -y update</span><br><span class="line"><span class="comment"># 0.2</span></span><br><span class="line">gaoc@openpaiTest03:~$ sudo apt-get -y install \</span><br><span class="line">      nano \</span><br><span class="line">      vim \</span><br><span class="line">      joe \</span><br><span class="line">      wget \</span><br><span class="line">      curl \</span><br><span class="line">      jq \</span><br><span class="line">      gawk \</span><br><span class="line">      psmisc \</span><br><span class="line">      python \</span><br><span class="line">      python-yaml \</span><br><span class="line">      python-jinja2 \</span><br><span class="line">      python-paramiko \</span><br><span class="line">      python-urllib3 \</span><br><span class="line">      python-tz \</span><br><span class="line">      python-nose \</span><br><span class="line">      python-prettytable \</span><br><span class="line">      python-netifaces \</span><br><span class="line">      python-dev \</span><br><span class="line">      python-pip \</span><br><span class="line">      python-mysqldb \</span><br><span class="line">      openjdk-8-jre \</span><br><span class="line">      openjdk-8-jdk \</span><br><span class="line">      openssh-server \</span><br><span class="line">      openssh-client \</span><br><span class="line">      git \</span><br><span class="line">      bash-completion \</span><br><span class="line">      inotify-tools \</span><br><span class="line">      rsync \</span><br><span class="line">      realpath \</span><br><span class="line">      net-tools</span><br><span class="line">      </span><br><span class="line"><span class="comment"># 0.3</span></span><br><span class="line">gaoc@openpaiTest03:~$ pip install python-etcd docker kubernetes GitPython</span><br><span class="line"></span><br><span class="line"><span class="comment"># 0.4 </span></span><br><span class="line">gaoc@openpaiTest03:~$ git <span class="built_in">clone</span> https://github.com/Microsoft/pai.git</span><br></pre></td></tr></table></figure><blockquote><ul><li><p>0.3 pip包安装失败报错如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;   ...</span><br><span class="line">&gt;     File <span class="string">"/usr/lib/python2.7/dist-packages/OpenSSL/SSL.py"</span>, line 118, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">&gt;       SSL_ST_INIT = _lib.SSL_ST_INIT</span><br><span class="line">&gt;   AttributeError: <span class="string">'module'</span> object has no attribute <span class="string">'SSL_ST_INIT'</span></span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></li></ul></blockquote><p>&gt;</p><blockquote><p>  修复如下：</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt;   <span class="comment">#1.1</span></span><br><span class="line">&gt;   sudo python -m easy_install --upgrade pyOpenSSL</span><br><span class="line">&gt;   <span class="comment">#1.2 更新pip版本</span></span><br><span class="line">&gt;   gaoc@openpaiTest03:~$ pip install --upgrade pip</span><br><span class="line">&gt;   <span class="comment">#1.3 修复pip新版本bug </span></span><br><span class="line">&gt;   sudo vim /usr/bin/pip</span><br><span class="line">&gt;   </span><br><span class="line">&gt;   from pip import __main__</span><br><span class="line">&gt;   <span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">&gt;       sys.exit(__main__._main())</span><br><span class="line">&gt;   <span class="comment">#1.4 重新安装包</span></span><br><span class="line">&gt;   gaoc@openpaiTest03:~$ pip install python-etcd docker kubernetes GitPython</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><h2 id="配置文件准备"><a href="#配置文件准备" class="headerlink" title="配置文件准备"></a>配置文件准备</h2><ol><li>使用快速部署文件<code>quick-start.yaml</code></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gaoc@openpaiTest03:~$ <span class="built_in">cd</span> pai/deployment/quick-start/</span><br><span class="line">gaoc@openpaiTest03:~/pai/deployment/quick-start$ mv quick-start-example.yaml quick-start.yaml</span><br></pre></td></tr></table></figure><ol><li><p>修改<code>quick-start.yaml</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1.</span></span><br><span class="line">machines:</span><br><span class="line">  - &lt;ip-of-master&gt;</span><br><span class="line">  - &lt;ip-of-worker1&gt;</span><br><span class="line">  - &lt;ip-of-worder2&gt;</span><br><span class="line"><span class="comment">#--------------------</span></span><br><span class="line"><span class="comment">#修改为本机内网IP地址，因为All-in-One,所以配置一个master IP即可：</span></span><br><span class="line">machines:</span><br><span class="line">  - 10.0.7.4</span><br><span class="line"><span class="comment">#2.</span></span><br><span class="line">ssh-username: &lt;username&gt;</span><br><span class="line">ssh-password: &lt;password&gt;</span><br><span class="line"><span class="comment">#--------------------</span></span><br><span class="line"><span class="comment">#修改为openPAI用户的用户名/密码</span></span><br></pre></td></tr></table></figure></li><li><p>生成配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /pai</span><br><span class="line"></span><br><span class="line"><span class="comment"># cmd should be executed under pai directory</span></span><br><span class="line"></span><br><span class="line">python paictl.py config generate -i ~/pai/deployment/quick-start/quick-start.yaml -o ~/pai-config -f</span><br></pre></td></tr></table></figure></li><li><p>修改生成的配置文件</p><blockquote><p>目录 <code>~/pai-config</code></p></blockquote><p><code>cluster-configuration.yaml  k8s-role-definition.yaml  kubernetes-configuration.yaml  services-configuration.yaml</code></p></li></ol><ul><li><p><code>`cluster-configuration.yaml</code></p><p>修改<code>machine-sku</code>,如果有需要进一步修改<code>machine-list</code></p><p>因此部署电脑没有GPU，将GPU的<code>count</code>调整为0，同时按照服务器内存和cpu虚拟核心数目调整参数</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">machine-sku:</span><br><span class="line">  GENERIC:</span><br><span class="line">    mem: 56</span><br><span class="line">    gpu:</span><br><span class="line">      <span class="built_in">type</span>: generic</span><br><span class="line">      count: 0</span><br><span class="line">    cpu:</span><br><span class="line">      vcore: 16</span><br><span class="line">    os: ubuntu16.04</span><br><span class="line"></span><br><span class="line">machine-list:</span><br><span class="line">  - hostname: openpaiTest03</span><br><span class="line">    hostip: 10.0.7.4</span><br><span class="line">    machine-type: GENERIC</span><br><span class="line">    k8s-role: master</span><br><span class="line">    etcdid: etcdid1</span><br><span class="line">    zkid: <span class="string">"1"</span></span><br><span class="line">    dashboard: <span class="string">"true"</span></span><br><span class="line">    pai-master: <span class="string">"true"</span></span><br><span class="line">    pai-worker: <span class="string">"true"</span></span><br><span class="line">    docker-data: /var/lib/docker</span><br></pre></td></tr></table></figure></li><li><p><code>kubernetes-configuration.yaml</code></p><p>修改docker registry为国内源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-registry: docker.io/openpai</span><br></pre></td></tr></table></figure></li><li><p><code>services-configuration.yaml</code></p><p>修改<code>docker-registry</code>的<code>tag</code>值为openPAI版本号</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tag: 0.8.3</span><br></pre></td></tr></table></figure></li></ul><p>更多配置修改详见： <a href="https://github.com/Microsoft/pai/blob/master/docs/pai-management/doc/how-to-generate-cluster-config.md">https://github.com/Microsoft/pai/blob/master/docs/pai-management/doc/how-to-generate-cluster-config.md</a></p><h2 id="部署Kubernetes-集群"><a href="#部署Kubernetes-集群" class="headerlink" title="部署Kubernetes 集群"></a>部署Kubernetes 集群</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/pai</span><br><span class="line"></span><br><span class="line">sudo python paictl.py cluster k8s-bootup -p ~/pai-config</span><br></pre></td></tr></table></figure><p>集群部署完成可通过如下地址访问集群管理系统：</p><p><code>http://&lt;master&gt;:9090</code></p><p>部署过程中遇到问题重新部署前先执行如下命令删掉<code>kubelet</code>的容器：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo docker ps</span><br><span class="line">sudo docker stop kubelet</span><br><span class="line">sudo docker rm kubelet</span><br></pre></td></tr></table></figure><h2 id="更新集群配置"><a href="#更新集群配置" class="headerlink" title="更新集群配置"></a>更新集群配置</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/pai</span><br><span class="line">python paictl.py config push -p ~/pai-config</span><br></pre></td></tr></table></figure><p>执行完成之后会提示输入一个cluster id：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Please input the cluster-id <span class="keyword">for</span> your cluster: 123456</span><br></pre></td></tr></table></figure><h2 id="启动OpenPAI服务"><a href="#启动OpenPAI服务" class="headerlink" title="启动OpenPAI服务"></a>启动OpenPAI服务</h2><blockquote><p>此步骤将依次安装如下服务：</p><p><code>[&#39;watchdog&#39;, &#39;node-exporter&#39;, &#39;yarn-frameworklauncher&#39;, &#39;hadoop-name-node&#39;, &#39;cleaner&#39;, &#39;rest-server&#39;, &#39;grafana&#39;, &#39;hadoop-resource-manager&#39;, &#39;hadoop-batch-job&#39;, &#39;drivers&#39;, &#39;cluster-configuration&#39;, &#39;alert-manager&#39;, &#39;pylon&#39;, &#39;hadoop-jobhistory&#39;, &#39;hadoop-node-manager&#39;, &#39;end-to-end-test&#39;, &#39;job-exporter&#39;, &#39;webportal&#39;, &#39;zookeeper&#39;, &#39;prometheus&#39;, &#39;hadoop-data-node&#39;]</code></p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/pai</span><br><span class="line">python paictl.py service start</span><br></pre></td></tr></table></figure><p>此时可以通过kebernetes的管理界面查看服务所在容器的部署情况：<code>http://127.0.0.1:9090/#!/job?namespace=default</code></p><p><img src="/2018/12/26/深度学习资源调度平台OpenPAI部署/k8s-management.png" alt="k8s-management"></p><p>在此步骤中遇到了<code>watchdog</code>无法部署成功的问题，指定的配置文件版本无法找到对应0.8.3的watchdog：</p><p><img src="/2018/12/26/深度学习资源调度平台OpenPAI部署/watchdog-error.png" alt="watchdog-error"></p><ul><li><p>解决办法</p><ul><li><p>通过如下命令删除已经部署的watchdog容器</p></li><li><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ python paictl.py service delete -n watchdog</span><br></pre></td></tr></table></figure><p>更新<code>pai-config</code>中的配置文件<code>services-configuration.yaml</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">namespace: xudifsd</span><br><span class="line">tag: latest</span><br></pre></td></tr></table></figure></li><li><p>重新执行配置更新命令</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd ~/pai</span><br><span class="line">python paictl.py<span class="built_in"> config </span>push -p ~/pai-config</span><br></pre></td></tr></table></figure></li><li><p>重启启动服务部署命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/pai</span><br><span class="line">python paictl.py service start</span><br></pre></td></tr></table></figure></li></ul></li></ul><blockquote><p><code>end-to-end-test</code>服务可以通过如下命令删除：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;python paictl.py service delete -n end-to-end-test</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><p>最后，可以通过如下链接的方法验证部署成功与否：</p><p><a href="https://github.com/Microsoft/pai/blob/master/docs/pai-management/doc/validate-deployment.md">https://github.com/Microsoft/pai/blob/master/docs/pai-management/doc/validate-deployment.md</a></p><h4 id="删掉整个集群"><a href="#删掉整个集群" class="headerlink" title="删掉整个集群"></a>删掉整个集群</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python paictl.py service delete</span><br><span class="line">sudo python paictl.py cluster k8s-clean -p ~/pai-config/</span><br><span class="line"></span><br><span class="line"><span class="comment">#optional</span></span><br><span class="line">sudo rm –rf /var/etcd/data</span><br></pre></td></tr></table></figure><h2 id="其它更新"><a href="#其它更新" class="headerlink" title="其它更新"></a>其它更新</h2><h3 id="2019-03-14-更新"><a href="#2019-03-14-更新" class="headerlink" title="2019/03/14 更新"></a>2019/03/14 更新</h3><blockquote><p>最近在一台新的虚拟机环境部署v0.9.1版本，遇到了 <code>pylon</code>hung住的问题，详见github提交的issue: <a href="https://github.com/Microsoft/pai/issues/2282">https://github.com/Microsoft/pai/issues/2282</a></p><p>后来发现是Linux默认配置的apache服务占用了80端口，导致docker-proxy抢占端口失败，pylon无法启动，停掉apache服务或修改pylon的端口(<code>services-configuration.yaml</code>)可以解决问题。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/2018/12/26/深度学习资源调度平台OpenPAI部署/sysarch.png&quot; alt=&quot;OpenPAI&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="动手实践营" scheme="http://blog.a-stack.com/categories/%E5%8A%A8%E6%89%8B%E5%AE%9E%E8%B7%B5%E8%90%A5/"/>
    
    
      <category term="部署" scheme="http://blog.a-stack.com/tags/%E9%83%A8%E7%BD%B2/"/>
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="资源调度" scheme="http://blog.a-stack.com/tags/%E8%B5%84%E6%BA%90%E8%B0%83%E5%BA%A6/"/>
    
      <category term="开源平台" scheme="http://blog.a-stack.com/tags/%E5%BC%80%E6%BA%90%E5%B9%B3%E5%8F%B0/"/>
    
  </entry>
  
  <entry>
    <title>机器在学习——EDA</title>
    <link href="http://blog.a-stack.com/2018/12/11/%E6%9C%BA%E5%99%A8%E5%9C%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94EDA/"/>
    <id>http://blog.a-stack.com/2018/12/11/机器在学习——EDA/</id>
    <published>2018-12-11T06:46:47.000Z</published>
    <updated>2020-03-22T07:29:47.453Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/2018/12/11/机器在学习——EDA/pairplot.png" alt="EDA"></p><a id="more"></a><hr><h1 id="Topic-1：-EDA-with-pandas"><a href="#Topic-1：-EDA-with-pandas" class="headerlink" title="Topic 1： EDA with pandas"></a>Topic 1： EDA with pandas</h1><ol><li><p>调整column类型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'Churn'</span>] = df[<span class="string">'Churn'</span>].astype(<span class="string">'int64'</span>)</span><br></pre></td></tr></table></figure></li><li><p><code>df.describe()</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.describe(include=[<span class="string">'object'</span>, <span class="string">'bool'</span>])</span><br></pre></td></tr></table></figure></li><li><p><code>df.value_counts(normalize=True)</code></p><blockquote><p>对于离散量数据（<code>object</code>或<code>bool</code>）统计不同类型的数目</p></blockquote><p>另外可以通过如下命令来统计一个离散属性的所有类别数目：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flights_df[<span class="string">'UniqueCarrier'</span>].nunique()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">flights_df.groupby(<span class="string">'UniqueCarrier'</span>).size().plot(kind=<span class="string">'bar'</span>);</span><br><span class="line"><span class="comment">#等价于</span></span><br><span class="line">flights_df[<span class="string">'UniqueCarrier'</span>].value_counts().plot(kind=<span class="string">'bar'</span>)</span><br></pre></td></tr></table></figure></li></ol><ol><li><p>排序方法：<code>sort_values(by=&#39;...&#39;,ascending=False)</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df.sort_values(by=<span class="string">'Total day charge'</span>, ascending=<span class="keyword">False</span>).head()</span><br><span class="line"></span><br><span class="line">df.sort_values(by=[<span class="string">'Churn'</span>, <span class="string">'Total day charge'</span>],</span><br><span class="line">        ascending=[<span class="keyword">True</span>, <span class="keyword">False</span>])</span><br></pre></td></tr></table></figure></li><li><p>Boolean indexing：<code>df[P(df[&#39;Name&#39;])]</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[(df[<span class="string">'Churn'</span>] == <span class="number">0</span>) &amp; (df[<span class="string">'International plan'</span>] == <span class="string">'No'</span>)][<span class="string">'Total intl minutes'</span>].max()</span><br></pre></td></tr></table></figure></li><li><p><code>.loc</code>与<code>.iloc</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df.loc[<span class="number">0</span>:<span class="number">5</span>, <span class="string">'State'</span>:<span class="string">'Area code'</span>]</span><br><span class="line">df.iloc[<span class="number">0</span>:<span class="number">5</span>, <span class="number">0</span>:<span class="number">3</span>]</span><br><span class="line">df[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure></li><li><p><code>apply</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将apply应用到每一行，注意添加 axis=1</span></span><br><span class="line">df[<span class="string">'State'</span>].apply(<span class="keyword">lambda</span> state: state[<span class="number">0</span>] == <span class="string">'W'</span>)</span><br></pre></td></tr></table></figure></li><li><p><code>map</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">d = &#123;<span class="string">'No'</span> : <span class="keyword">False</span>, <span class="string">'Yes'</span> : <span class="keyword">True</span>&#125;</span><br><span class="line">df[<span class="string">'International plan'</span>] = df[<span class="string">'International plan'</span>].map(d)</span><br></pre></td></tr></table></figure></li><li><p><code>Grouping</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">df.groupby(by=grouping_columns)[columns_to_show].function()</span><br><span class="line"></span><br><span class="line">columns_to_show = [<span class="string">'Total day minutes'</span>, <span class="string">'Total eve minutes'</span>, </span><br><span class="line">                   <span class="string">'Total night minutes'</span>]</span><br><span class="line"></span><br><span class="line">df.groupby([<span class="string">'Churn'</span>])[columns_to_show].agg([np.mean, np.std, np.min, </span><br><span class="line">                                            np.max])</span><br></pre></td></tr></table></figure></li><li><p>Summary Tables</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.crosstab(df[<span class="string">'Churn'</span>], df[<span class="string">'International plan'</span>])</span><br></pre></td></tr></table></figure></li></ol><h1 id="Topic-2：-EDA-with-plot"><a href="#Topic-2：-EDA-with-plot" class="headerlink" title="Topic 2： EDA with plot"></a>Topic 2： EDA with plot</h1><blockquote><p>收集 ML toolbox： <code>pandas</code>,<code>matplotlib</code>,<code>seaborn</code></p></blockquote><h2 id="1-看数据分布"><a href="#1-看数据分布" class="headerlink" title="1. 看数据分布"></a>1. 看数据分布</h2><h3 id="直方图"><a href="#直方图" class="headerlink" title="直方图"></a>直方图</h3><blockquote><p>使用<code>pandas</code> DataFrame的<code>hist()</code>方法直接绘制：将数据划分至等长区间(bins)。</p><p>用于统计数据分布，在不同区间的计数值；</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[features].hist(figsize=(<span class="number">10</span>, <span class="number">4</span>));</span><br></pre></td></tr></table></figure><h3 id="Box图"><a href="#Box图" class="headerlink" title="Box图"></a>Box图</h3><p>箱形图（Box-plot）又称为盒须图、盒式图或箱线图，是一种用作显示一组数据分散情况资料的统计图。它能显示出一组数据的<strong>最大值</strong>、<strong>最小值</strong>、<strong>中位数</strong>及<strong>上下四分位数</strong>。因形状如箱子而得名。在各种领域也经常被使用，常见于品质管理。</p><p>接下来我们介绍Seaborn中的箱型图的具体实现方法，这是boxplot的API：</p><blockquote><p>seaborn.boxplot(x=None, y=None, hue=None, data=None, order=None, hue_order=None, orient=None, color=None, palette=None, saturation=0.75, width=0.8, dodge=True, fliersize=5, linewidth=None, whis=1.5, notch=False, ax=None, **kwargs)</p></blockquote><h3 id="Kernel-Density-Plots"><a href="#Kernel-Density-Plots" class="headerlink" title="Kernel Density Plots"></a>Kernel Density Plots</h3><blockquote><p>看作为直方图的平滑版本</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df[features].plot(kind=<span class="string">'density'</span>, subplots=<span class="keyword">True</span>, layout=(<span class="number">1</span>, <span class="number">2</span>), </span><br><span class="line">                  sharex=<span class="keyword">False</span>, figsize=(<span class="number">10</span>, <span class="number">4</span>));</span><br></pre></td></tr></table></figure><p><img src="/2018/12/11/机器在学习——EDA/kernel-density-plots.png" alt="kernel-density-plots"></p><h3 id="Seaborn的displot方法"><a href="#Seaborn的displot方法" class="headerlink" title="Seaborn的displot方法"></a>Seaborn的<code>displot</code>方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.distplot(df[<span class="string">'Total intl calls'</span>]);</span><br></pre></td></tr></table></figure><p><img src="/2018/12/11/机器在学习——EDA/sns.distplot.png" alt="sns.distplot"></p><h3 id="pandas的describe-方法"><a href="#pandas的describe-方法" class="headerlink" title="pandas的describe()方法"></a><code>pandas</code>的<code>describe()</code>方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[features].describe()</span><br></pre></td></tr></table></figure><blockquote><p>也可以通过seaborn的box方法</p></blockquote><h2 id="2-离散变量"><a href="#2-离散变量" class="headerlink" title="2. 离散变量"></a>2. 离散变量</h2><h3 id="pandas的value-counts"><a href="#pandas的value-counts" class="headerlink" title="pandas的value_counts"></a><code>pandas</code>的<code>value_counts</code></h3><blockquote><p> <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.value_counts.html"><code>value_counts()</code></a> </p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'feature_name'</span>].value_counts(normalize=Fase)</span><br></pre></td></tr></table></figure><h3 id="seaborn的countplot"><a href="#seaborn的countplot" class="headerlink" title="seaborn的countplot"></a><code>seaborn</code>的<code>countplot</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">_, axes = plt.subplots(nrows=<span class="number">1</span>, ncols=<span class="number">2</span>, figsize=(<span class="number">12</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">sns.countplot(x=<span class="string">'Churn'</span>, data=df, ax=axes[<span class="number">0</span>]);</span><br><span class="line">sns.countplot(x=<span class="string">'Customer service calls'</span>, data=df, ax=axes[<span class="number">1</span>]);</span><br></pre></td></tr></table></figure><p><img src="/2018/12/11/机器在学习——EDA/barplot.png" alt="barplot"></p><h3 id="lmplot"><a href="#lmplot" class="headerlink" title="lmplot"></a><code>lmplot</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.lmplot(<span class="string">'Total day minutes'</span>, <span class="string">'Total night minutes'</span>, data=df, hue=<span class="string">'Churn'</span>, fit_reg=<span class="keyword">False</span>);</span><br></pre></td></tr></table></figure><p><img src="/2018/12/11/机器在学习——EDA/lmplot.png" alt="lmplot"></p><h2 id="3-关联分析"><a href="#3-关联分析" class="headerlink" title="3. 关联分析"></a>3. 关联分析</h2><h3 id="相关性分析"><a href="#相关性分析" class="headerlink" title="相关性分析"></a>相关性分析</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Drop non-numerical variables</span></span><br><span class="line">numerical = list(set(df.columns) - </span><br><span class="line">                 set([<span class="string">'State'</span>, <span class="string">'International plan'</span>, <span class="string">'Voice mail plan'</span>, </span><br><span class="line">                      <span class="string">'Area code'</span>, <span class="string">'Churn'</span>, <span class="string">'Customer service calls'</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate and plot</span></span><br><span class="line">corr_matrix = df[numerical].corr()</span><br><span class="line">sns.heatmap(corr_matrix);</span><br></pre></td></tr></table></figure><h3 id="散点图"><a href="#散点图" class="headerlink" title="散点图"></a>散点图</h3><blockquote><p><a href="https://seaborn.pydata.org/generated/seaborn.jointplot.html"><code>jointplot()</code></a> </p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.jointplot(x=<span class="string">'Total day minutes'</span>, y=<span class="string">'Total night minutes'</span>, </span><br><span class="line">              data=df, kind=<span class="string">'scatter'</span>);</span><br></pre></td></tr></table></figure><p><img src="/2018/12/11/机器在学习——EDA/scatter.png" alt="scatter"></p><h4 id="散点图的相关性矩阵：-pairplot"><a href="#散点图的相关性矩阵：-pairplot" class="headerlink" title="散点图的相关性矩阵： pairplot"></a>散点图的相关性矩阵： <code>pairplot</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># `pairplot()` may become very slow with the SVG format</span></span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'png'</span></span><br><span class="line">sns.pairplot(df[numerical]);</span><br></pre></td></tr></table></figure><p><img src="/2018/12/11/机器在学习——EDA/pairplot.png" alt="pairplot"></p><h3 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h3><h2 id="技巧总结"><a href="#技巧总结" class="headerlink" title="技巧总结"></a>技巧总结</h2><ol><li><p><code>seaborn</code>的<code>hue</code>属性是一个可视化很直接，比较有用的配置属性；</p><p>比如通过下图来看某个特征对于结果的不同分布：</p><p><img src="/2018/12/11/机器在学习——EDA/count-plot-hue.png" alt="count-plot-hue"></p></li><li><p>在量化离散变量之前，将数值变量和类别变量分别进行分析</p></li><li><p>环境准备</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Matplotlib forms basis for visualization in Python</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># We will use the Seaborn library</span></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">sns.set()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Graphics in SVG format are more sharp and legible</span></span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'svg'</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># Increase the default plot size and set the color scheme</span></span><br><span class="line">plt.rcParams[<span class="string">'figure.figsize'</span>] = <span class="number">8</span>, <span class="number">5</span></span><br><span class="line">plt.rcParams[<span class="string">'image.cmap'</span>] = <span class="string">'viridis'</span></span><br></pre></td></tr></table></figure></li><li><p>熟练使用特征选择命令，限定画图范围</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">top_features = df[<span class="string">'features'</span>].value_counts().sort_values(ascending=<span class="keyword">False</span>).head(<span class="number">5</span>).index.values</span><br></pre></td></tr></table></figure></li><li><p>善用<code>pandas.crosstab</code>进行分析</p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/2018/12/11/机器在学习——EDA/pairplot.png&quot; alt=&quot;EDA&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://blog.a-stack.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
  </entry>
  
  <entry>
    <title>机器在学习-时序数据分析</title>
    <link href="http://blog.a-stack.com/2018/12/04/%E6%9C%BA%E5%99%A8%E5%9C%A8%E5%AD%A6%E4%B9%A0-%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    <id>http://blog.a-stack.com/2018/12/04/机器在学习-时序数据分析/</id>
    <published>2018-12-04T08:50:11.000Z</published>
    <updated>2018-12-11T04:00:45.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/qnsource/banner/15.jpg" alt="Test Picture"></p><a id="more"></a><h2 id="算法理论"><a href="#算法理论" class="headerlink" title="算法理论"></a>算法理论</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><blockquote><p><strong>Time series</strong> is a series of data points indexed (or listed or graphed) in time order. </p></blockquote><h3 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h3><ul><li><a href="http://scikit-learn.org/stable/modules/model_evaluation.html#r2-score-the-coefficient-of-determination">R squared</a>: coefficient of determination (in econometrics, this can be interpreted as the percentage of variance explained by the model), $(-\infty, 1]$</li></ul><script type="math/tex; mode=display">R^2 = 1 - \frac{SS_{res}}{SS_{tot}}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.r2_score</span><br></pre></td></tr></table></figure><hr><ul><li><a href="http://scikit-learn.org/stable/modules/model_evaluation.html#mean-absolute-error">Mean Absolute Error</a>: this is an interpretable metric because it has the same unit of measurment as the initial series, $[0, +\infty)$</li></ul><script type="math/tex; mode=display">MAE = \frac{\sum\limits_{i=1}^{n} |y_i - \hat{y}_i|}{n}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.mean_absolute_error</span><br></pre></td></tr></table></figure><hr><ul><li><a href="http://scikit-learn.org/stable/modules/model_evaluation.html#median-absolute-error">Median Absolute Error</a>: again, an interpretable metric that is particularly interesting because it is robust to outliers, $[0, +\infty)$</li></ul><script type="math/tex; mode=display">MedAE = median(|y_1 - \hat{y}_1|, ... , |y_n - \hat{y}_n|)</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.median_absolute_error</span><br></pre></td></tr></table></figure><hr><ul><li><a href="http://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-error">Mean Squared Error</a>: the most commonly used metric that gives a higher penalty to large errors and vice versa, $[0, +\infty)$</li></ul><script type="math/tex; mode=display">MSE = \frac{1}{n}\sum\limits_{i=1}^{n} (y_i - \hat{y}_i)^2</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.mean_squared_error</span><br></pre></td></tr></table></figure><hr><ul><li><a href="http://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-logarithmic-error">Mean Squared Logarithmic Error</a>: practically, this is the same as MSE, but we take the logarithm of the series. As a result, we give more weight to small mistakes as well. This is usually used when the data has exponential trends, $[0, +\infty)$</li></ul><script type="math/tex; mode=display">MSLE = \frac{1}{n}\sum\limits_{i=1}^{n} (log(1+y_i) - log(1+\hat{y}_i))^2</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.mean_squared_log_error</span><br></pre></td></tr></table></figure><hr><ul><li>Mean Absolute Percentage Error: this is the same as MAE but is computed as a percentage, which is very convenient when you want to explain the quality of the model to management, $[0, +\infty)$</li></ul><script type="math/tex; mode=display">MAPE = \frac{100}{n}\sum\limits_{i=1}^{n} \frac{|y_i - \hat{y}_i|}{y_i}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mean_absolute_percentage_error</span><span class="params">(y_true, y_pred)</span>:</span> </span><br><span class="line">    <span class="keyword">return</span> np.mean(np.abs((y_true - y_pred) / y_true)) * <span class="number">100</span></span><br></pre></td></tr></table></figure><h2 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h2><h3 id="使用相关模型库"><a href="#使用相关模型库" class="headerlink" title="使用相关模型库"></a>使用相关模型库</h3><ol><li><p><a href="http://statsmodels.sourceforge.net/stable/">statsmodels</a> library </p><blockquote><p>R的统计学习库，被移植到了python中，包含对于时序数据分析的各种函数</p></blockquote></li><li></li></ol><h3 id="滑动平均"><a href="#滑动平均" class="headerlink" title="滑动平均"></a>滑动平均</h3><p><a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.rolling.html"><code>DataFrame.rolling(window).mean()</code></a> </p><h2 id="技巧"><a href="#技巧" class="headerlink" title="技巧"></a>技巧</h2><h3 id="并行化"><a href="#并行化" class="headerlink" title="并行化"></a>并行化</h3><p>随机森林支持树的并行构建和预测结果的并行计算，这可以通过 <code>n_jobs</code> 参数实现。 如果设置 <code>n_jobs = k</code> ，则计算被划分为 <code>k</code> 个作业，并运行在机器的 <code>k</code> 个核上。 如果设置 <code>n_jobs = -1</code> ，则使用机器的所有核。 注意由于进程间通信具有一定的开销，这里的提速并不是线性的（即，使用 <code>k</code> 个作业不会快 <code>k</code> 倍）。 当然，在建立大量的树，或者构建单个树需要相当长的时间（例如，在大数据集上）时，（通过并行化）仍然可以实现显著的加速。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><p>《机器学习》——周志华</p></li><li><p><a href="https://mlcourse.ai/">mlcourse.ai</a> – Open Machine Learning Course</p></li></ol><p>3.<a href="http://sklearn.apachecn.org/cn/0.19.0/">Sklearn文档</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/qnsource/banner/15.jpg&quot; alt=&quot;Test Picture&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://blog.a-stack.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="时序数据" scheme="http://blog.a-stack.com/tags/%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Time Series" scheme="http://blog.a-stack.com/tags/Time-Series/"/>
    
      <category term="SARIMA" scheme="http://blog.a-stack.com/tags/SARIMA/"/>
    
      <category term="Prophet" scheme="http://blog.a-stack.com/tags/Prophet/"/>
    
  </entry>
  
  <entry>
    <title>机器在学习-线性回归与分类</title>
    <link href="http://blog.a-stack.com/2018/11/29/%E6%9C%BA%E5%99%A8%E5%9C%A8%E5%AD%A6%E4%B9%A0-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/"/>
    <id>http://blog.a-stack.com/2018/11/29/机器在学习-随机森林/</id>
    <published>2018-11-29T08:50:11.000Z</published>
    <updated>2018-12-11T04:04:47.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/qnsource/banner/15.jpg" alt="Test Picture"></p><h2 id="算法理论"><a href="#算法理论" class="headerlink" title="算法理论"></a>算法理论</h2><h3 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h3><p><strong>集成方法</strong> 的目标是把多个使用给定学习算法构建的基估计器的预测结果结合起来，从而获得比单个估计器更好的泛化能力/鲁棒性。</p><p>集成方法通常分为两种:</p><ul><li><p><strong>平均方法</strong>，该方法的原理是构建多个独立的估计器，然后取它们的预测结果的平均。一般来说组合之后的估计器是会比单个估计器要好的，因为它的方差减小了。</p><p><strong>示例:</strong> <a href="http://sklearn.apachecn.org/cn/0.19.0/modules/ensemble.html#bagging">Bagging 方法</a> , <a href="http://sklearn.apachecn.org/cn/0.19.0/modules/ensemble.html#forest">随机森林</a> , …</p></li><li><p>相比之下，在 <strong>boosting 方法</strong> 中，基估计器是依次构建的，并且每一个基估计器都尝试去减少组合估计器的偏差。这种方法主要目的是为了结合多个弱模型，使集成的模型更加强大。</p><p><strong>示例:</strong> <a href="http://sklearn.apachecn.org/cn/0.19.0/modules/ensemble.html#adaboost">AdaBoost</a> , <a href="http://sklearn.apachecn.org/cn/0.19.0/modules/ensemble.html#gradient-boosting">梯度提升树</a> , …</p><a id="more"></a></li></ul><h3 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h3><h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h3><p>在随机森林中（参见 <a href="http://sklearn.apachecn.org/cn/0.19.0/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier"><code>RandomForestClassifier</code></a> 和 <a href="http://sklearn.apachecn.org/cn/0.19.0/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor"><code>RandomForestRegressor</code></a> 类）， 集成模型中的每棵树构建时的样本都是由训练集经过有放回抽样得来的（例如，自助采样法-bootstrap sample）。 另外，在构建树的过程中进行结点分割时，选择的分割点不再是所有特征中最佳分割点，而是特征的一个随机子集中的最佳分割点。 由于这种随机性，森林的偏差通常会有略微的增大（相对于单个非随机树的偏差），但是由于取了平均，其方差也会减小，通常能够补偿偏差的增加，从而产生一个总体上更好的模型。 </p><script type="math/tex; mode=display">\large p_{+} = \frac{OR_{+}}{1 + OR_{+}} = \frac{\exp^{\textbf{w}^\text{T}\textbf{x}}}{1 + \exp^{\textbf{w}^\text{T}\textbf{x}}} = \frac{1}{1 + \exp^{-\textbf{w}^\text{T}\textbf{x}}} = \sigma(\textbf{w}^\text{T}\textbf{x})</script><h2 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h2><h3 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h3><p>要调整的参数主要是 <code>n_estimators</code> 和 <code>max_features</code>。 前者（n_estimators）是森林里树的数量，通常数量越大，效果越好，但是计算时间也会随之增加。 此外要注意，当树的数量超过一个临界值之后，算法的效果并不会很显著地变好。 后者（max_features）是分割节点时考虑的特征的随机子集的大小。 这个值越低，方差减小得越多，但是偏差的增大也越多。 根据经验，回归问题中使用 <code>max_features = n_features</code>， 分类问题使用 <code>max_features = sqrt（n_features）</code> （其中 <code>n_features</code> 是特征的个数）是比较好的默认值。 <code>max_depth = None</code> 和 <code>min_samples_split = 2</code> 结合通常会有不错的效果（即生成完全的树）。 请记住，这些（默认）值通常不是最佳的，同时还可能消耗大量的内存，最佳参数值应由交叉验证获得。 另外，请注意，在随机森林中，默认使用自助采样法（<code>bootstrap = True</code>）， 然而 extra-trees 的默认策略是使用整个数据集（<code>bootstrap = False</code>）。 当使用自助采样法方法抽样时，泛化精度是可以通过剩余的或者袋外的样本来估算的，设置 <code>oob_score = True</code> 即可实现。</p><blockquote><p><strong>提示:</strong></p><p>默认参数下模型复杂度是：<code>O(M*N*log(N))</code> ， 其中 <code>M</code> 是树的数目， <code>N</code> 是样本数。 可以通过设置以下参数来降低模型复杂度： <code>min_samples_split</code> , <code>min_samples_leaf</code> , <code>max_leaf_nodes`` 和 ``max_depth</code> 。</p></blockquote><h2 id="技巧"><a href="#技巧" class="headerlink" title="技巧"></a>技巧</h2><h3 id="并行化"><a href="#并行化" class="headerlink" title="并行化"></a>并行化</h3><p>随机森林支持树的并行构建和预测结果的并行计算，这可以通过 <code>n_jobs</code> 参数实现。 如果设置 <code>n_jobs = k</code> ，则计算被划分为 <code>k</code> 个作业，并运行在机器的 <code>k</code> 个核上。 如果设置 <code>n_jobs = -1</code> ，则使用机器的所有核。 注意由于进程间通信具有一定的开销，这里的提速并不是线性的（即，使用 <code>k</code> 个作业不会快 <code>k</code> 倍）。 当然，在建立大量的树，或者构建单个树需要相当长的时间（例如，在大数据集上）时，（通过并行化）仍然可以实现显著的加速。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><p>《机器学习》——周志华</p></li><li><p><a href="https://mlcourse.ai/">mlcourse.ai</a> – Open Machine Learning Course</p></li></ol><p>3.<a href="http://sklearn.apachecn.org/cn/0.19.0/">Sklearn文档</a></p><p>- </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/qnsource/banner/15.jpg&quot; alt=&quot;Test Picture&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;算法理论&quot;&gt;&lt;a href=&quot;#算法理论&quot; class=&quot;headerlink&quot; title=&quot;算法理论&quot;&gt;&lt;/a&gt;算法理论&lt;/h2&gt;&lt;h3 id=&quot;集成学习&quot;&gt;&lt;a href=&quot;#集成学习&quot; class=&quot;headerlink&quot; title=&quot;集成学习&quot;&gt;&lt;/a&gt;集成学习&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;集成方法&lt;/strong&gt; 的目标是把多个使用给定学习算法构建的基估计器的预测结果结合起来，从而获得比单个估计器更好的泛化能力/鲁棒性。&lt;/p&gt;
&lt;p&gt;集成方法通常分为两种:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;平均方法&lt;/strong&gt;，该方法的原理是构建多个独立的估计器，然后取它们的预测结果的平均。一般来说组合之后的估计器是会比单个估计器要好的，因为它的方差减小了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;示例:&lt;/strong&gt; &lt;a href=&quot;http://sklearn.apachecn.org/cn/0.19.0/modules/ensemble.html#bagging&quot;&gt;Bagging 方法&lt;/a&gt; , &lt;a href=&quot;http://sklearn.apachecn.org/cn/0.19.0/modules/ensemble.html#forest&quot;&gt;随机森林&lt;/a&gt; , …&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;相比之下，在 &lt;strong&gt;boosting 方法&lt;/strong&gt; 中，基估计器是依次构建的，并且每一个基估计器都尝试去减少组合估计器的偏差。这种方法主要目的是为了结合多个弱模型，使集成的模型更加强大。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;示例:&lt;/strong&gt; &lt;a href=&quot;http://sklearn.apachecn.org/cn/0.19.0/modules/ensemble.html#adaboost&quot;&gt;AdaBoost&lt;/a&gt; , &lt;a href=&quot;http://sklearn.apachecn.org/cn/0.19.0/modules/ensemble.html#gradient-boosting&quot;&gt;梯度提升树&lt;/a&gt; , …&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://blog.a-stack.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
  </entry>
  
  <entry>
    <title>机器在学习-KNN</title>
    <link href="http://blog.a-stack.com/2018/11/23/%E6%9C%BA%E5%99%A8%E5%9C%A8%E5%AD%A6%E4%B9%A0%E2%80%94-KNN/"/>
    <id>http://blog.a-stack.com/2018/11/23/机器在学习—-KNN/</id>
    <published>2018-11-23T08:50:37.000Z</published>
    <updated>2018-12-11T10:30:24.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/qnsource/banner/15.jpg" alt="KNN"></p><a id="more"></a><h2 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h2><p><a href="http://sklearn.apachecn.org/cn/0.19.0/modules/classes.html#module-sklearn.neighbors"><code>sklearn.neighbors</code></a> 提供了 neighbors-based (基于邻居的) 无监督学习以及监督学习方法的功能。 无监督的最近邻是许多其它学习方法的基础，尤其是 manifold learning (流行学习) 和 spectral clustering (谱聚类)。 neighbors-based (基于邻居的) 监督学习分为两种： <a href="http://sklearn.apachecn.org/cn/0.19.0/modules/neighbors.html#classification">classification</a> （分类）针对的是具有离散标签的数据，<a href="http://sklearn.apachecn.org/cn/0.19.0/modules/neighbors.html#regression">regression</a> （回归）针对的是具有连续标签的数据。 </p><ol><li>Calculate the distance to each of the samples in the training set.</li><li>Select 𝑘k samples from the training set with the minimal distance to them.</li><li>The class of the test sample will be the most frequent class among those 𝑘k nearest neighbors.</li></ol><blockquote><p>在Kaggle比赛中，KNN经常作为前期特征生成的算法；</p><p>算法处理有两个关键：</p><ul><li>K的选取；</li><li>距离的评价准则（Hamming，Euclidean，cosine, Minkowski distance）</li><li>所有属性必须进行归一化操作，保证距离计算的一致性</li></ul></blockquote><h3 id="K-D-树¶"><a href="#K-D-树¶" class="headerlink" title="K-D 树¶"></a>K-D 树<a href="http://sklearn.apachecn.org/cn/0.19.0/modules/neighbors.html#k-d">¶</a></h3><p>为了解决效率低下的暴力计算方法，已经发明了大量的基于树的数据结构。总的来说， 这些结构试图通过有效地编码样本的 aggregate distance (聚合距离) 信息来减少所需的距离计算量。 基本思想是，若A点距离B点非常远，B距离C点非常近， 可知 A点与 C点很遥远，<em>不需要明确计算它们的距离</em>。 通过这样的方式，近邻搜索的计算成本可以降低为 $O[DNlog(N)]$或更低。 这是对于暴力搜索在大样本数 N中表现的显著改善。</p><p>利用这种聚合信息的早期方法是 <em>KD tree</em> 数据结构（<em> K-dimensional tree</em> 的简写）, 它将二维 <em>Quad-trees</em> 和三维 <em>Oct-trees</em>推广到任意数量的维度. KD 树是一个二叉树结构，它沿着数据轴递归地划分参数空间，将其划分为嵌入数据点的嵌套的各向异性区域。 KD 树的构造非常快：因为只需沿数据轴执行分区, 无需计算 D-dimensional 距离。 一旦构建完成, 查询点的最近邻距离计算复杂度仅为 $O[log(N)]$。 虽然 KD 树的方法对于低维度 （D&lt;20）近邻搜索非常快, 当D增长到很大时, 效率变低: 这就是所谓的 “维度灾难” 的一种体现。 在 scikit-learn 中, KD 树近邻搜索可以使用关键字 <code>algorithm = &#39;kd_tree&#39;</code> 来指定, 并且使用类 <a href="http://sklearn.apachecn.org/cn/0.19.0/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree"><code>KDTree</code></a> 来计算。</p><h2 id="工程实现"><a href="#工程实现" class="headerlink" title="工程实现"></a>工程实现</h2><p>The main parameters of the class <code>sklearn.neighbors.KNeighborsClassifier</code> are:</p><ul><li>weights: <code>uniform</code> (all weights are equal), <code>distance</code> (the weight is inversely proportional to the distance from the test sample), or any other user-defined function;</li><li>algorithm (optional): <code>brute</code>, <code>ball_tree</code>, <code>KD_tree</code>, or <code>auto</code>. In the first case, the nearest neighbors for each test case are computed by a grid search over the training set. In the second and third cases, the distances between the examples are stored in a tree to accelerate finding nearest neighbors. If you set this parameter to <code>auto</code>, the right way to find the neighbors will be automatically chosen based on the training set.</li><li>leaf_size (optional): threshold for switching to grid search if the algorithm for finding neighbors is BallTree or KDTree;</li><li>metric: <code>minkowski</code>, <code>manhattan</code>, <code>euclidean</code>, <code>chebyshev</code>, or other.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"></span><br><span class="line">knn_pipe = Pipeline([(<span class="string">'scaler'</span>, StandardScaler()), (<span class="string">'knn'</span>, KNeighborsClassifier(n_jobs=<span class="number">-1</span>))])</span><br><span class="line"></span><br><span class="line">knn_params = &#123;<span class="string">'knn__n_neighbors'</span>: range(<span class="number">1</span>, <span class="number">10</span>)&#125;</span><br><span class="line"></span><br><span class="line">knn_grid = GridSearchCV(knn_pipe, knn_params,</span><br><span class="line">                        cv=<span class="number">5</span>, n_jobs=<span class="number">-1</span>, verbose=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">knn_grid.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">knn_grid.best_params_, knn_grid.best_score_</span><br><span class="line"></span><br><span class="line">accuracy_score(y_holdout, knn_grid.predict(X_holdout))</span><br></pre></td></tr></table></figure><h2 id="KNN的优缺点"><a href="#KNN的优缺点" class="headerlink" title="KNN的优缺点"></a>KNN的优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ol><li>实现简单，理论完备；</li><li>一般作为机器学习使用的第一个测试算法；</li><li>可解释性强；</li></ol><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ol><li>处理大数据训练样本效率低；</li><li>难以处理特征数目多的数据集；</li><li>对距离测量算法依赖高；</li><li>K的选择也需要反复尝试；</li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://mlcourse.ai/">mlcourse.ai</a> – Open Machine Learning Course</li></ol><p>2.<a href="http://sklearn.apachecn.org/cn/0.19.0/modules/neighbors.html">Sklearn 最近邻</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/qnsource/banner/15.jpg&quot; alt=&quot;KNN&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://blog.a-stack.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
  </entry>
  
  <entry>
    <title>机器在学习-决策树(Dicision Tree)</title>
    <link href="http://blog.a-stack.com/2018/11/23/%E6%9C%BA%E5%99%A8%E5%9C%A8%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-Dicision-Tree/"/>
    <id>http://blog.a-stack.com/2018/11/23/机器在学习-决策树-Dicision-Tree/</id>
    <published>2018-11-23T08:50:11.000Z</published>
    <updated>2018-11-25T07:22:23.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/qnsource/banner/15.jpg" alt="Test Picture"></p><p><strong>摘要：</strong></p><a id="more"></a><h2 id="决策树的算法"><a href="#决策树的算法" class="headerlink" title="决策树的算法"></a>决策树的算法</h2><blockquote><p>ID3  C4.5  CART</p><p>ID3（Iterative Dichotomiser 3）由 Ross Quinlan 在1986年提出。该算法创建一个多路树，找到每个节点（即以贪心的方式）分类特征，这将产生分类目标的最大信息增益。决策树发展到其最大尺寸，然后通常利用剪枝来提高树对未知数据的泛华能力。</p><p>C4.5 是 ID3 的后继者，并且通过动态定义将连续属性值分割成一组离散间隔的离散属性（基于数字变量），消除了特征必须被明确分类的限制。C4.5 将训练的树（即，ID3算法的输出）转换成 if-then 规则的集合。然后评估每个规则的这些准确性，以确定应用它们的顺序。如果规则的准确性没有改变，则需要决策树的树枝来解决。</p><p>C5.0 是 Quinlan 根据专有许可证发布的最新版本。它使用更少的内存，并建立比 C4.5 更小的规则集，同时更准确。</p><p>CART（Classification and Regression Trees （分类和回归树））与 C4.5 非常相似，但它不同之处在于它支持数值目标变量（回归），并且不计算规则集。CART 使用在每个节点产生最大信息增益的特征和阈值来构造二叉树。</p><p>scikit-learn 使用 CART 算法的优化版本。</p></blockquote><p><strong>Decision Trees (DTs)</strong> 是一种用来 <a href="http://sklearn.apachecn.org/cn/0.19.0/modules/tree.html#tree-classification">classification</a> 和 <a href="http://sklearn.apachecn.org/cn/0.19.0/modules/tree.html#tree-regression">regression</a> 的无参监督学习方法。其目的是创建一种模型从数据特征中学习简单的决策规则来预测一个目标变量的值。 </p><p><img src="/2018/11/23/机器在学习-决策树-Dicision-Tree/credit_scoring_toy_tree_english.png" alt="credit_scoring_toy_tree_english"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build</span><span class="params">(L)</span>:</span></span><br><span class="line">    create node t</span><br><span class="line">    <span class="keyword">if</span> the stopping criterion <span class="keyword">is</span> <span class="keyword">True</span>:</span><br><span class="line">        assign a predictive model to t</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        Find the best binary split L = L_left + L_right</span><br><span class="line">        t.left = build(L_left)</span><br><span class="line">        t.right = build(L_right)</span><br><span class="line">    <span class="keyword">return</span> t</span><br></pre></td></tr></table></figure><h3 id="决策树的递归返回"><a href="#决策树的递归返回" class="headerlink" title="决策树的递归返回"></a>决策树的递归返回</h3><ul><li>(1) 当前结点包含的样本全属于同一类别，无需划分; </li><li>(2) 当前属性集为空，或是所有样本在所有属性上取值相同，无法划分; </li><li>(3) 当前结点包含的样本集合为空，不能划分.</li></ul><h3 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h3><ul><li><p>信息熵（香农）： $E(D) = -\sum_k p_klog_2p_k$</p></li><li><p>增益： $IG(D,a) = E(D) - \sum_v \frac{|D^v|}{|D|}E(D^v)$</p><p><img src="/2018/11/23/机器在学习-决策树-Dicision-Tree/topic3_credit_scoring_entropy.png" alt="scoring_entropy"></p><blockquote><ol><li>信息增益可以衡量使用某个属性划分的好坏；</li><li>信息增益准则对可能取值数目较多的属性有偏好，为减少这种偏好带来的不利影响，C4.5决策树算法使用增益率来选择最优划分属性。</li></ol></blockquote></li><li><p>增益率： $G_r(D,a)=\frac{IG(D,a)}{IV(a)}$</p><script type="math/tex; mode=display">IV(a) =\sum_v \frac{|D^v|}{|D|}log_2\frac{|D^v|}{|D|}</script></li></ul><h3 id="Gini"><a href="#Gini" class="headerlink" title="Gini"></a>Gini</h3><script type="math/tex; mode=display">Gini(D)=1-\sum_k p^2_k</script><blockquote><p>CART决策树使用的算法,Gini数值约小，数据集D的纯度越高。</p></blockquote><p><img src="/2018/11/23/机器在学习-决策树-Dicision-Tree/Criteria of quality as a function of binary classification.png" alt="Criteria of quality as a function of binary classification"></p><h3 id="剪枝（pruning）"><a href="#剪枝（pruning）" class="headerlink" title="剪枝（pruning）"></a>剪枝（pruning）</h3><ul><li><strong>预剪枝：</strong> （自顶向下） 预剪枝是指在决策树生成过程中，对每个结点在划 分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶结点;</li><li><strong>后剪枝：</strong>（自底向上）后剪枝则是先从训练集生成一棵完整的决策树， 然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为叶结点.</li></ul><blockquote><p>预剪枝减少了计算量，减少了过拟合，但存在欠拟合的风险；</p><p>后剪枝是自底向上的对树中所有非叶节点进行逐一考察，训练开销比预剪枝要大很多。</p></blockquote><h3 id="一些处理技巧"><a href="#一些处理技巧" class="headerlink" title="一些处理技巧"></a>一些处理技巧</h3><h4 id="处理连续值"><a href="#处理连续值" class="headerlink" title="处理连续值"></a>处理连续值</h4><ul><li>连续属性离散化技术（二分法）；</li><li>对训练样本值排序，查找最大信息增益的分割点（对结果影响大的点），划分为多个连续区间；</li><li>如果训练样本某个属性不同样本值特别多，可以选择top-N增益最大的点作为划分分类的点；</li></ul><h4 id="处理缺失值"><a href="#处理缺失值" class="headerlink" title="处理缺失值"></a>处理缺失值</h4><ul><li>根据缺失值赋权；</li></ul><h4 id="多变量决策树"><a href="#多变量决策树" class="headerlink" title="多变量决策树"></a>多变量决策树</h4><ul><li>组合多个变量，可以形成非与坐标轴平行的分类边界；</li></ul><h4 id="回归树"><a href="#回归树" class="headerlink" title="回归树"></a>回归树</h4><script type="math/tex; mode=display">\Large D = \frac{1}{\ell} \sum\limits_{i =1}^{\ell} (y_i - \frac{1}{\ell} \sum\limits_{j=1}^{\ell} y_j)^2</script><p>where $\ell$ is the number of samples in a leaf, $y_i$ is the value of the target variable.</p><h2 id="决策树算法的优缺点"><a href="#决策树算法的优缺点" class="headerlink" title="决策树算法的优缺点"></a>决策树算法的优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ol><li>可解释性强，决策树的计算原理和人做决策的过程十分类似，是解释性最强的机器学习模型；</li><li>可视化方便，计算过程可以在图中直观的反映出来；</li><li>训练和预测都十分迅速，计算代价小；</li><li>训练需要的数据少。其他机器学习模型通常需要数据规范化，比如构建虚拟变量和移除缺失值,不过请注意，这种模型不支持缺失值。</li><li>超参十分少，常用的只有层数、叶子节点中元素个数、最大特征数等少数几个超参；</li><li>对于连续变量、离散变量、分类问题和回归问题都可以处理。</li></ol><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ol><li>对噪声数据敏感，训练数据发生轻微变动，可能导致整个模型参数发生很大变化；</li><li>分割界面只能平行或垂直坐标轴方向，处理逻辑太过简单；</li><li>需要特别注意过拟合的发生；决策树模型容易产生一个过于复杂的模型,这样的模型对数据的泛化性能会很差。这就是所谓的过拟合.一些策略像剪枝、设置叶节点所需的最小样本数或设置数的最大深度是避免出现 该问题最为有效地方法。</li><li>稳定性差；因为数据中的微小变化可能会导致完全不同的树生成。这个问题可以通过决策树的集成来得到缓解 </li><li>最优决策树的选择是一个NP-完备问题。需要使用一些启发式算法寻找最优的信息增益，但未必能找到最优值；这个问题可以通过集成学习来训练多棵决策树来缓解,这多棵决策树一般通过对特征和样本有放回的随机采样来生成。 </li><li>缺失数据的处理比较麻烦；</li><li>数据集没有覆盖的区域，没有区分能力</li><li>有些概念很难被决策树学习到,因为决策树很难清楚的表述这些概念。例如XOR，奇偶或者复用器的问题。</li></ol><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><blockquote><p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"><code>sklearn.tree.DecisionTreeClassifier</code></a></p><ul><li><code>max_depth</code> – the maximum depth of the tree;</li><li><code>max_features</code> - the maximum number of features with which to search for the best partition (this is necessary with a large number of features because it would be “expensive” to search for partitions for <em>all</em> features);</li><li><code>min_samples_leaf</code> – the minimum number of samples in a leaf. This parameter prevents creating trees where any leaf would have only a few members.</li></ul><p><a href="http://sklearn.apachecn.org/cn/0.19.0/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor"><code>DecisionTreeRegressor</code></a> </p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Sklearn</span></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line">clf_tree = DecisionTreeClassifier(criterion=<span class="string">'entropy'</span>, max_depth=<span class="number">3</span>, </span><br><span class="line">                                  random_state=<span class="number">17</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># training the tree</span></span><br><span class="line">clf_tree.fit(train_data, train_labels)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line">tree_pred = tree.predict(X_holdout)</span><br><span class="line">accuracy_score(y_holdout, tree_pred) <span class="comment"># 0.94</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 超参</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV, cross_val_score</span><br><span class="line"></span><br><span class="line">tree_params = &#123;<span class="string">'max_depth'</span>: range(<span class="number">1</span>,<span class="number">11</span>),</span><br><span class="line">               <span class="string">'max_features'</span>: range(<span class="number">4</span>,<span class="number">19</span>)&#125;</span><br><span class="line"></span><br><span class="line">tree_grid = GridSearchCV(tree, tree_params,</span><br><span class="line">                         cv=<span class="number">5</span>, n_jobs=<span class="number">-1</span>, verbose=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">tree_grid.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">accuracy_score(y_holdout, tree_grid.predict(X_holdout)) <span class="comment">#0.946</span></span><br></pre></td></tr></table></figure><h3 id="画图"><a href="#画图" class="headerlink" title="画图"></a>画图</h3><p>经过训练，我们可以使用 <a href="http://sklearn.apachecn.org/cn/0.19.0/modules/generated/sklearn.tree.export_graphviz.html#sklearn.tree.export_graphviz"><code>export_graphviz</code></a> 导出器以 <a href="http://www.graphviz.org/">Graphviz</a> 格式导出决策树. 如果你是用 <a href="http://conda.io/">conda</a> 来管理包，那么安装 graphviz 二进制文件和 python 包可以用以下指令安装</p><blockquote><p>conda install python-graphviz</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pydotplus <span class="comment">#pip install pydotplus</span></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> export_graphviz</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tree_graph_to_png</span><span class="params">(tree, feature_names, png_file_to_save)</span>:</span></span><br><span class="line">    tree_str = export_graphviz(tree, feature_names=feature_names, </span><br><span class="line">                                     filled=<span class="keyword">True</span>, out_file=<span class="keyword">None</span>)</span><br><span class="line">    graph = pydotplus.graph_from_dot_data(tree_str)  </span><br><span class="line">    graph.write_png(png_file_to_save)</span><br><span class="line">    </span><br><span class="line">  tree_graph_to_png(tree=clf_tree, feature_names=[<span class="string">'x1'</span>, <span class="string">'x2'</span>], </span><br><span class="line">                  png_file_to_save=<span class="string">'../../img/topic3_tree1.png'</span>)</span><br></pre></td></tr></table></figure><p><img src="/2018/11/23/机器在学习-决策树-Dicision-Tree/tree1.png" alt="tree1"></p><h3 id="技巧"><a href="#技巧" class="headerlink" title="技巧"></a>技巧</h3><blockquote><ul><li>对于拥有大量特征的数据决策树会出现过拟合的现象。获得一个合适的样本比例和特征数量十分重要，因为在高维空间中只有少量的样本的树是十分容易过拟合的。</li><li>考虑事先进行降维( <a href="http://sklearn.apachecn.org/cn/0.19.0/modules/decomposition.html#pca">PCA</a> , <a href="http://sklearn.apachecn.org/cn/0.19.0/modules/decomposition.html#ica">ICA</a> ，使您的树更好地找到具有分辨性的特征。</li><li>通过 <code>export</code> 功能可以可视化您的决策树。使用 <code>max_depth=3</code> 作为初始树深度，让决策树知道如何适应您的数据，然后再增加树的深度。</li><li>请记住，填充树的样本数量会增加树的每个附加级别。使用 <code>max_depth</code> 来控制输的大小防止过拟合。</li><li>通过使用 <code>min_samples_split</code> 和 <code>min_samples_leaf</code> 来控制叶节点上的样本数量。当这个值很小时意味着生成的决策树将会过拟合，然而当这个值很大时将会不利于决策树的对样本的学习。所以尝试 <code>min_samples_leaf=5</code> 作为初始值。如果样本的变化量很大，可以使用浮点数作为这两个参数中的百分比。两者之间的主要区别在于 <code>min_samples_leaf</code> 保证叶结点中最少的采样数，而 <code>min_samples_split</code> 可以创建任意小的叶子，尽管在文献中 <code>min_samples_split</code> 更常见。</li><li>在训练之前平衡您的数据集，以防止决策树偏向于主导类.可以通过从每个类中抽取相等数量的样本来进行类平衡，或者优选地通过将每个类的样本权重 (<code>sample_weight</code>) 的和归一化为相同的值。还要注意的是，基于权重的预修剪标准 (<code>min_weight_fraction_leaf</code>) 对于显性类别的偏倚偏小，而不是不了解样本权重的标准，如 <code>min_samples_leaf</code> 。</li></ul></blockquote><ul><li>如果样本被加权，则使用基于权重的预修剪标准 <code>min_weight_fraction_leaf</code> 来优化树结构将更容易，这确保叶节点包含样本权重的总和的至少一部分。</li><li>所有的决策树内部使用 <code>np.float32</code> 数组 ，如果训练数据不是这种格式，将会复制数据集。</li><li>如果输入的矩阵X为稀疏矩阵，建议您在调用fit之前将矩阵X转换为稀疏的<code>csc_matrix</code> ,在调用predict之前将 <code>csr_matrix</code> 稀疏。当特征在大多数样本中具有零值时，与密集矩阵相比，稀疏矩阵输入的训练时间可以快几个数量级。</li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><p>《机器学习》——周志华</p></li><li><p><a href="https://mlcourse.ai/">mlcourse.ai</a> – Open Machine Learning Course</p></li></ol><p>3.<a href="http://sklearn.apachecn.org/cn/0.19.0/modules/tree.html#tree">Sklearn 决策树</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/qnsource/banner/15.jpg&quot; alt=&quot;Test Picture&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://blog.a-stack.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
  </entry>
  
</feed>
