<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Ebby&#39;s Notes</title>
  
  <subtitle>=Blog for AI Learning=</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://blog.a-stack.com/"/>
  <updated>2018-09-29T09:41:43.630Z</updated>
  <id>http://blog.a-stack.com/</id>
  
  <author>
    <name>Ebby DD</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>读书笔记：Machine Learning Yearning</title>
    <link href="http://blog.a-stack.com/2018/09/29/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%9AMachine-Learning-Yearning/"/>
    <id>http://blog.a-stack.com/2018/09/29/读书笔记：Machine-Learning-Yearning/</id>
    <published>2018-09-29T02:00:21.000Z</published>
    <updated>2018-09-29T09:41:43.630Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/2018/09/29/读书笔记：Machine-Learning-Yearning/MachineLearningYearning.jpg" alt="Machine Learning Yearning"></p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>《Machine Learning Yearning》是Andrew Ng写的一本在深度学习领域偏重工程实践的小册子，终于在九月底把坑填完了，有需要的可以在其<a href="http://www.mlyearning.org/" target="_blank" rel="noopener">官网</a>索取,或者直接通过该地址下载<a href="https://gallery.mailchimp.com/dc3a7ef4d750c0abfc19202a3/files/514ed488-bcae-4924-8fd8-dcabeec2e440/Ng_MLY13.pdf" target="_blank" rel="noopener">目前的版本</a>。从吴恩达开始撰写前面几章时我便订阅了相关邮件，持续跟进文章内容，这本小册子可以配合deeplearning.ai的深度学习课程一起学习，效果更佳。本文简单的记录一下阅读过程中一些的新的收货。</p><h2 id="端到端学习的选择"><a href="#端到端学习的选择" class="headerlink" title="端到端学习的选择"></a>端到端学习的选择</h2><p>深度学习与传统机器学习算法的一个主要差异，在于它本质上是一个端到端的学习过程，不再需要或很少需要手工特征的介入。但端到端学习真的好么？适用于所有的业务场景么？</p><p>深度学习的端到端学习策略有效是建立在足够训练数据的基础上的，当数据量有限的情况下，手工特征的过程有助于加速网络收敛和限制网络的发散。而当存在足够的训练数据</p><h2 id="错误分析"><a href="#错误分析" class="headerlink" title="错误分析"></a>错误分析</h2><p>由于模型的复杂性，导致在深度神经网络中，出现误差或错误可能来自于多个方面，甚至是多个方面的共同作用结果，所以制定合理的错误分析策略对于寻找问题根源和优化模型效果至关重要。</p><ul><li>错误分析的过程，本质上还是一个控制变量法的过程，保证其它相关变量的最优来聚焦所需要观测的变量信息；</li><li>错误分析针对那些人类自身可以做的很好的任务，比如图片分类、物体识别等，会有很好的效果，而对人类不擅长的，很难进一步的进行直接的错误分析；</li><li>当你把一个pipeline的各部分已经优化到极致的情况，如果整体模型效果依然不好时，你需要考虑是不是模型设计存在本质缺陷，如没有包含所有有效的相关因素，没有形成合理的推断流程；</li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li>​</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/2018/09/29/读书笔记：Machine-Learning-Yearning/MachineLearningYearning.jpg&quot; alt=&quot;Machine Learning Yearning&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;概述&quot;&gt;&lt;a hre
      
    
    </summary>
    
      <category term="读书笔记" scheme="http://blog.a-stack.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="工程实践" scheme="http://blog.a-stack.com/tags/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/"/>
    
      <category term="教学" scheme="http://blog.a-stack.com/tags/%E6%95%99%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>HMM与Veterbi算法</title>
    <link href="http://blog.a-stack.com/2018/08/28/HMM%E4%B8%8EVeterbi%E7%AE%97%E6%B3%95/"/>
    <id>http://blog.a-stack.com/2018/08/28/HMM与Veterbi算法/</id>
    <published>2018-08-28T08:53:06.000Z</published>
    <updated>2018-08-28T09:26:36.540Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/qnsource/banner/13.jpg" alt="Test Picture"></p><p><strong>摘要：</strong></p><a id="more"></a><h2 id="从概率图模型谈起"><a href="#从概率图模型谈起" class="headerlink" title="从概率图模型谈起"></a>从概率图模型谈起</h2><p>概率模型(probabilistic model)提供了一种描述框架，将学习任务归结于计算变量的概率分布。在概 率模型中，利用已知变量推测未知变量的分布称为”推断” (inference)，其 核心是如何基于可观测变量推测出未知变量的条件分布具体来说，假定所关心的变量集合为Y,可观测变量集合为 O，其他变量的集合为 R，”生成式” (generative)模型考虑联合分布 P(Y，R，O) ， “判别式” (discriminative)模 型考虑条件分布 P(Y，R I O)。给定一组观测变量值，推断就是要由 P(Y ,R,O) 或 P(Y, R |O) 得到条件概率分布 P(Y I O)。</p><p>概率图是一类利用图来表达变量相关关系的概率模型。若变量之间存在显示的因果关系，则常用贝叶斯网络（有向图模型）；若变量之间存在相关性，但难以获得显示的因果关系，则常使用马尔可夫网络（无向图模型）。</p><h2 id="HMM"><a href="#HMM" class="headerlink" title="HMM"></a>HMM</h2><p>隐马尔科夫模型（Hidden Markov Model, HMM）是结构最简单的动态贝叶斯网络，主要用于时序数据建模，应用于语音识别、自然语言处理等领域。</p><h3 id="马尔可夫假设"><a href="#马尔可夫假设" class="headerlink" title="马尔可夫假设"></a>马尔可夫假设</h3><ol><li>系统下一时刻的状态仅有当前状态决定，不依赖于以往的任何状态，即<script type="math/tex; mode=display">P(x_1,y_1,...,x_n,y_n)=P(y_1)P(x_1|y_1)</script></li></ol><h3 id="三个基本问题"><a href="#三个基本问题" class="headerlink" title="三个基本问题"></a>三个基本问题</h3><ol><li>概率计算问题： 给定模型，如何有效计算产生关测序列的概率$P(x|\lambda)$，可以利用求解结果求未来的观测数据值；</li><li>预测/解码问题： 给定模型和观测序列$x$，如何找到于此观测序列最匹配的状态序列$y$, $P(y|0)$；</li><li>学习问题： 给定观测序列$x$，如何调整模型参数，使得该序列出现的概率$P(x|\lambda)$ 最大，即如何训练模型使其能更好的描述观测数据；</li></ol><h2 id="Viterbi算法"><a href="#Viterbi算法" class="headerlink" title="Viterbi算法"></a>Viterbi算法</h2><p><img src="/2018/08/28/HMM与Veterbi算法/Viterbi_animated_demo.gif" alt="Viterbi_animated_demo"></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li>《统计学习方法》—李航</li><li>《机器学习》—周志华</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/qnsource/banner/13.jpg&quot; alt=&quot;Test Picture&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://blog.a-stack.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
  </entry>
  
  <entry>
    <title>读书笔记:数学之美</title>
    <link href="http://blog.a-stack.com/2018/08/26/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BE%8E/"/>
    <id>http://blog.a-stack.com/2018/08/26/读书笔记-数学之美/</id>
    <published>2018-08-26T11:25:58.000Z</published>
    <updated>2018-08-27T13:50:02.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/2018/08/26/读书笔记-数学之美/数学之美.jpg" alt="数学之美"></p><ul><li><p>作者： 吴军</p></li><li><p>2014年11月第二版</p></li><li><p>北京：人民邮电出版社</p><hr><a id="more"></a></li></ul><p>时隔多年，在人工智能概念进入鼎盛时期的今天，花一个周末，细细品读了吴军先生的《数学之美》，又有了不少新的感悟，新的收货，稍作整理，便于复查。</p><p>此次重读恰逢归纳自然语言处理相关技术和脉络，而吴军本身就是这个学科的专家，所以其著作中对相关内容的描述条例清晰，结构完备，值得思考。</p><h2 id="经典语句摘录"><a href="#经典语句摘录" class="headerlink" title="经典语句摘录"></a>经典语句摘录</h2><blockquote><p><strong>WWW发明人蒂姆.伯纳斯。李：</strong></p><p>简单性和模块化是软件工程的基石；分布式和容错性是互联网的生命。</p></blockquote><h2 id="自然语言处理"><a href="#自然语言处理" class="headerlink" title="自然语言处理"></a>自然语言处理</h2><h3 id="从历史看：语言、数字、文字都是信息的载体，或是对信息的编码"><a href="#从历史看：语言、数字、文字都是信息的载体，或是对信息的编码" class="headerlink" title="从历史看：语言、数字、文字都是信息的载体，或是对信息的编码"></a>从历史看：语言、数字、文字都是信息的载体，或是对信息的编码</h3><p>从人来进化角度来看，先有的语言（声音元素最先），再有的数字，然后是文字。目的都在于方便人与人之间通信（传递信息）。</p><p>早期人来了解和需要传递的信息十分有限，因此不需要高级的语言或者数字、文字来进行表达。但随着人类的进化和文明的发展，需要表达的信息越来越多，不再是几种不同的声音就能够完全覆盖，语言就此产生。知识也通过口述的方式，逐代传递。</p><p>我们祖先迅速学习新鲜事物，语言越来越丰富，内容越来越抽象，语言描述的共同要素，比如某些物体、数量、行为动作便被抽象出来形成了<strong>词汇</strong>。当语言和词汇多到一定程度，人类靠大脑已经记不住所有词汇，于是高效记录信息的需求就产生了，这便是文字的起源。</p><blockquote><p>由此可见，产品果真是由需求决定的！</p></blockquote><p>最初文字的词汇依靠模拟/模仿物体或行为形成的象形文字来展现，但随着文明进步，信息量逐步增加，象形文字数目不再随着文明发展而增加了，因为没人能够记住这么多的文字。于是，概念的第一次概括和归类开始了。比如“日”除了表示太阳，还可以表示一天。</p><blockquote><p>在那个时间，人类就已经领会了聚类算法的精髓 …只不过由于“算力不足”，这个聚类的过程一般持续几千年才能收敛到合适的位置。</p></blockquote><p>聚类虽然减少了表达信息的文字数量，却带来了一个严重的问题——歧义性。多义字在一段文字中的表达需要依靠上下文推理来完成去除歧义。</p><blockquote><p>虽然经过训练的人类可以很好的依靠理解消除歧义，但苦了计算机模型，需要打破状态无记忆的机理，沿着上下文的思路去解决问题。可见这是语言产生伊始就埋的一个坑。</p></blockquote><h4 id="不同文明在信息的维度上是等价的"><a href="#不同文明在信息的维度上是等价的" class="headerlink" title="不同文明在信息的维度上是等价的"></a>不同文明在信息的维度上是等价的</h4><p>虽然受地域和文明发展进度差异影响，不同文明发明了不同的语言和文字，但本质上都是一种对信息的编码方式，所以可以通过一定的手段进行翻译的。</p><blockquote><p>文字是信息的载体，而非信息本身。</p></blockquote><h4 id="罗塞塔"><a href="#罗塞塔" class="headerlink" title="罗塞塔"></a>罗塞塔</h4><p>古埃及罗塞塔的石碑记录了最早的象形文字多语平行语料库，上面有三种语言：埃及象形文字、埃及拼音文字和古希腊文。因此Google的机器翻译项目也被命名为罗塞塔。</p><p><img src="/2018/08/26/读书笔记-数学之美/罗塞塔石碑.jpg" alt="罗塞塔石碑"></p><blockquote><p><strong>百度百科解读：</strong></p><p>罗塞塔<a href="https://baike.baidu.com/item/%E7%9F%B3%E7%A2%91/36268" target="_blank" rel="noopener">石碑</a>（Rosetta Stone，也译作罗塞达碑），高1.14米，宽0.73米，制作于公元前196年，刻有<a href="https://baike.baidu.com/item/%E5%8F%A4%E5%9F%83%E5%8F%8A/226771" target="_blank" rel="noopener">古埃及</a>国王<a href="https://baike.baidu.com/item/%E6%89%98%E5%8B%92%E5%AF%86%E4%BA%94%E4%B8%96/3481978" target="_blank" rel="noopener">托勒密五世</a>登基的诏书。石碑上用<a href="https://baike.baidu.com/item/%E5%B8%8C%E8%85%8A%E6%96%87%E5%AD%97/12722009" target="_blank" rel="noopener">希腊文字</a>、<a href="https://baike.baidu.com/item/%E5%8F%A4%E5%9F%83%E5%8F%8A%E6%96%87%E5%AD%97/2494489" target="_blank" rel="noopener">古埃及文字</a>和当时的通俗体文字刻了同样的内容，这使得近代的<a href="https://baike.baidu.com/item/%E8%80%83%E5%8F%A4%E5%AD%A6%E5%AE%B6/1217571" target="_blank" rel="noopener">考古学家</a>得以有机会对照各语言<a href="https://baike.baidu.com/item/%E7%89%88%E6%9C%AC/505574" target="_blank" rel="noopener">版本</a>的内容后，解读出已经失传千余年的埃及象形文之意义与结构，而成为今日研究古埃及历史的重要里程碑。 </p></blockquote><h4 id="数字产生及编码"><a href="#数字产生及编码" class="headerlink" title="数字产生及编码"></a>数字产生及编码</h4><p>数字产生与文字类似，当人类发展到一定程度，需要计数系统来进行计算的时候便产生了信息的载体数字。当然，早期数字没有书写的形式，而是掰指头，这就是今天我们使用十进制的原因。</p><blockquote><p>玛雅文明使用的是二十进制（手脚都算上…）</p></blockquote><p>罗马人用字符I代表1，V代表5，X代表10，L代表50，C代表100，D代表500，M代表1000，解码规则是加减法（中国解码规则是乘法），小数字出现在大数字左边为减，右边为加。比如IIXX（10+10-1-1=18），如果要用罗马数字表示100万 …</p><p>阿拉伯数字最初由古印度人发明，由阿拉伯人传入欧洲，被中间商冠名了。</p><h4 id="从象形文字到楔形文字"><a href="#从象形文字到楔形文字" class="headerlink" title="从象形文字到楔形文字"></a>从象形文字到楔形文字</h4><p>楔形文字又称拼音文字，是一个很大的进化，人类在描述物体的方式上，从外表化到了抽象概念的层级，是一种高效的信息编码方式。比如，常用字短，生僻字长就是符合最短编码原理的一种实现。</p><h4 id="语言与语法"><a href="#语言与语法" class="headerlink" title="语言与语法"></a>语言与语法</h4><p>词可以被认为是有限而且封闭的集合，而语言则是无限开放的集合；从数学上讲，前者可以由完备的编码规则，后者则不具备。</p><p>任何一种语言都是一种信息的编码方式；</p><p>语法可以认为是解码的规则，但很多时候文章的撰写不完全符合语法，比如鲁迅先生的文字。</p><p>语言vs语法： 语言简直从真实的语句文本（称为语料）出发，而后者坚持从规则出发；经过三四十年的争论，最后实践证明，自然语言的成就最终宣布了前者的胜利。</p><h3 id="自然语言发展的两个阶段：从规则到统计"><a href="#自然语言发展的两个阶段：从规则到统计" class="headerlink" title="自然语言发展的两个阶段：从规则到统计"></a>自然语言发展的两个阶段：从规则到统计</h3><p><img src="/2018/08/26/读书笔记-数学之美/信息传输.jpeg" alt="信息传输"></p><p><img src="/2018/08/26/读书笔记-数学之美/4组织语言.png" alt="4组织语言"></p><blockquote><p>我们要把一个意思表达出来，通过某种语言的一句话表述出来就是用这种语言的编码方式对头脑中的信息做了一次编码，编码结果就是一串文字；而如果对方懂得这么语言，他就可以利用这么语言的语法解码处说话人想表达的意思。</p></blockquote><h4 id="NLP的历史"><a href="#NLP的历史" class="headerlink" title="NLP的历史"></a>NLP的历史</h4><ul><li><p>1950年，图灵提出的图灵测试可以作为NLP的开始；</p></li><li><p>20世纪50年代到70年代，计算机处理NLP问题的认识都局限在人类学习语言的方式上，也就是用电脑模拟人脑，这20多年的成果近乎为零，其中由大量的语言学家参与其中；</p><ul><li>让计算机理解自然语言，必须让计算机拥有类似人类的智能；</li><li>更多的采用仿生学的方法解决问题；</li><li>为什么会有这种错误的认识？ 因为人类就是这么做的，这就是直觉的作用；</li><li>这样的方法被称为“鸟飞派”（怀特兄弟发明飞机靠的是空气动力学而不是仿生学）；</li><li>手段是：句法分析和语义分析<ul><li>分析句法结构，建立文法规则</li><li>20世纪80年代以前，NLP的文法规则都是由人工总结完成的</li><li>有两大困难：<ul><li>为了覆盖哪怕20%的真实语句，文法规则需要至少几万条；语言学家来不及写；更可怕的是，写到后面出现了各种矛盾，为了解决矛盾需要为规则建立限定规则；如果要覆盖50%的语句，文法规则会多到每增加一个语句，需要添加一条规则；（正如英语语法学的再好，不练习，不看文献，照样看不懂英文电影）</li><li>计算机解析规则困难重重，计算机解码方式是上下文无关的，而NLP都是复杂的上下文有关的文法；前者算法复杂度为语句长度的二次方，后者是语句长度的六次方；</li></ul></li></ul></li></ul><p><img src="/2018/08/26/读书笔记-数学之美/句法分析树.png" alt="句法分析树"></p></li><li><p>20世纪70年代，开始使用统计方法和数学模型解决NLP问题</p><ul><li>语义方面的多义性也遇到了困难；</li><li>贾里尼克和他领导的IBM华生实验室（T.J. Watson）采用基于统计的方法解决语音识别取得了突破；感染了许多研究人员转投统计领域；比如李开复和洪小文；</li><li>但基于规则和基于统计的争执还是持续了15年左右，直到20世纪90年代才分出胜负<ul><li>基于统计方法的核心模型是通信系统+隐马尔科夫模型，最早成功的领域是语音识别、词性分析（一维符号序列），机器翻译和句法分析输入是一维，输出是多维或乱序信息，简单应用不管用；同时数据量不足，发展不是很快；</li><li>传统方法认为基于统计的方法只能处理浅层的自然语言问题，无法进入深层次研究；</li><li>随着计算力的提高和数据量的增加，一切变的不一样了，2005年随着Google机器翻译战胜SysTran,最后一个领域也被统计方法攻占；</li><li>另一个重要原因，用基于统计的方法替代传统方法，需要等原有的一批语言学家退休；</li></ul></li></ul></li></ul><blockquote><p>类比到我们学习英语的过程,当时教授课程过程还是以英语语法、词性和构词法为主，主谓宾、定状补；而我基本上都这些语法缺乏概念，更多的是靠语感在做题目，这是建立在读了大量英语文献基础上，也是一种基于统计的预测算法。</p></blockquote><h4 id="统计语言模型"><a href="#统计语言模型" class="headerlink" title="统计语言模型"></a>统计语言模型</h4><p>统计语言模型的目的在于为计算机建立一种具备上下文相关的数学模型。</p><p>自然语言处理过程可以简单的认为是判断一句话是不是自然语句，以前是通过语法规则来判断的，统计语言模型是通过概率来衡量的。</p><h4 id="马尔可夫"><a href="#马尔可夫" class="headerlink" title="马尔可夫"></a>马尔可夫</h4><p>马尔可夫假设认为一个词出现的概率只与它前面一个词有关，形成二元模型；如果跟前面两个词有关就是三元模型(二阶马尔可夫模型)。</p><p>这样一个句子出现的概率可以表示为：</p><script type="math/tex; mode=display">P(S) = P(w_1)*P(w_2|w_1)*P(w_3|w_2)*...*P(w_n|w_{n-1})</script><blockquote><p>关于N元模型：</p><p>N越大效果越好，但需要的计算量越大，N元模型的空间复杂度几乎是N的指数函数$O(|V|^N)$,其中$|V|$是语言词典的词汇量，一般几万到几十万个。</p><p>当N从3到4时，其实模型效果的提升已经不是十分明显了。</p><p>Google的罗塞塔翻译使用了四元模型，存储与至少500台Google服务器中，当然2017年也被神经翻译机替代了。</p></blockquote><p>马尔可夫的局限性： 由于文本的上下文信息可能跳跃性存在，所以当N不是十分大的情况下，无法覆盖所有的语言现象。需要具备一定记忆性的单元来完成长期记忆的存储。</p><blockquote><p>关于语料库的覆盖问题：</p><p>汉语词汇量大概20万，训练一个三元模型产生$200000^3=8X10^{15}$个参数；</p><p>加深互联网中抛去垃圾数据，有100亿个有意义的中文网页，每个网页平均1000个词，即使爬取所有的词只有$10^{13}$个语料词汇。大部分条件概率为零。</p><ul><li>卡茨退避法，拿出一部分概率给语料库为出现的词，同时调低低频词的概率；</li><li>线性插值法</li></ul></blockquote><h3 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h3><p>词是表达语义的最小单位；对于拼音语言来说，由于词之间有明确的分界符，统计和使用语言模型非常直接。</p><ul><li>最简单的分词方法是查词典，遇到复合词进行最长词匹配；<ul><li>对于二义性的分割没法解决；</li><li>“发展中国家”==发展 中国 家</li><li>“上海大学城” == 上海大学 城 书店</li><li>“北京大学生” == 北京大学 生</li></ul></li><li>统计方法：保证分完词之后这个句子出现的概率最大<ul><li>求解过程可以建模成动态规划问题</li></ul></li><li>但是，并不是所有的语句都有分词结果的，比如：<ul><li>此地安能居住，其人好不悲伤</li><li>下雨天留客天天留我不留</li></ul></li><li>中文分词技术后来还用于了英文手写字的分词；</li><li>分词问题已经属于解决了的问题，目前没有太多值得深入研究的技术领域了，除了偶尔增加一些新词</li></ul><h3 id="隐马尔科夫模型（HMM）"><a href="#隐马尔科夫模型（HMM）" class="headerlink" title="隐马尔科夫模型（HMM）"></a>隐马尔科夫模型（HMM）</h3><p>隐马尔科夫模型（Hidden Markov Model，以下简称HMM）是比较经典的机器学习模型了，它在语言识别，自然语言处理，模式识别等领域得到广泛的应用。当然，随着目前深度学习的崛起，尤其是<a href="http://www.cnblogs.com/pinard/p/6509630.html" target="_blank" rel="noopener">RNN</a>，<a href="http://www.cnblogs.com/pinard/p/6519110.html" target="_blank" rel="noopener">LSTM</a>等神经网络序列模型的火热，HMM的地位有所下降。</p><p>使用HMM模型时我们的问题一般有这两个特征：１）我们的问题是基于序列的，比如时间序列，或者状态序列。２）我们的问题中有两类数据，一类序列数据是可以观测到的，即观测序列；而另一类数据是不能观察到的，即隐藏状态序列，简称状态序列。</p><p>马尔可夫的求解过程就是从观测序列推断出隐藏序列的过程。</p><h3 id="最大熵模型"><a href="#最大熵模型" class="headerlink" title="最大熵模型"></a>最大熵模型</h3><h3 id="Viterbi算法"><a href="#Viterbi算法" class="headerlink" title="Viterbi算法"></a>Viterbi算法</h3><h2 id="信息论"><a href="#信息论" class="headerlink" title="信息论"></a>信息论</h2><h2 id="搜索引擎"><a href="#搜索引擎" class="headerlink" title="搜索引擎"></a>搜索引擎</h2><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://www.cnblogs.com/pinard/p/6945257.html" target="_blank" rel="noopener">https://www.cnblogs.com/pinard/p/6945257.html</a></li><li></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/2018/08/26/读书笔记-数学之美/数学之美.jpg&quot; alt=&quot;数学之美&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;作者： 吴军&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;2014年11月第二版&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;北京：人民邮电出版社&lt;/p&gt;
&lt;hr&gt;&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
      <category term="读书笔记" scheme="http://blog.a-stack.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="书籍" scheme="http://blog.a-stack.com/tags/%E4%B9%A6%E7%B1%8D/"/>
    
  </entry>
  
  <entry>
    <title>FastText-A better choice for word embedding?</title>
    <link href="http://blog.a-stack.com/2018/08/21/FastText-A-better-choice-for-word-embedding/"/>
    <id>http://blog.a-stack.com/2018/08/21/FastText-A-better-choice-for-word-embedding/</id>
    <published>2018-08-21T07:45:46.000Z</published>
    <updated>2018-08-28T14:08:26.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/qnsource/banner/10.jpg" alt="Test Picture"></p><p><strong>摘要：</strong></p><a id="more"></a><h2 id="FastText-vs-Word2vec"><a href="#FastText-vs-Word2vec" class="headerlink" title="FastText vs Word2vec"></a>FastText vs Word2vec</h2><p>fastText的架构和word2vec中的CBOW的架构类似，因为它们的作者都是Facebook的科学家Tomas Mikolov，而且确实fastText也算是words2vec所衍生出来的。 </p><p>According to a detailed comparison of Word2Vec and FastText in <a href="https://render.githubusercontent.com/view/Word2Vec_FastText_Comparison.ipynb" target="_blank" rel="noopener">this notebook</a>, fastText does significantly better on syntactic tasks as compared to the original Word2Vec, especially when the size of the training corpus is small. Word2Vec slightly outperforms FastText on semantic tasks though. The differences grow smaller as the size of training corpus increases. Training time for fastText is significantly higher than the Gensim version of Word2Vec (<code>15min 42s</code> vs <code>6min 42s</code> on text8, 17 mil tokens, 5 epochs, and a vector size of 100). </p><p><img src="/2018/08/21/FastText-A-better-choice-for-word-embedding/fasttextVSword2vec.png" alt="fasttextVSword2vec"></p><blockquote><p><strong>重要：</strong></p><p>fastText can be used to obtain vectors for <strong>out-of-vocabulary (OOV)</strong> words, by summing up vectors for its component char-ngrams, provided at least one of the char-ngrams was present in the training data. </p></blockquote><p>FastText is an extension to Word2Vec proposed by Facebook in 2016. Instead of feeding individual words into the Neural Network, FastText breaks words into several n-grams (sub-words). For instance, the tri-grams for the word apple is <code>app</code>, <code>ppl</code>, and <code>ple</code>(ignoring the starting and ending of boundaries of words). The word embedding vector for apple will be the sum of all these n-grams. After training the Neural Network, we will have word embeddings for all the n-grams given the training dataset. Rare words can now be properly represented since it is highly likely that some of their n-grams also appears in other words. </p><h2 id="Training-Models"><a href="#Training-Models" class="headerlink" title="Training Models"></a>Training Models</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">importimport  gensimgensim</span><br><span class="line"> importimport  osos</span><br><span class="line"> fromfrom  gensim.models.word2vecgensim.  <span class="keyword">import</span> LineSentence</span><br><span class="line"><span class="keyword">from</span> gensim.models.fasttext <span class="keyword">import</span> FastText <span class="keyword">as</span> FT_gensim</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set file names for train and test data</span></span><br><span class="line">data_dir = <span class="string">'&#123;&#125;'</span>.format(os.sep).join([gensim.__path__[<span class="number">0</span>], <span class="string">'test'</span>, <span class="string">'test_data'</span>]) + os.sep</span><br><span class="line">lee_train_file = data_dir + <span class="string">'lee_background.cor'</span></span><br><span class="line">lee_data = LineSentence(lee_train_file)</span><br><span class="line"></span><br><span class="line">model_gensim = FT_gensim(size=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># build the vocabulary</span></span><br><span class="line">model_gensim.build_vocab(lee_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># train the model</span></span><br><span class="line">model_gensim.train(lee_data, total_examples=model_gensim.corpus_count, epochs=model_gensim.iter)</span><br><span class="line"></span><br><span class="line">print(model_gensim)</span><br><span class="line">----</span><br><span class="line">FastText(vocab=<span class="number">1763</span>, size=<span class="number">100</span>, alpha=<span class="number">0.025</span>)</span><br></pre></td></tr></table></figure><p>训练中使用的相关参数：</p><ul><li>model: Training architecture. Allowed values: <code>cbow</code>, <code>skipgram</code> (Default <code>cbow</code>) </li><li>size: Size of embeddings to be learnt (Default 100) </li><li>alpha: Initial learning rate (Default 0.025) </li><li>window: Context window size (Default 5) </li><li>min_count: Ignore words with number of occurrences below this (Default 5) </li><li>loss: Training objective. Allowed values: <code>ns</code>, <code>hs</code>, <code>softmax</code> (Default <code>ns</code>) </li><li>sample: Threshold for downsampling higher-frequency words (Default 0.001) </li><li>negative: Number of negative words to sample, for <code>ns</code> (Default 5) </li><li>iter: Number of epochs (Default 5) </li><li>sorted_vocab: Sort vocab by descending frequency (Default 1) </li><li>threads: Number of threads to use (Default 12) </li><li>min_n: min length of char ngrams (Default 3) </li><li>max_n: max length of char ngrams (Default 6) </li><li>bucket: number of buckets used for hashing ngrams (Default 2000000) </li></ul><h3 id="模型的存储与加载"><a href="#模型的存储与加载" class="headerlink" title="模型的存储与加载"></a>模型的存储与加载</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># saving a model trained via Gensim's fastText implementation</span></span><br><span class="line">model_gensim.save(<span class="string">'saved_model_gensim'</span>)</span><br><span class="line">loaded_model = FT_gensim.load(<span class="string">'saved_model_gensim'</span>)</span><br><span class="line">print(loaded_model)</span><br></pre></td></tr></table></figure><h2 id="Using-FastText"><a href="#Using-FastText" class="headerlink" title="Using FastText"></a>Using FastText</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> FastText</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model = FastText.load_fasttext_format(<span class="string">"./data/fasttext/cc.zh.300.bin"</span>)</span><br><span class="line">len(model.wv.vocab)</span><br><span class="line">w1 = <span class="string">"人工智能"</span></span><br><span class="line">w1 <span class="keyword">in</span> model.wv.vocab</span><br><span class="line">model.wv.most_similar(w1)</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/FastText_Tutorial.ipynb" target="_blank" rel="noopener">https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/FastText_Tutorial.ipynb</a></li><li><a href="https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/FastText_Tutorial.ipynb" target="_blank" rel="noopener">https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/FastText_Tutorial.ipynb</a></li><li><a href="https://radimrehurek.com/gensim/models/fasttext.html" target="_blank" rel="noopener">models.fasttext – FastText model</a></li><li><a href="https://towardsdatascience.com/fasttext-batteries-included-fa23f46d52e4" target="_blank" rel="noopener">https://towardsdatascience.com/fasttext-batteries-included-fa23f46d52e4</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/qnsource/banner/10.jpg&quot; alt=&quot;Test Picture&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://blog.a-stack.com/categories/NLP/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="词嵌入" scheme="http://blog.a-stack.com/tags/%E8%AF%8D%E5%B5%8C%E5%85%A5/"/>
    
      <category term="FastText" scheme="http://blog.a-stack.com/tags/FastText/"/>
    
  </entry>
  
  <entry>
    <title>弄懂word2vec之原理解析</title>
    <link href="http://blog.a-stack.com/2018/08/21/%E5%BC%84%E6%87%82word2vec%E4%B9%8B%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/"/>
    <id>http://blog.a-stack.com/2018/08/21/弄懂word2vec之原理解析/</id>
    <published>2018-08-21T05:36:53.000Z</published>
    <updated>2018-08-24T15:18:05.202Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/qnsource/banner/07.jpg" alt="Test Picture"></p><p><strong>摘要：</strong></p><a id="more"></a><h2 id="关键点提要"><a href="#关键点提要" class="headerlink" title="关键点提要"></a>关键点提要</h2><ul><li>word2vec不是深度学习模型（只有输入层、输出层）</li><li>效果并非最好，但易用性最强（其实FastText开源之后易用性直逼Word2vec）</li><li>受训练语料库影响大，尤其中文语料库本身缺乏</li></ul><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Word2vec核心算法包括CBOW和skip-gram，再加上两种目标优化方式层次Softmax和负采样的组合，可以形成总共四种实现方式。需要特别理解的一点，其实词向量是模型的中间产物（词向量矩阵在模型中为隐藏层的权重值）而不是优化目标产物。模型的训练数据为（sourceword，targetword）的词语对。本文简单整理近段时间通过翻看代码、原理解析总结的一些对word2vec的认知，希望能够加深对整合词嵌入模型的理解。</p><p><img src="/2018/08/21/弄懂word2vec之原理解析/word2vec_architectures.png" alt="word2vec_architectures"></p><p>其中</p><ul><li>CBOW的实现原理为由中心词来预测前后的相关词；</li><li>Skip-Gram正好相反，为由中心词的前后相关词来倒推中心词为某词的可能性；</li><li>无论哪种方法，都不需要事先对数据进行标记，换句话说这可以看作一种无监督的学习方法。</li></ul><blockquote><p>有相关研究也对两种方法的实现效果进行了比较，CBOW在小数据集上表现要优于Skip-Gram，在大数据集合上两者相当。</p></blockquote><p><img src="/2018/08/21/弄懂word2vec之原理解析/模型原理示意.png" alt="模型原理示意"></p><h2 id="训练数据的定义"><a href="#训练数据的定义" class="headerlink" title="训练数据的定义"></a>训练数据的定义</h2><blockquote><p>详见代码</p></blockquote><p>在生成训练数据之前先要明确窗口的概念，窗口的概念与n-gram中强调的前后词之前的语义关联有关，用于描述某个词语与其后多个词语有直接或间接的关系。在word2vec中使用的是中心词前后各n个词组成的窗口大小。原则上，窗口设置越大预测效果越好，但计算量等比例增大，一般选择5-8作为恰当的窗口值。</p><p><strong>Embedding Lookup的解释</strong>：词向量存储为一个以词典词个数为行，词嵌入维度为列的权重矩阵，而输入单词可以被编码为数字值，利用数值在词向量矩阵中获得词的向量表达的过程成为Embedding Lookup.</p><p><img src="/2018/08/21/弄懂word2vec之原理解析/tokenize_lookup.png" alt="tokenize_lookup"></p><p>Words that show up often such as “the”, “of”, and “for” don’t provide much context to the nearby words. If we discard some of them, we can remove some of the noise from our data and in return get faster training and better representations. This process is called subsampling by Mikolov. For each word $w_i$ in the training set, we’ll discard it with probability given by </p><script type="math/tex; mode=display"> P(w_i) = 1 - \sqrt{\frac{t}{f(w_i)}}</script><p>where $t$ is a threshold parameter and $f(w_i)$ is the frequency of word $w_i$ in the total dataset.</p><h3 id="训练数据的切分"><a href="#训练数据的切分" class="headerlink" title="训练数据的切分"></a>训练数据的切分</h3><p><img src="/2018/08/21/弄懂word2vec之原理解析/training_data.png" alt="training_data"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">corpus = <span class="string">''' I read magazine weekly . </span></span><br><span class="line"><span class="string">I read newspaper daily . I like to read books daily .'''</span></span><br><span class="line"></span><br><span class="line">corpus_tokens = []</span><br><span class="line"><span class="keyword">for</span> text <span class="keyword">in</span> corpus.split(<span class="string">'.'</span>):</span><br><span class="line">    corpus_tokens.append(text.lower().split())</span><br><span class="line"></span><br><span class="line"><span class="comment">########## Create vocabulary </span></span><br><span class="line">vocab = &#123;&#125;</span><br><span class="line">counter = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> sentence_tokens <span class="keyword">in</span> corpus_tokens:</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> sentence_tokens:</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> vocab:</span><br><span class="line">            vocab[word] = counter</span><br><span class="line">            counter += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">########## Create training pairs .</span></span><br><span class="line">window = <span class="number">5</span></span><br><span class="line">target_words = []</span><br><span class="line">target_words_index = []</span><br><span class="line">c = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> corpus_tokens:</span><br><span class="line">    <span class="keyword">for</span> index,center_word <span class="keyword">in</span> enumerate(i):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            right = i[index+<span class="number">1</span>: index+<span class="number">1</span>+window]</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            right == []</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            left = i[index<span class="number">-1</span>: (index<span class="number">-1</span>)+window]</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            left == []</span><br><span class="line">        total_words = list(set(right+left))</span><br><span class="line">        <span class="keyword">if</span> total_words:</span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> total_words:</span><br><span class="line">                <span class="keyword">if</span> center_word <span class="keyword">in</span> vocab <span class="keyword">and</span> word <span class="keyword">in</span> vocab:</span><br><span class="line">                    target_words.append((center_word, word))</span><br><span class="line">                    target_words_index.append((vocab[center_word], vocab[word]))</span><br><span class="line">    c += <span class="number">1</span></span><br></pre></td></tr></table></figure><h3 id="网络的构建"><a href="#网络的构建" class="headerlink" title="网络的构建"></a>网络的构建</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">embedding_dimension = <span class="number">100</span></span><br><span class="line">n_classes           = len(vocab) </span><br><span class="line">X = np.random.uniform(<span class="number">-1</span>,<span class="number">1</span>, (len(vocab), embedding_dimension)) <span class="comment"># input features for X </span></span><br><span class="line">W = np.random.uniform(<span class="number">-1</span>,<span class="number">1</span>, (len(vocab), embedding_dimension))   </span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> each_pair <span class="keyword">in</span> target_words_index:</span><br><span class="line">    </span><br><span class="line">    inp_pair_index = each_pair[<span class="number">0</span>]</span><br><span class="line">    op_pair_index  = each_pair[<span class="number">1</span>] </span><br><span class="line">    </span><br><span class="line">    x_input = random_embeddings[inp_pair_index] <span class="comment"># 1 x embedding_dimension </span></span><br><span class="line">    </span><br><span class="line">    probs = softmax(np.dot(W, x_input))        <span class="comment"># 1 x n_classes   </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">####### loss(probs, op_pair_index)</span></span><br><span class="line">    <span class="comment">####### backpropagate , update W</span></span><br></pre></td></tr></table></figure><blockquote><p>虽然示意代码中使用了softmax，但从计算量上来看这并非一种好的方法； Word2vec中使用了两种替代方案，可以大大节约计算成本：分别是层次softmax和副采样算法； </p></blockquote><h2 id="CBOW"><a href="#CBOW" class="headerlink" title="CBOW"></a>CBOW</h2><h2 id="Skip-gram"><a href="#Skip-gram" class="headerlink" title="Skip-gram"></a>Skip-gram</h2><p><img src="/2018/08/21/弄懂word2vec之原理解析/skip_gram_net_arch.png" alt="skip_gram_net_arch"></p><h2 id="负采样损失函数定义"><a href="#负采样损失函数定义" class="headerlink" title="负采样损失函数定义"></a>负采样损失函数定义</h2><p><img src="/2018/08/21/弄懂word2vec之原理解析/sampled-softmax.png" alt="sampled-softmax"></p><p>其中前一部分为真实结果的损失惩罚，后面的K部分为噪声词组的K次采样。</p><p>TensorFlow实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Number of negative labels to sample</span></span><br><span class="line">n_sampled = <span class="number">100</span></span><br><span class="line"><span class="keyword">with</span> train_graph.as_default():</span><br><span class="line">    softmax_w = tf.Variable(tf.truncated_normal((n_vocab, n_embedding))) <span class="comment"># create softmax weight matrix here</span></span><br><span class="line">    softmax_b = tf.Variable(tf.zeros(n_vocab), name=<span class="string">"softmax_bias"</span>) <span class="comment"># create softmax biases here</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Calculate the loss using negative sampling</span></span><br><span class="line">    loss = tf.nn.sampled_softmax_loss(</span><br><span class="line">        weights=softmax_w,</span><br><span class="line">        biases=softmax_b,</span><br><span class="line">        labels=labels,</span><br><span class="line">        inputs=embed,</span><br><span class="line">        num_sampled=n_sampled,</span><br><span class="line">        num_classes=n_vocab)</span><br><span class="line">    </span><br><span class="line">    cost = tf.reduce_mean(loss)</span><br><span class="line">    optimizer = tf.train.AdamOptimizer().minimize(cost)</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://zhuanlan.zhihu.com/p/29364112" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/29364112</a></li><li><a href="https://www.tensorflow.org/tutorials/representation/word2vec" target="_blank" rel="noopener">https://www.tensorflow.org/tutorials/representation/word2vec</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/qnsource/banner/07.jpg&quot; alt=&quot;Test Picture&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://blog.a-stack.com/categories/NLP/"/>
    
    
      <category term="词嵌入" scheme="http://blog.a-stack.com/tags/%E8%AF%8D%E5%B5%8C%E5%85%A5/"/>
    
      <category term="word2vec" scheme="http://blog.a-stack.com/tags/word2vec/"/>
    
      <category term="原理解析" scheme="http://blog.a-stack.com/tags/%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>弄懂word2vec之实践</title>
    <link href="http://blog.a-stack.com/2018/08/21/%E5%BC%84%E6%87%82word2vec%E4%B9%8B%E5%AE%9E%E8%B7%B5/"/>
    <id>http://blog.a-stack.com/2018/08/21/弄懂word2vec之实践/</id>
    <published>2018-08-21T05:34:57.000Z</published>
    <updated>2018-08-24T06:26:01.190Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/qnsource/banner/08.jpg" alt="Test Picture"></p><p><strong>摘要：</strong></p><a id="more"></a><h2 id="训练词向量模型"><a href="#训练词向量模型" class="headerlink" title="训练词向量模型"></a>训练词向量模型</h2><h3 id="工具准备"><a href="#工具准备" class="headerlink" title="工具准备"></a>工具准备</h3><ul><li><p>opencc 1.04</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1、下载包地址（我下载的是opencc-1.0.4.tar.gz）：</span></span><br><span class="line"><span class="comment"># https://bintray.com/package/files/byvoid/opencc/OpenCC</span></span><br><span class="line"><span class="comment"># https://bintray.com/byvoid/opencc/download_file?file_path=opencc-1.0.4.tar.gz</span></span><br><span class="line"><span class="comment">#2、进入tar.gz目录，命令行解压：</span></span><br><span class="line">tar -xzvf opencc-1.0.4.tar.gz</span><br><span class="line"><span class="comment"># 3、编译（需要工具cmake、gcc（4.6）gcc -v查看gcc版本、doxygen）</span></span><br><span class="line"><span class="built_in">cd</span> opencc-1.0.4/</span><br><span class="line">make</span><br><span class="line"><span class="comment"># 4.安装</span></span><br><span class="line">sudo make install</span><br><span class="line"><span class="comment"># 5.使用</span></span><br><span class="line">opencc -i &lt;input-file&gt; -o output-file&gt; -c &lt;config-file&gt; </span><br><span class="line"><span class="comment"># 例如：opencc -i wiki.zh.txt -o wiki.zh.simp.txt -c t2s.json</span></span><br></pre></td></tr></table></figure></li><li><p>gensim</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install gensim</span><br></pre></td></tr></table></figure></li><li><p>Wikipedia Extractor</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install unzip python python-dev python-pip</span><br><span class="line">$ git <span class="built_in">clone</span> https://github.com/attardi/wikiextractor.git wikiextractor</span><br><span class="line">$ <span class="built_in">cd</span> wikiextractor</span><br><span class="line">$ sudo python setup.py install</span><br></pre></td></tr></table></figure></li><li><p>jieba</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install jieba</span><br></pre></td></tr></table></figure></li></ul><h3 id="下载语料库并准备预料资源"><a href="#下载语料库并准备预料资源" class="headerlink" title="下载语料库并准备预料资源"></a>下载语料库并准备预料资源</h3><ol><li>标准的word2vec中文语料库目前影响范围最广的为维基百科语料库，下载地址：</li></ol><ul><li><a href="https://dumps.wikimedia.org/zhwiki/latest/zhwiki-latest-pages-articles.xml.bz2" target="_blank" rel="noopener">https://dumps.wikimedia.org/zhwiki/latest/zhwiki-latest-pages-articles.xml.bz2</a> （1.3G）</li></ul><ol><li><p>抽取语料正文</p><p>可以使用工具<code>Wikipedia Extractor</code>进行抽取：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ./WikiExtractor.py -b 1024M -o extracted zhwiki-latest-pages-articles.xml.bz2</span><br></pre></td></tr></table></figure><blockquote><p>参数-b 1024M表示以1024M为单位切分文件，默认是1M。</p></blockquote><p>（推荐，处理完成可以跳过第4步）也可以使用网上大牛写的处理脚本：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="keyword">from</span> gensim.corpora.wikicorpus <span class="keyword">import</span> extract_pages,filter_wiki</span><br><span class="line"><span class="keyword">import</span> bz2file</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> opencc</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line">wiki = extract_pages(bz2file.open(<span class="string">'zhwiki-latest-pages-articles.xml.bz2'</span>))</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">wiki_replace</span><span class="params">(d)</span>:</span></span><br><span class="line">    s = d[<span class="number">1</span>]</span><br><span class="line">    s = re.sub(<span class="string">':*&#123;\|[\s\S]*?\|&#125;'</span>, <span class="string">''</span>, s)</span><br><span class="line">    s = re.sub(<span class="string">'&lt;gallery&gt;[\s\S]*?&lt;/gallery&gt;'</span>, <span class="string">''</span>, s)</span><br><span class="line">    s = re.sub(<span class="string">'(.)&#123;&#123;([^&#123;&#125;\n]*?\|[^&#123;&#125;\n]*?)&#125;&#125;'</span>, <span class="string">'\\1[[\\2]]'</span>, s)</span><br><span class="line">    s = filter_wiki(s)</span><br><span class="line">    s = re.sub(<span class="string">'\* *\n|\'&#123;2,&#125;'</span>, <span class="string">''</span>, s)</span><br><span class="line">    s = re.sub(<span class="string">'\n+'</span>, <span class="string">'\n'</span>, s)</span><br><span class="line">    s = re.sub(<span class="string">'\n[:;]|\n +'</span>, <span class="string">'\n'</span>, s)</span><br><span class="line">    s = re.sub(<span class="string">'\n=='</span>, <span class="string">'\n\n=='</span>, s)</span><br><span class="line">    s = <span class="string">u'【'</span> + d[<span class="number">0</span>] + <span class="string">u'】\n'</span> + s</span><br><span class="line">    <span class="keyword">return</span> opencc.convert(s).strip()</span><br><span class="line">i = <span class="number">0</span></span><br><span class="line">f = codecs.open(<span class="string">'wiki.txt'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">w = tqdm(wiki, desc=<span class="string">u'已获取0篇文章'</span>)</span><br><span class="line"><span class="keyword">for</span> d <span class="keyword">in</span> w:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> re.findall(<span class="string">'^[a-zA-Z]+:'</span>, d[<span class="number">0</span>]) <span class="keyword">and</span> d[<span class="number">0</span>] <span class="keyword">and</span> <span class="keyword">not</span> re.findall(<span class="string">u'^#'</span>, d[<span class="number">1</span>]):</span><br><span class="line">        s = wiki_replace(d)</span><br><span class="line">        f.write(s+<span class="string">'\n\n\n'</span>)</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            w.set_description(<span class="string">u'已获取%s篇文章'</span>%i)</span><br><span class="line">f.close()</span><br></pre></td></tr></table></figure></li><li><p>繁体转简体</p><p>维基百科的中文数据是繁简混杂的，里面包含大陆简体、台湾繁体、港澳繁体等多种不同的数据。有时候在一篇文章的不同段落间也会使用不同的繁简字。</p><p>为了处理方便起见，我们直接使用了开源项目<code>opencc</code>。参照安装说明的方法，安装完成之后，使用下面的命令进行繁简转换，整个过程也很快：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install opencc</span><br><span class="line">$ opencc -i wiki_00 -o zh_wiki_00 -c zht2zhs.ini</span><br></pre></td></tr></table></figure><p>命令中的<code>wiki_00</code>这个文件是此前使用<code>Wikipedia Extractor</code>得到的。到了这里，我们已经完成了大部分繁简转换工作。</p></li><li><p>预处理</p><p>由于Wikipedia Extractor抽取正文时，会将有特殊标记的外文直接剔除。我们最后再将「」『』这些符号替换成引号，顺便删除空括号，就大功告成了！代码如下： </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">myfun</span><span class="params">(input_file)</span>:</span></span><br><span class="line">    p1 = re.compile(<span class="string">ur'-\&#123;.*?(zh-hans|zh-cn):([^;]*?)(;.*?)?\&#125;-'</span>)</span><br><span class="line">    p2 = re.compile(<span class="string">ur'[（\(][，；。？！\s]*[）\)]'</span>)</span><br><span class="line">    p3 = re.compile(<span class="string">ur'[「『]'</span>)</span><br><span class="line">    p4 = re.compile(<span class="string">ur'[」』]'</span>)</span><br><span class="line">    outfile = codecs.open(<span class="string">'std_'</span> + input_file, <span class="string">'w'</span>, <span class="string">'utf-8'</span>)</span><br><span class="line">    <span class="keyword">with</span> codecs.open(input_file, <span class="string">'r'</span>, <span class="string">'utf-8'</span>) <span class="keyword">as</span> myfile:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> myfile:</span><br><span class="line">            line = p1.sub(<span class="string">ur'\2'</span>, line)</span><br><span class="line">            line = p2.sub(<span class="string">ur''</span>, line)</span><br><span class="line">            line = p3.sub(<span class="string">ur'“'</span>, line)</span><br><span class="line">            line = p4.sub(<span class="string">ur'”'</span>, line)</span><br><span class="line">   <span class="comment"># line = re.sub('[a-zA-Z0-9]','',line)</span></span><br><span class="line">            outfile.write(line)</span><br><span class="line">    outfile.close()</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">if</span> len(sys.argv) != <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">"Usage: python script.py inputfile"</span></span><br><span class="line">        sys.exit()</span><br><span class="line">    reload(sys)</span><br><span class="line">    sys.setdefaultencoding(<span class="string">'utf-8'</span>)</span><br><span class="line">    input_file = sys.argv[<span class="number">1</span>]</span><br><span class="line">    myfun(input_file)</span><br></pre></td></tr></table></figure></li></ol><p>5.中文分词</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ python -m jieba -d <span class="string">" "</span> ./std_zh_wiki_00 &gt; ./cut_std_zh_wiki_00</span><br></pre></td></tr></table></figure><h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><p>模型训练使用工具<code>gensim</code>，可以通过<code>pip install gensim</code>直接安装。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from gensim.models import word2vec</span><br><span class="line">import logging</span><br><span class="line">logging.basicConfig(format=<span class="string">'%(asctime)s : %(levelname)s : %(message)s'</span>, level=logging.INFO)</span><br><span class="line">sentences = word2vec.LineSentence(u<span class="string">'./cut_std_zh_wiki_00'</span>)</span><br><span class="line">model = word2vec.Word2Vec(sentences,size=200,window=5,min_count=5,workers=4)</span><br><span class="line">outp1 = <span class="string">'wiki.zh.text.model'</span></span><br><span class="line">outp2 = <span class="string">'wiki.zh.text.vector'</span></span><br><span class="line">model.save(outp1)</span><br><span class="line">model.wv.save_word2vec_format(outp2, binary=False)</span><br></pre></td></tr></table></figure><h3 id="训练效果评价"><a href="#训练效果评价" class="headerlink" title="训练效果评价"></a>训练效果评价</h3><h4 id="词聚类"><a href="#词聚类" class="headerlink" title="词聚类"></a>词聚类</h4><p>可以采用 kmeans 聚类，看聚类簇的分布</p><h4 id="词cos-相关性"><a href="#词cos-相关性" class="headerlink" title="词cos 相关性"></a>词cos 相关性</h4><p>查找cos相近的词</p><h4 id="Analogy对比"><a href="#Analogy对比" class="headerlink" title="Analogy对比"></a>Analogy对比</h4><p>a:b 与 c:d的cos距离 (man-king woman-queen )</p><h4 id="使用tnse，pca等降维可视化展示"><a href="#使用tnse，pca等降维可视化展示" class="headerlink" title="使用tnse，pca等降维可视化展示"></a>使用tnse，pca等降维可视化展示</h4><p>词的分布，推荐用google的<a href="https://link.zhihu.com/?target=https%3A//www.tensorflow.org/get_started/summaries_and_tensorboard" target="_blank" rel="noopener">tensorboard</a>，可以多视角查看，如果不想搭建服务，直接<a href="https://link.zhihu.com/?target=http%3A//projector.tensorflow.org/" target="_blank" rel="noopener">访问这里</a>。另外可以用python的matplotlib。</p><p><img src="/2018/08/21/弄懂word2vec之实践/v2-7a3b04197eab7a2ccc40bfab3f81b7f6_hd.jpg" alt="img"></p><p><img src="/2018/08/21/弄懂word2vec之实践/v2-e8f100b3b0b5be4c343317e2db2bb706_hd.jpg" alt="img"></p><h4 id="Categorization-分类-看词在每个分类中的概率"><a href="#Categorization-分类-看词在每个分类中的概率" class="headerlink" title="Categorization 分类 看词在每个分类中的概率"></a>Categorization 分类 看词在每个分类中的概率</h4><div class="table-container"><table><thead><tr><th>词</th><th>动物</th><th>食物</th><th>汽车</th><th>电子</th></tr></thead><tbody><tr><td>橘子</td><td>0.11</td><td>0.68</td><td>0.12</td><td>0.11</td></tr><tr><td>鸟</td><td>0.66</td><td>0.11</td><td>0.13</td><td>0.11</td></tr><tr><td>雅阁</td><td>0.14</td><td>0.23</td><td>0.67</td><td>0.11</td></tr><tr><td>苹果</td><td>0.11</td><td>0.65</td><td>0.11</td><td>0.65</td></tr></tbody></table></div><blockquote><p>前三条来自<a href="https://link.zhihu.com/?target=https%3A//code.google.com/archive/p/word2vec/" target="_blank" rel="noopener">官网的评测</a>方法</p><p>网上也有相关的word embedding 的评估方法，可以<a href="https://link.zhihu.com/?target=http%3A//www.aclweb.org/anthology/D15-1036" target="_blank" rel="noopener">参考这里</a></p></blockquote><h2 id="模型使用"><a href="#模型使用" class="headerlink" title="模型使用"></a>模型使用</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> gensim</span><br><span class="line"><span class="comment"># 模型加载</span></span><br><span class="line">model = gensim.models.word2vec.Word2Vec.load(<span class="string">'/data2/word2vec/new.model'</span>)</span><br></pre></td></tr></table></figure><ol><li>比较词关联</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model.wv.most_similar(positive=[<span class="string">'woman'</span>, <span class="string">'king'</span>], negative=[<span class="string">'man'</span>], topn=<span class="number">1</span>)</span><br><span class="line">[(<span class="string">'queen'</span>, <span class="number">0.50882536</span>)]</span><br><span class="line">model.doesnt_match(<span class="string">"breakfast cereal dinner lunch"</span>;.split())</span><br><span class="line"><span class="string">'cereal'</span></span><br><span class="line">model.similarity(<span class="string">'woman'</span>, <span class="string">'man'</span>)</span><br><span class="line"><span class="number">0.73723527</span></span><br></pre></td></tr></table></figure><ol><li>输出词向量</li></ol><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">model</span>[<span class="string">'中国'</span>]</span><br></pre></td></tr></table></figure><h3 id="利用word2vec实现的关键词提取"><a href="#利用word2vec实现的关键词提取" class="headerlink" title="利用word2vec实现的关键词提取"></a>利用word2vec实现的关键词提取</h3><blockquote><p>参考自<a href="https://kexue.fm/archives/4316" target="_blank" rel="noopener">【不可思议的Word2Vec】 3.提取关键词</a> </p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> gensim</span><br><span class="line">model = gensim.models.word2vec.Word2Vec.load(<span class="string">'word2vec_wx'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_proba</span><span class="params">(oword, iword)</span>:</span></span><br><span class="line">    iword_vec = model[iword]</span><br><span class="line">    oword = model.wv.vocab[oword]</span><br><span class="line">    oword_l = model.syn1[oword.point].T</span><br><span class="line">    dot = np.dot(iword_vec, oword_l)</span><br><span class="line">    lprob = -sum(np.logaddexp(<span class="number">0</span>, -dot) + oword.code*dot) </span><br><span class="line">    <span class="keyword">return</span> lprob</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">keywords</span><span class="params">(s)</span>:</span></span><br><span class="line">    s = [w <span class="keyword">for</span> w <span class="keyword">in</span> s <span class="keyword">if</span> w <span class="keyword">in</span> model]</span><br><span class="line">    ws = &#123;w:sum([predict_proba(u, w) <span class="keyword">for</span> u <span class="keyword">in</span> s]) <span class="keyword">for</span> w <span class="keyword">in</span> s&#125;</span><br><span class="line">    <span class="keyword">return</span> Counter(ws).most_common()</span><br><span class="line">  </span><br><span class="line"> s = <span class="string">u'2018年7月17日，国务院食品安全办在全国食品安全宣传周主会场公布了7起食品保健食品欺诈和虚假宣传整治案件：一、广东广州钟某、林某等制售非法添加药品的食品案2017年10月，广东省广州市公安机关联合食品药品监管部门破获钟某、林某等制售非法添加药品的食品案，涉案货值逾亿元。查获非法添加西药成分的咖啡1万多盒、半成品及原料粉末3吨。林某等在咖啡、蜂蜜、减肥茶等食品中非法添加他达拉非、西布曲明等西药成分，并假冒其他品牌食品销售。钟某、林某等5名犯罪嫌疑人已被依法批捕。二、河北石家庄秦某等制售非法添加药品的食品案2018年1月，河北省石家庄市公安机关、食品药品监管部门联手侦破秦某等制售非法添加药品的食品案，涉案货值3500余万元，捣毁生产、销售、储存窝点7处，打掉加工生产线12条，食品成品6500余盒。秦某等非法添加苯乙双胍等西药成分生产“胰宝唐安” “唐康”等宣称降糖功能的食品，通过电话推销、聘用假冒专家等进行销售。秦某等犯罪嫌疑人已被依法批捕。'</span></span><br><span class="line">pd.Series(keywords(jieba.cut(s)))</span><br><span class="line"></span><br><span class="line">----</span><br><span class="line"><span class="number">0</span>        (制售, <span class="number">-1987.67916328</span>)</span><br><span class="line"><span class="number">1</span>        (药品, <span class="number">-2023.50590123</span>)</span><br><span class="line"><span class="number">2</span>        (食品, <span class="number">-2037.03856341</span>)</span><br><span class="line"><span class="number">3</span>        (查获, <span class="number">-2042.32583652</span>)</span><br><span class="line"><span class="number">4</span>        (窝点, <span class="number">-2056.79129232</span>)</span><br><span class="line"><span class="number">5</span>      (保健食品, <span class="number">-2064.19993636</span>)</span><br><span class="line"><span class="number">6</span>        (西药, <span class="number">-2073.77825261</span>)</span><br><span class="line"><span class="number">7</span>      (监管部门, <span class="number">-2082.29241248</span>)</span><br><span class="line"><span class="number">8</span>        (非法, <span class="number">-2089.17887737</span>)</span><br><span class="line"><span class="number">9</span>        (销售, <span class="number">-2099.67683021</span>)</span><br><span class="line"><span class="number">10</span>     (食品安全, <span class="number">-2104.52601517</span>)</span><br><span class="line"><span class="number">11</span>       (涉案, <span class="number">-2106.51930849</span>)</span><br><span class="line"><span class="number">12</span>        (加工, <span class="number">-2110.4709589</span>)</span><br><span class="line"><span class="number">13</span>       (破获, <span class="number">-2111.47298087</span>)</span><br><span class="line"><span class="number">14</span>        (案, <span class="number">-2111.82806077</span>)</span><br><span class="line"><span class="number">15</span>       (欺诈, <span class="number">-2112.95137531</span>)</span><br><span class="line"><span class="number">16</span>       (生产, <span class="number">-2115.57760446</span>)</span><br><span class="line"><span class="number">17</span>       (原料, <span class="number">-2124.36521695</span>)</span><br><span class="line"><span class="number">18</span>       (案件, <span class="number">-2125.21520575</span>)</span><br><span class="line"><span class="number">19</span>        (等, <span class="number">-2126.20670381</span>)</span><br><span class="line"><span class="number">20</span>       (依法, <span class="number">-2126.65278663</span>)</span><br><span class="line"><span class="number">21</span>     (公安机关, <span class="number">-2130.61494485</span>)</span><br><span class="line"><span class="number">22</span>       (咖啡, <span class="number">-2140.98083555</span>)</span><br><span class="line"><span class="number">23</span>      (半成品, <span class="number">-2143.70307556</span>)</span><br><span class="line"><span class="number">24</span>        (虚假, <span class="number">-2144.3973437</span>)</span><br><span class="line"><span class="number">25</span>        (侦破, <span class="number">-2144.4260255</span>)</span><br><span class="line"><span class="number">26</span>       (假冒, <span class="number">-2145.73825612</span>)</span><br><span class="line"><span class="number">27</span>       (曲明, <span class="number">-2147.48180124</span>)</span><br><span class="line"><span class="number">28</span>     (食品药品, <span class="number">-2151.19137764</span>)</span><br><span class="line"><span class="number">29</span>       (专家, <span class="number">-2151.42459357</span>)</span><br><span class="line">                ...          </span><br><span class="line">dtype: object</span><br></pre></td></tr></table></figure><h3 id="基于词向量的聚类分析"><a href="#基于词向量的聚类分析" class="headerlink" title="基于词向量的聚类分析"></a>基于词向量的聚类分析</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Word2Vec</span><br><span class="line">sentences = [[<span class="string">'this'</span>, <span class="string">'is'</span>, <span class="string">'the'</span>, <span class="string">'good'</span>, <span class="string">'machine'</span>, <span class="string">'learning'</span>, <span class="string">'book'</span>],</span><br><span class="line">            [<span class="string">'this'</span>, <span class="string">'is'</span>,  <span class="string">'another'</span>, <span class="string">'book'</span>],</span><br><span class="line">            [<span class="string">'one'</span>, <span class="string">'more'</span>, <span class="string">'book'</span>],</span><br><span class="line">            [<span class="string">'this'</span>, <span class="string">'is'</span>, <span class="string">'the'</span>, <span class="string">'new'</span>, <span class="string">'post'</span>],</span><br><span class="line">                        [<span class="string">'this'</span>, <span class="string">'is'</span>, <span class="string">'about'</span>, <span class="string">'machine'</span>, <span class="string">'learning'</span>, <span class="string">'post'</span>],  </span><br><span class="line">            [<span class="string">'and'</span>, <span class="string">'this'</span>, <span class="string">'is'</span>, <span class="string">'the'</span>, <span class="string">'last'</span>, <span class="string">'post'</span>]]</span><br><span class="line">model = Word2Vec(sentences, min_count=<span class="number">1</span>)</span><br><span class="line">X = model[model.wv.vocab]</span><br></pre></td></tr></table></figure><ol><li><p>使用nltk.cluster.KMeansClusterer</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">from nltk.cluster import KMeansClusterer</span><br><span class="line">import nltk</span><br><span class="line">NUM_CLUSTERS=3</span><br><span class="line">kclusterer = KMeansClusterer(NUM_CLUSTERS, distance=nltk.cluster.util.cosine_distance, repeats=25)</span><br><span class="line">assigned_clusters = kclusterer.cluster(X, assign_clusters=True)</span><br><span class="line"><span class="built_in">print</span> (assigned_clusters)</span><br><span class="line"></span><br><span class="line">[1, 0, 2, 2, 0, 2, 2, 2, 2, 2, 1, 0, 2, 1, 0]</span><br><span class="line">words = list(model.wv.vocab)</span><br><span class="line"><span class="keyword">for</span> i, word <span class="keyword">in</span> enumerate(words):  </span><br><span class="line">    <span class="built_in">print</span> (word + <span class="string">":"</span> + str(assigned_clusters[i]))</span><br><span class="line">post:1</span><br><span class="line">one:0</span><br><span class="line">the:2</span><br><span class="line">machine:2</span><br><span class="line">another:0</span><br><span class="line">this:2</span><br><span class="line">last:2</span><br><span class="line">is:2</span><br><span class="line">book:2</span><br><span class="line">learning:2</span><br><span class="line">new:1</span><br><span class="line">good:0</span><br><span class="line">more:2</span><br><span class="line">and:1</span><br><span class="line">about:0</span><br></pre></td></tr></table></figure></li><li><p>使用sklearn.Keams</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> cluster</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line">kmeans = cluster.KMeans(n_clusters=NUM_CLUSTERS)</span><br><span class="line">kmeans.fit(X)</span><br><span class="line"> </span><br><span class="line">labels = kmeans.labels_</span><br><span class="line">centroids = kmeans.cluster_centers_</span><br><span class="line"> </span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Cluster id labels for inputted data"</span>)</span><br><span class="line"><span class="keyword">print</span> (labels)</span><br><span class="line"><span class="comment">#print ("Centroids data")</span></span><br><span class="line"><span class="comment">#print (centroids)</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Score (Opposite of the value of X on the K-means objective which is Sum of distances of samples to their closest cluster center):"</span>)</span><br><span class="line"><span class="keyword">print</span> (kmeans.score(X))</span><br><span class="line"> </span><br><span class="line">silhouette_score = metrics.silhouette_score(X, labels, metric=<span class="string">'euclidean'</span>)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Silhouette_score: "</span>)</span><br><span class="line"><span class="keyword">print</span> (silhouette_score)</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">Cluster id labels <span class="keyword">for</span> inputted data</span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span>]</span><br><span class="line">Score (Opposite of the value of X on the K-means objective which <span class="keyword">is</span> Sum of distances of samples to their closest cluster center):</span><br><span class="line"><span class="number">-0.00961963500595</span></span><br><span class="line">Silhouette_score: </span><br><span class="line"><span class="number">0.0289495</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="Word2vec的可视化"><a href="#Word2vec的可视化" class="headerlink" title="Word2vec的可视化"></a>Word2vec的可视化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys, os</span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Word2Vec</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tensorflow.contrib.tensorboard.plugins <span class="keyword">import</span> projector</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">visualize</span><span class="params">(model, output_path)</span>:</span></span><br><span class="line">    meta_file = <span class="string">"w2x_metadata.tsv"</span></span><br><span class="line">    placeholder = np.zeros((len(model.wv.index2word), <span class="number">256</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> open(os.path.join(output_path,meta_file), <span class="string">'wb'</span>) <span class="keyword">as</span> file_metadata:</span><br><span class="line">        <span class="keyword">for</span> i, word <span class="keyword">in</span> enumerate(model.wv.index2word):</span><br><span class="line">            placeholder[i] = model[word]</span><br><span class="line">            <span class="comment"># temporary solution for https://github.com/tensorflow/tensorflow/issues/9094</span></span><br><span class="line">            <span class="keyword">if</span> word == <span class="string">''</span>:</span><br><span class="line">                print(<span class="string">"Emply Line, should replecaed by any thing else, or will cause a bug of tensorboard"</span>)</span><br><span class="line">                file_metadata.write(<span class="string">"&#123;0&#125;"</span>.format(<span class="string">'&lt;Empty Line&gt;'</span>).encode(<span class="string">'utf-8'</span>) + <span class="string">b'\n'</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                file_metadata.write(<span class="string">"&#123;0&#125;"</span>.format(word).encode(<span class="string">'utf-8'</span>) + <span class="string">b'\n'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># define the model without training</span></span><br><span class="line">    sess = tf.InteractiveSession()</span><br><span class="line"></span><br><span class="line">    embedding = tf.Variable(placeholder, trainable = <span class="keyword">False</span>, name = <span class="string">'w2x_metadata'</span>)</span><br><span class="line">    tf.global_variables_initializer().run()</span><br><span class="line"></span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line">    writer = tf.summary.FileWriter(output_path, sess.graph)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># adding into projector</span></span><br><span class="line">    config = projector.ProjectorConfig()</span><br><span class="line">    embed = config.embeddings.add()</span><br><span class="line">    embed.tensor_name = <span class="string">'w2x_metadata'</span></span><br><span class="line">    embed.metadata_path = meta_file</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Specify the width and height of a single thumbnail.</span></span><br><span class="line">    projector.visualize_embeddings(writer, config)</span><br><span class="line">    saver.save(sess, os.path.join(output_path,<span class="string">'w2x_metadata.ckpt'</span>))</span><br><span class="line">    print(<span class="string">'Run `tensorboard --logdir=&#123;0&#125;` to run visualize result on tensorboard'</span>.format(output_path))</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    model = Word2Vec.load(<span class="string">"./data/model/word2vec_wx"</span>)</span><br><span class="line">    visualize(model,<span class="string">"./visual/"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Run `tensorboard --logdir=./visual/` to run visualize result on tensorboard</span><br></pre></td></tr></table></figure><h2 id="Word2vec的应用场景"><a href="#Word2vec的应用场景" class="headerlink" title="Word2vec的应用场景"></a>Word2vec的应用场景</h2><blockquote><p>参考自<a href="http://www.zhuanzhi.ai/document/b614a5ceb61c95574515415a53cbf2e3" target="_blank" rel="noopener">word2vec在工业界的应用场景</a></p></blockquote><h3 id="在社交网络中的推荐"><a href="#在社交网络中的推荐" class="headerlink" title="在社交网络中的推荐"></a>在社交网络中的推荐</h3><p>在个性化推荐的场景，给当前用户推荐他可能关注的『大V』。对一个新用户，此题基本无解，如果在已知用户关注了几个『大V』之后，相当于知道了当前用户的一些关注偏好，根据此偏好给他推荐和他关注过大V相似的大V，就是一个很不错的推荐策略。所以，如果可以求出来任何两个V用户的相似度，上面问题就可以基本得到解决。</p><p>我们知道word2vec中两个词的相似度可以直接通过余弦来衡量，接下来就是如何将每个V用户变为一个词向量的问题了。巧妙的地方就是如何定义doc和word，针对上面问题，可以将doc和word定义为：</p><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">word</span> -&gt;</span>   每一个大V就是一个词</span><br><span class="line"><span class="function"><span class="title">doc</span>  -&gt;</span>   根据每一个用户关注大V的顺序，生成一篇文章</span><br></pre></td></tr></table></figure><p>由于用户量很大（大约4亿），可以将关注word个数少的doc删掉，因为本身大V的种类是十万级别（如果我没记错的话）， 选择可以覆盖绝大多数大V的文章数量就足够了。</p><h3 id="计算商品的相似度"><a href="#计算商品的相似度" class="headerlink" title="计算商品的相似度"></a>计算商品的相似度</h3><p>在商品推荐的场景中，竞品推荐和搭配推荐的时候都有可能需要计算任何两个商品的相似度，根据浏览/收藏/下单/App下载等行为，可以将商品看做词，将每一个用户的一类行为序看做一个文档，通过word2vec将其训练为一个向量。</p><p>同样的，在计算广告中，根据用户的点击广告的点击序列，将每一个广告变为一个向量。变为向量后，用此向量可以生成特征融入到rank模型中。</p><h3 id="作为另一个模型的输入"><a href="#作为另一个模型的输入" class="headerlink" title="作为另一个模型的输入"></a>作为另一个模型的输入</h3><p>在nlp的任务中，可以通过将词聚类后，生成一维新的特征来使用。在CRF实体识别的任务中，聚类结果类似词性，可以作为特征来使用。</p><p>在依存句法分析的任务中，哈工大ltp的nndepparser则是将词向量直接作为输入。</p><p>具体论文『A Fast and Accurate Dependency Parser using Neural Networks』</p><h3 id="向量快速检索"><a href="#向量快速检索" class="headerlink" title="向量快速检索"></a>向量快速检索</h3><p>当我们将一个文档变成一个向量之后，如何根据余弦/欧氏距离快速得到其最相似的top k个文章，是工程实现上不得不考虑的问题。例如线上可以允许的时间是5ms以内，如果文章数量往往上万或者更多，O(n)的方式计算明显不可接受了。</p><p>如果文章更新的速度很慢，可以通过离线的方式一天或者几天计算一次，导入redis（或者别的）提供线上快速查询。 但是如果文章实时新增，并且大量流量来自新文章，这个问题就要好好考虑一下。</p><p>一般可以通过PQ, kd-tree、simhash、聚类等方式解决，选择不同的方式和具体的推荐场景、数据分布有关。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://zhuanlan.zhihu.com/p/29364112" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/29364112</a></li><li><a href="https://code.google.com/archive/p/word2vec/" target="_blank" rel="noopener">https://code.google.com/archive/p/word2vec/</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/qnsource/banner/08.jpg&quot; alt=&quot;Test Picture&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://blog.a-stack.com/categories/NLP/"/>
    
    
      <category term="实践" scheme="http://blog.a-stack.com/tags/%E5%AE%9E%E8%B7%B5/"/>
    
      <category term="word2vec" scheme="http://blog.a-stack.com/tags/word2vec/"/>
    
      <category term="词向量" scheme="http://blog.a-stack.com/tags/%E8%AF%8D%E5%90%91%E9%87%8F/"/>
    
  </entry>
  
  <entry>
    <title>CRUSH in Ceph</title>
    <link href="http://blog.a-stack.com/2018/08/19/CRUSH-in-Ceph/"/>
    <id>http://blog.a-stack.com/2018/08/19/CRUSH-in-Ceph/</id>
    <published>2018-08-19T11:13:01.000Z</published>
    <updated>2018-08-19T15:32:33.813Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/qnsource/banner/22.jpg" alt="聊聊Ceph中的核心数据分布选择算法——CRUSH"></p><a id="more"></a><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>CRUSH算法构建了Ceph存储体系的核心，解决了计算效率和计算性能的同步优化，解放了元数据节点，让ceph的客户端侧完成数据目标位置的计算任务，保障了系统的可扩展性和鲁棒性。具备计算寻址、高并发能力、动态数据再平衡、可定制的副本策略等优秀特性。</p><p><strong>CRUSH</strong>：Controlled Replication Under Scalable Hashing ，基于可扩展哈希的受控副本分布策略。CRUSH本质上是一种基于hash的数据分布式算法，主要解决两个问题：</p><ol><li><p>当系统发生变化时，如何最小化数据的迁移量并尽快恢复平衡；</p></li><li><p>如何保证数据的多个副本合理分布，保证数据的可靠性；</p></li></ol><h2 id="CRUSH中的5种设备选择算法"><a href="#CRUSH中的5种设备选择算法" class="headerlink" title="CRUSH中的5种设备选择算法"></a>CRUSH中的5种设备选择算法</h2><div class="table-container"><table><thead><tr><th>对比项/算法</th><th>unique</th><th>list</th><th>tree</th><th>straw</th><th>staw2</th></tr></thead><tbody><tr><td>时间复杂度</td><td>O(1)</td><td>O(N)</td><td>O(log(N))</td><td>O(N)</td><td>O(N)</td></tr><tr><td>添加元素</td><td>差</td><td>最好</td><td>好</td><td>最好</td><td>最好</td></tr><tr><td>删除元素</td><td>差</td><td>差</td><td>好</td><td>最好</td><td>最好</td></tr></tbody></table></div><p>以上对比可以看出，straw虽然时间复杂度高，但应对环境变化能力强，所以作为ceph的默认配置算法。</p><p>straw算法的本质是一个抽签算法，选取抽取签长最长的作为结果，同时考虑不同设备的权重，来补偿签长权重，让容量大的设备更容易被抽中。</p><p>straw抽签算法可以保证，每个设备的签长计算只与该设备的权重有关，这样当添加或删除设备时，不会导致数据在除添加/删除之外的两个元素之间迁移。</p><p>但straw算法并非完美，在算法设计的权重排序中，由于需要和其它元素的权重进行比较，从而导致每次有元素加入当前集合或从当前集合删除时，都会引起不相关的数据迁移。为此，straw2提出了改良算法。</p><h2 id="CRUSH算法"><a href="#CRUSH算法" class="headerlink" title="CRUSH算法"></a>CRUSH算法</h2><p><strong>输入：</strong>x，cluster map，placement rule</p><p>目的： 为输入PG寻找合适的OSD set</p><script type="math/tex; mode=display">CRUSH（x,cluster map, placement rule） = (osd0,osd1,…, osdn)</script><h3 id="Cluster-Map"><a href="#Cluster-Map" class="headerlink" title="Cluster Map"></a>Cluster Map</h3><p>cluster map也成为CRUSH map是集群拓扑结构的逻辑描述形式，采用树这种数据结构实现，比如“数据中心——机架——主机——磁盘”的树状层级关系。其中叶子节点为device，中间节点统称bucket，根节点为root，每个节点通过ID和类型描述。</p><p>cluster map中包含CRUSH MAP Devices表，用于统计所有的设备资源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#devices</span></span><br><span class="line">device &#123;num&#125; &#123;osd.name&#125;</span><br></pre></td></tr></table></figure><p>Bucket类型表，描述了不同的设备类型信息：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">type 0 osd</span><br><span class="line">type 1 host</span><br><span class="line">type 2 chassis</span><br><span class="line">type 3 rack</span><br><span class="line">type 4 row</span><br><span class="line">type 5 pdu</span><br><span class="line">type 6 pod</span><br><span class="line">type 7 room</span><br><span class="line">type 8 datacenter</span><br><span class="line">type 9 region</span><br><span class="line">type 10 root</span><br></pre></td></tr></table></figure><figure class="highlight clojure"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[bucket-type] [bucket-name] &#123;</span><br><span class="line">        id [a unique negative numeric ID]</span><br><span class="line">        weight [the relative capacity/capability of the item(<span class="name">s</span>)]</span><br><span class="line">        alg [the bucket type: uniform | list | tree | straw | straw2]</span><br><span class="line">        hash [the hash type: <span class="number">0</span> by default]</span><br><span class="line">        item [item-name] weight [weight]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">host ceph-node3 &#123;</span><br><span class="line">        id <span class="number">-4</span>           # do not change unnecessarily</span><br><span class="line">        # weight <span class="number">0.053</span></span><br><span class="line">        alg straw</span><br><span class="line">        hash <span class="number">0</span>  # rjenkins1</span><br><span class="line">        item osd<span class="number">.4</span> weight <span class="number">0.018</span></span><br><span class="line">        item osd<span class="number">.5</span> weight <span class="number">0.018</span></span><br><span class="line">        item osd<span class="number">.8</span> weight <span class="number">0.018</span></span><br><span class="line">&#125;</span><br><span class="line">root <span class="section">default</span> &#123;</span><br><span class="line">        id <span class="number">-1</span>           # do not change unnecessarily</span><br><span class="line">        # weight <span class="number">0.158</span></span><br><span class="line">        alg straw</span><br><span class="line">        hash <span class="number">0</span>  # rjenkins1</span><br><span class="line">        item ceph-node1 weight <span class="number">0.053</span></span><br><span class="line">        item ceph-node2 weight <span class="number">0.053</span></span><br><span class="line">        item ceph-node3 weight <span class="number">0.053</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Placement-Rule"><a href="#Placement-Rule" class="headerlink" title="Placement Rule"></a>Placement Rule</h3><p>数据分布策略：Placement Rule，用于利用cluster map完成数据映射，包括take，select和emit三种操作。</p><p>核心是select算法，将根据需求返回指定数量的叶子设备，并保证这些叶子设备位于不同的指定类型的容灾域之下。 </p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">rule &lt;rulename&gt; &#123;</span><br><span class="line"></span><br><span class="line">        ruleset &lt;ruleset&gt;</span><br><span class="line">       <span class="built_in"> type </span>[ replicated | erasure ]</span><br><span class="line">        min_size &lt;min-size&gt;</span><br><span class="line">        max_size &lt;max-size&gt;</span><br><span class="line">        <span class="keyword">step</span> take &lt;bucket-name&gt;</span><br><span class="line">        <span class="keyword">step</span> [choose|chooseleaf] [firstn|indep] &lt;N&gt; &lt;bucket-type&gt;</span><br><span class="line">        <span class="keyword">step</span> emit</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="CRUSH算法的缺陷"><a href="#CRUSH算法的缺陷" class="headerlink" title="CRUSH算法的缺陷"></a>CRUSH算法的缺陷</h3><p>CRUSH算法本身仍然存在缺陷，从基本选择算法上看，每次选择都是计算单个条目被选中的独立概率，但是CRUSH所要求的副本策略使得针对同一输入、多个副本之间的选择变成了计算条件概率，所以CRUSH无法处理好多副本模式下的副本均匀分布问题；</p><p>这导致了在Ceph集群中，特别是异构集群中，出现大量磁盘数据分布悬殊的情况，因此需要对其计算结果进行人工干预。除了本身的weight，人工设置一个reweight值，叫做过载测试。</p><h3 id="CRUSH规则修改常用命令"><a href="#CRUSH规则修改常用命令" class="headerlink" title="CRUSH规则修改常用命令"></a>CRUSH规则修改常用命令</h3><p>CRUSH修改满足如下流程：</p><ol><li><a href="http://docs.ceph.com/docs/jewel/rados/operations/crush-map/#getcrushmap" target="_blank" rel="noopener">Get the CRUSH map</a>.</li><li><a href="http://docs.ceph.com/docs/jewel/rados/operations/crush-map/#decompilecrushmap" target="_blank" rel="noopener">Decompile</a> the CRUSH map.</li><li>Edit at least one of <a href="http://docs.ceph.com/docs/jewel/rados/operations/crush-map/#crushmapdevices" target="_blank" rel="noopener">Devices</a>, <a href="http://docs.ceph.com/docs/jewel/rados/operations/crush-map/#crushmapbuckets" target="_blank" rel="noopener">Buckets</a> and <a href="http://docs.ceph.com/docs/jewel/rados/operations/crush-map/#crushmaprules" target="_blank" rel="noopener">Rules</a>.</li><li><a href="http://docs.ceph.com/docs/jewel/rados/operations/crush-map/#compilecrushmap" target="_blank" rel="noopener">Recompile</a> the CRUSH map.</li><li>Test it.</li><li><a href="http://docs.ceph.com/docs/jewel/rados/operations/crush-map/#setcrushmap" target="_blank" rel="noopener">Set the CRUSH map</a>.</li></ol><figure class="highlight dsconfig"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.</span></span><br><span class="line"><span class="string">ceph </span><span class="string">osd </span><span class="string">getcrushmap </span>-o &#123;<span class="string">compiled </span><span class="string">crush </span><span class="string">map </span><span class="string">file&#125;</span></span><br><span class="line"><span class="comment"># 2.</span></span><br><span class="line"><span class="string">crushtool </span>-d &#123;<span class="string">compiled </span><span class="string">crush </span><span class="string">map </span><span class="string">file&#125;</span> -o &#123;<span class="string">decompiled </span><span class="string">crush </span><span class="string">map </span><span class="string">file&#125;</span></span><br><span class="line"><span class="comment"># 3.</span></span><br><span class="line"><span class="comment">#4.</span></span><br><span class="line"><span class="string">crushtool </span>-c &#123;<span class="string">decompiled </span><span class="string">crush </span><span class="string">map </span><span class="string">file&#125;</span> -o &#123;<span class="string">compiled </span><span class="string">crush </span><span class="string">map </span><span class="string">file&#125;</span></span><br><span class="line"><span class="comment"># 5. 模拟测试</span></span><br><span class="line"><span class="string">crushtool </span>-i <span class="string">mycrushmap </span><span class="built_in">--test</span> <span class="built_in">--min-x</span> - <span class="built_in">--max-x</span> 9 <span class="built_in">--num-rep</span> 3 <span class="built_in">--ruleset</span> 0 <span class="built_in">--show_mappings</span></span><br><span class="line"><span class="built_in">crushtool</span> -i <span class="string">mycrushmap </span><span class="built_in">--test</span> <span class="built_in">--min-x</span> - <span class="built_in">--max-x</span> 9 <span class="built_in">--num-rep</span> 3 <span class="built_in">--ruleset</span> 0 <span class="built_in">--show_utilization</span></span><br><span class="line"><span class="built_in">#</span> 6.</span><br><span class="line"><span class="string">ceph </span><span class="string">osd </span><span class="string">setcrushmap </span>-i &#123;<span class="string">compiled </span><span class="string">crush </span><span class="string">map </span><span class="string">file&#125;</span></span><br></pre></td></tr></table></figure><h3 id="定制CRUSH规则"><a href="#定制CRUSH规则" class="headerlink" title="定制CRUSH规则"></a>定制CRUSH规则</h3><ol><li><p>修改容灾域（如下为以rack作为容灾域）</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rules</span></span><br><span class="line">rule replicated_ruleset &#123;</span><br><span class="line">ruleset 0</span><br><span class="line"><span class="built_in">type </span>replicated</span><br><span class="line">min_size 1</span><br><span class="line">max_size 10</span><br><span class="line"><span class="keyword">step</span> take default</span><br><span class="line"><span class="keyword">step</span> chooseleaf firstn 0<span class="built_in"> type </span>rack</span><br><span class="line"><span class="keyword">step</span> emit</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><p>2.限制只选择特定范围的OSD，比如下面只选择rack2的OSD</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rules</span></span><br><span class="line">rule replicated_ruleset &#123;</span><br><span class="line">ruleset 0</span><br><span class="line"><span class="built_in">type </span>replicated</span><br><span class="line">min_size 1</span><br><span class="line">max_size 10</span><br><span class="line"><span class="keyword">step</span> take rack2</span><br><span class="line"><span class="keyword">step</span> chooseleaf firstn 0<span class="built_in"> type </span>host</span><br><span class="line"><span class="keyword">step</span> emit</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li><p>构建虚拟隔离池</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">host virtualhost &#123;</span><br><span class="line">id -10# <span class="keyword">do</span> <span class="keyword">not</span> change unnecessarily</span><br><span class="line"># weight 0.053</span><br><span class="line">alg straw2</span><br><span class="line">hash 0# rjenkins1</span><br><span class="line">item osd.3 weight 0.018</span><br><span class="line">item osd.6 weight 0.018</span><br><span class="line">item osd.7 weight 0.018</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># rules</span></span><br><span class="line">rule replicated_ruleset &#123;</span><br><span class="line">ruleset 0</span><br><span class="line"><span class="built_in">type </span>replicated</span><br><span class="line">min_size 1</span><br><span class="line">max_size 10</span><br><span class="line"><span class="keyword">step</span> take virtualhost</span><br><span class="line"><span class="keyword">step</span> chooseleaf firstn 0<span class="built_in"> type </span>osd</span><br><span class="line"><span class="keyword">step</span> emit</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h3 id="数据重平衡"><a href="#数据重平衡" class="headerlink" title="数据重平衡"></a>数据重平衡</h3><p>人为干预可以通过reweight来调节数据分布：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd reweight &#123;osd_numeric_id&#125; &#123;reweight&#125;</span><br></pre></td></tr></table></figure><p>也可以批量调整，比如按照<code>reweight-by-utilizaiton</code> 或 <code>reweight-by-pg</code>,可以调整前通过如下命令测试：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">ceph osd <span class="built_in">test</span>-reweight-by-utilization &#123;overload&#125; &#123;max_change&#125; &#123;max_osds&#125; &#123;--no-incresing&#125;</span><br><span class="line">[root@ceph-node1 ~]<span class="comment"># ceph osd test-reweight-by-utilization 105 .2 4 --no-increasing</span></span><br><span class="line">no change</span><br><span class="line">moved 6 / 384 (1.5625%)</span><br><span class="line">avg 42.6667</span><br><span class="line">stddev 5.4365 -&gt; 4.49691 (expected baseline 6.1584)</span><br><span class="line">min osd.7 with 33 -&gt; 37 pgs (0.773438 -&gt; 0.867188 * mean)</span><br><span class="line">max osd.6 with 52 -&gt; 48 pgs (1.21875 -&gt; 1.125 * mean)</span><br><span class="line"></span><br><span class="line">oload 105</span><br><span class="line">max_change 0.2</span><br><span class="line">max_change_osds 4</span><br><span class="line">average 0.007894</span><br><span class="line">overload 0.008289</span><br><span class="line">osd.6 weight 1.000000 -&gt; 0.843857</span><br><span class="line">osd.4 weight 1.000000 -&gt; 0.940109</span><br></pre></td></tr></table></figure><div class="table-container"><table><thead><tr><th>参数</th><th>含义</th></tr></thead><tbody><tr><td>overload</td><td>可选，默认值为120，为大于100的数，当且仅当OSD的空间利用与大于等于集群平均利用率的overload/100时，调整reweight</td></tr><tr><td>max_change</td><td>[0,1],每次调整reweight的最大幅度，默认0.05</td></tr><tr><td>max_osds</td><td>整型，默认 4；每次至多调整的OSD数目</td></tr><tr><td>–no-incresing</td><td>可选，不将reweight进行上调</td></tr></tbody></table></div><h2 id="其它可配置信息"><a href="#其它可配置信息" class="headerlink" title="其它可配置信息"></a>其它可配置信息</h2><h3 id="主OSD的选择"><a href="#主OSD的选择" class="headerlink" title="主OSD的选择"></a>主OSD的选择</h3><p>可以通过给OSD一个[0,1]之间的权重，来选择该OSD是否适合作为主OSD，0代表不作为主OSD，1作为可以被选为主OSD。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd primary-affinity <span class="tag">&lt;<span class="name">osd-id</span>&gt;</span> <span class="tag">&lt;<span class="name">weight</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="Tunable"><a href="#Tunable" class="headerlink" title="Tunable"></a>Tunable</h3><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">ceph osd crush tunables optimal</span></span><br></pre></td></tr></table></figure><ul><li><code>legacy</code>: the legacy behavior from argonaut and earlier.</li><li><code>argonaut</code>: the legacy values supported by the original argonaut release</li><li><code>bobtail</code>: the values supported by the bobtail release</li><li><code>firefly</code>: the values supported by the firefly release</li><li><code>optimal</code>: the current best values</li><li><code>default</code>: the current default values for a new cluster</li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li>《Ceph设计与实现原理》</li><li><a href="https://ceph.com/wp-content/uploads/2016/08/weil-crush-sc06.pdf" target="_blank" rel="noopener">《CRUSH: Controlled, Scalable, Decentralized Placement of Replicated Data》</a></li><li><a href="http://docs.ceph.com/docs/jewel/rados/operations/crush-map/" target="_blank" rel="noopener">http://docs.ceph.com/docs/jewel/rados/operations/crush-map/</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/qnsource/banner/22.jpg&quot; alt=&quot;聊聊Ceph中的核心数据分布选择算法——CRUSH&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="云存储" scheme="http://blog.a-stack.com/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    
      <category term="Ceph" scheme="http://blog.a-stack.com/tags/Ceph/"/>
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="云存储" scheme="http://blog.a-stack.com/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>Ceph-install-by-ceph-ansible</title>
    <link href="http://blog.a-stack.com/2018/08/04/Ceph-install-by-ceph-ansible/"/>
    <id>http://blog.a-stack.com/2018/08/04/Ceph-install-by-ceph-ansible/</id>
    <published>2018-08-04T11:12:55.000Z</published>
    <updated>2018-08-14T14:59:47.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/qnsource/banner/08.jpg" alt="Test Picture"></p><p><strong>摘要：</strong></p><a id="more"></a><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><ul><li>操作系统：Centos 7.2</li><li>Vagrant：2.1.2</li><li>VirtualBox-5.1 </li><li>Ansible：2.6.2</li><li>pip</li><li>git</li></ul><h2 id="安装Vagrant"><a href="#安装Vagrant" class="headerlink" title="安装Vagrant"></a>安装Vagrant</h2><p>第1步：在CentOS 7上安装VirtualBox 5.1</p><p>尽管在www.howtoing.com上有几个关于安装virtualBox的教程（例如， <a href="https://www.howtoing.com/install-virtualbox-on-redhat-centos-fedora/" target="_blank" rel="noopener">在CentOS 7上安装VirtualBox</a> ），但是，我将很快通过virtualbox 5.1安装。</p><p>首先安装VirtualBox依赖项。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum -y install gcc dkms make qt libgomp patch </span></span><br><span class="line"><span class="comment"># yum -y install kernel-headers kernel-devel binutils glibc-headers glibc-devel font-forge</span></span><br></pre></td></tr></table></figure><p>接下来添加VirtualBox库。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">cd</span> /etc/yum.repos.d/</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> wget http://download.virtualbox.org/virtualbox/rpm/rhel/virtualbox.repo</span></span><br></pre></td></tr></table></figure><p>现在安装和构建内核模块。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum install -y VirtualBox-5.1</span></span><br><span class="line"><span class="comment"># /sbin/rcvboxdrv setup</span></span><br></pre></td></tr></table></figure><blockquote><p>Bug fix： yum install kernel-devel-3.10.0-862.3.3.el7.x86_64</p></blockquote><p>第2步：在CentOS 7上安装Vagrant</p><p>在这里，我们将使用<a href="https://www.howtoing.com/20-linux-yum-yellowdog-updater-modified-commands-for-package-mangement/" target="_blank" rel="noopener">yum命令</a>下载并安装Vagrant的最新版本（即在编写时为1.9.6）。</p><p>—————- For 64-bit machine —————-</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum -y install https://releases.hashicorp.com/vagrant/2.1.2/vagrant_2.1.2_x86_64.rpm</span></span><br></pre></td></tr></table></figure><h2 id="安装pip"><a href="#安装pip" class="headerlink" title="安装pip"></a>安装pip</h2><blockquote><p>需要先安装扩展源EPEL。EPEL(<a href="http://fedoraproject.org/wiki/EPEL" target="_blank" rel="noopener">http://fedoraproject.org/wiki/EPEL</a>) 是由 Fedora 社区打造，为 RHEL 及衍生发行版如 CentOS、Scientific Linux 等提供高质量软件包的项目。</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sudo yum -y install epel-release</span></span><br><span class="line"><span class="comment"># sudo yum -y install python-pip</span></span><br></pre></td></tr></table></figure><h2 id="Ceph-Ansible"><a href="#Ceph-Ansible" class="headerlink" title="Ceph-Ansible"></a>Ceph-Ansible</h2><p>You can install directly from the source on GitHub by following these steps:</p><ul><li><p>Clone the repository:</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="keyword">clone</span> <span class="title">https</span>://github.com/ceph/ceph-ansible.git</span><br></pre></td></tr></table></figure></li><li><p>Next, you must decide which branch of <code>ceph-ansible</code> you wish to use. There are stable branches to choose from or you could use the master branch:</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">git</span> checkout <span class="variable">$branch</span></span><br></pre></td></tr></table></figure></li><li><p>Next, use pip and the provided requirements.txt to install ansible and other needed python libraries:</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip <span class="keyword">install</span> -r requirements.txt</span><br></pre></td></tr></table></figure></li></ul><h2 id="Ansible-on-RHEL-and-CentOS"><a href="#Ansible-on-RHEL-and-CentOS" class="headerlink" title="Ansible on RHEL and CentOS"></a>Ansible on RHEL and CentOS</h2><p>You can acquire Ansible on RHEL and CentOS by installing from <a href="https://access.redhat.com/articles/3174981" target="_blank" rel="noopener">Ansible channel</a>.</p><p>On RHEL:</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">subscription-manager repos --enable=rhel<span class="number">-7</span>-server-ansible<span class="number">-2</span>-rpms</span><br></pre></td></tr></table></figure><p>(CentOS does not use subscription-manager and already has “Extras” enabled by default.)</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum <span class="keyword">install</span> ansible</span><br></pre></td></tr></table></figure><h2 id="Ansible-on-Ubuntu"><a href="#Ansible-on-Ubuntu" class="headerlink" title="Ansible on Ubuntu"></a>Ansible on Ubuntu</h2><p>You can acquire Ansible on Ubuntu by using the <a href="https://launchpad.net/~ansible/+archive/ubuntu/ansible" target="_blank" rel="noopener">Ansible PPA</a>.</p><figure class="highlight smali"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo<span class="built_in"> add-apt-repository </span>ppa:ansible/ansible</span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt install ansible</span><br></pre></td></tr></table></figure><h1 id="Releases"><a href="#Releases" class="headerlink" title="Releases"></a>Releases</h1><p>The following branches should be used depending on your requirements. The <code>stable-*</code>branches have been QE tested and sometimes recieve backport fixes throughout their lifecycle. The <code>master</code> branch should be considered experimental and used with caution.</p><ul><li><code>stable-3.0</code> Support for ceph versions <code>jewel</code> and <code>luminous</code>. This branch supports ansible versions <code>2.4</code> and <code>2.5</code>.</li><li><code>stable-3.1</code> Support for ceph version <code>luminous</code> and <code>mimic</code>. This branch supports ansible versions <code>2.4</code> and <code>2.5</code></li><li><code>master</code> Support for ceph versions <code>luminous</code>, and <code>mimic</code>. This branch supports ansible version 2.5``.</li></ul><p>We will customize the following sample files for sandbox deployment: vagrant_variables.yml.sample<br>options that ought to be supplied to Vagrantfile the instructions from Vagrantfile<br>need to be built and the actions to provision them. site.yml.sample<br>: This file presents a sample of configuration to describe the types of virtual machine that<br>. The vagrant command uses : This represents a set of sample Ansible tasks as a part of<br>main Ansible playbook. The vagrant provisioner that runs after you start all the virtual machines is tasked with the responsibility of running this playbook. This playbook is responsible for completing the final step of bringing the Ceph cluster up. group_vars/all.yml.sample<br>: The all .yml.sample present within group_vars/<br>directory contains an Ansible-specific configuration that applies to all virtual machine hostgroups. These variables will be consumed by the Ansible playbook when the vagrant provisioner runs it.</p><blockquote><p>在VM中需要配置V-TX；</p></blockquote><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="http://docs.ceph.com/ceph-ansible/master/index.html" target="_blank" rel="noopener">http://docs.ceph.com/ceph-ansible/master/index.html</a></li><li>​</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/qnsource/banner/08.jpg&quot; alt=&quot;Test Picture&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="云存储" scheme="http://blog.a-stack.com/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    
      <category term="Ceph" scheme="http://blog.a-stack.com/tags/Ceph/"/>
    
      <category term="云存储" scheme="http://blog.a-stack.com/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
      <category term="部署" scheme="http://blog.a-stack.com/tags/%E9%83%A8%E7%BD%B2/"/>
    
  </entry>
  
  <entry>
    <title>经典网络复现之SqueezeNet</title>
    <link href="http://blog.a-stack.com/2018/07/12/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E5%A4%8D%E7%8E%B0%E4%B9%8BSqueezeNet/"/>
    <id>http://blog.a-stack.com/2018/07/12/经典网络复现之SqueezeNet/</id>
    <published>2018-07-12T05:58:12.000Z</published>
    <updated>2018-07-20T15:52:08.839Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/qnsource/images/2018-07-12-经典网络复现之SqueezeNet/Fire-Module.PNG" alt="Fire-Module"></p><p><strong>摘要：</strong> 本文记录利用ImageNet数据集复现经典网络SqueezeNet的过程，并记录在大型数据集训练过程中需要考虑的问题。</p><a id="more"></a><p>为了增强对state of the art深度神经网络模型的认知，准备进行一系列模型的复现工作，使用ImageNet的大规模图像分类数据集，从头训练各个经典的神经网络模型，同时结合作者论文对训练过程中的技巧进行归纳总结，主要安排如下几部分内容：</p><ul><li>ImageNet数据集及数据准备</li><li>AlexNet网络</li><li>VGG网络</li><li>GoogLeNet网络</li><li>ResNet网络</li><li><strong>SqueezeNet网络</strong></li></ul><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>SqueezeNet正如作者在论文题目中特别强调的那样，主要针对模型大小进行了深度优化，在保证模型精度没有太多损失的情况下，极大的缩小了所需模型的尺寸，为在嵌入式设备部署提供了强力支撑。SqueezeNet为我们裁剪模型和设计可在资源受限设备上运行的高性能模型提供了指导，特别是Fire Module的设计原理值得思考。</p><ul><li>论文：SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and &lt;0.5MB  model size，2016.<ul><li>URL: <a href="https://arxiv.org/abs/1602.07360" target="_blank" rel="noopener">https://arxiv.org/abs/1602.07360</a></li></ul></li><li>代码链接：<a href="https://github.com/DeepScale/SqueezeNet" target="_blank" rel="noopener">https://github.com/DeepScale/SqueezeNet</a></li><li>数据集： ImageNet 2012 ILSRVC数据集（数据集的获取及准备详见<a href="/2018/07/06/ImageNet-DataSet/">ImageNet-DataSet</a>）</li><li>计算框架： MxNet</li><li>算力资源：AWS云主机p2.8xlarge：8个Tesla K80 GPU ($7.20/hour)<ul><li>总计训练时间1天左右</li><li>每轮迭代时间：~1060秒</li><li>在ImageNet数据集上的效果：</li></ul></li></ul><h2 id="SqueezeNet"><a href="#SqueezeNet" class="headerlink" title="SqueezeNet"></a>SqueezeNet</h2><ul><li>microarchitecture and macro architecture<ul><li>在设计深度网络架构的过程中，如果手动选择每一层的滤波器显得过于繁复。通常先构建由几个卷积层组成的小模块，再将模块堆叠形成完整的网络。定义这种模块的网络为CNN microarchitecture。</li><li>与模块相对应，定义完整的网络架构为CNN macroarchitecture。在完整的网络架构中，深度是一个重要的参数。</li></ul></li><li>比如FPGA中只有10MB的片上内存空间，没有片下存储，对模型大小要求较高；ASICs也会有相同的需求；</li><li>​</li></ul><h3 id="设计原则"><a href="#设计原则" class="headerlink" title="设计原则"></a>设计原则</h3><p>作者在论文中给出SqueezeNet的三条设计原则：</p><ul><li>尽量用1x1卷积替代3x3卷积，目的自然是降低参数量；</li><li>降低输入到3x3卷积对象的channel数目，在SqueezeNet中是使用squeeze模块来实现的；</li><li>尽量在网络后面层次中进行降采样，这样可以是卷积层获得更大的激活地图，从而获得更高的精度；</li></ul><h3 id="Fire-Module"><a href="#Fire-Module" class="headerlink" title="Fire Module"></a>Fire Module</h3><p><img src="/qnsource/images/2018-07-12-经典网络复现之SqueezeNet/Fire-Module.PNG" alt="Fire-Module"></p><p>Fire Module是本文的核心构件，思想非常简单，就是将原来简单的一层conv层变成两层：squeeze层+expand层，各自带上Relu激活层。Fire Moduel主要包括squeeze模块和expand模块，其中squeeze模块全部由1x1卷积组成，而expand模块由1x1卷积和3x3卷积组成：</p><ul><li>squeeze模块中卷积核个数一定要小于expand模块中卷积核的个数，只有这样才能达到降参和压缩的目的；</li><li>squeeze中的1x1卷积起到了降维的效果；</li><li>为了实现expand模块中1x1卷积和3x3卷积之后的数据能够concatenate在一起，对于输入3x3的对象需要增加1的zero-padding操作；</li><li>在squeeze模块和expand模块之后通过ReLU进行激活；</li></ul><h3 id="模型架构及参数"><a href="#模型架构及参数" class="headerlink" title="模型架构及参数"></a>模型架构及参数</h3><p><img src="/qnsource/images/2018-07-12-经典网络复现之SqueezeNet/architechtureofSqueezeNet.png" alt="architechtureofSqueezeNet"></p><p><img src="/qnsource/images/2018-07-12-经典网络复现之SqueezeNet/parameters-in-SqueezeNet.PNG" alt="parameters-in-SqueezeNet"></p><p>如图所示，</p><ul><li>SqueezeNet中彻底放弃了全连接网络；</li><li>作者论文中初始学习率很大，为0.04，实际实验中，发现这么大的学习率震荡太厉害，降为0.01；</li><li>降维的操作尽量放在了模型后半段，为了满足第三条设计原则；</li><li>参数方面：使用了8个Fire Module，每个Fire Module中，squeeze的卷积核数目是expand的1/8；</li><li>fire9之后采用了dropout，其中keep_prob=0.5;</li></ul><h3 id="分析结果"><a href="#分析结果" class="headerlink" title="分析结果"></a>分析结果</h3><p><img src="/qnsource/images/2018-07-12-经典网络复现之SqueezeNet/lab_results.png" alt="lab_results"></p><p>如图所示，SqueezeNet模型本身是AlexNet的1/50，却可以获得相近的准确率，通过利用Deep Compression技术可以进一步压缩模型，实现1/510模型大小情况下的相同性能（当然实际中，由于Deep Compression采取了编码策略，需要编码本，会带来一定的额外开销）。</p><h3 id="扩展阅读-Deep-Compression"><a href="#扩展阅读-Deep-Compression" class="headerlink" title="[扩展阅读]Deep Compression"></a>[扩展阅读]Deep Compression</h3><ul><li>Deep compression: Compressing DNNs with pruning, trained quantization and huffman coding， 2015</li><li>常见的模型压缩技术<ul><li>奇异值分解(singular value decomposition (SVD))<a href="https://blog.csdn.net/csdnldp/article/details/78648543#fn:1" target="_blank" rel="noopener">1</a> </li><li>网络剪枝（Network Pruning）<a href="https://blog.csdn.net/csdnldp/article/details/78648543#fn:2" target="_blank" rel="noopener">2</a>：使用网络剪枝和稀疏矩阵 </li><li>深度压缩（Deep compression）<a href="https://blog.csdn.net/csdnldp/article/details/78648543#fn:3" target="_blank" rel="noopener">3</a>：使用网络剪枝，数字化和huffman编码 </li><li>硬件加速器（hardware accelerator）<a href="https://blog.csdn.net/csdnldp/article/details/78648543#fn:4" target="_blank" rel="noopener">4</a></li></ul></li></ul><h2 id="重头训练一个SqueezeNet"><a href="#重头训练一个SqueezeNet" class="headerlink" title="重头训练一个SqueezeNet"></a>重头训练一个SqueezeNet</h2><ol><li>使用MxNet构建AlexNet代码</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import the necessary packages</span></span><br><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MxSqueezeNet</span>:</span></span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">squeeze</span><span class="params">(input, numFilter)</span>:</span></span><br><span class="line"><span class="comment"># the first part of a FIRE module consists of a number of 1x1</span></span><br><span class="line"><span class="comment"># filter squeezes on the input data followed by an activation</span></span><br><span class="line">squeeze_1x1 = mx.sym.Convolution(data=input, kernel=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">stride=(<span class="number">1</span>, <span class="number">1</span>), num_filter=numFilter)</span><br><span class="line">act_1x1 = mx.sym.LeakyReLU(data=squeeze_1x1,</span><br><span class="line">act_type=<span class="string">"elu"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># return the activation for the squeeze</span></span><br><span class="line"><span class="keyword">return</span> act_1x1</span><br><span class="line"></span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fire</span><span class="params">(input, numSqueezeFilter, numExpandFilter)</span>:</span></span><br><span class="line"><span class="comment"># construct the 1x1 squeeze followed by the 1x1 expand</span></span><br><span class="line">squeeze_1x1 = MxSqueezeNet.squeeze(input, numSqueezeFilter)</span><br><span class="line">expand_1x1 = mx.sym.Convolution(data=squeeze_1x1,</span><br><span class="line">kernel=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), num_filter=numExpandFilter)</span><br><span class="line">relu_expand_1x1 = mx.sym.LeakyReLU(data=expand_1x1,</span><br><span class="line">act_type=<span class="string">"elu"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># construct the 3x3 expand</span></span><br><span class="line">expand_3x3 = mx.sym.Convolution(data=squeeze_1x1, pad=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">kernel=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), num_filter=numExpandFilter)</span><br><span class="line">relu_expand_3x3 = mx.sym.LeakyReLU(data=expand_3x3,</span><br><span class="line">act_type=<span class="string">"elu"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># the output of the FIRE module is the concatenation of the</span></span><br><span class="line"><span class="comment"># activation for the 1x1 and 3x3 expands along the channel</span></span><br><span class="line"><span class="comment"># dimension</span></span><br><span class="line">output = mx.sym.Concat(relu_expand_1x1, relu_expand_3x3,</span><br><span class="line">dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># return the output of the FIRE module</span></span><br><span class="line"><span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build</span><span class="params">(classes)</span>:</span></span><br><span class="line"><span class="comment"># data input</span></span><br><span class="line">data = mx.sym.Variable(<span class="string">"data"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #1: CONV =&gt; RELU =&gt; POOL</span></span><br><span class="line">conv_1 = mx.sym.Convolution(data=data, kernel=(<span class="number">7</span>, <span class="number">7</span>),</span><br><span class="line">stride=(<span class="number">2</span>, <span class="number">2</span>), num_filter=<span class="number">96</span>)</span><br><span class="line">relu_1 = mx.sym.LeakyReLU(data=conv_1, act_type=<span class="string">"elu"</span>)</span><br><span class="line">pool_1 = mx.sym.Pooling(data=relu_1, kernel=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">stride=(<span class="number">2</span>, <span class="number">2</span>), pool_type=<span class="string">"max"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #2-4: (FIRE * 3) =&gt; POOL</span></span><br><span class="line">fire_2 = MxSqueezeNet.fire(pool_1, numSqueezeFilter=<span class="number">16</span>,</span><br><span class="line">numExpandFilter=<span class="number">64</span>)</span><br><span class="line">fire_3 = MxSqueezeNet.fire(fire_2, numSqueezeFilter=<span class="number">16</span>,</span><br><span class="line">numExpandFilter=<span class="number">64</span>)</span><br><span class="line">fire_4 = MxSqueezeNet.fire(fire_3, numSqueezeFilter=<span class="number">32</span>,</span><br><span class="line"> numExpandFilter=<span class="number">128</span>)</span><br><span class="line">pool_4 = mx.sym.Pooling(data=fire_4, kernel=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">stride=(<span class="number">2</span>, <span class="number">2</span>), pool_type=<span class="string">"max"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #5-8: (FIRE * 4) =&gt; POOL</span></span><br><span class="line">fire_5 = MxSqueezeNet.fire(pool_4, numSqueezeFilter=<span class="number">32</span>,</span><br><span class="line">numExpandFilter=<span class="number">128</span>)</span><br><span class="line">fire_6 = MxSqueezeNet.fire(fire_5, numSqueezeFilter=<span class="number">48</span>,</span><br><span class="line">numExpandFilter=<span class="number">192</span>)</span><br><span class="line">fire_7 = MxSqueezeNet.fire(fire_6, numSqueezeFilter=<span class="number">48</span>,</span><br><span class="line">numExpandFilter=<span class="number">192</span>)</span><br><span class="line">fire_8 = MxSqueezeNet.fire(fire_7, numSqueezeFilter=<span class="number">64</span>,</span><br><span class="line">numExpandFilter=<span class="number">256</span>)</span><br><span class="line">pool_8 = mx.sym.Pooling(data=fire_8, kernel=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">stride=(<span class="number">2</span>, <span class="number">2</span>), pool_type=<span class="string">"max"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #9-10: FIRE =&gt; DROPOUT =&gt; CONV =&gt; RELU =&gt; POOL</span></span><br><span class="line">fire_9 = MxSqueezeNet.fire(pool_8, numSqueezeFilter=<span class="number">64</span>,</span><br><span class="line">numExpandFilter=<span class="number">256</span>)</span><br><span class="line">do_9 = mx.sym.Dropout(data=fire_9, p=<span class="number">0.5</span>)</span><br><span class="line">conv_10 = mx.sym.Convolution(data=do_9, num_filter=classes,</span><br><span class="line">kernel=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">relu_10 = mx.sym.LeakyReLU(data=conv_10, act_type=<span class="string">"elu"</span>)</span><br><span class="line">pool_10 = mx.sym.Pooling(data=relu_10, kernel=(<span class="number">13</span>, <span class="number">13</span>),</span><br><span class="line">pool_type=<span class="string">"avg"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># softmax classifier</span></span><br><span class="line">flatten = mx.sym.Flatten(data=pool_10)</span><br><span class="line">model = mx.sym.SoftmaxOutput(data=flatten, name=<span class="string">"softmax"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># return the network architecture</span></span><br><span class="line"><span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><blockquote><p><strong>几点注意点：</strong></p><ol><li>使用ELU替代了ReLU激活函数；在ImageNet数据集中，ELU表现效果由于ReLU；</li><li>3x3 expand中有个pad=（1，1）</li><li>最有使用的全局平均池化层，kernel=（13，13）</li><li>全局池化输出被flatten之后直接丢给softmax</li></ol></blockquote><h3 id="SqueezeNet的TensorFLow实现"><a href="#SqueezeNet的TensorFLow实现" class="headerlink" title="SqueezeNet的TensorFLow实现"></a>SqueezeNet的TensorFLow实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SqueezeNet</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, inputs, nb_classes=<span class="number">1000</span>, is_training=True)</span>:</span></span><br><span class="line">        <span class="comment"># conv1</span></span><br><span class="line">        net = tf.layers.conv2d(inputs, <span class="number">96</span>, [<span class="number">7</span>, <span class="number">7</span>], strides=[<span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">                                 padding=<span class="string">"SAME"</span>, activation=tf.nn.relu,</span><br><span class="line">                                 name=<span class="string">"conv1"</span>)</span><br><span class="line">        <span class="comment"># maxpool1</span></span><br><span class="line">        net = tf.layers.max_pooling2d(net, [<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">                                      name=<span class="string">"maxpool1"</span>)</span><br><span class="line">        <span class="comment"># fire2</span></span><br><span class="line">        net = self._fire(net, <span class="number">16</span>, <span class="number">64</span>, <span class="string">"fire2"</span>)</span><br><span class="line">        <span class="comment"># fire3</span></span><br><span class="line">        net = self._fire(net, <span class="number">16</span>, <span class="number">64</span>, <span class="string">"fire3"</span>)</span><br><span class="line">        <span class="comment"># fire4</span></span><br><span class="line">        net = self._fire(net, <span class="number">32</span>, <span class="number">128</span>, <span class="string">"fire4"</span>)</span><br><span class="line">        <span class="comment"># maxpool4</span></span><br><span class="line">        net = tf.layers.max_pooling2d(net, [<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">                                      name=<span class="string">"maxpool4"</span>)</span><br><span class="line">        <span class="comment"># fire5</span></span><br><span class="line">        net = self._fire(net, <span class="number">32</span>, <span class="number">128</span>, <span class="string">"fire5"</span>)</span><br><span class="line">        <span class="comment"># fire6</span></span><br><span class="line">        net = self._fire(net, <span class="number">48</span>, <span class="number">192</span>, <span class="string">"fire6"</span>)</span><br><span class="line">        <span class="comment"># fire7</span></span><br><span class="line">        net = self._fire(net, <span class="number">48</span>, <span class="number">192</span>, <span class="string">"fire7"</span>)</span><br><span class="line">        <span class="comment"># fire8</span></span><br><span class="line">        net = self._fire(net, <span class="number">64</span>, <span class="number">256</span>, <span class="string">"fire8"</span>)</span><br><span class="line">        <span class="comment"># maxpool8</span></span><br><span class="line">        net = tf.layers.max_pooling2d(net, [<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">                                      name=<span class="string">"maxpool8"</span>)</span><br><span class="line">        <span class="comment"># fire9</span></span><br><span class="line">        net = self._fire(net, <span class="number">64</span>, <span class="number">256</span>, <span class="string">"fire9"</span>)</span><br><span class="line">        <span class="comment"># dropout</span></span><br><span class="line">        net = tf.layers.dropout(net, <span class="number">0.5</span>, training=is_training)</span><br><span class="line">        <span class="comment"># conv10</span></span><br><span class="line">        net = tf.layers.conv2d(net, <span class="number">1000</span>, [<span class="number">1</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                               padding=<span class="string">"SAME"</span>, activation=tf.nn.relu,</span><br><span class="line">                               name=<span class="string">"conv10"</span>)</span><br><span class="line">        <span class="comment"># avgpool10</span></span><br><span class="line">        net = tf.layers.average_pooling2d(net, [<span class="number">13</span>, <span class="number">13</span>], strides=[<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                                          name=<span class="string">"avgpool10"</span>)</span><br><span class="line">        <span class="comment"># squeeze the axis</span></span><br><span class="line">        net = tf.squeeze(net, axis=[<span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">        self.logits = net</span><br><span class="line">        self.prediction = tf.nn.softmax(net)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_fire</span><span class="params">(self, inputs, squeeze_depth, expand_depth, scope)</span>:</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(scope):</span><br><span class="line">            squeeze = tf.layers.conv2d(inputs, squeeze_depth, [<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                                       strides=[<span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">"SAME"</span>,</span><br><span class="line">                                       activation=tf.nn.relu, name=<span class="string">"squeeze"</span>)</span><br><span class="line">            <span class="comment"># squeeze</span></span><br><span class="line">            expand_1x1 = tf.layers.conv2d(squeeze, expand_depth, [<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                                          strides=[<span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">"SAME"</span>,</span><br><span class="line">                                          activation=tf.nn.relu, name=<span class="string">"expand_1x1"</span>)</span><br><span class="line">            expand_3x3 = tf.layers.conv2d(squeeze, expand_depth, [<span class="number">3</span>, <span class="number">3</span>],</span><br><span class="line">                                          strides=[<span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">"SAME"</span>,</span><br><span class="line">                                          activation=tf.nn.relu, name=<span class="string">"expand_3x3"</span>)</span><br><span class="line">            <span class="keyword">return</span> tf.concat([expand_1x1, expand_3x3], axis=<span class="number">3</span>)</span><br></pre></td></tr></table></figure><h3 id="训练SqueezeNet"><a href="#训练SqueezeNet" class="headerlink" title="训练SqueezeNet"></a>训练SqueezeNet</h3><p>训练用的脚本和前面几个网络一致。</p><blockquote><p><strong>几个注意点：</strong></p><ol><li><code>batchSize = config.BATCH_SIZE * config.NUM_DEVICES</code>; 使用k80 12GB先存，选择batchSzie=128；</li><li>优化算法使用SGD，初始学习率为1e-2，动量0.9，L2权重正则化参数0.0002；rescale参数尤为关键，根据批的大小放大梯度：rescale_grad=1.0 / batchSize；</li><li>model中的<code>ctx</code>参数用于指定用于训练的GPU；</li><li>使用了Xavier进行参数初始化，与原模型略有不同，Xavier是目前CNN网络常采用的参数初始化方式；initializer=mx.initializer.Xavier()；</li><li>In Keras, the ELU activation uses a default α value of 1.0. • But in mxnet, the ELU α value defaults to 0.25.</li></ol></blockquote><h4 id="学习率的控制"><a href="#学习率的控制" class="headerlink" title="学习率的控制"></a>学习率的控制</h4><div class="table-container"><table><thead><tr><th>Epoch</th><th>学习率</th></tr></thead><tbody><tr><td>1-64</td><td>1e-2</td></tr><tr><td>65-80</td><td>1e-3</td></tr><tr><td>81-89</td><td>1e-4</td></tr><tr><td>90-100</td><td>1e-5</td></tr></tbody></table></div><blockquote><ol><li>控制每轮学习率修改的观察窗口要在10-15个epoch之后再下结论，确定该阶段验证集准确率饱和了再行降低学习率；</li><li>调整学习率 <code>python train_alexnet.py --checkpoints checkpoints --prefix alexnet \ --start-epoch 50</code></li><li>在8个GPU上，每轮用时1000多秒；</li></ol></blockquote><ol><li><p>第一遍训练采用1e-2的学习率训练75轮，发现65轮以后，验证集准确率已经不再增加；为此在65轮之后调整学习率为1e-3；</p><p><img src="/qnsource/images/2018-07-12-经典网络复现之SqueezeNet/0-86-accuracy.png" alt="0-86-accuracy"></p><p><img src="/qnsource/images/2018-07-12-经典网络复现之SqueezeNet/0-86-loss.png" alt="0-86-loss"></p></li><li><p>将学习率调整到1e-3之后，验证集准确率有大幅提升，代表调整有效，80轮之后再度饱和，降低学习率到1e-4;到89轮验证集结果如下：</p><p><img src="/qnsource/images/2018-07-12-经典网络复现之SqueezeNet/0-89-accuracy.png" alt="0-89-accuracy"></p><p><img src="/qnsource/images/2018-07-12-经典网络复现之SqueezeNet/0-89-loss.png" alt="0-89-loss"></p><p>​</p></li><li><p>进一步降低学习率到1e-5，发现整个网络没有性能提升，结束该批次参数训练过程。</p></li></ol><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><ol><li>初始学习率的选择</li></ol><p>   <img src="/qnsource/images/2018-07-12-经典网络复现之SqueezeNet/lr=0.04.PNG" alt="lr=0.04"></p><ol><li><p>BN的效果</p><p>在SqueezeNet中没有效果</p></li><li><p>ReLU vs ELU ？</p><p>用ELU替代ReLU，提升1-2%的性能；</p></li><li><p>选取90轮的训练结果，在测试集数据上进行验证，结果如下：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-attr">[INFO]</span> <span class="selector-tag">rank-1</span>: 55<span class="selector-class">.44</span>%</span><br><span class="line"><span class="selector-attr">[INFO]</span> <span class="selector-tag">rank-5</span>: 78<span class="selector-class">.10</span>%</span><br></pre></td></tr></table></figure></li></ol><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>今天终于完成了所有预定神经网络的训练过程，虽然有些网络由于本身对网络结构的认知或者是实际训练过程中没有很好的把握节奏，导致训练效果不是十分理想，但从这次的训练过程中还是学到了很多东西。整个过程大概持续了半个月左右的时间，得益于AWS上8 GPU的资源，使得很多网络的训练比原想进度要快很多，但费用也是惊人，看了下账单，发生在虚拟机上的费用大概有1万3千多，主要由于8 GPU服务器要85元人民币每个小时的费用不是所有人都可以承受的起的。所以我一直认为短期内，深度学习还是很难真正产业化的一个泡沫，很难有应用业务可以抵消这个昂贵的训练成本。我这只是复现网络，真实训练一个产品级的网络、所需要测试的参数十倍百倍于此。</p><p><img src="/qnsource/images/2018-07-12-经典网络复现之SqueezeNet/cost_AWS.png" alt="cost_AWS"></p><p>付了昂贵的学费，学习的动力也更加充足，将几种网络的训练过程进行一下简单的横向比较，同时总结一下大型网络训练过程中注意的主要内容。</p><h3 id="几种网络在训练过程的简单比较"><a href="#几种网络在训练过程的简单比较" class="headerlink" title="几种网络在训练过程的简单比较"></a>几种网络在训练过程的简单比较</h3><div class="table-container"><table><thead><tr><th>网络名称</th><th>模型大小</th><th>每轮训练时间（8GPU Tesla K80）</th><th>总迭代数+训练时间</th><th>初始化参数选择</th><th>初始学习率</th><th>激活函数</th><th>最终测试集准确率（Top-1/Top-5）</th></tr></thead><tbody><tr><td>AlexNet</td><td>239MB</td><td>~670s</td><td>~1.5天</td><td>Xavier</td><td>1e-2,动量0.9，L2 0.0005</td><td>ELU</td><td>60.20%/81.99%</td></tr><tr><td>VGG-16</td><td>529MB</td><td>~</td><td>~10天</td><td>MSRA</td><td>1e-2,动量0.9，L2 0.0005</td><td>PReLU</td><td></td></tr><tr><td>GoogLeNet</td><td>28MB</td><td>~1200s</td><td>~2天</td><td>Xavier</td><td>1e-3，Adam，L2 0.0002</td><td>ReLU</td><td>69.58%/89.01%</td></tr><tr><td>ResNet</td><td>98MB</td><td>~3500s</td><td>~3天</td><td>MSRA</td><td>1e-1,动量0.9，L2 0.0001</td><td>ReLU</td><td>71.49%/89.96%</td></tr><tr><td>SqueezeNet</td><td>5MB</td><td>~1060s</td><td>~1.5天</td><td>Xavier</td><td>1e-2，动量0.9，L2 0.0002</td><td>ELU</td><td>55.44%/78.10%</td></tr></tbody></table></div><h3 id="训练心得"><a href="#训练心得" class="headerlink" title="训练心得"></a>训练心得</h3><ol><li>训练一个大型数据集的深度神经网络是个费时费力的活，为了获得最优的参数，一般需要进行10-100次参数实验，需要极大的耐心和计算资源；</li><li><strong>原则：</strong>训练深度神经网络的目的不是找寻全局最优解，因为一般很难找到这个解，我们只是在探寻一个比上次效果更好的模型；</li><li>网络参数如何入手？<ol><li>逆机器学习流程的思考：在机器学习算法的应用逻辑里，我们总是强调要快速的开始搭建第一个模型，设定测试的基准，然后再迭代更新模型。而训练大型神经网络，由于训练过程对时间和资源消耗十分巨大，为充分利用资源，切不可盲目起步；</li><li>由于可调参数终端，所以必须要想办法缩小可调参数范围，优先选择重要参数进行调试，同时通过查阅相似数据集文献中使用的参数来进一步缩小自己调试参数的范围；</li></ol></li><li>初始学习率选择：<ol><li>学习率参数是整个参数空间中最重要的一个，如果你只想调试一个参数，那么请选择它；</li><li>初始学习率需要根据网络模型的特点来决定，一般而言1e-2可能是一个合适的学习率，但不是对所有的网络都是最佳的学习率，比如ResNet支持更大的学习率，比如1e-1,GoogLeNet而言，1e-2有点太大，验证集准确率会发生比较大的震荡；</li></ol></li><li>学习率控制：<ol><li>初始学习率选择好以后，需要在第一次迭代中让网络多运行一段时间，观察验证集上的表现决定是否变更学习率，一般当验证集误差出现阻塞或者出现明显过拟合现象时，需要停止训练，调整学习率，从打断位置或前面位置继续训练；</li><li>学习率手段衰减一般采取对数衰减的策略，比如每次衰减十倍；</li></ol></li><li>优化算法选择：<ol><li>关于优化算法的选择，一般先从尝试经典的SGD算法、配合动量设置开始训练看网络是否能够有效学习参数空间信息；</li><li>进一步的可以调整为Adam来加快梯度的更新；</li><li>在大型网络训练中还经常使用梯度的rescale操作，根据batchsize大小，放大梯度：rescale_grad=1.0 / batchSize；</li></ol></li><li>激活函数选择：先使用ReLU作为激活函数获得baseline，再选择提花为ELU来获得提升；</li><li>初始化参数选择：训练深层网络时，考虑使用Xavier,MSRA/HE的初始化参数，并配合PReLU一起使用，效果更好。</li><li>训练过程的控制：<ol><li>训练过程要利用callback机制，随时记录训练参数、checkpoints；</li><li>通过Tensorboard等工具观察训练过程的精度、误差、损失函数变化情况；</li><li>有些网络需要预训练过程，通过预训练可以加速网络学习；</li></ol></li><li>参数调优的其它技巧：<ol><li>BN</li><li>DropOut</li><li>Data Augmentation</li><li>计算框架：TensorFlow or MxNet</li><li>论文阅读与讨论</li><li>​…</li></ol></li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">ImageNet Classification with Deep Convolutional Neural Networks</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/qnsource/images/2018-07-12-经典网络复现之SqueezeNet/Fire-Module.PNG&quot; alt=&quot;Fire-Module&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 本文记录利用ImageNet数据集复现经典网络SqueezeNet的过程，并记录在大型数据集训练过程中需要考虑的问题。&lt;/p&gt;
    
    </summary>
    
      <category term="动手实践营" scheme="http://blog.a-stack.com/categories/%E5%8A%A8%E6%89%8B%E5%AE%9E%E8%B7%B5%E8%90%A5/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="网络复现" scheme="http://blog.a-stack.com/tags/%E7%BD%91%E7%BB%9C%E5%A4%8D%E7%8E%B0/"/>
    
  </entry>
  
  <entry>
    <title>经典网络复现之VGGNet</title>
    <link href="http://blog.a-stack.com/2018/07/12/2018-07-9-%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E5%A4%8D%E7%8E%B0%E4%B9%8BVGG/"/>
    <id>http://blog.a-stack.com/2018/07/12/2018-07-9-经典网络复现之VGG/</id>
    <published>2018-07-12T05:58:12.000Z</published>
    <updated>2018-07-20T14:53:24.141Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/qnsource/images/2018-07-09-经典网络复现之VGG/VGGNet.jpg" alt="VGGNet"></p><p><strong>摘要：</strong> 本文记录利用ImageNet数据集复现经典网络VGGNet的过程，并记录在大型数据集训练过程中需要考虑的问题。</p><a id="more"></a><p>为了增强对state of the art深度神经网络模型的认知，准备进行一系列模型的复现工作，使用ImageNet的大规模图像分类数据集，从头训练各个经典的神经网络模型，同时结合作者论文对训练过程中的技巧进行归纳总结，主要安排如下几部分内容：</p><ul><li>ImageNet数据集及数据准备</li><li>AlexNet网络</li><li><strong>VGG网络</strong></li><li>GoogLeNet网络</li><li>ResNet网络</li><li>SqueezeNet网络</li></ul><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>VGGNet是英国牛津大学2014年ImageNet ILSVRC第二名的网络，由于其良好的泛化性能，在被迁移到其它深度学习任务中体现出来良好的效果，是目前迁移学习中用的最多的网络。但由于网络规模和参数量实在庞大，从头训练一个网络充满难度。</p><ul><li>论文：<ul><li><a href="https://arxiv.org/abs/1409.1556" target="_blank" rel="noopener">Very Deep Convolutional Networks for Large-Scale Image Recognition</a></li></ul></li><li>数据集： ImageNet 2012 ILSRVC数据集（数据集的获取及准备详见<a href="/2018/07/06/ImageNet-DataSet/">ImageNet-DataSet</a>）</li><li>计算框架： MxNet</li><li>算力资源：AWS云主机p2.8xlarge：8个Tesla K80 GPU ($7.20/hour)<ul><li>总计训练时间&gt;10天左右</li></ul></li></ul><h2 id="重头训练一个VGGNet"><a href="#重头训练一个VGGNet" class="headerlink" title="重头训练一个VGGNet"></a>重头训练一个VGGNet</h2><p><img src="/qnsource/images/2018-07-09-经典网络复现之VGG/parameter_vgg.png" alt="parameter_vgg"></p><ol><li>由于网络深度太深、参数太多，所以从头按部就班的训练VGGNet是很漫长的过程，为此VGG的作者使用了一种<code>pre-training</code>的方式。通过不断训练小一号的网络架构，将训练后的参数作为后续较大网络的初始参数来逐步逼近完整的网络。比如为了训练VGG16，作者先训练了A网络VGG11，然后利用A网络的参数逐步训练B VGG13，最后才是D网络 VGG16。这种方式使用了<code>warmed pre-trained up</code>层参数来推进后续的网络训练。</li><li>虽然上述方法是个很好的技巧，但训练N个网络才能达到目的实在是一个痛苦的过程，随着深度学习技术的发展，尤其是参数初始化技术的发展，为训练VGG提供了更加高效的策略——使用高级的初始化策略，如Xavier或MSRA，同时配合使用参数化ReLU可以抛弃1中的预训练方式。</li></ol><h3 id="训练VGGNet"><a href="#训练VGGNet" class="headerlink" title="训练VGGNet"></a>训练VGGNet</h3><p>训练用的脚本和前面几个网络一致。</p><blockquote><p><strong>几个注意点：</strong></p><ol><li><code>batchSize = config.BATCH_SIZE * config.NUM_DEVICES</code>; 使用k80 12GB先存，选择batchSzie=<strong>32</strong>；</li><li>初始学习率为1e-2，动量0.9，L2权重正则化参数0.0005；rescale参数尤为关键，根据批的大小放大梯度：rescale_grad=1.0 / batchSize；</li><li>使用了MSRA进行参数初始化，initializer=mx.initializer.MSRAPrelu()；</li><li>同时使用参数PReLU代替ReLU作为激活函数；</li></ol></blockquote><h4 id="学习率的控制"><a href="#学习率的控制" class="headerlink" title="学习率的控制"></a>学习率的控制</h4><div class="table-container"><table><thead><tr><th>Epoch</th><th>学习率</th></tr></thead><tbody><tr><td>1-50</td><td>1e-2</td></tr><tr><td>51-70</td><td>1e-3</td></tr><tr><td>71-80</td><td>1e-4</td></tr></tbody></table></div><blockquote><ol><li>控制每轮学习率修改的观察窗口要在10-15个epoch之后再下结论，确定该阶段验证集准确率饱和了再行降低学习率；</li><li>调整学习率 <code>python train_alexnet.py --checkpoints checkpoints --prefix alexnet \ --start-epoch 50</code></li></ol></blockquote><p><img src="/qnsource/images/2018-07-09-经典网络复现之VGG/training.png" alt="training"></p><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>1.选取40轮的训练结果，在测试集数据上进行验证，结果如下：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-attr">[INFO]</span> <span class="selector-tag">rank-1</span>: 71<span class="selector-class">.42</span>% </span><br><span class="line"><span class="selector-attr">[INFO]</span> <span class="selector-tag">rank-5</span>: 90<span class="selector-class">.03</span>%</span><br></pre></td></tr></table></figure><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ol><li>为了训练VGGNet，一定要使用高级初始化参数方法，并配合参数化ReLU使用；</li><li>训练一个大型数据集的深度神经网络是个费时费力的活，为了获得最优的参数，一般需要进行10-100次参数实验，需要极大的耐心和计算资源；</li><li>训练深度神经网络的目的不是找寻全局最优解，因为一般很难找到这个解，我们只是在探寻一个比上次效果更好的模型；</li><li>先使用ReLU作为激活函数获得baseline，再选择提花为ELU来获得提升；</li><li>训练深层网络时，考虑使用MSRA/HE的初始化参数，并配合PReLU一起使用，效果更好；</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/qnsource/images/2018-07-09-经典网络复现之VGG/VGGNet.jpg&quot; alt=&quot;VGGNet&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 本文记录利用ImageNet数据集复现经典网络VGGNet的过程，并记录在大型数据集训练过程中需要考虑的问题。&lt;/p&gt;
    
    </summary>
    
      <category term="动手实践营" scheme="http://blog.a-stack.com/categories/%E5%8A%A8%E6%89%8B%E5%AE%9E%E8%B7%B5%E8%90%A5/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="网络复现" scheme="http://blog.a-stack.com/tags/%E7%BD%91%E7%BB%9C%E5%A4%8D%E7%8E%B0/"/>
    
  </entry>
  
  <entry>
    <title>经典网络复现之ResNet</title>
    <link href="http://blog.a-stack.com/2018/07/12/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E5%A4%8D%E7%8E%B0%E4%B9%8BResNet/"/>
    <id>http://blog.a-stack.com/2018/07/12/经典网络复现之ResNet/</id>
    <published>2018-07-12T05:58:12.000Z</published>
    <updated>2018-07-20T15:52:21.624Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://p4ygzcmtw.bkt.clouddn.com/images/2018-05-21-ResNet/residual-Module-2.PNG" alt="Residual Module"></p><p><strong>摘要：</strong> 本文记录利用ImageNet数据集复现经典网络ResNet的过程，并记录在大型数据集训练过程中需要考虑的问题。</p><a id="more"></a><p>为了增强对state of the art深度神经网络模型的认知，准备进行一系列模型的复现工作，使用ImageNet的大规模图像分类数据集，从头训练各个经典的神经网络模型，同时结合作者论文对训练过程中的技巧进行归纳总结，主要安排如下几部分内容：</p><ul><li>ImageNet数据集及数据准备</li><li>AlexNet网络</li><li>VGG网络</li><li>GoogLeNet网络</li><li><strong>ResNet网络</strong></li><li>SqueezeNet网络</li></ul><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>ResNet在整个深度神经网络发展过程中国起到了里程碑式的意义，残差模块的提出为训练数千层的神经网络提供了方法，后续许多网络也纷纷在其网络架构中增加残差模块，力图提升训练效率。</p><ul><li>论文：<ul><li><a href="http://arxiv.org/abs/1512.03385" target="_blank" rel="noopener">Deep Residual Learning for Image Recognition</a></li><li><a href="https://arxiv.org/abs/1603.05027" target="_blank" rel="noopener">Identity Mappings in Deep Residual Networks</a></li></ul></li><li>数据集： ImageNet 2012 ILSRVC数据集（数据集的获取及准备详见<a href="/2018/07/06/ImageNet-DataSet/">ImageNet-DataSet</a>）</li><li>计算框架： MxNet</li><li>算力资源：AWS云主机p2.8xlarge：8个Tesla K80 GPU ($7.20/hour)<ul><li>总计训练时间3天左右</li><li>每轮迭代时间：~3500秒(~1小时)</li></ul></li></ul><h2 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h2><p>由于之前准备写过一篇博客来分析ResNet，再次不再展开说明了，详细内容参见：<a href="/2018/05/21/ResNet/">经典网络归纳： ResNet</a></p><h2 id="重头训练一个ResNet"><a href="#重头训练一个ResNet" class="headerlink" title="重头训练一个ResNet"></a>重头训练一个ResNet</h2><p>我们训练的标的是ResNet50，即50层的残差网络，50代表了整个网络中所有含参数层的数目：</p><p>1 + （3x3） + (4x3) + (6x3) + (3x3) + 1 = 50</p><p>第一个卷积层使用7x7的卷积核，用于快速降低网络尺寸，配合紧接着的池化层，将输入224x224的尺寸降低到56x56。</p><p><img src="/qnsource/images/2018-07-10-经典网络复现之ResNet/ResNet—Architecture.png" alt="ResNet—Architecture"></p><ol><li>使用MxNet构建ResNet代码</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MxResNet</span>:</span></span><br><span class="line"><span class="comment"># uses "bottleneck" module with pre-activation (He et al. 2016)</span></span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">residual_module</span><span class="params">(data, K, stride, red=False, bnEps=<span class="number">2e-5</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">bnMom=<span class="number">0.9</span>)</span>:</span></span><br><span class="line"><span class="comment"># the shortcut branch of the ResNet module should be</span></span><br><span class="line"><span class="comment"># initialized as the input (identity) data</span></span><br><span class="line">shortcut = data</span><br><span class="line"></span><br><span class="line"><span class="comment"># the first block of the ResNet module are 1x1 CONVs</span></span><br><span class="line">bn1 = mx.sym.BatchNorm(data=data, fix_gamma=<span class="keyword">False</span>,</span><br><span class="line">eps=bnEps, momentum=bnMom)</span><br><span class="line">act1 = mx.sym.Activation(data=bn1, act_type=<span class="string">"relu"</span>)</span><br><span class="line">conv1 = mx.sym.Convolution(data=act1, pad=(<span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">kernel=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), num_filter=int(K * <span class="number">0.25</span>),</span><br><span class="line">no_bias=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># the second block of the ResNet module are 3x3 CONVs</span></span><br><span class="line">bn2 = mx.sym.BatchNorm(data=conv1, fix_gamma=<span class="keyword">False</span>,</span><br><span class="line">eps=bnEps, momentum=bnMom)</span><br><span class="line">act2 = mx.sym.Activation(data=bn2, act_type=<span class="string">"relu"</span>)</span><br><span class="line">conv2 = mx.sym.Convolution(data=act2, pad=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">kernel=(<span class="number">3</span>, <span class="number">3</span>), stride=stride, num_filter=int(K * <span class="number">0.25</span>),</span><br><span class="line">no_bias=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># the third block of the ResNet module is another set of 1x1</span></span><br><span class="line"><span class="comment"># CONVs</span></span><br><span class="line">bn3 = mx.sym.BatchNorm(data=conv2, fix_gamma=<span class="keyword">False</span>,</span><br><span class="line">eps=bnEps, momentum=bnMom)</span><br><span class="line">act3 = mx.sym.Activation(data=bn3, act_type=<span class="string">"relu"</span>)</span><br><span class="line">conv3 = mx.sym.Convolution(data=act3, pad=(<span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">kernel=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), num_filter=K, no_bias=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># if we are to reduce the spatial size, apply a CONV layer</span></span><br><span class="line"><span class="comment"># to the shortcut</span></span><br><span class="line"><span class="keyword">if</span> red:</span><br><span class="line">shortcut = mx.sym.Convolution(data=act1, pad=(<span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">kernel=(<span class="number">1</span>, <span class="number">1</span>), stride=stride, num_filter=K,</span><br><span class="line">no_bias=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># add together the shortcut and the final CONV</span></span><br><span class="line">add = conv3 + shortcut</span><br><span class="line"></span><br><span class="line"><span class="comment"># return the addition as the output of the ResNet module</span></span><br><span class="line"><span class="keyword">return</span> add</span><br><span class="line"></span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build</span><span class="params">(classes, stages, filters, bnEps=<span class="number">2e-5</span>, bnMom=<span class="number">0.9</span>)</span>:</span></span><br><span class="line"><span class="comment"># data input</span></span><br><span class="line">data = mx.sym.Variable(<span class="string">"data"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #1: BN =&gt; CONV =&gt; ACT =&gt; POOL, then initialize the</span></span><br><span class="line"><span class="comment"># "body" of the network</span></span><br><span class="line">bn1_1 = mx.sym.BatchNorm(data=data, fix_gamma=<span class="keyword">True</span>,</span><br><span class="line">eps=bnEps, momentum=bnMom)</span><br><span class="line">conv1_1 = mx.sym.Convolution(data=bn1_1, pad=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">kernel=(<span class="number">7</span>, <span class="number">7</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), num_filter=filters[<span class="number">0</span>],</span><br><span class="line">no_bias=<span class="keyword">True</span>)</span><br><span class="line">bn1_2 = mx.sym.BatchNorm(data=conv1_1, fix_gamma=<span class="keyword">False</span>,</span><br><span class="line">eps=bnEps, momentum=bnMom)</span><br><span class="line">act1_2 = mx.sym.Activation(data=bn1_2, act_type=<span class="string">"relu"</span>)</span><br><span class="line">pool1 = mx.sym.Pooling(data=act1_2, pool_type=<span class="string">"max"</span>,</span><br><span class="line">pad=(<span class="number">1</span>, <span class="number">1</span>), kernel=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">body = pool1</span><br><span class="line"></span><br><span class="line"><span class="comment"># loop over the number of stages</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(stages)):</span><br><span class="line"><span class="comment"># initialize the stride, then apply a residual module</span></span><br><span class="line"><span class="comment"># used to reduce the spatial size of the input volume</span></span><br><span class="line">stride = (<span class="number">1</span>, <span class="number">1</span>) <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">else</span> (<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">body = MxResNet.residual_module(body, filters[i + <span class="number">1</span>],</span><br><span class="line">stride, red=<span class="keyword">True</span>, bnEps=bnEps, bnMom=bnMom)</span><br><span class="line"></span><br><span class="line"><span class="comment"># loop over the number of layers in the stage</span></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>, stages[i] - <span class="number">1</span>):</span><br><span class="line"><span class="comment"># apply a ResNet module</span></span><br><span class="line">body = MxResNet.residual_module(body, filters[i + <span class="number">1</span>],</span><br><span class="line">(<span class="number">1</span>, <span class="number">1</span>), bnEps=bnEps, bnMom=bnMom)</span><br><span class="line"></span><br><span class="line"><span class="comment"># apply BN =&gt; ACT =&gt; POOL</span></span><br><span class="line">bn2_1 = mx.sym.BatchNorm(data=body, fix_gamma=<span class="keyword">False</span>,</span><br><span class="line">eps=bnEps, momentum=bnMom)</span><br><span class="line">act2_1 = mx.sym.Activation(data=bn2_1, act_type=<span class="string">"relu"</span>)</span><br><span class="line">pool2 = mx.sym.Pooling(data=act2_1, pool_type=<span class="string">"avg"</span>,</span><br><span class="line">global_pool=<span class="keyword">True</span>, kernel=(<span class="number">7</span>, <span class="number">7</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># softmax classifier</span></span><br><span class="line">flatten = mx.sym.Flatten(data=pool2)</span><br><span class="line">fc1 = mx.sym.FullyConnected(data=flatten, num_hidden=classes)</span><br><span class="line">model = mx.sym.SoftmaxOutput(data=fc1, name=<span class="string">"softmax"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># return the network architecture</span></span><br><span class="line"><span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><blockquote><p><strong>几点注意点：</strong></p><ol><li>在bottleneck版本的残差模块中，前两个卷积核的数目是第三个的1/4；</li><li>本次试验中使用了预激活版本的残差块；</li><li>整个网络中没有使用dropout层；</li><li>注意，网络结构一开始，先使用一个BN应用到输入数据，起到正则化的作用；</li><li>全局池化输出被flatten之后接一个FC层丢给softmax</li></ol></blockquote><h3 id="训练ResNet"><a href="#训练ResNet" class="headerlink" title="训练ResNet"></a>训练ResNet</h3><p>训练用的脚本和前面几个网络一致。</p><blockquote><p><strong>几个注意点：</strong></p><ol><li><code>batchSize = config.BATCH_SIZE * config.NUM_DEVICES</code>; 使用k80 12GB先存，选择batchSzie=<strong>32</strong>；</li><li>优化算法使用SGD，初始学习率为1e-1，动量0.9，L2权重正则化参数0.0001；rescale参数尤为关键，根据批的大小放大梯度：rescale_grad=1.0 / batchSize；（He论文的建议参数）</li><li>使用了MSRA进行参数初始化，initializer=mx.initializer.MSRAPrelu()；</li></ol></blockquote><h4 id="学习率的控制"><a href="#学习率的控制" class="headerlink" title="学习率的控制"></a>学习率的控制</h4><blockquote><p>训练ResNet由于初始学习率高，所以最终完成训练所需的迭代数目要小很多；</p></blockquote><div class="table-container"><table><thead><tr><th>Epoch</th><th>学习率</th></tr></thead><tbody><tr><td>1-64</td><td>1e-2</td></tr><tr><td>65-80</td><td>1e-3</td></tr><tr><td>81-89</td><td>1e-4</td></tr><tr><td>90-100</td><td>1e-5</td></tr></tbody></table></div><blockquote><ol><li>控制每轮学习率修改的观察窗口要在10-15个epoch之后再下结论，确定该阶段验证集准确率饱和了再行降低学习率；</li><li>调整学习率 <code>python train_alexnet.py --checkpoints checkpoints --prefix alexnet \ --start-epoch 50</code></li><li>在8个GPU上，每轮用时1000多秒；</li></ol></blockquote><ol><li><p>第一遍训练采用1e-1的学习率训练16轮，发现饱和现象，而且训练误差和测试误差约拉越大；</p><p><img src="/qnsource/images/2018-07-10-经典网络复现之ResNet/1-16.png" alt="1-16"></p><p><img src="/qnsource/images/2018-07-10-经典网络复现之ResNet/1-16-loss.png" alt="1-16-loss"></p></li><li><p>在第10个迭代调整学习率到1e-2，验证集准确率有大幅提升，代表调整有效，之后在16轮迭代之后再次降低学习率到1e-3,25轮调整学习率到1e-4，最终top-5的准确率为0.884073，top-1准确率为0.68338：</p><p><img src="/qnsource/images/2018-07-10-经典网络复现之ResNet/1-31-accuracy.png" alt="1-31-accuracy"><img src="/qnsource/images/2018-07-10-经典网络复现之ResNet/1-31-loss.png" alt="1-31-loss"></p></li></ol><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><ol><li><p>初始学习率的选择</p><p>初始学习率如果选择1e-2，与1e-1比，很早模型就出现过拟合现象，无法到达更高的训练精度；</p><p>比如使用1e-1，在第10轮调整学习率到1e-2之后，网络准确率会出现一个10%以上的跳变；</p></li><li><p>如果不采用预激活</p></li></ol><p>   3-5%点的性能下降，原因见作者原文分析；</p><ol><li>选取30轮的训练结果，在测试集数据上进行验证，结果如下：</li></ol><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-attr">[INFO]</span> <span class="selector-tag">rank-1</span>: 71<span class="selector-class">.49</span>%</span><br><span class="line"><span class="selector-attr">[INFO]</span> <span class="selector-tag">rank-5</span>: 89<span class="selector-class">.96</span>%</span><br></pre></td></tr></table></figure><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ol><li>效果不是十分理想，主要原因应该是第一阶段1e-1学习率的训练过程过早的认为过拟合打断了训练过程，应该让这个过程再持续一段时间观察效果，无奈训练一次ResNet实在太久，放弃继续尝试了；</li><li>训练一个大型数据集的深度神经网络是个费时费力的活，为了获得最优的参数，一般需要进行10-100次参数实验，需要极大的耐心和计算资源；</li><li>训练深度神经网络的目的不是找寻全局最优解，因为一般很难找到这个解，我们只是在探寻一个比上次效果更好的模型；</li><li>先使用ReLU作为激活函数获得baseline，再选择提花为ELU来获得提升；</li><li>训练深层网络时，考虑使用MSRA/HE的初始化参数，并配合PReLU一起使用，效果更好；</li><li>对于ResNet要想再进一步提升性能，需要考虑加强正则化、更多的数据放大、合理的应用dropout等方式。</li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">ImageNet Classification with Deep Convolutional Neural Networks</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://p4ygzcmtw.bkt.clouddn.com/images/2018-05-21-ResNet/residual-Module-2.PNG&quot; alt=&quot;Residual Module&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 本文记录利用ImageNet数据集复现经典网络ResNet的过程，并记录在大型数据集训练过程中需要考虑的问题。&lt;/p&gt;
    
    </summary>
    
      <category term="动手实践营" scheme="http://blog.a-stack.com/categories/%E5%8A%A8%E6%89%8B%E5%AE%9E%E8%B7%B5%E8%90%A5/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="网络复现" scheme="http://blog.a-stack.com/tags/%E7%BD%91%E7%BB%9C%E5%A4%8D%E7%8E%B0/"/>
    
  </entry>
  
  <entry>
    <title>经典网络复现之GoogleNet</title>
    <link href="http://blog.a-stack.com/2018/07/12/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E5%A4%8D%E7%8E%B0%E4%B9%8BGoogleNet/"/>
    <id>http://blog.a-stack.com/2018/07/12/经典网络复现之GoogleNet/</id>
    <published>2018-07-12T05:58:12.000Z</published>
    <updated>2018-07-20T15:52:31.842Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/qnsource/images/2018-07-10-经典网络复现之GoogleNet/inception.jpg" alt="inception"></p><p><strong>摘要：</strong> 本文记录利用ImageNet数据集复现经典网络GoogLeNet的过程，并记录在大型数据集训练过程中需要考虑的问题。</p><a id="more"></a><p>为了增强对state of the art深度神经网络模型的认知，准备进行一系列模型的复现工作，使用ImageNet的大规模图像分类数据集，从头训练各个经典的神经网络模型，同时结合作者论文对训练过程中的技巧进行归纳总结，主要安排如下几部分内容：</p><ul><li>ImageNet数据集及数据准备</li><li>AlexNet网络</li><li>VGG网络</li><li><strong>GoogLeNet网络</strong></li><li>ResNet网络</li><li>SqueezeNet网络</li></ul><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>GoogleNet作为2012年ILSVRC的冠军，最近几年在原先Inception v1版本上也在不断的演化发展，目前已经到了v4版本。GoogleNet模型设计在保证准确率的同时大大降低了模型的大小，与VGG接近500MB相比，只有28MB左右的模型大小。</p><ul><li>论文：<ul><li>Christian Szegedy et al. “Going Deeper with Convolutions”. In: Computer Vision and Pattern Recognition (CVPR). 2015. URL: <a href="http://arxiv.org/abs/1409.4842" target="_blank" rel="noopener">http://arxiv.org/abs/1409.4842</a> </li></ul></li><li>数据集： ImageNet 2012 ILSRVC数据集（数据集的获取及准备详见<a href="/2018/07/06/ImageNet-DataSet/">ImageNet-DataSet</a>）</li><li>计算框架： MxNet</li><li>算力资源：AWS云主机p2.8xlarge：8个Tesla K80 GPU ($7.20/hour)<ul><li>总计训练时间2天左右</li><li>每轮迭代时间：~1200秒(~20分钟)</li></ul></li></ul><h2 id="GoogleNet"><a href="#GoogleNet" class="headerlink" title="GoogleNet"></a>GoogleNet</h2><p>GoogleNet的主要创新点体现在：</p><p>一、打破了常规的卷积层串联的模式，提出了将1x1，3x3，5x5的卷积层和3x3的pooling池化层并联组合后concatenate组装在一起的设计思路。</p><p>二、InceptionV1降低了参数量，目的有两个：1 参数越多模型越大，需要提供模型学习的数据量就越大，数据量不大的情况下容易过拟合；2 参数越多，耗费的计算资源也会更大。</p><p>三、去除了最后的全连接层，用全局平均池化层来取代它。全连接层几乎占据了AlexNet或VGGNet中90%的参数量，而且会引起过拟合，去除全连接层后模型训练更快并且减轻了过拟合。用全局平均池化层取代全连接层的做法借鉴了NetworkIn Network（以下简称NIN）论文。</p><p>四、InceptionV1中精心设计的InceptionModule提高了参数的利用效率。这一部分也借鉴了NIN的思想，形象的解释就是InceptionModule本身如同大网络中的一个小网络，其结构可以反复堆叠在一起形成大网络。InceptionV1比NIN更进一步的是增加了分支网络，NIN则主要是级联的卷积层和MLPConv层。一般来说卷积层要提升表达能力，主要依靠增加输出通道数，但副作用是计算量增大和过拟合。每一个输出通道对应一个滤波器，同一个滤波器共享参数，只能提取一类特征，因此一个输出通道只能做一种特征处理。而NIN中的MLPConv则拥有更强大的能力，允许在输出通道之间组合信息，因此效果明显。可以说，MLPConv基本等效于普通卷积层后再连接1*1的卷积和ReLU激活函数。</p><h2 id="重头训练一个GoogLeNet"><a href="#重头训练一个GoogLeNet" class="headerlink" title="重头训练一个GoogLeNet"></a>重头训练一个GoogLeNet</h2><p><img src="/qnsource/images/2018-07-10-经典网络复现之GoogleNet/parameters.png" alt="parameters"></p><ol><li>使用MxNet构建GoogleNet代码</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MxGoogLeNet</span>:</span></span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_module</span><span class="params">(data, K, kX, kY, pad=<span class="params">(<span class="number">0</span>, <span class="number">0</span>)</span>, stride=<span class="params">(<span class="number">1</span>, <span class="number">1</span>)</span>)</span>:</span></span><br><span class="line"><span class="comment"># define the CONV =&gt; BN =&gt; RELU pattern</span></span><br><span class="line">conv = mx.sym.Convolution(data=data, kernel=(kX, kY),</span><br><span class="line">num_filter=K, pad=pad, stride=stride)</span><br><span class="line"><span class="comment">#bn = mx.sym.BatchNorm(data=conv)</span></span><br><span class="line">act = mx.sym.Activation(data=conv, act_type=<span class="string">"relu"</span>)</span><br><span class="line">bn = mx.sym.BatchNorm(data=act)</span><br><span class="line"></span><br><span class="line"><span class="comment"># return the block</span></span><br><span class="line"><span class="keyword">return</span> bn</span><br><span class="line"></span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inception_module</span><span class="params">(data, num1x1, num3x3Reduce, num3x3,</span></span></span><br><span class="line"><span class="function"><span class="params">num5x5Reduce, num5x5, num1x1Proj)</span>:</span></span><br><span class="line"><span class="comment"># the first branch of the Inception module consists of 1x1</span></span><br><span class="line"><span class="comment"># convolutions</span></span><br><span class="line">conv_1x1 = MxGoogLeNet.conv_module(data, num1x1, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># the second branch of the Inception module is a set of 1x1</span></span><br><span class="line"><span class="comment"># convolutions followed by 3x3 convolutions</span></span><br><span class="line">conv_r3x3 = MxGoogLeNet.conv_module(data, num3x3Reduce, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">conv_3x3 = MxGoogLeNet.conv_module(conv_r3x3, num3x3, <span class="number">3</span>, <span class="number">3</span>,</span><br><span class="line">pad=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># the third branch of the Inception module is a set of 1x1</span></span><br><span class="line"><span class="comment"># convolutions followed by 5x5 convolutions</span></span><br><span class="line">conv_r5x5 = MxGoogLeNet.conv_module(data, num5x5Reduce, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">conv_5x5 = MxGoogLeNet.conv_module(conv_r5x5, num5x5, <span class="number">5</span>, <span class="number">5</span>,</span><br><span class="line">pad=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># the final branch of the Inception module is the POOL +</span></span><br><span class="line"><span class="comment"># projection layer set</span></span><br><span class="line">pool = mx.sym.Pooling(data=data, pool_type=<span class="string">"max"</span>, pad=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">kernel=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">conv_proj = MxGoogLeNet.conv_module(pool, num1x1Proj, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># concatenate the filters across the channel dimension</span></span><br><span class="line">concat = mx.sym.Concat(*[conv_1x1, conv_3x3, conv_5x5,</span><br><span class="line">conv_proj])</span><br><span class="line"></span><br><span class="line"><span class="comment"># return the block</span></span><br><span class="line"><span class="keyword">return</span> concat</span><br><span class="line"></span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build</span><span class="params">(classes)</span>:</span></span><br><span class="line"><span class="comment"># data input</span></span><br><span class="line">data = mx.sym.Variable(<span class="string">"data"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #1: CONV =&gt; POOL =&gt; CONV =&gt; CONV =&gt; POOL</span></span><br><span class="line">conv1_1 = MxGoogLeNet.conv_module(data, <span class="number">64</span>, <span class="number">7</span>, <span class="number">7</span>,</span><br><span class="line">pad=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">pool1 = mx.sym.Pooling(data=conv1_1, pool_type=<span class="string">"max"</span>,</span><br><span class="line">pad=(<span class="number">1</span>, <span class="number">1</span>), kernel=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">conv1_2 = MxGoogLeNet.conv_module(pool1, <span class="number">64</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">conv1_3 = MxGoogLeNet.conv_module(conv1_2, <span class="number">192</span>, <span class="number">3</span>, <span class="number">3</span>,</span><br><span class="line">pad=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">pool2 = mx.sym.Pooling(data=conv1_3, pool_type=<span class="string">"max"</span>,</span><br><span class="line">pad=(<span class="number">1</span>, <span class="number">1</span>), kernel=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #3: (INCEP * 2) =&gt; POOL</span></span><br><span class="line">in3a = MxGoogLeNet.inception_module(pool2, <span class="number">64</span>, <span class="number">96</span>, <span class="number">128</span>, <span class="number">16</span>,</span><br><span class="line"><span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">in3b = MxGoogLeNet.inception_module(in3a, <span class="number">128</span>, <span class="number">128</span>, <span class="number">192</span>, <span class="number">32</span>,</span><br><span class="line"><span class="number">96</span>, <span class="number">64</span>)</span><br><span class="line">pool3 = mx.sym.Pooling(data=in3b, pool_type=<span class="string">"max"</span>,</span><br><span class="line">pad=(<span class="number">1</span>, <span class="number">1</span>), kernel=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #4: (INCEP * 5) =&gt; POOL</span></span><br><span class="line">in4a = MxGoogLeNet.inception_module(pool3, <span class="number">192</span>, <span class="number">96</span>, <span class="number">208</span>, <span class="number">16</span>,</span><br><span class="line"><span class="number">48</span>, <span class="number">64</span>)</span><br><span class="line">in4b = MxGoogLeNet.inception_module(in4a, <span class="number">160</span>, <span class="number">112</span>, <span class="number">224</span>, <span class="number">24</span>,</span><br><span class="line"><span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">in4c = MxGoogLeNet.inception_module(in4b, <span class="number">128</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">24</span>,</span><br><span class="line"><span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">in4d = MxGoogLeNet.inception_module(in4c, <span class="number">112</span>, <span class="number">144</span>, <span class="number">288</span>, <span class="number">32</span>,</span><br><span class="line"><span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">in4e = MxGoogLeNet.inception_module(in4d, <span class="number">256</span>, <span class="number">160</span>, <span class="number">320</span>, <span class="number">32</span>,</span><br><span class="line"><span class="number">128</span>, <span class="number">128</span>,)</span><br><span class="line">pool4 = mx.sym.Pooling(data=in4e, pool_type=<span class="string">"max"</span>,</span><br><span class="line">pad=(<span class="number">1</span>, <span class="number">1</span>), kernel=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #5: (INCEP * 2) =&gt; POOL =&gt; DROPOUT</span></span><br><span class="line">in5a = MxGoogLeNet.inception_module(pool4, <span class="number">256</span>, <span class="number">160</span>, <span class="number">320</span>, <span class="number">32</span>,</span><br><span class="line"><span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">in5b = MxGoogLeNet.inception_module(in5a, <span class="number">384</span>, <span class="number">192</span>, <span class="number">384</span>, <span class="number">48</span>,</span><br><span class="line"><span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">pool5 = mx.sym.Pooling(data=in5b, pool_type=<span class="string">"avg"</span>,</span><br><span class="line">kernel=(<span class="number">7</span>, <span class="number">7</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">do = mx.sym.Dropout(data=pool5, p=<span class="number">0.4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># softmax classifier</span></span><br><span class="line">flatten = mx.sym.Flatten(data=do)</span><br><span class="line">fc1 = mx.sym.FullyConnected(data=flatten, num_hidden=classes)</span><br><span class="line">model = mx.sym.SoftmaxOutput(data=fc1, name=<span class="string">"softmax"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># return the network architecture</span></span><br><span class="line"><span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><blockquote><p><strong>几点注意点：</strong></p><ol><li>与原网络不同，我们将BN放在了activation之后，提升了模型效果；</li><li>Dropout原网络使用40%，当然现在更常见的是使用50%；</li><li>​Inception Module中几个分支网络通过concat连接在一起，这点与ResNet的本质区别；</li></ol></blockquote><h3 id="训练GoogLeNet"><a href="#训练GoogLeNet" class="headerlink" title="训练GoogLeNet"></a>训练GoogLeNet</h3><p>训练用的脚本和前面几个网络一致。</p><blockquote><p><strong>几个注意点：</strong></p><ol><li><code>batchSize = config.BATCH_SIZE * config.NUM_DEVICES</code>; 使用k80 12GB先存，选择batchSzie=<strong>128</strong>；</li><li>优化算法使用Adam，初始学习率为1e-3，L2权重正则化参数0.0002；rescale参数尤为关键，根据批的大小放大梯度：rescale_grad=1.0 / batchSize；（使用SGD训练效果一般）</li><li>使用了Xavier进行参数初始化，initializer=mx.initializer.Xavier(),；</li></ol></blockquote><h4 id="学习率的控制"><a href="#学习率的控制" class="headerlink" title="学习率的控制"></a>学习率的控制</h4><blockquote><p>训练ResNet由于初始学习率高，所以最终完成训练所需的迭代数目要小很多；</p></blockquote><div class="table-container"><table><thead><tr><th>Epoch</th><th>学习率</th></tr></thead><tbody><tr><td>1-31</td><td>1e-3</td></tr><tr><td>32-40</td><td>1e-4</td></tr><tr><td>41-47</td><td>1e-5</td></tr></tbody></table></div><blockquote><ol><li>控制每轮学习率修改的观察窗口要在10-15个epoch之后再下结论，确定该阶段验证集准确率饱和了再行降低学习率；</li><li>调整学习率 <code>python train_alexnet.py --checkpoints checkpoints --prefix alexnet \ --start-epoch 50</code></li><li>在8个GPU上，每轮用时1200多秒；</li></ol></blockquote><ol><li><p>第一遍训练采用1e-3的学习率配合Adam算法训练31轮，发现饱和现象，降低学习率到1e-4，继续训练到42轮；</p><p>​</p><p><img src="/qnsource/images/2018-07-10-经典网络复现之GoogleNet/42epoch-accuracy.png" alt="42epoch-accuracy"></p><p><img src="/qnsource/images/2018-07-10-经典网络复现之GoogleNet/42epoch-loss.png" alt="42epoch-loss"></p></li><li><p>发现40轮之后就已经出现了验证准确率的饱和现象，在40轮之后调整学习率为1e-5继续训练几轮完成：</p><p><img src="/qnsource/images/2018-07-10-经典网络复现之GoogleNet/47epoch-accuracy.png" alt="47epoch-accuracy"></p><p><img src="/qnsource/images/2018-07-10-经典网络复现之GoogleNet/47epoch-loss.png" alt="47epoch-loss"></p></li></ol><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><ol><li><p>Adam or SGD</p><p>如果使用SGD + 1e-2的经典开始配合，在GoogleNet上效果并不好，抖动剧烈，虽然这是作者推荐的参数，如下：</p><p><img src="/qnsource/images/2018-07-10-经典网络复现之GoogleNet/1e-2lr.png" alt="1e-2lr"></p><p>首先修改初始学习率为1e-3，尽管抖动降低了，但学习太慢，效果也不佳，为此进一步的调整了优化算法为Adam算法。</p></li><li><p>使用BN在激活函数之后</p><p>取得了1%以上的性能提升</p></li></ol><ol><li>选取40轮的训练结果，在测试集数据上进行验证，结果如下：</li></ol><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-attr">[INFO]</span> <span class="selector-tag">rank-1</span>: 69<span class="selector-class">.58</span>%</span><br><span class="line"><span class="selector-attr">[INFO]</span> <span class="selector-tag">rank-5</span>: 89<span class="selector-class">.01</span>%</span><br></pre></td></tr></table></figure><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ol><li>GoogleNet很难复现作者的效果，实际上还没有VGG的效果好，可能是作者论文中某些参数没有有效标注出来；</li><li>训练一个大型数据集的深度神经网络是个费时费力的活，为了获得最优的参数，一般需要进行10-100次参数实验，需要极大的耐心和计算资源；</li><li>训练深度神经网络的目的不是找寻全局最优解，因为一般很难找到这个解，我们只是在探寻一个比上次效果更好的模型；</li><li>先使用ReLU作为激活函数获得baseline，再选择提花为ELU来获得提升；</li><li>训练深层网络时，考虑使用MSRA/HE的初始化参数，并配合PReLU一起使用，效果更好；</li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">ImageNet Classification with Deep Convolutional Neural Networks</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/qnsource/images/2018-07-10-经典网络复现之GoogleNet/inception.jpg&quot; alt=&quot;inception&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 本文记录利用ImageNet数据集复现经典网络GoogLeNet的过程，并记录在大型数据集训练过程中需要考虑的问题。&lt;/p&gt;
    
    </summary>
    
      <category term="动手实践营" scheme="http://blog.a-stack.com/categories/%E5%8A%A8%E6%89%8B%E5%AE%9E%E8%B7%B5%E8%90%A5/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="网络复现" scheme="http://blog.a-stack.com/tags/%E7%BD%91%E7%BB%9C%E5%A4%8D%E7%8E%B0/"/>
    
  </entry>
  
  <entry>
    <title>经典网络复现之AlexNet</title>
    <link href="http://blog.a-stack.com/2018/07/08/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E5%A4%8D%E7%8E%B0%E4%B9%8BAlexNet/"/>
    <id>http://blog.a-stack.com/2018/07/08/经典网络复现之AlexNet/</id>
    <published>2018-07-08T05:58:12.000Z</published>
    <updated>2018-07-20T15:52:42.648Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://p4ygzcmtw.bkt.clouddn.com/cover/12.jpg" alt="Test Picture"></p><p><strong>摘要：</strong> 本文记录利用ImageNet数据集复现经典网络AlexNet的过程，并记录在大型数据集训练过程中需要考虑的问题。</p><a id="more"></a><p>为了增强对state of the art深度神经网络模型的认知，准备进行一系列模型的复现工作，使用ImageNet的大规模图像分类数据集，从头训练各个经典的神经网络模型，同时结合作者论文对训练过程中的技巧进行归纳总结，主要安排如下几部分内容：</p><ul><li>ImageNet数据集及数据准备</li><li>AlexNet网络</li><li>VGG网络</li><li>GoogLeNet网络</li><li>ResNet网络</li><li>SqueezeNet网络</li></ul><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>2012年的AlexNet是通用CNN的开山之作（早在1986年，Yann LeCun就利用卷积神经网络构建了LeNet并第一次将其运用到了生产环节——邮政编码识别，详见<a href="http://yann.lecun.com/exdb/lenet/a35.html" target="_blank" rel="noopener">http://yann.lecun.com/exdb/lenet/a35.html</a> ，但相关网络结构未能得到充分复制和发展），从此以后，CNN被广泛应用于各种机器视觉比赛、应用之中，得到了空前的发展。本文，主要根据AlexNet论文回顾其网络结构、设计技巧，并利用ImageNet的图像分类数据集复现在2012年ImageNet挑战赛中的结果。</p><ul><li>论文： Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. “ImageNet Classification with Deep Convolutional Neural Networks”. In: Advances in Neural Information Processing Systems 25. Edited by F. Pereira et al. Curran Associates, Inc., 2012, pages 1097–1105. URL: <a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deepconvolutional-neural-networks.pdf" target="_blank" rel="noopener">http://papers.nips.cc/paper/4824-imagenet-classification-with-deepconvolutional-neural-networks.pdf</a></li><li>数据集： ImageNet 2012 ILSRVC数据集（数据集的获取及准备详见<a href="/2018/07/06/ImageNet-DataSet/">ImageNet-DataSet</a>）</li><li>计算框架： MxNet</li><li>算力资源：AWS云主机p2.8xlarge：8个Tesla K80 GPU ($7.20/hour)</li></ul><p><img src="/qnsource/images/2018-07-08-经典网络复现之AlexNet/GPUs.png" alt="GPUs"></p><h2 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h2><p>AlexNet在2012年ImageNet ILSVRC比赛中top-5的错误率未15.3%，领先第二名10.9%个百分点，整个网络架构总共有8层参数网络层，其中5层卷积网络+3层全连接网络。本节将按照AlexNet论文描述的内容，整理AlexNet的特点，和极具借鉴性的创新成果。</p><h3 id="网络架构"><a href="#网络架构" class="headerlink" title="网络架构"></a>网络架构</h3><p><img src="/qnsource/images/2018-07-08-经典网络复现之AlexNet/AlexNet.png" alt="AlexNet"></p><p>AlexNet的网络架构如图所示，输入图像尺寸为（224，224，3），经过5个CNN层，3个FC层输出1000个分类结果，为了便于使网络训练采用GPU，所以整个网络分为上下两部分，分别在两个GPU上进行训练，其中第一层CNN和3个FC层在两个GPU上进行了参数共享。</p><p>AlexNet网络中拥有600万个参数，650 000个神经元。</p><h3 id="GPU的第一次使用"><a href="#GPU的第一次使用" class="headerlink" title="GPU的第一次使用"></a>GPU的第一次使用</h3><p>AlexNet是第一个使用GPU进行训练的深度神经网络，受当时硬件条件限制，使用了2块3GB内存的GTX 580 GPU，同时由于全部的网络参数超过了3GB的显存空间，所以将网络分成了两部分。训练时间上实际比单块GPU没有提升太多，但将错误率降低了1.2个百分点。</p><h3 id="激活函数的选择——从此ReLU函数得到重用"><a href="#激活函数的选择——从此ReLU函数得到重用" class="headerlink" title="激活函数的选择——从此ReLU函数得到重用"></a>激活函数的选择——从此ReLU函数得到重用</h3><p>AlexNet中经过实践测试发现，采用ReLU作为激活函数比tanh要快很多（在CIFAR-10上测试前者速度是后者的6倍多），这也奠定了ReLU称为后来CNN网络的首选。</p><h3 id="解决过拟合"><a href="#解决过拟合" class="headerlink" title="解决过拟合"></a>解决过拟合</h3><p>整个AlexNet都是围绕着计算效率提升和解决过拟合进行优化和尝试。AlexNet中的600万参数增强网络学习能力的同时也带来了潜在的过拟合问题，其中对解决过拟合的诸多尝试在未来的网络发展中被反复验证和使用。</p><h4 id="1-数据增强"><a href="#1-数据增强" class="headerlink" title="1. 数据增强"></a>1. 数据增强</h4><p>AlexNet中数据增强主要采用了两种方式，一种是随机扣取和水平翻转，另一种是白化。</p><ul><li>随机扣取和水平翻转：AlexNet将原始图像处理成256x256大小的统一图像，在训练阶段，随机从原始图像中扣取227x227的像素，并通过水平翻转来提升训练集的差异性，增强网络泛化性能；在测试阶段，对于输入测试图像分别从四个顶角和中心位置获得5张图像，并通过水平翻转形成10张图像，通过评价10张图像的预测结果作为最终输出结果，将网络性能提升了将近1个百分点；</li><li>白化： 利用PCA进行主成分抽取</li></ul><h4 id="2-Dropout"><a href="#2-Dropout" class="headerlink" title="2. Dropout"></a>2. Dropout</h4><p>这是Dropout的第一次正式使用，Dropout本身起到了模型组合的作用，同时起到正则化效果，可以避免过拟合，提升效果。当然代价是网络收敛时间被延长。</p><ul><li>在前两个FC层之后使用了Dropout</li></ul><h3 id="训练参数"><a href="#训练参数" class="headerlink" title="训练参数"></a>训练参数</h3><ul><li>优化算法选择SGD， 动量为0.9；</li><li>batch_size = 128</li><li>权重衰减为0.0005，这个很小的权重衰减对于模型学习起到了不可忽视的作用；</li><li>权重参数初始化为零均值，0.01标准差的高斯分布；</li><li>为了使得初始参数落在ReLU的正值区域，将偏差参数初始化为1；</li><li>初始学习率为0.01，当验证集错误率饱和时以对数形式降低学习率，一共降低3次，即1e-3,1e-4,1e-5；</li><li>训练了90个epoch，总共用时5-6天</li></ul><h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><ul><li>使用5个CNN的组合，top-5错误率为16.4%​</li></ul><h3 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h3><p>AlexNet还使用了局部响应归一化（Local Response Normalization）、重叠池化等优化策略，不过在未来的网络结构中没有得到良好的效果和应用普及。</p><h2 id="重头训练一个AlexNet"><a href="#重头训练一个AlexNet" class="headerlink" title="重头训练一个AlexNet"></a>重头训练一个AlexNet</h2><ol><li><p>ImageNet数据准备参见前序博文</p></li><li><p>由于现在GPU硬件和深度学习计算框架的发展，我们不需要将网络拆成两个部分，单独训练了，所以网络架构进行了微调，详见下图；</p><p><img src="/qnsource/images/2018-07-08-经典网络复现之AlexNet/AlexNet-Details.png" alt="AlexNet-Details"></p><ol><li>使用MxNet训练网络比Keras + TensroFlow要快；</li></ol></li></ol><h3 id="使用MxNet构建AlexNet代码"><a href="#使用MxNet构建AlexNet代码" class="headerlink" title="使用MxNet构建AlexNet代码"></a>使用MxNet构建AlexNet代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MxAlexNet</span>:</span></span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build</span><span class="params">(classes)</span>:</span></span><br><span class="line"><span class="comment"># data input</span></span><br><span class="line">data = mx.sym.Variable(<span class="string">"data"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #1: first CONV =&gt; RELU =&gt; POOL layer set</span></span><br><span class="line">conv1_1 = mx.sym.Convolution(data=data, kernel=(<span class="number">11</span>, <span class="number">11</span>),</span><br><span class="line">stride=(<span class="number">4</span>, <span class="number">4</span>), num_filter=<span class="number">96</span>)</span><br><span class="line">act1_1 = mx.sym.LeakyReLU(data=conv1_1, act_type=<span class="string">"elu"</span>)</span><br><span class="line">bn1_1 = mx.sym.BatchNorm(data=act1_1)</span><br><span class="line">pool1 = mx.sym.Pooling(data=bn1_1, pool_type=<span class="string">"max"</span>,</span><br><span class="line">kernel=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">do1 = mx.sym.Dropout(data=pool1, p=<span class="number">0.25</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #2: second CONV =&gt; RELU =&gt; POOL layer set</span></span><br><span class="line">conv2_1 = mx.sym.Convolution(data=do1, kernel=(<span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">pad=(<span class="number">2</span>, <span class="number">2</span>), num_filter=<span class="number">256</span>)</span><br><span class="line">act2_1 = mx.sym.LeakyReLU(data=conv2_1, act_type=<span class="string">"elu"</span>)</span><br><span class="line">bn2_1 = mx.sym.BatchNorm(data=act2_1)</span><br><span class="line">pool2 = mx.sym.Pooling(data=bn2_1, pool_type=<span class="string">"max"</span>,</span><br><span class="line">kernel=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">do2 = mx.sym.Dropout(data=pool2, p=<span class="number">0.25</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #3: (CONV =&gt; RELU) * 3 =&gt; POOL</span></span><br><span class="line">conv3_1 = mx.sym.Convolution(data=do2, kernel=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">pad=(<span class="number">1</span>, <span class="number">1</span>), num_filter=<span class="number">384</span>)</span><br><span class="line">act3_1 = mx.sym.LeakyReLU(data=conv3_1, act_type=<span class="string">"elu"</span>)</span><br><span class="line">bn3_1 = mx.sym.BatchNorm(data=act3_1)</span><br><span class="line">conv3_2 = mx.sym.Convolution(data=bn3_1, kernel=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">pad=(<span class="number">1</span>, <span class="number">1</span>), num_filter=<span class="number">384</span>)</span><br><span class="line">act3_2 = mx.sym.LeakyReLU(data=conv3_2, act_type=<span class="string">"elu"</span>)</span><br><span class="line">bn3_2 = mx.sym.BatchNorm(data=act3_2)</span><br><span class="line">conv3_3 = mx.sym.Convolution(data=bn3_2, kernel=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">pad=(<span class="number">1</span>, <span class="number">1</span>), num_filter=<span class="number">256</span>)</span><br><span class="line">act3_3 = mx.sym.LeakyReLU(data=conv3_3, act_type=<span class="string">"elu"</span>)</span><br><span class="line">bn3_3 = mx.sym.BatchNorm(data=act3_3)</span><br><span class="line">pool3 = mx.sym.Pooling(data=bn3_3, pool_type=<span class="string">"max"</span>,</span><br><span class="line">kernel=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">do3 = mx.sym.Dropout(data=pool3, p=<span class="number">0.25</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #4: first set of FC =&gt; RELU layers</span></span><br><span class="line">flatten = mx.sym.Flatten(data=do3)</span><br><span class="line">fc1 = mx.sym.FullyConnected(data=flatten, num_hidden=<span class="number">4096</span>)</span><br><span class="line">act4_1 = mx.sym.LeakyReLU(data=fc1, act_type=<span class="string">"elu"</span>)</span><br><span class="line">bn4_1 = mx.sym.BatchNorm(data=act4_1)</span><br><span class="line">do4 = mx.sym.Dropout(data=bn4_1, p=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #5: second set of FC =&gt; RELU layers</span></span><br><span class="line">fc2 = mx.sym.FullyConnected(data=do4, num_hidden=<span class="number">4096</span>)</span><br><span class="line">act5_1 = mx.sym.LeakyReLU(data=fc2, act_type=<span class="string">"elu"</span>)</span><br><span class="line">bn5_1 = mx.sym.BatchNorm(data=act5_1)</span><br><span class="line">do5 = mx.sym.Dropout(data=bn5_1, p=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># softmax classifier</span></span><br><span class="line">fc3 = mx.sym.FullyConnected(data=do5, num_hidden=classes)</span><br><span class="line">model = mx.sym.SoftmaxOutput(data=fc3, name=<span class="string">"softmax"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># return the network architecture</span></span><br><span class="line"><span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><blockquote><p><strong>几点注意点：</strong></p><ol><li>主要采用了Caffe中实现的AlexNet版本；</li><li>使用ELU替代了ReLU激活函数；</li><li>每个block都使用了dropout，而不是原文只在两个FC层使用；其中CNN层参数为0.25，FC层为0.5；</li><li>使用了BN层加速网络训练，而且BN在激活函数之后使用；</li></ol></blockquote><h3 id="训练AlexNet"><a href="#训练AlexNet" class="headerlink" title="训练AlexNet"></a>训练AlexNet</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># USAGE</span></span><br><span class="line"><span class="comment"># python train_alexnet.py --checkpoints checkpoints --prefix alexnet</span></span><br><span class="line"><span class="comment"># python train_alexnet.py --checkpoints checkpoints --prefix alexnet --start-epoch 25</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># import the necessary packages</span></span><br><span class="line"><span class="keyword">from</span> config <span class="keyword">import</span> imagenet_alexnet_config <span class="keyword">as</span> config</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.nn.mxconv <span class="keyword">import</span> MxAlexNet</span><br><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># construct the argument parse and parse the arguments</span></span><br><span class="line">ap = argparse.ArgumentParser()</span><br><span class="line">ap.add_argument(<span class="string">"-c"</span>, <span class="string">"--checkpoints"</span>, required=<span class="keyword">True</span>,</span><br><span class="line">help=<span class="string">"path to output checkpoint directory"</span>)</span><br><span class="line">ap.add_argument(<span class="string">"-p"</span>, <span class="string">"--prefix"</span>, required=<span class="keyword">True</span>,</span><br><span class="line">help=<span class="string">"name of model prefix"</span>)</span><br><span class="line">ap.add_argument(<span class="string">"-s"</span>, <span class="string">"--start-epoch"</span>, type=int, default=<span class="number">0</span>,</span><br><span class="line">help=<span class="string">"epoch to restart training at"</span>)</span><br><span class="line">args = vars(ap.parse_args())</span><br><span class="line"></span><br><span class="line"><span class="comment"># set the logging level and output file</span></span><br><span class="line">logging.basicConfig(level=logging.DEBUG,</span><br><span class="line">filename=<span class="string">"training_&#123;&#125;.log"</span>.format(args[<span class="string">"start_epoch"</span>]),</span><br><span class="line">filemode=<span class="string">"w"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># load the RGB means for the training set, then determine the batch</span></span><br><span class="line"><span class="comment"># size</span></span><br><span class="line">means = json.loads(open(config.DATASET_MEAN).read())</span><br><span class="line">batchSize = config.BATCH_SIZE * config.NUM_DEVICES</span><br><span class="line"></span><br><span class="line"><span class="comment"># construct the training image iterator</span></span><br><span class="line">trainIter = mx.io.ImageRecordIter(</span><br><span class="line">path_imgrec=config.TRAIN_MX_REC,</span><br><span class="line">data_shape=(<span class="number">3</span>, <span class="number">227</span>, <span class="number">227</span>),</span><br><span class="line">batch_size=batchSize,</span><br><span class="line">rand_crop=<span class="keyword">True</span>,</span><br><span class="line">rand_mirror=<span class="keyword">True</span>,</span><br><span class="line">rotate=<span class="number">15</span>,</span><br><span class="line">max_shear_ratio=<span class="number">0.1</span>,</span><br><span class="line">mean_r=means[<span class="string">"R"</span>],</span><br><span class="line">mean_g=means[<span class="string">"G"</span>],</span><br><span class="line">mean_b=means[<span class="string">"B"</span>],</span><br><span class="line">preprocess_threads=config.NUM_DEVICES * <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># construct the validation image iterator</span></span><br><span class="line">valIter = mx.io.ImageRecordIter(</span><br><span class="line">path_imgrec=config.VAL_MX_REC,</span><br><span class="line">data_shape=(<span class="number">3</span>, <span class="number">227</span>, <span class="number">227</span>),</span><br><span class="line">batch_size=batchSize,</span><br><span class="line">mean_r=means[<span class="string">"R"</span>],</span><br><span class="line">mean_g=means[<span class="string">"G"</span>],</span><br><span class="line">mean_b=means[<span class="string">"B"</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># initialize the optimizer</span></span><br><span class="line">opt = mx.optimizer.SGD(learning_rate=<span class="number">1e-2</span>, momentum=<span class="number">0.9</span>, wd=<span class="number">0.0005</span>,</span><br><span class="line">rescale_grad=<span class="number">1.0</span> / batchSize)</span><br><span class="line"></span><br><span class="line"><span class="comment"># construct the checkpoints path, initialize the model argument and</span></span><br><span class="line"><span class="comment"># auxiliary parameters</span></span><br><span class="line">checkpointsPath = os.path.sep.join([args[<span class="string">"checkpoints"</span>],</span><br><span class="line">args[<span class="string">"prefix"</span>]])</span><br><span class="line">argParams = <span class="keyword">None</span></span><br><span class="line">auxParams = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># if there is no specific model starting epoch supplied, then</span></span><br><span class="line"><span class="comment"># initialize the network</span></span><br><span class="line"><span class="keyword">if</span> args[<span class="string">"start_epoch"</span>] &lt;= <span class="number">0</span>:</span><br><span class="line"><span class="comment"># build the LeNet architecture</span></span><br><span class="line">print(<span class="string">"[INFO] building network..."</span>)</span><br><span class="line">model = MxAlexNet.build(config.NUM_CLASSES)</span><br><span class="line"></span><br><span class="line"><span class="comment"># otherwise, a specific checkpoint was supplied</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="comment"># load the checkpoint from disk</span></span><br><span class="line">print(<span class="string">"[INFO] loading epoch &#123;&#125;..."</span>.format(args[<span class="string">"start_epoch"</span>]))</span><br><span class="line">model = mx.model.FeedForward.load(checkpointsPath,</span><br><span class="line">args[<span class="string">"start_epoch"</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># update the model and parameters</span></span><br><span class="line">argParams = model.arg_params</span><br><span class="line">auxParams = model.aux_params</span><br><span class="line">model = model.symbol</span><br><span class="line"></span><br><span class="line"><span class="comment"># compile the model</span></span><br><span class="line">model = mx.model.FeedForward(</span><br><span class="line">ctx=[mx.gpu(<span class="number">0</span>), mx.gpu(<span class="number">1</span>), mx.gpu(<span class="number">2</span>), mx.gpu(<span class="number">3</span>), mx.gpu(<span class="number">4</span>), mx.gpu(<span class="number">5</span>), mx.gpu(<span class="number">6</span>), mx.gpu(<span class="number">7</span>)],</span><br><span class="line">symbol=model,</span><br><span class="line">initializer=mx.initializer.Xavier(),</span><br><span class="line">arg_params=argParams,</span><br><span class="line">aux_params=auxParams,</span><br><span class="line">optimizer=opt,</span><br><span class="line">num_epoch=<span class="number">90</span>,</span><br><span class="line">begin_epoch=args[<span class="string">"start_epoch"</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># initialize the callbacks and evaluation metrics</span></span><br><span class="line">batchEndCBs = [mx.callback.Speedometer(batchSize, <span class="number">500</span>)]</span><br><span class="line">epochEndCBs = [mx.callback.do_checkpoint(checkpointsPath)]</span><br><span class="line">metrics = [mx.metric.Accuracy(), mx.metric.TopKAccuracy(top_k=<span class="number">5</span>),</span><br><span class="line">mx.metric.CrossEntropy()]</span><br><span class="line"></span><br><span class="line"><span class="comment"># train the network</span></span><br><span class="line">print(<span class="string">"[INFO] training network..."</span>)</span><br><span class="line">model.fit(</span><br><span class="line">X=trainIter,</span><br><span class="line">eval_data=valIter,</span><br><span class="line">eval_metric=metrics,</span><br><span class="line">batch_end_callback=batchEndCBs,</span><br><span class="line">epoch_end_callback=epochEndCBs)</span><br></pre></td></tr></table></figure><blockquote><p><strong>几个注意点：</strong></p><ol><li><code>batchSize = config.BATCH_SIZE * config.NUM_DEVICES</code>;</li><li>优化算法使用SGD，初始学习率为1e-2，动量0.9，L2权重正则化参数0.0005；rescale参数尤为关键，根据批的大小放大梯度；</li><li>model中的<code>ctx</code>参数用于指定用于训练的GPU；</li><li>使用了Xavier进行参数初始化，与原模型略有不同，Xavier是目前CNN网络常采用的参数初始化方式；</li></ol></blockquote><h4 id="学习率的控制"><a href="#学习率的控制" class="headerlink" title="学习率的控制"></a>学习率的控制</h4><div class="table-container"><table><thead><tr><th>Epoch</th><th>学习率</th></tr></thead><tbody><tr><td>1-80</td><td>1e-2</td></tr><tr><td>81-100</td><td>1e-3</td></tr><tr><td>86-100</td><td>1e-4</td></tr></tbody></table></div><blockquote><ol><li>控制每轮学习率修改的观察窗口要在10-15个epoch之后再下结论，确定该阶段验证集准确率饱和了再行降低学习率；</li><li>调整学习率 <code>python train_alexnet.py --checkpoints checkpoints --prefix alexnet \ --start-epoch 50</code></li><li>在8个GPU上，每轮用时600多秒（当然我batch size设的比较小，这个速度可以提升一个数量级）；</li></ol></blockquote><ol><li><p>第一遍训练采用1e-2的学习率训练90轮，发现80轮以后，验证集准确率已经不再增加；为此在80轮之后调整学习率；80轮的性能参数如下：</p><ul><li><p>INFO:root:Epoch[78] Validation-accuracy=0.517843</p><p>INFO:root:Epoch[78] Validation-top_k_accuracy_5=0.759725</p><p>INFO:root:Epoch[78] Validation-cross-entropy=2.123822</p><p>INFO:root:Saved checkpoint to “checkpoints/1//alexnet01-0080.params”</p></li></ul><p><img src="/qnsource/images/2018-07-08-经典网络复现之AlexNet/1st_try_accuracy.png" alt="1st_try_accuracy"></p><p><img src="/qnsource/images/2018-07-08-经典网络复现之AlexNet/1st_try_loss.png" alt="1st_try_loss"></p></li><li><p>将学习率调整到1e-3之后，验证集准确率有大幅提升，代表调整有效，100轮之后再度饱和，降低学习率到1e-4;105轮验证集结果如下：</p><ul><li><p>INFO:root:Epoch[105] Validation-accuracy=0.564901</p><p>INFO:root:Epoch[105] Validation-top_k_accuracy_5=<strong>0.796509</strong></p><p>INFO:root:Epoch[105] Validation-cross-entropy=1.880376</p></li></ul><p><img src="/qnsource/images/2018-07-08-经典网络复现之AlexNet/105epoch-accuracy.png" alt="105epoch-accuracy"></p><p><img src="/qnsource/images/2018-07-08-经典网络复现之AlexNet/105epoch.png" alt="105epoch"></p></li><li><p>保持1e-4学习率，训练到125轮，进一步降低学习率到1e-5，发现整个网络没有性能提升，结束该批次参数训练过程。</p></li></ol><p><img src="/qnsource/images/2018-07-08-经典网络复现之AlexNet/130epoch-accuracy.png" alt="130epoch-accuracy"></p><p><img src="/qnsource/images/2018-07-08-经典网络复现之AlexNet/130epoch-loss.png" alt="130epoch-loss"></p><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><ol><li><p>BN放在激活之前还是之后？</p><p>调整BN位置，准确率从77.9%—&gt; 79.6%</p></li><li><p>ReLU vs ELU ？</p><p>用ELU替代ReLU，提升1-2%的性能；</p></li><li><p>选取125轮的训练结果，在测试集数据上进行验证，结果如下：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-attr">[INFO]</span> <span class="selector-tag">rank-1</span>: 60<span class="selector-class">.20</span>%</span><br><span class="line"><span class="selector-attr">[INFO]</span> <span class="selector-tag">rank-5</span>: 81<span class="selector-class">.99</span>%</span><br></pre></td></tr></table></figure><p>​</p></li></ol><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ol><li>训练一个大型数据集的深度神经网络是个费时费力的活，为了获得最优的参数，一般需要进行10-100次参数实验，需要极大的耐心和计算资源；</li><li>训练深度神经网络的目的不是找寻全局最优解，因为一般很难找到这个解，我们只是在探寻一个比上次效果更好的模型；</li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">ImageNet Classification with Deep Convolutional Neural Networks</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://p4ygzcmtw.bkt.clouddn.com/cover/12.jpg&quot; alt=&quot;Test Picture&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 本文记录利用ImageNet数据集复现经典网络AlexNet的过程，并记录在大型数据集训练过程中需要考虑的问题。&lt;/p&gt;
    
    </summary>
    
      <category term="动手实践营" scheme="http://blog.a-stack.com/categories/%E5%8A%A8%E6%89%8B%E5%AE%9E%E8%B7%B5%E8%90%A5/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="网络复现" scheme="http://blog.a-stack.com/tags/%E7%BD%91%E7%BB%9C%E5%A4%8D%E7%8E%B0/"/>
    
  </entry>
  
  <entry>
    <title>ImageNet-DataSet</title>
    <link href="http://blog.a-stack.com/2018/07/06/ImageNet-DataSet/"/>
    <id>http://blog.a-stack.com/2018/07/06/ImageNet-DataSet/</id>
    <published>2018-07-06T08:02:00.000Z</published>
    <updated>2018-07-20T15:52:52.732Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://p4ygzcmtw.bkt.clouddn.com/cover/09.jpg" alt="ImageNET"></p><p><strong>摘要：</strong></p><a id="more"></a><h2 id="ImageNet数据集"><a href="#ImageNet数据集" class="headerlink" title="ImageNet数据集"></a>ImageNet数据集</h2><p>ImageNet数据集是伴随着CNN和机器视觉乃至人工智能发展的里程碑式的数据集，虽然利用该数据集大规模机器视觉比赛2017年以后停止举办，但该数据集对整个人工智能产业革命的影响必将持续下去。</p><p><strong>ImageNet</strong> is an image database organized according to the <a href="http://wordnet.princeton.edu/" target="_blank" rel="noopener">WordNet</a> hierarchy (currently only the nouns), in which each node of the hierarchy is depicted by hundreds and thousands of images. Currently we have an average of over five hundred images per node. We hope ImageNet will become a useful resource for researchers, educators, students and all of you who share our passion for pictures. </p><ul><li>22k分类，14M 照片</li></ul><ul><li>网址： <a href="http://image-net.org/" target="_blank" rel="noopener">http://image-net.org/</a></li></ul><blockquote><p>这些数据靠人来标记，需要一个人19年时间；</p><p>使用Amazon的众包服务，调用了167个国家的49000人次在2007-2010年间完成标记</p></blockquote><ul><li>WordNet</li></ul><p><img src="/qnsource/images/2018-07-06-ImageNet-DataSet/imagenet_wordnet.png" alt="imagenet_wordnet"></p><ul><li><p>ImageNet Large Scale Visual Recognition Challenge(ILSVRC)</p><ul><li>Models are trained on ≈ 1.2 million training images with another 50,000 images for validation (50 images per synset) and 100,000 images for testing (100 images per synset).</li><li>分类难度大：比如ImageNet instead includes 120 different breeds of dogs.</li><li>ILSVRC2017主要有三项挑战：<ul><li><a href="">I: Object localization</a></li><li><a href="">II: Object detection</a></li><li><a href="">III: Object detection from video</a></li></ul></li><li>当然，正是由于ImageNet的难度和种类繁多特性，使得在ImageNet训练的模型可以很容易通过迁移学习用到其它领域的图像识别；</li></ul><p><img src="/qnsource/images/2018-07-06-ImageNet-DataSet/ILSVRC.png" alt="ILSVRC"></p></li></ul><h2 id="数据集的获取"><a href="#数据集的获取" class="headerlink" title="数据集的获取"></a>数据集的获取</h2><ul><li>训练数据大小138 GB</li><li>验证数据6.3 GB</li><li>测试数据 13GB</li></ul><p>下载ImageNet数据集需要使用学校邮箱注册一个账号，获得数据下载权限，然后可以登陆<a href="http://image-net.org/challenges/LSVRC/2017/download-images-1p39.php" target="_blank" rel="noopener">数据下载页面</a>如下图下载红色标记部分。</p><p><img src="/qnsource/images/2018-07-06-ImageNet-DataSet/ILSVRC2017.png" alt="ILSVRC2017"></p><blockquote><p>其中Development Kit包含了对数据结构和分类的描述文件，便于我们通过脚本读取图像数据；</p></blockquote><p>可以使用<code>wget</code>命令下载</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget -t 0 -c -i urls -o <span class="built_in">log</span></span><br></pre></td></tr></table></figure><p>其中<code>-c</code>代表端点续传，<code>-t 0</code>代表失败重试，<code>urls</code>文件为所有需要下载目录地址：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">www<span class="selector-class">.image-net</span><span class="selector-class">.org</span>/challenges/LSVRC/<span class="number">2012</span>/nnoupb/ILSVRC2012_img_train.tar</span><br><span class="line">www<span class="selector-class">.image-net</span><span class="selector-class">.org</span>/challenges/LSVRC/<span class="number">2012</span>/nnoupb/ILSVRC2012_img_train_t3.tar</span><br><span class="line">www<span class="selector-class">.image-net</span><span class="selector-class">.org</span>/challenges/LSVRC/<span class="number">2012</span>/nnoupb/ILSVRC2012_img_val.tar</span><br><span class="line">www<span class="selector-class">.image-net</span><span class="selector-class">.org</span>/challenges/LSVRC/<span class="number">2012</span>/nnoupb/ILSVRC2012_img_test.tar</span><br><span class="line">www<span class="selector-class">.image-net</span><span class="selector-class">.org</span>/challenges/LSVRC/<span class="number">2012</span>/nnoupb/ILSVRC2012_bbox_train_v2<span class="selector-class">.tar</span><span class="selector-class">.gz</span></span><br><span class="line">www<span class="selector-class">.image-net</span><span class="selector-class">.org</span>/challenges/LSVRC/<span class="number">2012</span>/nnoupb/ILSVRC2012_bbox_train_dogs<span class="selector-class">.tar</span><span class="selector-class">.gz</span></span><br><span class="line">www<span class="selector-class">.image-net</span><span class="selector-class">.org</span>/challenges/LSVRC/<span class="number">2012</span>/nnoupb/ILSVRC2012_bbox_val_v3.tgz</span><br><span class="line">www<span class="selector-class">.image-net</span><span class="selector-class">.org</span>/challenges/LSVRC/<span class="number">2012</span>/nnoupb/ILSVRC2012_bbox_test_dogs.zip</span><br></pre></td></tr></table></figure><p>实际使用过程中，发现国内网络原因使用这种方法只有50KB-100KB/s左右的速度，整个数据集下载需要12-15天。为了快速下载，可以使用如下磁力链接地址：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">magnet:?xt=urn:btih:A306397CCF9C2EAD27155983C254227C0FD938E2</span><br><span class="line">magnet:?xt=urn:btih:5D6D0DF7ED81EFD49CA99EA4737E0AE5E3A5F2E5</span><br></pre></td></tr></table></figure><h2 id="ImageNet数据的从属权问题"><a href="#ImageNet数据的从属权问题" class="headerlink" title="ImageNet数据的从属权问题"></a>ImageNet数据的从属权问题</h2><ul><li>ImageNet中的每张图片属于提供图片的个人</li><li>ImageNet数据集可以免费用于学术研究和非商业用途</li><li>但不能直接使用这些数据作为产品的一部分</li><li>使用ImageNet训练的模型（自己从头训练）的从属权问题是一个目前<strong>没有答案的问题</strong>，目前从头训练一个模型是可以应用到商业软件中的</li></ul><blockquote><p><strong>官方的给出的介绍性内容如下：</strong></p><p><strong>Does ImageNet own the images? Can I download the images?</strong></p><p>No, ImageNet does not own the copyright of the images. ImageNet only provides thumbnails and URLs of images, in a way similar to what image search engines do. In other words, ImageNet compiles an accurate list of web images for each synset of WordNet. </p><p>For researchers and educators who wish to use the images for non-commercial research and/or educational purposes, we can provide access through our site under certain conditions and terms. </p></blockquote><h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><ul><li>下载数据集中每个文件采用WordNetID的方式命名，比如<code>n01440764</code>；</li><li>每个分类有732~1300张图片</li><li>使用MXNET的<code>.rec</code>格式文件存储数据；</li><li>​</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">dir=./</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> `ls *.tar`</span><br><span class="line">  <span class="keyword">do</span></span><br><span class="line">    filename=`basename <span class="variable">$x</span> .tar`</span><br><span class="line">    mkdir <span class="variable">$filename</span></span><br><span class="line">    tar -xvf <span class="variable">$x</span> -C ./<span class="variable">$filename</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><h3 id="关键文件"><a href="#关键文件" class="headerlink" title="关键文件"></a>关键文件</h3><p><code>map_clsloc.txt</code>: 记录了WordNet ID到分类名称的映射关系，格式如下：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">n02119789 1 kit_fox</span><br><span class="line">n02100735 2 English_setter</span><br><span class="line">n02110185 3 Siberian_husky</span><br><span class="line">n02096294 4 Australian_terrier</span><br><span class="line">n02102040 5 English_springer</span><br><span class="line">n02066245 6 grey_whale</span><br><span class="line">n02509815 7 lesser_panda</span><br><span class="line">n02124075 8 Egyptian_cat</span><br><span class="line">n02417914 9 ibex</span><br><span class="line">n02123394 10 Persian_cat</span><br></pre></td></tr></table></figure><ul><li><p>构建一个<code>.lst</code>文件，包括： [图像ID， 标签， 图像存储的完整地址]</p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ wc -l /raid/datasets/imagenet/lists/*.lst </span><br><span class="line"><span class="symbol">50000 </span>/raid/datasets/imagenet/lists/test.lst </span><br><span class="line"><span class="symbol">1231167 </span>/raid/datasets/imagenet/lists/train.lst </span><br><span class="line"><span class="symbol">48238 </span>/raid/datasets/imagenet/lists/<span class="keyword">val</span>.lst </span><br><span class="line"><span class="symbol">1329405 </span>total</span><br></pre></td></tr></table></figure><p>​</p></li><li><p>去除黑名单数据</p></li><li><p>创建<code>.rec</code> 文件</p></li></ul><p><code>mxnet</code>提供一个工具im2rec来准备训练数据，工具地址如下：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/tools/im2rec.py</span><br></pre></td></tr></table></figure><blockquote><p><strong>关于<code>im2rec</code>的更多用法:</strong></p><p>1) 生成list文件</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; python ~/mxnet/tools/im2rec.py –list True –recursive True –train-ratio 0.9 myData /home/xxx/data/</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><p>&gt;</p><blockquote><p><strong>参数：</strong></p><p><strong>–list</strong>：当要生成list文件时，这个参数一定要设为True，表示当前用来生成的list文件；默认是生成rec文件；</p><p><strong>–recursive</strong>：递归的遍历你的所有数据集，要设为True；</p><p><strong>–train-ratio</strong>：用来将你的全部数据集拆分成两部分：训练集（train）和交叉验证集（val），具体多少作为训练集，多少作为验证集，就由这个参数来确定；</p><p><strong>–test-ratio</strong>：同上，分成训练集和测试集两部分；</p><p><strong>–exts</strong>：这个是你数据的后缀（注，这里我们一般说的图片数据），目前的MXNet只支持两种图片格式：jpg和jpeg</p><p><strong>prefix</strong>：这里指的是你要生成list文件的前缀名，我这里命名为myData；</p><p><strong>root</strong>：这里指的是你的图片数据存放的路径；</p><p>2）生成rec文件</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; python ~/mxnet/tools/im2rec.py –num-thread 4 –pass-through 1 myData /home/xxx/data/</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure><p><strong>参数：</strong></p><p>Options for creating database:<br>  —pass-through        whether to skip transformation and save image as is<br>                        (default: False)<br>  —resize RESIZE       resize the shorter edge of image to the newsize,<br>                        original images will be packed by default.<br>  —center-crop         specify whether to crop the center image to make it<br>                        rectangular. (default: False)<br>  —quality QUALITY     JPEG quality for encoding, 1-100; or PNG compression<br>                        for encoding, 1-9 (default: 95)<br>  —num-thread NUM_THREAD<br>                        number of thread to use for encoding. order of images<br>                        will be different from the input list if &gt;1. the input<br>                        list will be modified to match the resulting order.<br>                        (default: 1)<br>  —color {-1,0,1}      specify the color mode of the loaded image. 1: Loads a<br>                        color image. Any transparency of image will be<br>                        neglected. It is the default flag. 0: Loads image in<br>                        grayscale mode. -1:Loads image as such including alpha<br>                        channel. (default: 1)<br>  —encoding {.jpg,.png}<br>                        specify the encoding of the images. (default: .jpg)<br>  —pack-label          Whether to also pack multi dimensional label in the<br>                        record file (default: False)</p></blockquote><p>使用如下命令分别准备训练集、验证集和测试集数据：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python im2rec.py /home/ubuntu/data/imagenet/lists/val.lst "" --num-thread 16 --resize 256 --encoding '.jpg' --quality 100 </span><br><span class="line"></span><br><span class="line">python im2rec.py /home/ubuntu/data/imagenet/lists/train.lst "" --num-thread 16 --resize 256 --encoding '.jpg' --quality 100</span><br><span class="line"></span><br><span class="line">python im2rec.py /home/ubuntu/data/imagenet/lists/test.lst "" --num-thread 16 --resize 256 --encoding '.jpg' --quality 100</span><br></pre></td></tr></table></figure><h2 id="其它相关内容"><a href="#其它相关内容" class="headerlink" title="其它相关内容"></a>其它相关内容</h2><ol><li><a href="http://image-net.org/challenges/talks_2017/imagenet_ilsvrc2017_v1.0.pdf" target="_blank" rel="noopener">李飞飞在ILSVRC2017的报告</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://p4ygzcmtw.bkt.clouddn.com/cover/09.jpg&quot; alt=&quot;ImageNET&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="动手实践营" scheme="http://blog.a-stack.com/categories/%E5%8A%A8%E6%89%8B%E5%AE%9E%E8%B7%B5%E8%90%A5/"/>
    
      <category term="机器视觉" scheme="http://blog.a-stack.com/categories/%E5%8A%A8%E6%89%8B%E5%AE%9E%E8%B7%B5%E8%90%A5/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="数据集" scheme="http://blog.a-stack.com/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
    
  </entry>
  
  <entry>
    <title>深度学习实践方法论</title>
    <link href="http://blog.a-stack.com/2018/07/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    <id>http://blog.a-stack.com/2018/07/03/深度学习实践方法论/</id>
    <published>2018-07-03T09:34:48.000Z</published>
    <updated>2018-07-20T15:53:03.168Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://p4ygzcmtw.bkt.clouddn.com/cover/04.jpg" alt="Test Picture"></p><p><strong>摘要：</strong> 深度学习实践的方法论是一套靠经验而非算法总结的行之有效的指导，后续随着研究深入将不断更新补充相关内容。</p><a id="more"></a><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>从Cousera学习吴恩达的机器学习、深度学习系列课程便开始希望能够根据课程学习内容，逐步总结深度学习算法在项目实践中应该如何应用，是否能够总结一份最佳实践手册，并通过不断的更新维护，方便日后查阅和指导深度学习工程师的项目开发。最近在看Goodfellow的深度学习圣经——《Deep Learning》，第十一章再次讲到了这个问题，于是便以书中内容为基础，总结这篇深度学习实践的博客。</p><p>正如书中所说要成功地使用深度学习技术，仅仅知道存在哪些算法和解释他们为何有效的原理是不够的。一个优秀的机器学习实践者还需要知道如何针对具体应用挑选一个合适的算法以及如何监控，并根据实验反馈改进机器学习系统。书中建议参考如下几个实践设计流程：</p><ul><li>确定目标——使用什么样的误差度量，并为此误差度量指定目标值。这些目标 和误差度量取决于该应用旨在解决的问题。</li><li>尽快建立一个端到端的工作流程，包括估计合适的性能度量。 </li><li>搭建系统，并确定性能瓶颈。检查哪个部分的性能差于预期，以及是否是因 为过拟合、欠拟合，或者数据或软件缺陷造成的。</li><li>根据具体观察反复地进行增量式的改动，如收集新数据、调整超参数或改进算 法。</li></ul><p><img src="/qnsource/images/2018-07-03-深度学习实践方法论/deeplearning_workflow.png" alt="我们项目实践中使用的流程图"></p><h2 id="问题的定义和描述"><a href="#问题的定义和描述" class="headerlink" title="问题的定义和描述"></a>问题的定义和描述</h2><ul><li>选定误差度量标准；</li></ul><p><img src="/qnsource/images/2018-07-03-深度学习实践方法论/bayes_error.PNG" alt="bayes_error"></p><ul><li>科研中，目标通常是在某个确定基准下探讨哪个算法更好，一般会固定训练集，不允许收集更多的数据。</li><li>性能期望的设计</li><li>度量： 准确率、错误率，召回率，精确率，F1分数，mAP …<ul><li>覆盖（coverage）： 机器学习系统能够产生响应的样本所占的比率；</li></ul></li></ul><h2 id="基准模型"><a href="#基准模型" class="headerlink" title="基准模型"></a>基准模型</h2><ul><li>明确任务的度量和目标之后，需要快速的迭代第一个端到端的系统。</li><li>项目开始时，可能无需使用深度学习，构建一个简单的统计模型可以快速实现原型开发，当然如果问题本身属于“AI-完全”的，如对象识别、语音识别、机器翻译，那么可以根据数据的结构选择从一个基本的CNN/RNN/DNN模型开始。</li><li>优化算法方面，具有衰减学习率以及动量的SGD是优化算法一个合理的选择（流行的衰减方法有，衰减到固定最低学习率的线性衰减、指数衰减，或每次发生验证错误停滞时 将学习率降低 2 − 10 倍，这些衰减方法在不同问题上好坏不一）。<ul><li>也可以直接使用Adam算法</li></ul></li><li>批标准化可以视情况逐步采用；</li><li>如果项目内容和别人已经完成的模型任务很相像，复制现成的网络结构或利用迁移学习fine-tune也是这阶段应该考虑的；</li></ul><h2 id="数据收集"><a href="#数据收集" class="headerlink" title="数据收集"></a>数据收集</h2><ul><li>收集更多数据对于深度学习来说是最直接改观性能的方式，但何时收集，是否应该收集需要评估投入-产出比；</li><li>也许正则化可以弥补模型的误差期望差距，没有必要投入代价更好的数据收集工作；</li></ul><p><img src="/qnsource/images/2018-07-03-深度学习实践方法论/data_split.PNG" alt="data_split"></p><p><img src="/qnsource/images/2018-07-03-深度学习实践方法论/data_split2.PNG" alt="data_split2"></p><ul><li><p>如果收集数据，应该收集多少数据？</p><ul><li><p>如图所示，绘制曲线显示训练集规模和泛化误差之间的关系是很有帮助的。根据走势延伸曲线，可以预测还需要多少训练数据来达到一定的性能。</p><p><img src="/qnsource/images/2018-07-03-深度学习实践方法论/number_of_training_examples.PNG" alt="训练集大小对训练误差的影响"></p></li></ul></li></ul><h2 id="超参选择"><a href="#超参选择" class="headerlink" title="超参选择"></a>超参选择</h2><p>大部分深度学习算法都有许多超参数来控制不同方面的算法表现。有些超参数会影响算法运行的时间和存储成本。有些超参数会影响学习到的模型质量，以及 在新输入上推断正确结果的能力。 有两种选择超参数的基本方法：手动选择和自动选择。</p><h3 id="手动调节超参"><a href="#手动调节超参" class="headerlink" title="手动调节超参"></a>手动调节超参</h3><p>手动搜索超参数的目标通常是最小化受限于运行时间和内存预算的泛化误差。通过调整模型的有效容量以匹配任务的复杂性。有效容量受限于三个因素：</p><ul><li>模型的表示容量</li><li>学习算法成功最小化训练模型代价函数的能力</li><li>代价函数和训练过程正则化模型的程度</li></ul><p>学习率可能是最重要的超参数，如果你只有时间调整一个超参，那就调整学习率。相比其他超参数，它以一种更复杂的方式控制模型的有效容量——当学习率适合优化问题时，模型的有效容量最高，此时学习率是正确的，既不是特别大也不是特别小。学习率关于训练误差具有 U 形曲线，如图所示。当学习率过大时，梯度下降可能会不经意地增加而非减少训练误差。在理想化的二次情况下，如果学习率是最佳值的两倍大时，会发生这种情况 (LeCun et al., 1998b)。当学习率太小，训练不仅慢，还有可能永久停留在一个很高的训练误差。</p><p><img src="/qnsource/images/2018-07-03-深度学习实践方法论/learning_rate.PNG" alt="learning_rate"></p><blockquote><p>实践中能够确保学习有效的暴力方法就是不断提高模型容量和训练 集的大小，直到解决问题。</p></blockquote><h3 id="自动超参优化"><a href="#自动超参优化" class="headerlink" title="自动超参优化"></a>自动超参优化</h3><p>如果我们仔细想想使用者搜索学习算法合适超参数的方式，我们会意识到这其实是一种优化：我们在试图寻找超参数来优化目标函数，例如验证误差，有时还会有一些约束（如训练时间，内存或识别时间的预算）。</p><p><strong>网格搜索（grid search）</strong>是超参选择的常用方法，利用几个小的有限集训练参数模型，从中挑选验证集误差最小的超参。超参范围的设定一般采用对数尺度小挑选合适的值。</p><p>随机搜索： 为每个超参数定义一个边缘分布，或者对数尺度上的均匀分布。与网格搜索不懂，不需要离散化超参数的值。实践证明，随机搜索效率比网格搜索更高。</p><h2 id="调整策略"><a href="#调整策略" class="headerlink" title="调整策略"></a>调整策略</h2><p><img src="/qnsource/images/2018-07-03-深度学习实践方法论/adjust_error.PNG" alt="adjust_error"></p><p><img src="/qnsource/images/2018-07-03-深度学习实践方法论/adjust_error_2.PNG" alt="adjust_error_2"></p><p><img src="/qnsource/images/2018-07-03-深度学习实践方法论/adjust_error_3.PNG" alt="adjust_error_3"></p><h2 id="调试策略"><a href="#调试策略" class="headerlink" title="调试策略"></a>调试策略</h2><ol><li>可视化计算中模型的行为：当训练模型检测图像中的对象时，查看一些模型检测到部分重叠的图像。在训练语音生成模型时，试听一些生成的语音样本。这似乎是显而易见的，但在实际中很容易只注意量化性能度量，如准确率或对数似然。直接观察机器学习模型运行其任务，有助于确定其达到的量化性能数据是否看上去合 理。错误评估模型性能可能是最具破坏性的错误之一，因为它们会使你在系统出问题时误以为系统运行良好。 </li><li>可视化最严重的错误：大多数模型能够输出运行任务时的某种置信度量。例如，基于softmax 函数输出层的分类器给每个类分配一个概率。因此，分配给最有可能的类的概率给出了模型在其分类决定上的置信估计值。通常，相比于正确预测的概率最大似然训练会略有高估。但是由于实际上模型的较小概率不太可能对应着正确 的标签，因此它们在一定意义上还是有些用的。通过查看训练集中很难正确建模的样本，通常可以发现该数据预处理或者标记方式的问题。</li><li>根据训练和测试误差检测软件：我们往往很难确定底层软件是否是正确实现。训练和测试误差能够提供一些线索。如果训练误差较低，但是测试误差较高，那么很有可能训练过程是在正常运行，但模型由于算法原因过拟合了。另一种可能是，测试误差没有被正确地度量，可能是由于训练后保存模型再重载去度量测试集时出现 问题，或者是因为测试数据和训练数据预处理的方式不同。如果训练和测试误差都很高，那么很难确定是软件错误，还是由于算法原因模型欠拟合。这种情况需要进一步的测试。</li><li>拟合极小的数据集：当训练集上有很大的误差时，我们需要确定问题是真正的欠拟合，还是软件错误。通常，即使是小模型也可以保证很好地拟合一个足够小的数据集。例如，只有一个样本的分类数据可以通过正确设置输出层的偏置来拟合。通常，如果不能训练一个分类器来正确标注一个单独的样本，或不能训练一个自编码 器来成功地精准再现一个单独的样本，或不能训练一个生成模型来一致地生成一个单独的样本，那么很有可能是由于软件错误阻止训练集上的成功优化。此测试可以扩展到只有少量样本的小数据集上。 </li><li>比较反向传播导数和数值导数：如果读者正在使用一个需要实现梯度计算的软件框架，或者在添加一个新操作到求导库中，必须定义它的 bprop 方法，那么常见的错误原因是没能正确地实现梯度表达。验证这些求导正确性的一种方法是比较实现的自动求导和通过有限差分（finite difference）计算的导数。</li><li>监控激活函数值和梯度的直方图：可视化神经网络在大量训练迭代后（也许是一个轮）收集到的激活函数值和梯度的统计量往往是有用的。隐藏单元的预激活值可以告诉我们该单元是否饱和，或者它们饱和的频率如何。例如，对于整流器，它们多久关一次？是否有单元一直关闭？对于双曲正切单元而言，预激活绝对值的平均值可以告诉我们该单元的饱和程度。在深度网络中，传播梯度的快速增长或快速消失，可能会阻碍优化过程。最后，比较参数梯度和参数的量级也是有帮助的。正如 (Bottou, 2015) 所建议的，我们希望参数在一个小批量更新中变化的幅度是参数量值 1% 这样的级别，而不是50% 或者0.001%（这会导致参数移动得太慢）。也有可能是某些参数以良好的步长移动，而另一些停滞。如果数据是稀疏的（比如自然语言），有些参数可能很少更新，检测它们变化时应该记住这一点。</li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="http://www.deeplearningbook.org/" target="_blank" rel="noopener">《Deep Learning》Book</a></li><li>Ng, A. (2015). Advice for applying machine <a href="https://see.stanford.edu/materials/aimlcs229/ML-advice.pdf" target="_blank" rel="noopener">https://see.stanford.edu/materials/aimlcs229/ML-advice.pdf</a>. </li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://p4ygzcmtw.bkt.clouddn.com/cover/04.jpg&quot; alt=&quot;Test Picture&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 深度学习实践的方法论是一套靠经验而非算法总结的行之有效的指导，后续随着研究深入将不断更新补充相关内容。&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://blog.a-stack.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="实践" scheme="http://blog.a-stack.com/tags/%E5%AE%9E%E8%B7%B5/"/>
    
  </entry>
  
  <entry>
    <title>Thinking Stats</title>
    <link href="http://blog.a-stack.com/2018/06/20/thinking-stats/"/>
    <id>http://blog.a-stack.com/2018/06/20/thinking-stats/</id>
    <published>2018-06-20T12:09:03.000Z</published>
    <updated>2018-07-20T15:53:25.907Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://p4ygzcmtw.bkt.clouddn.com/cover/06.jpg" alt="Test Picture"></p><a id="more"></a><h2 id="Pandas技巧"><a href="#Pandas技巧" class="headerlink" title="Pandas技巧"></a>Pandas技巧</h2><h3 id="1-统计属性的独立值数目"><a href="#1-统计属性的独立值数目" class="headerlink" title="1. 统计属性的独立值数目"></a>1. 统计属性的独立值数目</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd[<span class="string">"outcome"</span>].value_counts().sort_index()</span><br></pre></td></tr></table></figure><h2 id="数据的相关性"><a href="#数据的相关性" class="headerlink" title="数据的相关性"></a>数据的相关性</h2><p>衡量两组数据或数据的两个变量（维度）线性相关性的方法主要有：</p><ul><li>皮尔逊相关系数</li><li>斯皮尔曼相关系数</li><li>最小二乘拟合</li></ul><h3 id="协方差"><a href="#协方差" class="headerlink" title="协方差"></a>协方差</h3><p><strong>标准分数(standard score):</strong> $z_i = (x_i - \mu)/\sigma$ </p><p>其中$x_i - \mu$称为离差，描述了$x_i$与均值$\mu$的差异，除以方差是为了归一化偏差，这样形成的数据集$Z$就是均值为0，方差为1，且与原数据集$X$同分布，且统一单位为1，不需要再考虑原先不同数据维度的单位不同的问题。</p><p>协方差(covariance)衡量相关变量变化趋势是否相同，定义如下：</p><script type="math/tex; mode=display">Cov(X,Y) = \frac{1}{n}\sum(x_i-\mu_x)(y_i-\mu_y)</script><p>由定义可知，协方差描述了两组数据离差相乘的加和，可以描述两个序列的变化是否一致。</p><p>但由于X,Y本身单位有可能不同，没有被归一化，导致结果很难反应实际的情况。</p><h3 id="皮尔逊相关系数"><a href="#皮尔逊相关系数" class="headerlink" title="皮尔逊相关系数"></a>皮尔逊相关系数</h3><p><strong>皮尔逊相关系数（Pearson’s correlation）:</strong> </p><script type="math/tex; mode=display">\rho = \frac{1}{n}\sum\frac{(x_i-\mu_x)}{\sigma_x} \frac{(y_i-\mu_y)}{\sigma_y}=\frac{Cov(X,Y)}{\sigma_x \sigma_y}</script><p>这样相关系数的单位为1，且取值范围为-1到1。$\rho$决定值的大小描述了两个变量的线性相关程度。当$\rho=1$时，两个变量完全正相关，当$\rho=0$时，两个变量完全负相关。</p><blockquote><p>但是$\rho=0$并不代表着两个变量毫无关系，皮尔逊系数只能衡量两个变量之间的线性关系，如果两个变量是非线性相关，无法通过该系数描述。</p></blockquote><p><img src="/qnsource/images/2018-06-20-thinking-stats/Correlation_examples.png" alt="相关性示意图"></p><p>上图描述了具有一定相关性的示例数据和对应的相关系数，第一行为一组有相关性和无线性相关性的数据，第二组为对应的严格相关数据，第三行为非线性相关数据，但相关系数为0。</p><h3 id="斯皮尔曼秩相关"><a href="#斯皮尔曼秩相关" class="headerlink" title="斯皮尔曼秩相关"></a>斯皮尔曼秩相关</h3><p>是为了解决皮尔逊相关系数对异常值敏感的问题，<strong>斯皮尔曼秩相关系数（Spearman’s Rank Correlation）</strong>可以用在存在异 常值和变量分布非常不对称的情况。</p><p>首先计算序列中数值的秩（rank），即某个数据在序列中大小排序的序号，将序列转换为秩之后再计算皮尔逊相关系数。</p><h3 id="散点图观察数据相关性"><a href="#散点图观察数据相关性" class="headerlink" title="散点图观察数据相关性"></a>散点图观察数据相关性</h3><p>既然皮尔逊系数无法完全表征数据的相关性，我们可以通过画散点图的方法来直观的观察数据的相关性。</p><ul><li>scatter</li><li>hexbin</li><li><todo> 补充相关代码</todo></li></ul><h3 id="最小二乘拟合"><a href="#最小二乘拟合" class="headerlink" title="最小二乘拟合"></a>最小二乘拟合</h3><p>相关系数可以描述两个变量的线性相关性强弱，但无法评估他们的斜率，最小二乘法可以通过数据拟合的方式计算斜率。首先定义数据的预测偏差(残差)：$\epsilon_i = (\alpha + \beta x_i) - y_i$， 通过求解最小化残差的平方和，可以获得相关参数。</p><blockquote><p>选择残差平方和最小作为最优化目标的原因：</p><ol><li>平方能将正残差和负残差都变成正数，这符合我们的目标。 </li><li>平方相当于给残差赋予了一个权重，越大的残差（绝对量）被赋予 的权重越大。但是并不是所有情况下大的残差都应该被赋予大的权 重，因为这样拟合方程就很容易受到异常值的影响。 </li><li>在残差服从均值为 0、方差为$\sigma^2$的正态分布，且在残差与 x 独立的假设下，参数的最小二乘估计结果与极大似然估计量相同。</li></ol></blockquote><p>斜率可以计算为：</p><script type="math/tex; mode=display">\hat\beta = \frac{Cov(X,Y)}{Var(X)}</script><h3 id="相关性不等于因果性"><a href="#相关性不等于因果性" class="headerlink" title="相关性不等于因果性"></a>相关性不等于因果性</h3><p>两个变量的相关关系并不代表他们之间存在因果关系，Correlation does not imply causation。如何确认两个变量的因果关系，一般采用随机对照试验和自然试验(natural experiment)。</p><ul><li>随机对照试验多用于实验研究和药物研发，通过设立实验组和对照组来控制变量；</li><li>自然试验通过尽量控制群体在各方面是相似的，然后对不同群体实施不同的处理。</li></ul><h2 id="估计"><a href="#估计" class="headerlink" title="估计"></a>估计</h2><ul><li>极大似然估计（Maximum Likelihood Estimator，MLE）：根据已有信息获得的最大可能估计；</li><li>最小误差值估计（最小二乘估计）：分布数据均匀，没有且很少有异常值的情况下；</li><li>无偏估计：$\sigma^2$的无偏估计为$S_{n-1}^2$<ul><li>估计是无偏的：估计量的<a href="https://baike.baidu.com/item/%E6%95%B0%E5%AD%A6%E6%9C%9F%E6%9C%9B" target="_blank" rel="noopener">数学期望</a>等于被估计参数的<a href="https://baike.baidu.com/item/%E7%9C%9F%E5%AE%9E%E5%80%BC" target="_blank" rel="noopener">真实值</a>，则称此此估计量为被估计参数的无偏估计，即具有无偏性，是一种用于评价估计量优良性的准则。无偏估计的意义是：在多次重复下，它们的平均数接近所估计的参数真值。</li></ul></li><li>贝叶斯估计<ul><li>贝叶斯置信区间</li></ul></li><li>经典问题： 火车头问题（德国坦克问题）</li></ul><blockquote><p>铁路公司将它所有的火车头都进行了编号，从1到N。有一天 你看见一个编号为60的火车头，那该铁路公司总共有多少火 车头呢？</p></blockquote><p>对于一个给定的估计量$\hat N$ ，观测到编号为 $i(i \le \hat N)$的火车的概率为$1/\hat N$，$i&gt;\hat N$的概率为 0。所以 N的极大似然估计量是$\hat N =i$ 。换言之,如果观测到的火车的编号是 60，而且我们要以最大的概率保证结果的 正确性，那么我们就会猜测铁路公司有 60 辆火车。</p><p>但从均方误差最小化的角度来看，上述结果不理想，我们需要选择一个$\hat N = ai$ 使得估计的均方误差最小：</p><script type="math/tex; mode=display">\min \frac{1}{N}\sum^N_{i=1} (ai-N)^2</script><p>从无偏估计角度出发，令平均误差为零，即</p><script type="math/tex; mode=display">ME = \frac{1}{N}\sum^N_{i=1} (ai-N)=0</script><p>贝叶斯估计</p><p>假如有足够的先验信息，那么所有的估计量将倾向于收敛到同一个值。</p><h2 id="时序数据分析"><a href="#时序数据分析" class="headerlink" title="时序数据分析"></a>时序数据分析</h2><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li>​</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://p4ygzcmtw.bkt.clouddn.com/cover/06.jpg&quot; alt=&quot;Test Picture&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://blog.a-stack.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
  </entry>
  
  <entry>
    <title>Feature_Visualization_in_NN</title>
    <link href="http://blog.a-stack.com/2018/05/22/Feature-Visualization-in-NN/"/>
    <id>http://blog.a-stack.com/2018/05/22/Feature-Visualization-in-NN/</id>
    <published>2018-05-22T02:23:04.000Z</published>
    <updated>2018-07-20T15:53:39.979Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/qnsource/images/2018-05-22-Feature-Visualization-in-NN/features.png" alt="features"></p><p><strong>摘要：</strong></p><a id="more"></a><p><strong>Feature visualization</strong> answers questions about what a network — or parts of a network — are looking for by generating examples.</p><p><strong>Attribution</strong> 1 studies what part of an example is responsible for the network activating a particular way.</p><p>TODO: 根据参考文献整理相关内容和思路。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://distill.pub/2017/feature-visualization/" target="_blank" rel="noopener">Feature Visualization -How neural networks build up their understanding of images</a></li><li><a href="https://distill.pub/2018/building-blocks/" target="_blank" rel="noopener">The Building Blocks of Interpretability</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/qnsource/images/2018-05-22-Feature-Visualization-in-NN/features.png&quot; alt=&quot;features&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://blog.a-stack.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="可视化" scheme="http://blog.a-stack.com/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>经典网络归纳： ResNet</title>
    <link href="http://blog.a-stack.com/2018/05/21/ResNet/"/>
    <id>http://blog.a-stack.com/2018/05/21/ResNet/</id>
    <published>2018-05-21T12:14:49.000Z</published>
    <updated>2018-05-22T01:35:37.537Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://p4ygzcmtw.bkt.clouddn.com/cover/04.jpg" alt="Test Picture"></p><p><strong>摘要：</strong> 作为深度卷积神经网络的里程碑式的作品，ResNet为卷积网络往更深层次扩展指明了方向，本文结合相关论文总结一下ResNet中创造性的想法。</p><a id="more"></a><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>随着网络深度增加，人们发现出现了Degradation问题，这不是过拟合导致的，因为在训练数据集上发现了同样的问题。ResNet解决了深层神经网络难训练的问题，在此之前要训练一个层次较深的网络需要在参数初始化上下功夫，当然还需要一定的运气。</p><p>ResNet网络获得了2015年所有的主流比赛冠军，相关内容被发表在论文《Deep Residual Learning for Image Recognition》中。除了残差网络的引入，在ResNet我们也看到逐渐摒弃了全连接层、池化层。全部网络中只在最开始使用了一个max pooling层，在最后使用了average pooling层。</p><p>2016年，在上述论文的基础上，He发表了第二篇改进的论文 <sup><a href="#fn_2" id="reffn_2">2</a></sup> </p><h2 id="残差网络"><a href="#残差网络" class="headerlink" title="残差网络"></a>残差网络</h2><p><img src="/qnsource/images/2018-05-21-ResNet/residual-Module.PNG" alt="residual-Module"></p><script type="math/tex; mode=display">y = F(x, {W_i}) + x</script><blockquote><p>“F是求和前网络映射，H是从输入到求和后的网络映射。比如把5映射到5.1，那么引入残差前是F’(5)=5.1，引入残差后是H(5)=5.1, H(5)=F(5)+5, F(5)=0.1。这里的F’和F都表示网络参数映射，<strong>引入残差后的映射对输出的变化更敏感</strong>。比如s输出从5.1变到5.2，映射F’的输出增加了1/51=2%，而对于残差结构输出从5.1到5.2，映射F是从0.1到0.2，增加了100%。明显后者输出变化对权重的调整作用更大，所以效果更好。残差的思想都是去掉相同的主体部分，从而突出微小的变化，看到残差网络我第一反应就是差分放大器”</p></blockquote><p>在ResNet中，残差使得网络学习更快，可以使用更高的学习率，比如常用的起始学习率为0.1。</p><p>Boottleneck残差网络中，一般最后一个1x1卷积的filter数目是另外两个的4倍；</p><p>残差网络可以从另一个角度理解，如下图所示，残差网络可以看成是由多种路径组合的一个网络，即，残差网络其实是很多并行子网络的组合。</p><p><img src="/qnsource/images/2018-05-21-ResNet/residual-Module-2.PNG" alt="residual-Module-2"></p><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p><img src="/qnsource/images/2018-05-21-ResNet/network-architect.png" alt="network-architect"></p><h2 id="Highway-Networks"><a href="#Highway-Networks" class="headerlink" title="Highway Networks"></a>Highway Networks</h2><h2 id="ResNet的改进及优化"><a href="#ResNet的改进及优化" class="headerlink" title="ResNet的改进及优化"></a>ResNet的改进及优化</h2><blockquote><p>He在2016年发布论文《Identity Mappings in Deep Residual Networks》，对ResNet中的一些内容进行了进一步的优化及完善，并证明了“identity Mapping” 的最优配置：$h(x_l) = x_l$。</p></blockquote><p><img src="/qnsource/images/2018-05-21-ResNet/new_restnet_block.png" alt="new_restnet_block"></p><p>论文中提出了在ResNet单元中采取“预激活”的方式，参考图（b）中方案，在权重更新之前先进行BN层和ReLU层操作。实践证明，采用这种方式更容易训练深层网络,同时具备更好的泛化性能。采用（b）的误差为6.36%小于(a)的6.61%<resnet-110></resnet-110></p><p>作者使用如下图所示的多种不同的残差单元比较性能，结果表明直连的方式效果最佳。</p><p><img src="/qnsource/images/2018-05-21-ResNet/other-resnet-shortcut.PNG" alt="other-resnet-shortcut"></p><blockquote><p>网络训练时间： 在CIFAR数据集，ResNet-1001，使用2GPU训练27小时； 在ImageNet数据集，ResNet-200使用8块GPU训练3周</p></blockquote><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>Keras中已经包含了ResNet50</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.applications.resnet50 <span class="keyword">import</span> ResNet50</span><br><span class="line">ResNet50(include_top=<span class="keyword">True</span>, weights=<span class="string">'imagenet'</span>, input_tensor=<span class="keyword">None</span>, input_shape=<span class="keyword">None</span>, pooling=<span class="keyword">None</span>, classes=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure><blockquote><p>当 <code>include_top=False</code>时，可以通过<code>input_shape</code> 调整输入图像尺寸，但图像高度不小于197；默认大小为<code>(224,24,3)</code></p><p>pooling: 可选，当 <code>include_top</code> 为 ‘False’ 时，该参数指定了特征提取时的池化方式。</p><ul><li><code>None</code> 代表不池化，直接输出最后一层卷积层的输出，该输出是一个四维张量。</li><li><code>avg</code> 代表全局平均池化（GLobalAveragePool2D），相当于在最后一层卷积层后面再加一层全局平均池化层，输出是一个二维张量。</li><li><code>max</code> 代表全局最大池化</li></ul></blockquote><p>利用ResNet50的迁移学习方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"><span class="keyword">from</span> keras.applications.resnet50 <span class="keyword">import</span> preprocess_input, decode_predictions</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras.applications.resnet50 <span class="keyword">import</span> ResNet50</span><br><span class="line"></span><br><span class="line">model = ResNet50(weights=<span class="string">'imagenet'</span>)</span><br><span class="line"><span class="comment">## 直接使用进行图像分类</span></span><br><span class="line">img_path = <span class="string">'elephant.jpg'</span></span><br><span class="line">img = image.load_img(img_path, target_size=(<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">x = image.img_to_array(img)</span><br><span class="line">x = np.expand_dims(x, axis=<span class="number">0</span>)</span><br><span class="line">x = preprocess_input(x)</span><br><span class="line"></span><br><span class="line">preds = model.predict(x)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 迁移学习1</span></span><br><span class="line">image_input = Input(shape=(<span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">model = ResNet50(input_tensor=image_input, include_top=<span class="keyword">True</span>,weights=<span class="string">'imagenet'</span>)</span><br><span class="line">last_layer = model.get_layer(<span class="string">'avg_pool'</span>).output</span><br><span class="line">x= Flatten(name=<span class="string">'flatten'</span>)(last_layer)</span><br><span class="line">out = Dense(num_classes, activation=<span class="string">'softmax'</span>, name=<span class="string">'output_layer'</span>)(x)</span><br><span class="line">custom_resnet_model = Model(inputs=image_input,outputs= out)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> custom_resnet_model.layers[:<span class="number">-1</span>]:</span><br><span class="line">layer.trainable = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line">custom_resnet_model.compile(loss=<span class="string">'categorical_crossentropy'</span>,optimizer=<span class="string">'adam'</span>,metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">## Fine Tune</span></span><br><span class="line">image_input = Input(shape=(<span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>))</span><br><span class="line">model = ResNet50(weights=<span class="string">'imagenet'</span>,include_top=<span class="keyword">False</span>)</span><br><span class="line">last_layer = model.output</span><br><span class="line"><span class="comment"># add a global spatial average pooling layer</span></span><br><span class="line">x = GlobalAveragePooling2D()(last_layer)</span><br><span class="line"><span class="comment"># add fully-connected &amp; dropout layers</span></span><br><span class="line">x = Dense(<span class="number">512</span>, activation=<span class="string">'relu'</span>,name=<span class="string">'fc-1'</span>)(x)</span><br><span class="line">x = Dropout(<span class="number">0.5</span>)(x)</span><br><span class="line">x = Dense(<span class="number">256</span>, activation=<span class="string">'relu'</span>,name=<span class="string">'fc-2'</span>)(x)</span><br><span class="line">x = Dropout(<span class="number">0.5</span>)(x)</span><br><span class="line"><span class="comment"># a softmax layer for 4 classes</span></span><br><span class="line">out = Dense(num_classes, activation=<span class="string">'softmax'</span>,name=<span class="string">'output_layer'</span>)(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># this is the model we will train</span></span><br><span class="line">custom_resnet_model2 = Model(inputs=model.input, outputs=out)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> custom_resnet_model2.layers[:<span class="number">-6</span>]:</span><br><span class="line">layer.trainable = <span class="keyword">False</span></span><br><span class="line">    </span><br><span class="line">custom_resnet_model2.compile(loss=<span class="string">'categorical_crossentropy'</span>,optimizer=<span class="string">'adam'</span>,metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="http://arxiv.org/abs/1512.03385" target="_blank" rel="noopener">Deep Residual Learning for Image Recognition</a></li><li><a href="https://arxiv.org/abs/1603.05027" target="_blank" rel="noopener">Identity Mappings in Deep Residual Networks</a></li><li><a href="https://keras.io/zh/applications/#resnet50" target="_blank" rel="noopener">Keras实现</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://p4ygzcmtw.bkt.clouddn.com/cover/04.jpg&quot; alt=&quot;Test Picture&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 作为深度卷积神经网络的里程碑式的作品，ResNet为卷积网络往更深层次扩展指明了方向，本文结合相关论文总结一下ResNet中创造性的想法。&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://blog.a-stack.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="机器视觉" scheme="http://blog.a-stack.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="机器视觉" scheme="http://blog.a-stack.com/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
      <category term="图像分类" scheme="http://blog.a-stack.com/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"/>
    
  </entry>
  
  <entry>
    <title>OpenCV and Python</title>
    <link href="http://blog.a-stack.com/2018/05/19/OpenCV-and-Python/"/>
    <id>http://blog.a-stack.com/2018/05/19/OpenCV-and-Python/</id>
    <published>2018-05-19T14:16:29.000Z</published>
    <updated>2018-05-22T07:07:39.842Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://p4ygzcmtw.bkt.clouddn.com/cover/03.jpg" alt="Ice and Sunshine"></p><p><strong>摘要：</strong> 本文整理了常用的OpenCV图像处理操作的python代码，便于后续使用过程中的速查。</p><a id="more"></a><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p><strong>OpenCV：</strong> is an image and video processing library with bindings in C++, C, Python, and Java. OpenCV is used for all sorts of image and video analysis, like facial recognition and detection, license plate reading, photo editing, advanced robotic vision, optical character recognition, and a whole lot more.</p><p><strong>python-OpenCV:</strong> OpenCV的python版实现</p><blockquote><p><code>python-OpenCV</code> 只是OpenCV部分功能的实现，一个完整的OpenCV包大小超过3G</p></blockquote><h2 id="图像-视频读写"><a href="#图像-视频读写" class="headerlink" title="图像/视频读写"></a>图像/视频读写</h2><ol><li><p>图像读写</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment">#IMREAD_GRAYSCALE（0），IMREAD_COLOR（1），IMREAD_UNCHANGED（-1）</span></span><br><span class="line">img = cv2.imread(<span class="string">'test.jpg'</span>,cv2.IMREAD_GRAYSCALE)</span><br><span class="line">cv2.imshow(<span class="string">'image'</span>,img)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br><span class="line"></span><br><span class="line">plt.imshow(img, cmap = <span class="string">'gray'</span>, interpolation = <span class="string">'bicubic'</span>)</span><br><span class="line"><span class="comment"># write an image</span></span><br><span class="line">cv2.imwrite(<span class="string">'watchgray.png'</span>,img)</span><br></pre></td></tr></table></figure><p>​</p></li><li><p>视频操作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line">cap = cv2.VideoCapture(<span class="number">0</span>)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">while</span>(<span class="keyword">True</span>):</span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)</span><br><span class="line"> </span><br><span class="line">    cv2.imshow(<span class="string">'frame'</span>,gray)</span><br><span class="line">    <span class="keyword">if</span> cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span> == ord(<span class="string">'q'</span>):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">cap.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure><p>保存视频录像：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line">cap = cv2.VideoCapture(<span class="number">1</span>)</span><br><span class="line">fourcc = cv2.VideoWriter_fourcc(*<span class="string">'XVID'</span>)</span><br><span class="line">out = cv2.VideoWriter(<span class="string">'output.avi'</span>,fourcc, <span class="number">20.0</span>, (<span class="number">640</span>,<span class="number">480</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(<span class="keyword">True</span>):</span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)</span><br><span class="line">    out.write(frame)</span><br><span class="line">    cv2.imshow(<span class="string">'frame'</span>,gray)</span><br><span class="line">    <span class="keyword">if</span> cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span> == ord(<span class="string">'q'</span>):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">cap.release()</span><br><span class="line">out.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></li></ol><h2 id="画图"><a href="#画图" class="headerlink" title="画图"></a>画图</h2><ol><li><p>Line</p><p><code>cv2.line(img,(0,0),(150,150),(255,255,255),15)</code></p><p>​         对象， 起始点， 结束点， 颜色， 粗细</p></li><li><p>rectangle</p><p><code>cv2.rectangle(img,(15,25),(200,150),(0,0,255),15)</code></p><p>​             对象;起点(x,y); 终点(x,y); 颜色；粗细</p></li><li><p>circle</p><p><code>cv2.circle(img,(100,63), 55, (0,255,0), -1)</code> </p><p>​               中心点；半径； 颜色； 粗细（-1—填充）</p></li><li><p>多边形</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pts = np.array([[<span class="number">10</span>,<span class="number">5</span>],[<span class="number">20</span>,<span class="number">30</span>],[<span class="number">70</span>,<span class="number">20</span>],[<span class="number">50</span>,<span class="number">10</span>]], np.int32)</span><br><span class="line"><span class="comment"># OpenCV documentation had this code, which reshapes the array to a 1 x 2. I did not </span></span><br><span class="line"><span class="comment"># find this necessary, but you may:</span></span><br><span class="line"><span class="comment">#pts = pts.reshape((-1,1,2))</span></span><br><span class="line">cv2.polylines(img, [pts], <span class="keyword">True</span>, (<span class="number">0</span>,<span class="number">255</span>,<span class="number">255</span>), <span class="number">3</span>)</span><br></pre></td></tr></table></figure></li><li><p>添加文字</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">font = cv2.FONT_HERSHEY_SIMPLEX</span><br><span class="line">cv2.putText(img,<span class="string">'OpenCV Tuts!'</span>,(<span class="number">0</span>,<span class="number">130</span>), font, <span class="number">1</span>, (<span class="number">200</span>,<span class="number">255</span>,<span class="number">155</span>), <span class="number">2</span>, cv2.LINE_AA)</span><br><span class="line"><span class="comment">#                                起点        大小      颜色     粗细</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="图像操作"><a href="#图像操作" class="headerlink" title="图像操作"></a>图像操作</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">print(img.shape)</span><br><span class="line">print(img.size)</span><br><span class="line">print(img.dtype)</span><br><span class="line"><span class="comment"># 图像填充</span></span><br><span class="line">img[<span class="number">100</span>:<span class="number">150</span>,<span class="number">100</span>:<span class="number">150</span>] = [<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>]</span><br></pre></td></tr></table></figure><p>叠加图像（png图像效果佳，调整为same size）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 500 x 250</span></span><br><span class="line">img1 = cv2.imread(<span class="string">'3D-Matplotlib.png'</span>)</span><br><span class="line">img2 = cv2.imread(<span class="string">'mainsvmimage.png'</span>)</span><br><span class="line"></span><br><span class="line">add = img1+img2</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">'add'</span>,add)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure><p>与<code>cv2.add(img1,img2)</code>区分，<code>cv2.add()</code>是每个像素大小的求和；可以采用加权求和策略，<code>weighted = cv2.addWeighted(img1, 0.6, img2, 0.4, 0)</code></p><h2 id="图像组合-TODO"><a href="#图像组合-TODO" class="headerlink" title="图像组合(TODO)"></a>图像组合(TODO)</h2><h2 id="Threshold"><a href="#Threshold" class="headerlink" title="Threshold"></a>Threshold</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">retval, threshold = cv2.threshold(grayscaled, <span class="number">10</span>, <span class="number">255</span>, cv2.THRESH_BINARY)</span><br><span class="line"><span class="comment"># adaptive threshold</span></span><br><span class="line">th = cv2.adaptiveThreshold(grayscaled, <span class="number">255</span>, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, <span class="number">115</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><h2 id="模板匹配"><a href="#模板匹配" class="headerlink" title="模板匹配"></a>模板匹配</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">"test.jpg"</span>)</span><br><span class="line">img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">template = cv2.imread(<span class="string">"template.png"</span>,<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">w, h = template.shape</span><br><span class="line">res = cv2.matchTemplate(img_gray,template,cv2.TM_CCOEFF_NORMED)</span><br><span class="line">threshold = <span class="number">0.8</span></span><br><span class="line">loc = np.where( res &gt;= threshold)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> pt <span class="keyword">in</span> zip(*loc[::<span class="number">-1</span>]):</span><br><span class="line">    cv2.rectangle(img, pt, (pt[<span class="number">0</span>] + w, pt[<span class="number">1</span>] + h), (<span class="number">0</span>,<span class="number">255</span>,<span class="number">255</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">'Detected'</span>,img)</span><br></pre></td></tr></table></figure><h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://pythonprogramming.net/loading-images-python-opencv-tutorial/" target="_blank" rel="noopener">OpenCV with Python Intro and loading Images tutorial</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://p4ygzcmtw.bkt.clouddn.com/cover/03.jpg&quot; alt=&quot;Ice and Sunshine&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 本文整理了常用的OpenCV图像处理操作的python代码，便于后续使用过程中的速查。&lt;/p&gt;
    
    </summary>
    
      <category term="工具" scheme="http://blog.a-stack.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="机器视觉" scheme="http://blog.a-stack.com/categories/%E5%B7%A5%E5%85%B7/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="工具" scheme="http://blog.a-stack.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="OpenCV" scheme="http://blog.a-stack.com/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>cs231n课程笔记:（Lecture 6-7）Training Neural Networks</title>
    <link href="http://blog.a-stack.com/2018/05/07/cs231n-lecture-6/"/>
    <id>http://blog.a-stack.com/2018/05/07/cs231n-lecture-6/</id>
    <published>2018-05-07T08:50:26.000Z</published>
    <updated>2018-05-16T14:00:03.181Z</updated>
    
    <content type="html"><![CDATA[<p><strong>摘要：</strong> 计划花一个月的时间刷一遍斯坦福的机器视觉课程cs231n，并做笔记记录每天学习到的内容。</p><!-- excerpt --><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>cs231n是斯坦福在深度学习和机器视觉领域的入门经典课程，相关资源如下：</p><ul><li>课程主页： <a href="http://cs231n.stanford.edu/" target="_blank" rel="noopener">http://cs231n.stanford.edu/</a></li><li>课程Notes：<a href="http://cs231n.github.io/" target="_blank" rel="noopener">http://cs231n.github.io/</a></li></ul><div class="table-container"><table><thead><tr><th>Lecture 6</th><th>Thursday April 19</th><th><strong>Training Neural Networks, part I</strong> Activation functions, initialization, dropout, batch normalization</th><th><a href="http://cs231n.stanford.edu/slides/2018/cs231n_2018_lecture06.pdf" target="_blank" rel="noopener">[slides]</a> <a href="http://cs231n.github.io/neural-networks-1/" target="_blank" rel="noopener">Neural Nets notes 1</a><a href="http://cs231n.github.io/neural-networks-2/" target="_blank" rel="noopener">Neural Nets notes 2</a><a href="http://cs231n.github.io/neural-networks-3/" target="_blank" rel="noopener">Neural Nets notes 3</a>tips/tricks: <a href="http://research.microsoft.com/pubs/192769/tricks-2012.pdf" target="_blank" rel="noopener">[1]</a>, <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf" target="_blank" rel="noopener">[2]</a>, <a href="http://arxiv.org/pdf/1206.5533v2.pdf" target="_blank" rel="noopener">[3]</a> (optional) <a href="http://www.nature.com/nature/journal/v521/n7553/full/nature14539.html" target="_blank" rel="noopener">Deep Learning [Nature]</a> (optional)</th></tr></thead><tbody><tr><td>Discussion Section</td><td>Friday April 20</td><td><strong>Tips and tricks for tuning NNs</strong></td><td><a href="https://docs.google.com/presentation/d/183aCHcSq-YsaokZrqI3khuy_zPbehG-XgkyA6L5W4t4/edit?usp=sharing" target="_blank" rel="noopener">[slides]</a></td></tr><tr><td>Lecture 7</td><td>Tuesday April 24</td><td><strong>Training Neural Networks, part II</strong> Update rules, ensembles, data augmentation, transfer learning</td><td><a href="http://cs231n.stanford.edu/slides/2018/cs231n_2018_lecture07.pdf" target="_blank" rel="noopener">[slides]</a> <a href="http://cs231n.github.io/neural-networks-3/" target="_blank" rel="noopener">Neural Nets notes 3</a></td></tr></tbody></table></div><h2 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h2><ol><li><p>Batch Normalization的计算</p><script type="math/tex; mode=display">\begin{align}\mu_i = \frac{1}{m} \sum_{k \in S_i} x_k\\\sigma_i = \sqrt{\frac{1}{m}\sum_{k\in S_i} (x_k-\mu_i)^2 + \epsilon}\\y_i = \lambda \hat x_i + \beta\end{align}</script><p>由于BN会受到batch size大小的影响，如果batch size太小，算出的均值和方差就会不准确，太大存储可能不够用。所以衍生出了几种优化表达。</p></li><li><p>其它归一化方法与BN的区别</p><p><img src="/qnsource/images/2018-04-28-cs231n-notes/normalization_methods.png" alt="normalization_methods"></p></li></ol><ul><li>BatchNorm： batch方向做归一化，计算 <code>N*H*W</code> 的均值；</li><li>LayerNorm： channel方向做归一化，计算<code>C*H*W</code> 的均值；</li><li>InstanceNorm： 一个channel内做归一化，计算<code>H*W</code>的均值；</li><li>GroupNorm： 将Channel方向分为Group，然后每个Group内做归一化，计算<code>(C//G)*H*W</code>的均值</li></ul><blockquote><p>当G=C时，GroupNorm为LayerNorm，当G=1时，GroupNorm为InstanceNorm</p></blockquote><h2 id="训练过程的网络优化技巧"><a href="#训练过程的网络优化技巧" class="headerlink" title="训练过程的网络优化技巧"></a>训练过程的网络优化技巧</h2><blockquote><p>Parammeter tuning is more of an art.</p></blockquote><h3 id="网络优化-提升网络性能方法"><a href="#网络优化-提升网络性能方法" class="headerlink" title="网络优化/提升网络性能方法"></a>网络优化/提升网络性能方法</h3><ul><li>获取更多训练数据</li><li>增加网络复杂度</li><li>选择更多优化算法</li><li>训练更长时间</li><li>修改批大小</li><li>尝试正则化</li><li>权衡过拟合/欠拟合</li><li>…</li></ul><h3 id="参数调优"><a href="#参数调优" class="headerlink" title="参数调优"></a>参数调优</h3><p><strong>输入（超参）：</strong></p><ul><li>系统架构</li><li>学习率、优化算法</li><li>正则化（Dropout）</li><li>批处理/批量归一化（BN）</li></ul><p><strong>输出（分析图表）：</strong></p><ul><li>损失曲线</li><li>梯度基准</li><li>准确率</li><li>训练/验证数据集性能</li><li>其它</li></ul><h3 id="架构选择与设计"><a href="#架构选择与设计" class="headerlink" title="架构选择与设计"></a>架构选择与设计</h3><ul><li>架构选择<ul><li>分类问题：AlexNet,VGG, ResNet,DenseNet, …</li><li>语义分割：FCN, Dilated Convolution, Mask RCNN</li><li>识别： Faster-RCNN, YOLO, SSD</li><li>图像生成： UNet, Dilated Convolution, DCGAN, WGAN</li><li>…</li></ul></li><li>输入适配</li></ul><p><img src="/qnsource/images/2018-04-28-cs231n-notes/architecture_input.png" alt="architecture_input"></p><ul><li>数据集适配</li></ul><p><img src="/qnsource/images/2018-04-28-cs231n-notes/architecture_dataset.png" alt="architecture_dataset"></p><ul><li>输出任务适配</li></ul><p><img src="/qnsource/images/2018-04-28-cs231n-notes/architecture_output.png" alt="architecture_output"></p><h3 id="输出结果分析"><a href="#输出结果分析" class="headerlink" title="输出结果分析"></a>输出结果分析</h3><ol><li>Loss不变化，网络没有学到任何信息：梯度没有应用到权重上，或者不匹配</li></ol><p><img src="/qnsource/images/2018-04-28-cs231n-notes/tuning_tricks_not_learning.png" alt="tuning_tricks_not_learning"></p><ol><li><p>过拟合</p><p><img src="/qnsource/images/2018-04-28-cs231n-notes/tuning_tricks_overfitting_1.png" alt="tuning_tricks_overfitting_1"></p></li><li><p>不收敛：训练时间不足/学习率过低</p><p><img src="/qnsource/images/2018-04-28-cs231n-notes/tuning_tricks_not_converged.png" alt="tuning_tricks_not_converged"></p></li><li><p>慢启动</p><p><img src="/qnsource/images/2018-04-28-cs231n-notes/tuning_tricks_slow_start.png" alt="tuning_tricks_slow_start"></p></li><li><p>梯度更新方向错误</p><p><img src="/qnsource/images/2018-04-28-cs231n-notes/tuning_tricks_wrong_gradients.png" alt="tuning_tricks_wrong_gradients"></p></li><li><p>数据未打乱</p><p><img src="/qnsource/images/2018-04-28-cs231n-notes/tuning_tricks_not_shuffling_data.png" alt="tuning_tricks_not_shuffling_data"></p></li><li><p>损失函数出现<code>nans</code>值：模型中数据不稳定/较高的学习率</p><p><img src="/qnsource/images/2018-04-28-cs231n-notes/tuning_tricks_nans_loss.png" alt="tuning_tricks_nans_loss"></p></li><li><p>验证集效果优于训练集：验证集太小或分布异常</p><p><img src="/qnsource/images/2018-04-28-cs231n-notes/tuning_tricks_val_samll.png" alt="tuning_tricks_val_samll"></p></li></ol><h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><ol><li><p>DropOut本质上也是一种模型组合学习</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train</span></span><br><span class="line">H = np.maximum(<span class="number">0</span>, np.dot(W,X) + b)</span><br><span class="line">U = (np.random.rand(*H.shape) &lt; p) / p</span><br><span class="line">H *= U</span><br></pre></td></tr></table></figure><p>​</p></li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li>Fei,Nish, Tips and tricks for tuning NNs</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 计划花一个月的时间刷一遍斯坦福的机器视觉课程cs231n，并做笔记记录每天学习到的内容。&lt;/p&gt;
&lt;!-- excerpt --&gt;
&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title
      
    
    </summary>
    
      <category term="读书笔记" scheme="http://blog.a-stack.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="课程笔记" scheme="http://blog.a-stack.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="机器视觉" scheme="http://blog.a-stack.com/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
      <category term="笔记" scheme="http://blog.a-stack.com/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
</feed>
