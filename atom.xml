<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Ebby&#39;s Notes</title>
  
  <subtitle>=Blog for AI Learning=</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://blog.a-stack.com/"/>
  <updated>2018-07-20T14:53:24.141Z</updated>
  <id>http://blog.a-stack.com/</id>
  
  <author>
    <name>Ebby DD</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>经典网络复现之VGGNet</title>
    <link href="http://blog.a-stack.com/2018/07/12/2018-07-9-%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E5%A4%8D%E7%8E%B0%E4%B9%8BVGG/"/>
    <id>http://blog.a-stack.com/2018/07/12/2018-07-9-经典网络复现之VGG/</id>
    <published>2018-07-12T05:58:12.000Z</published>
    <updated>2018-07-20T14:53:24.141Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/qnsource/images/2018-07-09-经典网络复现之VGG/VGGNet.jpg" alt="VGGNet"></p><p><strong>摘要：</strong> 本文记录利用ImageNet数据集复现经典网络VGGNet的过程，并记录在大型数据集训练过程中需要考虑的问题。</p><a id="more"></a><p>为了增强对state of the art深度神经网络模型的认知，准备进行一系列模型的复现工作，使用ImageNet的大规模图像分类数据集，从头训练各个经典的神经网络模型，同时结合作者论文对训练过程中的技巧进行归纳总结，主要安排如下几部分内容：</p><ul><li>ImageNet数据集及数据准备</li><li>AlexNet网络</li><li><strong>VGG网络</strong></li><li>GoogLeNet网络</li><li>ResNet网络</li><li>SqueezeNet网络</li></ul><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>VGGNet是英国牛津大学2014年ImageNet ILSVRC第二名的网络，由于其良好的泛化性能，在被迁移到其它深度学习任务中体现出来良好的效果，是目前迁移学习中用的最多的网络。但由于网络规模和参数量实在庞大，从头训练一个网络充满难度。</p><ul><li>论文：<ul><li><a href="https://arxiv.org/abs/1409.1556" target="_blank" rel="noopener">Very Deep Convolutional Networks for Large-Scale Image Recognition</a></li></ul></li><li>数据集： ImageNet 2012 ILSRVC数据集（数据集的获取及准备详见<a href="/2018/07/06/ImageNet-DataSet/">ImageNet-DataSet</a>）</li><li>计算框架： MxNet</li><li>算力资源：AWS云主机p2.8xlarge：8个Tesla K80 GPU ($7.20/hour)<ul><li>总计训练时间&gt;10天左右</li></ul></li></ul><h2 id="重头训练一个VGGNet"><a href="#重头训练一个VGGNet" class="headerlink" title="重头训练一个VGGNet"></a>重头训练一个VGGNet</h2><p><img src="/qnsource/images/2018-07-09-经典网络复现之VGG/parameter_vgg.png" alt="parameter_vgg"></p><ol><li>由于网络深度太深、参数太多，所以从头按部就班的训练VGGNet是很漫长的过程，为此VGG的作者使用了一种<code>pre-training</code>的方式。通过不断训练小一号的网络架构，将训练后的参数作为后续较大网络的初始参数来逐步逼近完整的网络。比如为了训练VGG16，作者先训练了A网络VGG11，然后利用A网络的参数逐步训练B VGG13，最后才是D网络 VGG16。这种方式使用了<code>warmed pre-trained up</code>层参数来推进后续的网络训练。</li><li>虽然上述方法是个很好的技巧，但训练N个网络才能达到目的实在是一个痛苦的过程，随着深度学习技术的发展，尤其是参数初始化技术的发展，为训练VGG提供了更加高效的策略——使用高级的初始化策略，如Xavier或MSRA，同时配合使用参数化ReLU可以抛弃1中的预训练方式。</li></ol><h3 id="训练VGGNet"><a href="#训练VGGNet" class="headerlink" title="训练VGGNet"></a>训练VGGNet</h3><p>训练用的脚本和前面几个网络一致。</p><blockquote><p><strong>几个注意点：</strong></p><ol><li><code>batchSize = config.BATCH_SIZE * config.NUM_DEVICES</code>; 使用k80 12GB先存，选择batchSzie=<strong>32</strong>；</li><li>初始学习率为1e-2，动量0.9，L2权重正则化参数0.0005；rescale参数尤为关键，根据批的大小放大梯度：rescale_grad=1.0 / batchSize；</li><li>使用了MSRA进行参数初始化，initializer=mx.initializer.MSRAPrelu()；</li><li>同时使用参数PReLU代替ReLU作为激活函数；</li></ol></blockquote><h4 id="学习率的控制"><a href="#学习率的控制" class="headerlink" title="学习率的控制"></a>学习率的控制</h4><div class="table-container"><table><thead><tr><th>Epoch</th><th>学习率</th></tr></thead><tbody><tr><td>1-50</td><td>1e-2</td></tr><tr><td>51-70</td><td>1e-3</td></tr><tr><td>71-80</td><td>1e-4</td></tr></tbody></table></div><blockquote><ol><li>控制每轮学习率修改的观察窗口要在10-15个epoch之后再下结论，确定该阶段验证集准确率饱和了再行降低学习率；</li><li>调整学习率 <code>python train_alexnet.py --checkpoints checkpoints --prefix alexnet \ --start-epoch 50</code></li></ol></blockquote><p><img src="/qnsource/images/2018-07-09-经典网络复现之VGG/training.png" alt="training"></p><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>1.选取40轮的训练结果，在测试集数据上进行验证，结果如下：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-attr">[INFO]</span> <span class="selector-tag">rank-1</span>: 71<span class="selector-class">.42</span>% </span><br><span class="line"><span class="selector-attr">[INFO]</span> <span class="selector-tag">rank-5</span>: 90<span class="selector-class">.03</span>%</span><br></pre></td></tr></table></figure><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ol><li>为了训练VGGNet，一定要使用高级初始化参数方法，并配合参数化ReLU使用；</li><li>训练一个大型数据集的深度神经网络是个费时费力的活，为了获得最优的参数，一般需要进行10-100次参数实验，需要极大的耐心和计算资源；</li><li>训练深度神经网络的目的不是找寻全局最优解，因为一般很难找到这个解，我们只是在探寻一个比上次效果更好的模型；</li><li>先使用ReLU作为激活函数获得baseline，再选择提花为ELU来获得提升；</li><li>训练深层网络时，考虑使用MSRA/HE的初始化参数，并配合PReLU一起使用，效果更好；</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/qnsource/images/2018-07-09-经典网络复现之VGG/VGGNet.jpg&quot; alt=&quot;VGGNet&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 本文记录利用ImageNet数据集复现经典网络VGGNet的过程，并记录在大型数据集训练过程中需要考虑的问题。&lt;/p&gt;
    
    </summary>
    
      <category term="动手实践营" scheme="http://blog.a-stack.com/categories/%E5%8A%A8%E6%89%8B%E5%AE%9E%E8%B7%B5%E8%90%A5/"/>
    
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="网络复现" scheme="http://blog.a-stack.com/tags/%E7%BD%91%E7%BB%9C%E5%A4%8D%E7%8E%B0/"/>
    
  </entry>
  
  <entry>
    <title>经典网络复现之ResNet</title>
    <link href="http://blog.a-stack.com/2018/07/12/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E5%A4%8D%E7%8E%B0%E4%B9%8BResNet/"/>
    <id>http://blog.a-stack.com/2018/07/12/经典网络复现之ResNet/</id>
    <published>2018-07-12T05:58:12.000Z</published>
    <updated>2018-07-20T15:52:21.624Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://p4ygzcmtw.bkt.clouddn.com/images/2018-05-21-ResNet/residual-Module-2.PNG" alt="Residual Module"></p><p><strong>摘要：</strong> 本文记录利用ImageNet数据集复现经典网络ResNet的过程，并记录在大型数据集训练过程中需要考虑的问题。</p><a id="more"></a><p>为了增强对state of the art深度神经网络模型的认知，准备进行一系列模型的复现工作，使用ImageNet的大规模图像分类数据集，从头训练各个经典的神经网络模型，同时结合作者论文对训练过程中的技巧进行归纳总结，主要安排如下几部分内容：</p><ul><li>ImageNet数据集及数据准备</li><li>AlexNet网络</li><li>VGG网络</li><li>GoogLeNet网络</li><li><strong>ResNet网络</strong></li><li>SqueezeNet网络</li></ul><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>ResNet在整个深度神经网络发展过程中国起到了里程碑式的意义，残差模块的提出为训练数千层的神经网络提供了方法，后续许多网络也纷纷在其网络架构中增加残差模块，力图提升训练效率。</p><ul><li>论文：<ul><li><a href="http://arxiv.org/abs/1512.03385" target="_blank" rel="noopener">Deep Residual Learning for Image Recognition</a></li><li><a href="https://arxiv.org/abs/1603.05027" target="_blank" rel="noopener">Identity Mappings in Deep Residual Networks</a></li></ul></li><li>数据集： ImageNet 2012 ILSRVC数据集（数据集的获取及准备详见<a href="/2018/07/06/ImageNet-DataSet/">ImageNet-DataSet</a>）</li><li>计算框架： MxNet</li><li>算力资源：AWS云主机p2.8xlarge：8个Tesla K80 GPU ($7.20/hour)<ul><li>总计训练时间3天左右</li><li>每轮迭代时间：~3500秒(~1小时)</li></ul></li></ul><h2 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h2><p>由于之前准备写过一篇博客来分析ResNet，再次不再展开说明了，详细内容参见：<a href="/2018/05/21/ResNet/">经典网络归纳： ResNet</a></p><h2 id="重头训练一个ResNet"><a href="#重头训练一个ResNet" class="headerlink" title="重头训练一个ResNet"></a>重头训练一个ResNet</h2><p>我们训练的标的是ResNet50，即50层的残差网络，50代表了整个网络中所有含参数层的数目：</p><p>1 + （3x3） + (4x3) + (6x3) + (3x3) + 1 = 50</p><p>第一个卷积层使用7x7的卷积核，用于快速降低网络尺寸，配合紧接着的池化层，将输入224x224的尺寸降低到56x56。</p><p><img src="/qnsource/images/2018-07-10-经典网络复现之ResNet/ResNet—Architecture.png" alt="ResNet—Architecture"></p><ol><li>使用MxNet构建ResNet代码</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MxResNet</span>:</span></span><br><span class="line"><span class="comment"># uses "bottleneck" module with pre-activation (He et al. 2016)</span></span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">residual_module</span><span class="params">(data, K, stride, red=False, bnEps=<span class="number">2e-5</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">bnMom=<span class="number">0.9</span>)</span>:</span></span><br><span class="line"><span class="comment"># the shortcut branch of the ResNet module should be</span></span><br><span class="line"><span class="comment"># initialized as the input (identity) data</span></span><br><span class="line">shortcut = data</span><br><span class="line"></span><br><span class="line"><span class="comment"># the first block of the ResNet module are 1x1 CONVs</span></span><br><span class="line">bn1 = mx.sym.BatchNorm(data=data, fix_gamma=<span class="keyword">False</span>,</span><br><span class="line">eps=bnEps, momentum=bnMom)</span><br><span class="line">act1 = mx.sym.Activation(data=bn1, act_type=<span class="string">"relu"</span>)</span><br><span class="line">conv1 = mx.sym.Convolution(data=act1, pad=(<span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">kernel=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), num_filter=int(K * <span class="number">0.25</span>),</span><br><span class="line">no_bias=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># the second block of the ResNet module are 3x3 CONVs</span></span><br><span class="line">bn2 = mx.sym.BatchNorm(data=conv1, fix_gamma=<span class="keyword">False</span>,</span><br><span class="line">eps=bnEps, momentum=bnMom)</span><br><span class="line">act2 = mx.sym.Activation(data=bn2, act_type=<span class="string">"relu"</span>)</span><br><span class="line">conv2 = mx.sym.Convolution(data=act2, pad=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">kernel=(<span class="number">3</span>, <span class="number">3</span>), stride=stride, num_filter=int(K * <span class="number">0.25</span>),</span><br><span class="line">no_bias=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># the third block of the ResNet module is another set of 1x1</span></span><br><span class="line"><span class="comment"># CONVs</span></span><br><span class="line">bn3 = mx.sym.BatchNorm(data=conv2, fix_gamma=<span class="keyword">False</span>,</span><br><span class="line">eps=bnEps, momentum=bnMom)</span><br><span class="line">act3 = mx.sym.Activation(data=bn3, act_type=<span class="string">"relu"</span>)</span><br><span class="line">conv3 = mx.sym.Convolution(data=act3, pad=(<span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">kernel=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), num_filter=K, no_bias=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># if we are to reduce the spatial size, apply a CONV layer</span></span><br><span class="line"><span class="comment"># to the shortcut</span></span><br><span class="line"><span class="keyword">if</span> red:</span><br><span class="line">shortcut = mx.sym.Convolution(data=act1, pad=(<span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">kernel=(<span class="number">1</span>, <span class="number">1</span>), stride=stride, num_filter=K,</span><br><span class="line">no_bias=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># add together the shortcut and the final CONV</span></span><br><span class="line">add = conv3 + shortcut</span><br><span class="line"></span><br><span class="line"><span class="comment"># return the addition as the output of the ResNet module</span></span><br><span class="line"><span class="keyword">return</span> add</span><br><span class="line"></span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build</span><span class="params">(classes, stages, filters, bnEps=<span class="number">2e-5</span>, bnMom=<span class="number">0.9</span>)</span>:</span></span><br><span class="line"><span class="comment"># data input</span></span><br><span class="line">data = mx.sym.Variable(<span class="string">"data"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #1: BN =&gt; CONV =&gt; ACT =&gt; POOL, then initialize the</span></span><br><span class="line"><span class="comment"># "body" of the network</span></span><br><span class="line">bn1_1 = mx.sym.BatchNorm(data=data, fix_gamma=<span class="keyword">True</span>,</span><br><span class="line">eps=bnEps, momentum=bnMom)</span><br><span class="line">conv1_1 = mx.sym.Convolution(data=bn1_1, pad=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">kernel=(<span class="number">7</span>, <span class="number">7</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), num_filter=filters[<span class="number">0</span>],</span><br><span class="line">no_bias=<span class="keyword">True</span>)</span><br><span class="line">bn1_2 = mx.sym.BatchNorm(data=conv1_1, fix_gamma=<span class="keyword">False</span>,</span><br><span class="line">eps=bnEps, momentum=bnMom)</span><br><span class="line">act1_2 = mx.sym.Activation(data=bn1_2, act_type=<span class="string">"relu"</span>)</span><br><span class="line">pool1 = mx.sym.Pooling(data=act1_2, pool_type=<span class="string">"max"</span>,</span><br><span class="line">pad=(<span class="number">1</span>, <span class="number">1</span>), kernel=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">body = pool1</span><br><span class="line"></span><br><span class="line"><span class="comment"># loop over the number of stages</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(stages)):</span><br><span class="line"><span class="comment"># initialize the stride, then apply a residual module</span></span><br><span class="line"><span class="comment"># used to reduce the spatial size of the input volume</span></span><br><span class="line">stride = (<span class="number">1</span>, <span class="number">1</span>) <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">else</span> (<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">body = MxResNet.residual_module(body, filters[i + <span class="number">1</span>],</span><br><span class="line">stride, red=<span class="keyword">True</span>, bnEps=bnEps, bnMom=bnMom)</span><br><span class="line"></span><br><span class="line"><span class="comment"># loop over the number of layers in the stage</span></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>, stages[i] - <span class="number">1</span>):</span><br><span class="line"><span class="comment"># apply a ResNet module</span></span><br><span class="line">body = MxResNet.residual_module(body, filters[i + <span class="number">1</span>],</span><br><span class="line">(<span class="number">1</span>, <span class="number">1</span>), bnEps=bnEps, bnMom=bnMom)</span><br><span class="line"></span><br><span class="line"><span class="comment"># apply BN =&gt; ACT =&gt; POOL</span></span><br><span class="line">bn2_1 = mx.sym.BatchNorm(data=body, fix_gamma=<span class="keyword">False</span>,</span><br><span class="line">eps=bnEps, momentum=bnMom)</span><br><span class="line">act2_1 = mx.sym.Activation(data=bn2_1, act_type=<span class="string">"relu"</span>)</span><br><span class="line">pool2 = mx.sym.Pooling(data=act2_1, pool_type=<span class="string">"avg"</span>,</span><br><span class="line">global_pool=<span class="keyword">True</span>, kernel=(<span class="number">7</span>, <span class="number">7</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># softmax classifier</span></span><br><span class="line">flatten = mx.sym.Flatten(data=pool2)</span><br><span class="line">fc1 = mx.sym.FullyConnected(data=flatten, num_hidden=classes)</span><br><span class="line">model = mx.sym.SoftmaxOutput(data=fc1, name=<span class="string">"softmax"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># return the network architecture</span></span><br><span class="line"><span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><blockquote><p><strong>几点注意点：</strong></p><ol><li>在bottleneck版本的残差模块中，前两个卷积核的数目是第三个的1/4；</li><li>本次试验中使用了预激活版本的残差块；</li><li>整个网络中没有使用dropout层；</li><li>注意，网络结构一开始，先使用一个BN应用到输入数据，起到正则化的作用；</li><li>全局池化输出被flatten之后接一个FC层丢给softmax</li></ol></blockquote><h3 id="训练ResNet"><a href="#训练ResNet" class="headerlink" title="训练ResNet"></a>训练ResNet</h3><p>训练用的脚本和前面几个网络一致。</p><blockquote><p><strong>几个注意点：</strong></p><ol><li><code>batchSize = config.BATCH_SIZE * config.NUM_DEVICES</code>; 使用k80 12GB先存，选择batchSzie=<strong>32</strong>；</li><li>优化算法使用SGD，初始学习率为1e-1，动量0.9，L2权重正则化参数0.0001；rescale参数尤为关键，根据批的大小放大梯度：rescale_grad=1.0 / batchSize；（He论文的建议参数）</li><li>使用了MSRA进行参数初始化，initializer=mx.initializer.MSRAPrelu()；</li></ol></blockquote><h4 id="学习率的控制"><a href="#学习率的控制" class="headerlink" title="学习率的控制"></a>学习率的控制</h4><blockquote><p>训练ResNet由于初始学习率高，所以最终完成训练所需的迭代数目要小很多；</p></blockquote><div class="table-container"><table><thead><tr><th>Epoch</th><th>学习率</th></tr></thead><tbody><tr><td>1-64</td><td>1e-2</td></tr><tr><td>65-80</td><td>1e-3</td></tr><tr><td>81-89</td><td>1e-4</td></tr><tr><td>90-100</td><td>1e-5</td></tr></tbody></table></div><blockquote><ol><li>控制每轮学习率修改的观察窗口要在10-15个epoch之后再下结论，确定该阶段验证集准确率饱和了再行降低学习率；</li><li>调整学习率 <code>python train_alexnet.py --checkpoints checkpoints --prefix alexnet \ --start-epoch 50</code></li><li>在8个GPU上，每轮用时1000多秒；</li></ol></blockquote><ol><li><p>第一遍训练采用1e-1的学习率训练16轮，发现饱和现象，而且训练误差和测试误差约拉越大；</p><p><img src="/qnsource/images/2018-07-10-经典网络复现之ResNet/1-16.png" alt="1-16"></p><p><img src="/qnsource/images/2018-07-10-经典网络复现之ResNet/1-16-loss.png" alt="1-16-loss"></p></li><li><p>在第10个迭代调整学习率到1e-2，验证集准确率有大幅提升，代表调整有效，之后在16轮迭代之后再次降低学习率到1e-3,25轮调整学习率到1e-4，最终top-5的准确率为0.884073，top-1准确率为0.68338：</p><p><img src="/qnsource/images/2018-07-10-经典网络复现之ResNet/1-31-accuracy.png" alt="1-31-accuracy"><img src="/qnsource/images/2018-07-10-经典网络复现之ResNet/1-31-loss.png" alt="1-31-loss"></p></li></ol><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><ol><li><p>初始学习率的选择</p><p>初始学习率如果选择1e-2，与1e-1比，很早模型就出现过拟合现象，无法到达更高的训练精度；</p><p>比如使用1e-1，在第10轮调整学习率到1e-2之后，网络准确率会出现一个10%以上的跳变；</p></li><li><p>如果不采用预激活</p></li></ol><p>   3-5%点的性能下降，原因见作者原文分析；</p><ol><li>选取30轮的训练结果，在测试集数据上进行验证，结果如下：</li></ol><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-attr">[INFO]</span> <span class="selector-tag">rank-1</span>: 71<span class="selector-class">.49</span>%</span><br><span class="line"><span class="selector-attr">[INFO]</span> <span class="selector-tag">rank-5</span>: 89<span class="selector-class">.96</span>%</span><br></pre></td></tr></table></figure><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ol><li>效果不是十分理想，主要原因应该是第一阶段1e-1学习率的训练过程过早的认为过拟合打断了训练过程，应该让这个过程再持续一段时间观察效果，无奈训练一次ResNet实在太久，放弃继续尝试了；</li><li>训练一个大型数据集的深度神经网络是个费时费力的活，为了获得最优的参数，一般需要进行10-100次参数实验，需要极大的耐心和计算资源；</li><li>训练深度神经网络的目的不是找寻全局最优解，因为一般很难找到这个解，我们只是在探寻一个比上次效果更好的模型；</li><li>先使用ReLU作为激活函数获得baseline，再选择提花为ELU来获得提升；</li><li>训练深层网络时，考虑使用MSRA/HE的初始化参数，并配合PReLU一起使用，效果更好；</li><li>对于ResNet要想再进一步提升性能，需要考虑加强正则化、更多的数据放大、合理的应用dropout等方式。</li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">ImageNet Classification with Deep Convolutional Neural Networks</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://p4ygzcmtw.bkt.clouddn.com/images/2018-05-21-ResNet/residual-Module-2.PNG&quot; alt=&quot;Residual Module&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 本文记录利用ImageNet数据集复现经典网络ResNet的过程，并记录在大型数据集训练过程中需要考虑的问题。&lt;/p&gt;
    
    </summary>
    
      <category term="动手实践营" scheme="http://blog.a-stack.com/categories/%E5%8A%A8%E6%89%8B%E5%AE%9E%E8%B7%B5%E8%90%A5/"/>
    
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="网络复现" scheme="http://blog.a-stack.com/tags/%E7%BD%91%E7%BB%9C%E5%A4%8D%E7%8E%B0/"/>
    
  </entry>
  
  <entry>
    <title>经典网络复现之GoogleNet</title>
    <link href="http://blog.a-stack.com/2018/07/12/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E5%A4%8D%E7%8E%B0%E4%B9%8BGoogleNet/"/>
    <id>http://blog.a-stack.com/2018/07/12/经典网络复现之GoogleNet/</id>
    <published>2018-07-12T05:58:12.000Z</published>
    <updated>2018-07-20T15:52:31.842Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/qnsource/images/2018-07-10-经典网络复现之GoogleNet/inception.jpg" alt="inception"></p><p><strong>摘要：</strong> 本文记录利用ImageNet数据集复现经典网络GoogLeNet的过程，并记录在大型数据集训练过程中需要考虑的问题。</p><a id="more"></a><p>为了增强对state of the art深度神经网络模型的认知，准备进行一系列模型的复现工作，使用ImageNet的大规模图像分类数据集，从头训练各个经典的神经网络模型，同时结合作者论文对训练过程中的技巧进行归纳总结，主要安排如下几部分内容：</p><ul><li>ImageNet数据集及数据准备</li><li>AlexNet网络</li><li>VGG网络</li><li><strong>GoogLeNet网络</strong></li><li>ResNet网络</li><li>SqueezeNet网络</li></ul><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>GoogleNet作为2012年ILSVRC的冠军，最近几年在原先Inception v1版本上也在不断的演化发展，目前已经到了v4版本。GoogleNet模型设计在保证准确率的同时大大降低了模型的大小，与VGG接近500MB相比，只有28MB左右的模型大小。</p><ul><li>论文：<ul><li>Christian Szegedy et al. “Going Deeper with Convolutions”. In: Computer Vision and Pattern Recognition (CVPR). 2015. URL: <a href="http://arxiv.org/abs/1409.4842" target="_blank" rel="noopener">http://arxiv.org/abs/1409.4842</a> </li></ul></li><li>数据集： ImageNet 2012 ILSRVC数据集（数据集的获取及准备详见<a href="/2018/07/06/ImageNet-DataSet/">ImageNet-DataSet</a>）</li><li>计算框架： MxNet</li><li>算力资源：AWS云主机p2.8xlarge：8个Tesla K80 GPU ($7.20/hour)<ul><li>总计训练时间2天左右</li><li>每轮迭代时间：~1200秒(~20分钟)</li></ul></li></ul><h2 id="GoogleNet"><a href="#GoogleNet" class="headerlink" title="GoogleNet"></a>GoogleNet</h2><p>GoogleNet的主要创新点体现在：</p><p>一、打破了常规的卷积层串联的模式，提出了将1x1，3x3，5x5的卷积层和3x3的pooling池化层并联组合后concatenate组装在一起的设计思路。</p><p>二、InceptionV1降低了参数量，目的有两个：1 参数越多模型越大，需要提供模型学习的数据量就越大，数据量不大的情况下容易过拟合；2 参数越多，耗费的计算资源也会更大。</p><p>三、去除了最后的全连接层，用全局平均池化层来取代它。全连接层几乎占据了AlexNet或VGGNet中90%的参数量，而且会引起过拟合，去除全连接层后模型训练更快并且减轻了过拟合。用全局平均池化层取代全连接层的做法借鉴了NetworkIn Network（以下简称NIN）论文。</p><p>四、InceptionV1中精心设计的InceptionModule提高了参数的利用效率。这一部分也借鉴了NIN的思想，形象的解释就是InceptionModule本身如同大网络中的一个小网络，其结构可以反复堆叠在一起形成大网络。InceptionV1比NIN更进一步的是增加了分支网络，NIN则主要是级联的卷积层和MLPConv层。一般来说卷积层要提升表达能力，主要依靠增加输出通道数，但副作用是计算量增大和过拟合。每一个输出通道对应一个滤波器，同一个滤波器共享参数，只能提取一类特征，因此一个输出通道只能做一种特征处理。而NIN中的MLPConv则拥有更强大的能力，允许在输出通道之间组合信息，因此效果明显。可以说，MLPConv基本等效于普通卷积层后再连接1*1的卷积和ReLU激活函数。</p><h2 id="重头训练一个GoogLeNet"><a href="#重头训练一个GoogLeNet" class="headerlink" title="重头训练一个GoogLeNet"></a>重头训练一个GoogLeNet</h2><p><img src="/qnsource/images/2018-07-10-经典网络复现之GoogleNet/parameters.png" alt="parameters"></p><ol><li>使用MxNet构建GoogleNet代码</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MxGoogLeNet</span>:</span></span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_module</span><span class="params">(data, K, kX, kY, pad=<span class="params">(<span class="number">0</span>, <span class="number">0</span>)</span>, stride=<span class="params">(<span class="number">1</span>, <span class="number">1</span>)</span>)</span>:</span></span><br><span class="line"><span class="comment"># define the CONV =&gt; BN =&gt; RELU pattern</span></span><br><span class="line">conv = mx.sym.Convolution(data=data, kernel=(kX, kY),</span><br><span class="line">num_filter=K, pad=pad, stride=stride)</span><br><span class="line"><span class="comment">#bn = mx.sym.BatchNorm(data=conv)</span></span><br><span class="line">act = mx.sym.Activation(data=conv, act_type=<span class="string">"relu"</span>)</span><br><span class="line">bn = mx.sym.BatchNorm(data=act)</span><br><span class="line"></span><br><span class="line"><span class="comment"># return the block</span></span><br><span class="line"><span class="keyword">return</span> bn</span><br><span class="line"></span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inception_module</span><span class="params">(data, num1x1, num3x3Reduce, num3x3,</span></span></span><br><span class="line"><span class="function"><span class="params">num5x5Reduce, num5x5, num1x1Proj)</span>:</span></span><br><span class="line"><span class="comment"># the first branch of the Inception module consists of 1x1</span></span><br><span class="line"><span class="comment"># convolutions</span></span><br><span class="line">conv_1x1 = MxGoogLeNet.conv_module(data, num1x1, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># the second branch of the Inception module is a set of 1x1</span></span><br><span class="line"><span class="comment"># convolutions followed by 3x3 convolutions</span></span><br><span class="line">conv_r3x3 = MxGoogLeNet.conv_module(data, num3x3Reduce, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">conv_3x3 = MxGoogLeNet.conv_module(conv_r3x3, num3x3, <span class="number">3</span>, <span class="number">3</span>,</span><br><span class="line">pad=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># the third branch of the Inception module is a set of 1x1</span></span><br><span class="line"><span class="comment"># convolutions followed by 5x5 convolutions</span></span><br><span class="line">conv_r5x5 = MxGoogLeNet.conv_module(data, num5x5Reduce, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">conv_5x5 = MxGoogLeNet.conv_module(conv_r5x5, num5x5, <span class="number">5</span>, <span class="number">5</span>,</span><br><span class="line">pad=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># the final branch of the Inception module is the POOL +</span></span><br><span class="line"><span class="comment"># projection layer set</span></span><br><span class="line">pool = mx.sym.Pooling(data=data, pool_type=<span class="string">"max"</span>, pad=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">kernel=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">conv_proj = MxGoogLeNet.conv_module(pool, num1x1Proj, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># concatenate the filters across the channel dimension</span></span><br><span class="line">concat = mx.sym.Concat(*[conv_1x1, conv_3x3, conv_5x5,</span><br><span class="line">conv_proj])</span><br><span class="line"></span><br><span class="line"><span class="comment"># return the block</span></span><br><span class="line"><span class="keyword">return</span> concat</span><br><span class="line"></span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build</span><span class="params">(classes)</span>:</span></span><br><span class="line"><span class="comment"># data input</span></span><br><span class="line">data = mx.sym.Variable(<span class="string">"data"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #1: CONV =&gt; POOL =&gt; CONV =&gt; CONV =&gt; POOL</span></span><br><span class="line">conv1_1 = MxGoogLeNet.conv_module(data, <span class="number">64</span>, <span class="number">7</span>, <span class="number">7</span>,</span><br><span class="line">pad=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">pool1 = mx.sym.Pooling(data=conv1_1, pool_type=<span class="string">"max"</span>,</span><br><span class="line">pad=(<span class="number">1</span>, <span class="number">1</span>), kernel=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">conv1_2 = MxGoogLeNet.conv_module(pool1, <span class="number">64</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">conv1_3 = MxGoogLeNet.conv_module(conv1_2, <span class="number">192</span>, <span class="number">3</span>, <span class="number">3</span>,</span><br><span class="line">pad=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">pool2 = mx.sym.Pooling(data=conv1_3, pool_type=<span class="string">"max"</span>,</span><br><span class="line">pad=(<span class="number">1</span>, <span class="number">1</span>), kernel=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #3: (INCEP * 2) =&gt; POOL</span></span><br><span class="line">in3a = MxGoogLeNet.inception_module(pool2, <span class="number">64</span>, <span class="number">96</span>, <span class="number">128</span>, <span class="number">16</span>,</span><br><span class="line"><span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">in3b = MxGoogLeNet.inception_module(in3a, <span class="number">128</span>, <span class="number">128</span>, <span class="number">192</span>, <span class="number">32</span>,</span><br><span class="line"><span class="number">96</span>, <span class="number">64</span>)</span><br><span class="line">pool3 = mx.sym.Pooling(data=in3b, pool_type=<span class="string">"max"</span>,</span><br><span class="line">pad=(<span class="number">1</span>, <span class="number">1</span>), kernel=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #4: (INCEP * 5) =&gt; POOL</span></span><br><span class="line">in4a = MxGoogLeNet.inception_module(pool3, <span class="number">192</span>, <span class="number">96</span>, <span class="number">208</span>, <span class="number">16</span>,</span><br><span class="line"><span class="number">48</span>, <span class="number">64</span>)</span><br><span class="line">in4b = MxGoogLeNet.inception_module(in4a, <span class="number">160</span>, <span class="number">112</span>, <span class="number">224</span>, <span class="number">24</span>,</span><br><span class="line"><span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">in4c = MxGoogLeNet.inception_module(in4b, <span class="number">128</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">24</span>,</span><br><span class="line"><span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">in4d = MxGoogLeNet.inception_module(in4c, <span class="number">112</span>, <span class="number">144</span>, <span class="number">288</span>, <span class="number">32</span>,</span><br><span class="line"><span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">in4e = MxGoogLeNet.inception_module(in4d, <span class="number">256</span>, <span class="number">160</span>, <span class="number">320</span>, <span class="number">32</span>,</span><br><span class="line"><span class="number">128</span>, <span class="number">128</span>,)</span><br><span class="line">pool4 = mx.sym.Pooling(data=in4e, pool_type=<span class="string">"max"</span>,</span><br><span class="line">pad=(<span class="number">1</span>, <span class="number">1</span>), kernel=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #5: (INCEP * 2) =&gt; POOL =&gt; DROPOUT</span></span><br><span class="line">in5a = MxGoogLeNet.inception_module(pool4, <span class="number">256</span>, <span class="number">160</span>, <span class="number">320</span>, <span class="number">32</span>,</span><br><span class="line"><span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">in5b = MxGoogLeNet.inception_module(in5a, <span class="number">384</span>, <span class="number">192</span>, <span class="number">384</span>, <span class="number">48</span>,</span><br><span class="line"><span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">pool5 = mx.sym.Pooling(data=in5b, pool_type=<span class="string">"avg"</span>,</span><br><span class="line">kernel=(<span class="number">7</span>, <span class="number">7</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">do = mx.sym.Dropout(data=pool5, p=<span class="number">0.4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># softmax classifier</span></span><br><span class="line">flatten = mx.sym.Flatten(data=do)</span><br><span class="line">fc1 = mx.sym.FullyConnected(data=flatten, num_hidden=classes)</span><br><span class="line">model = mx.sym.SoftmaxOutput(data=fc1, name=<span class="string">"softmax"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># return the network architecture</span></span><br><span class="line"><span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><blockquote><p><strong>几点注意点：</strong></p><ol><li>与原网络不同，我们将BN放在了activation之后，提升了模型效果；</li><li>Dropout原网络使用40%，当然现在更常见的是使用50%；</li><li>​Inception Module中几个分支网络通过concat连接在一起，这点与ResNet的本质区别；</li></ol></blockquote><h3 id="训练GoogLeNet"><a href="#训练GoogLeNet" class="headerlink" title="训练GoogLeNet"></a>训练GoogLeNet</h3><p>训练用的脚本和前面几个网络一致。</p><blockquote><p><strong>几个注意点：</strong></p><ol><li><code>batchSize = config.BATCH_SIZE * config.NUM_DEVICES</code>; 使用k80 12GB先存，选择batchSzie=<strong>128</strong>；</li><li>优化算法使用Adam，初始学习率为1e-3，L2权重正则化参数0.0002；rescale参数尤为关键，根据批的大小放大梯度：rescale_grad=1.0 / batchSize；（使用SGD训练效果一般）</li><li>使用了Xavier进行参数初始化，initializer=mx.initializer.Xavier(),；</li></ol></blockquote><h4 id="学习率的控制"><a href="#学习率的控制" class="headerlink" title="学习率的控制"></a>学习率的控制</h4><blockquote><p>训练ResNet由于初始学习率高，所以最终完成训练所需的迭代数目要小很多；</p></blockquote><div class="table-container"><table><thead><tr><th>Epoch</th><th>学习率</th></tr></thead><tbody><tr><td>1-31</td><td>1e-3</td></tr><tr><td>32-40</td><td>1e-4</td></tr><tr><td>41-47</td><td>1e-5</td></tr></tbody></table></div><blockquote><ol><li>控制每轮学习率修改的观察窗口要在10-15个epoch之后再下结论，确定该阶段验证集准确率饱和了再行降低学习率；</li><li>调整学习率 <code>python train_alexnet.py --checkpoints checkpoints --prefix alexnet \ --start-epoch 50</code></li><li>在8个GPU上，每轮用时1200多秒；</li></ol></blockquote><ol><li><p>第一遍训练采用1e-3的学习率配合Adam算法训练31轮，发现饱和现象，降低学习率到1e-4，继续训练到42轮；</p><p>​</p><p><img src="/qnsource/images/2018-07-10-经典网络复现之GoogleNet/42epoch-accuracy.png" alt="42epoch-accuracy"></p><p><img src="/qnsource/images/2018-07-10-经典网络复现之GoogleNet/42epoch-loss.png" alt="42epoch-loss"></p></li><li><p>发现40轮之后就已经出现了验证准确率的饱和现象，在40轮之后调整学习率为1e-5继续训练几轮完成：</p><p><img src="/qnsource/images/2018-07-10-经典网络复现之GoogleNet/47epoch-accuracy.png" alt="47epoch-accuracy"></p><p><img src="/qnsource/images/2018-07-10-经典网络复现之GoogleNet/47epoch-loss.png" alt="47epoch-loss"></p></li></ol><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><ol><li><p>Adam or SGD</p><p>如果使用SGD + 1e-2的经典开始配合，在GoogleNet上效果并不好，抖动剧烈，虽然这是作者推荐的参数，如下：</p><p><img src="/qnsource/images/2018-07-10-经典网络复现之GoogleNet/1e-2lr.png" alt="1e-2lr"></p><p>首先修改初始学习率为1e-3，尽管抖动降低了，但学习太慢，效果也不佳，为此进一步的调整了优化算法为Adam算法。</p></li><li><p>使用BN在激活函数之后</p><p>取得了1%以上的性能提升</p></li></ol><ol><li>选取40轮的训练结果，在测试集数据上进行验证，结果如下：</li></ol><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-attr">[INFO]</span> <span class="selector-tag">rank-1</span>: 69<span class="selector-class">.58</span>%</span><br><span class="line"><span class="selector-attr">[INFO]</span> <span class="selector-tag">rank-5</span>: 89<span class="selector-class">.01</span>%</span><br></pre></td></tr></table></figure><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ol><li>GoogleNet很难复现作者的效果，实际上还没有VGG的效果好，可能是作者论文中某些参数没有有效标注出来；</li><li>训练一个大型数据集的深度神经网络是个费时费力的活，为了获得最优的参数，一般需要进行10-100次参数实验，需要极大的耐心和计算资源；</li><li>训练深度神经网络的目的不是找寻全局最优解，因为一般很难找到这个解，我们只是在探寻一个比上次效果更好的模型；</li><li>先使用ReLU作为激活函数获得baseline，再选择提花为ELU来获得提升；</li><li>训练深层网络时，考虑使用MSRA/HE的初始化参数，并配合PReLU一起使用，效果更好；</li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">ImageNet Classification with Deep Convolutional Neural Networks</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/qnsource/images/2018-07-10-经典网络复现之GoogleNet/inception.jpg&quot; alt=&quot;inception&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 本文记录利用ImageNet数据集复现经典网络GoogLeNet的过程，并记录在大型数据集训练过程中需要考虑的问题。&lt;/p&gt;
    
    </summary>
    
      <category term="动手实践营" scheme="http://blog.a-stack.com/categories/%E5%8A%A8%E6%89%8B%E5%AE%9E%E8%B7%B5%E8%90%A5/"/>
    
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="网络复现" scheme="http://blog.a-stack.com/tags/%E7%BD%91%E7%BB%9C%E5%A4%8D%E7%8E%B0/"/>
    
  </entry>
  
  <entry>
    <title>经典网络复现之SqueezeNet</title>
    <link href="http://blog.a-stack.com/2018/07/12/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E5%A4%8D%E7%8E%B0%E4%B9%8BSqueezeNet/"/>
    <id>http://blog.a-stack.com/2018/07/12/经典网络复现之SqueezeNet/</id>
    <published>2018-07-12T05:58:12.000Z</published>
    <updated>2018-07-20T15:52:08.839Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/qnsource/images/2018-07-12-经典网络复现之SqueezeNet/Fire-Module.PNG" alt="Fire-Module"></p><p><strong>摘要：</strong> 本文记录利用ImageNet数据集复现经典网络SqueezeNet的过程，并记录在大型数据集训练过程中需要考虑的问题。</p><a id="more"></a><p>为了增强对state of the art深度神经网络模型的认知，准备进行一系列模型的复现工作，使用ImageNet的大规模图像分类数据集，从头训练各个经典的神经网络模型，同时结合作者论文对训练过程中的技巧进行归纳总结，主要安排如下几部分内容：</p><ul><li>ImageNet数据集及数据准备</li><li>AlexNet网络</li><li>VGG网络</li><li>GoogLeNet网络</li><li>ResNet网络</li><li><strong>SqueezeNet网络</strong></li></ul><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>SqueezeNet正如作者在论文题目中特别强调的那样，主要针对模型大小进行了深度优化，在保证模型精度没有太多损失的情况下，极大的缩小了所需模型的尺寸，为在嵌入式设备部署提供了强力支撑。SqueezeNet为我们裁剪模型和设计可在资源受限设备上运行的高性能模型提供了指导，特别是Fire Module的设计原理值得思考。</p><ul><li>论文：SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and &lt;0.5MB  model size，2016.<ul><li>URL: <a href="https://arxiv.org/abs/1602.07360" target="_blank" rel="noopener">https://arxiv.org/abs/1602.07360</a></li></ul></li><li>代码链接：<a href="https://github.com/DeepScale/SqueezeNet" target="_blank" rel="noopener">https://github.com/DeepScale/SqueezeNet</a></li><li>数据集： ImageNet 2012 ILSRVC数据集（数据集的获取及准备详见<a href="/2018/07/06/ImageNet-DataSet/">ImageNet-DataSet</a>）</li><li>计算框架： MxNet</li><li>算力资源：AWS云主机p2.8xlarge：8个Tesla K80 GPU ($7.20/hour)<ul><li>总计训练时间1天左右</li><li>每轮迭代时间：~1060秒</li><li>在ImageNet数据集上的效果：</li></ul></li></ul><h2 id="SqueezeNet"><a href="#SqueezeNet" class="headerlink" title="SqueezeNet"></a>SqueezeNet</h2><ul><li>microarchitecture and macro architecture<ul><li>在设计深度网络架构的过程中，如果手动选择每一层的滤波器显得过于繁复。通常先构建由几个卷积层组成的小模块，再将模块堆叠形成完整的网络。定义这种模块的网络为CNN microarchitecture。</li><li>与模块相对应，定义完整的网络架构为CNN macroarchitecture。在完整的网络架构中，深度是一个重要的参数。</li></ul></li><li>比如FPGA中只有10MB的片上内存空间，没有片下存储，对模型大小要求较高；ASICs也会有相同的需求；</li><li>​</li></ul><h3 id="设计原则"><a href="#设计原则" class="headerlink" title="设计原则"></a>设计原则</h3><p>作者在论文中给出SqueezeNet的三条设计原则：</p><ul><li>尽量用1x1卷积替代3x3卷积，目的自然是降低参数量；</li><li>降低输入到3x3卷积对象的channel数目，在SqueezeNet中是使用squeeze模块来实现的；</li><li>尽量在网络后面层次中进行降采样，这样可以是卷积层获得更大的激活地图，从而获得更高的精度；</li></ul><h3 id="Fire-Module"><a href="#Fire-Module" class="headerlink" title="Fire Module"></a>Fire Module</h3><p><img src="/qnsource/images/2018-07-12-经典网络复现之SqueezeNet/Fire-Module.PNG" alt="Fire-Module"></p><p>Fire Module是本文的核心构件，思想非常简单，就是将原来简单的一层conv层变成两层：squeeze层+expand层，各自带上Relu激活层。Fire Moduel主要包括squeeze模块和expand模块，其中squeeze模块全部由1x1卷积组成，而expand模块由1x1卷积和3x3卷积组成：</p><ul><li>squeeze模块中卷积核个数一定要小于expand模块中卷积核的个数，只有这样才能达到降参和压缩的目的；</li><li>squeeze中的1x1卷积起到了降维的效果；</li><li>为了实现expand模块中1x1卷积和3x3卷积之后的数据能够concatenate在一起，对于输入3x3的对象需要增加1的zero-padding操作；</li><li>在squeeze模块和expand模块之后通过ReLU进行激活；</li></ul><h3 id="模型架构及参数"><a href="#模型架构及参数" class="headerlink" title="模型架构及参数"></a>模型架构及参数</h3><p><img src="/qnsource/images/2018-07-12-经典网络复现之SqueezeNet/architechtureofSqueezeNet.png" alt="architechtureofSqueezeNet"></p><p><img src="/qnsource/images/2018-07-12-经典网络复现之SqueezeNet/parameters-in-SqueezeNet.PNG" alt="parameters-in-SqueezeNet"></p><p>如图所示，</p><ul><li>SqueezeNet中彻底放弃了全连接网络；</li><li>作者论文中初始学习率很大，为0.04，实际实验中，发现这么大的学习率震荡太厉害，降为0.01；</li><li>降维的操作尽量放在了模型后半段，为了满足第三条设计原则；</li><li>参数方面：使用了8个Fire Module，每个Fire Module中，squeeze的卷积核数目是expand的1/8；</li><li>fire9之后采用了dropout，其中keep_prob=0.5;</li></ul><h3 id="分析结果"><a href="#分析结果" class="headerlink" title="分析结果"></a>分析结果</h3><p><img src="/qnsource/images/2018-07-12-经典网络复现之SqueezeNet/lab_results.png" alt="lab_results"></p><p>如图所示，SqueezeNet模型本身是AlexNet的1/50，却可以获得相近的准确率，通过利用Deep Compression技术可以进一步压缩模型，实现1/510模型大小情况下的相同性能（当然实际中，由于Deep Compression采取了编码策略，需要编码本，会带来一定的额外开销）。</p><h3 id="扩展阅读-Deep-Compression"><a href="#扩展阅读-Deep-Compression" class="headerlink" title="[扩展阅读]Deep Compression"></a>[扩展阅读]Deep Compression</h3><ul><li>Deep compression: Compressing DNNs with pruning, trained quantization and huffman coding， 2015</li><li>常见的模型压缩技术<ul><li>奇异值分解(singular value decomposition (SVD))<a href="https://blog.csdn.net/csdnldp/article/details/78648543#fn:1" target="_blank" rel="noopener">1</a> </li><li>网络剪枝（Network Pruning）<a href="https://blog.csdn.net/csdnldp/article/details/78648543#fn:2" target="_blank" rel="noopener">2</a>：使用网络剪枝和稀疏矩阵 </li><li>深度压缩（Deep compression）<a href="https://blog.csdn.net/csdnldp/article/details/78648543#fn:3" target="_blank" rel="noopener">3</a>：使用网络剪枝，数字化和huffman编码 </li><li>硬件加速器（hardware accelerator）<a href="https://blog.csdn.net/csdnldp/article/details/78648543#fn:4" target="_blank" rel="noopener">4</a></li></ul></li></ul><h2 id="重头训练一个SqueezeNet"><a href="#重头训练一个SqueezeNet" class="headerlink" title="重头训练一个SqueezeNet"></a>重头训练一个SqueezeNet</h2><ol><li>使用MxNet构建AlexNet代码</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import the necessary packages</span></span><br><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MxSqueezeNet</span>:</span></span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">squeeze</span><span class="params">(input, numFilter)</span>:</span></span><br><span class="line"><span class="comment"># the first part of a FIRE module consists of a number of 1x1</span></span><br><span class="line"><span class="comment"># filter squeezes on the input data followed by an activation</span></span><br><span class="line">squeeze_1x1 = mx.sym.Convolution(data=input, kernel=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">stride=(<span class="number">1</span>, <span class="number">1</span>), num_filter=numFilter)</span><br><span class="line">act_1x1 = mx.sym.LeakyReLU(data=squeeze_1x1,</span><br><span class="line">act_type=<span class="string">"elu"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># return the activation for the squeeze</span></span><br><span class="line"><span class="keyword">return</span> act_1x1</span><br><span class="line"></span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fire</span><span class="params">(input, numSqueezeFilter, numExpandFilter)</span>:</span></span><br><span class="line"><span class="comment"># construct the 1x1 squeeze followed by the 1x1 expand</span></span><br><span class="line">squeeze_1x1 = MxSqueezeNet.squeeze(input, numSqueezeFilter)</span><br><span class="line">expand_1x1 = mx.sym.Convolution(data=squeeze_1x1,</span><br><span class="line">kernel=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), num_filter=numExpandFilter)</span><br><span class="line">relu_expand_1x1 = mx.sym.LeakyReLU(data=expand_1x1,</span><br><span class="line">act_type=<span class="string">"elu"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># construct the 3x3 expand</span></span><br><span class="line">expand_3x3 = mx.sym.Convolution(data=squeeze_1x1, pad=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">kernel=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), num_filter=numExpandFilter)</span><br><span class="line">relu_expand_3x3 = mx.sym.LeakyReLU(data=expand_3x3,</span><br><span class="line">act_type=<span class="string">"elu"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># the output of the FIRE module is the concatenation of the</span></span><br><span class="line"><span class="comment"># activation for the 1x1 and 3x3 expands along the channel</span></span><br><span class="line"><span class="comment"># dimension</span></span><br><span class="line">output = mx.sym.Concat(relu_expand_1x1, relu_expand_3x3,</span><br><span class="line">dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># return the output of the FIRE module</span></span><br><span class="line"><span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build</span><span class="params">(classes)</span>:</span></span><br><span class="line"><span class="comment"># data input</span></span><br><span class="line">data = mx.sym.Variable(<span class="string">"data"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #1: CONV =&gt; RELU =&gt; POOL</span></span><br><span class="line">conv_1 = mx.sym.Convolution(data=data, kernel=(<span class="number">7</span>, <span class="number">7</span>),</span><br><span class="line">stride=(<span class="number">2</span>, <span class="number">2</span>), num_filter=<span class="number">96</span>)</span><br><span class="line">relu_1 = mx.sym.LeakyReLU(data=conv_1, act_type=<span class="string">"elu"</span>)</span><br><span class="line">pool_1 = mx.sym.Pooling(data=relu_1, kernel=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">stride=(<span class="number">2</span>, <span class="number">2</span>), pool_type=<span class="string">"max"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #2-4: (FIRE * 3) =&gt; POOL</span></span><br><span class="line">fire_2 = MxSqueezeNet.fire(pool_1, numSqueezeFilter=<span class="number">16</span>,</span><br><span class="line">numExpandFilter=<span class="number">64</span>)</span><br><span class="line">fire_3 = MxSqueezeNet.fire(fire_2, numSqueezeFilter=<span class="number">16</span>,</span><br><span class="line">numExpandFilter=<span class="number">64</span>)</span><br><span class="line">fire_4 = MxSqueezeNet.fire(fire_3, numSqueezeFilter=<span class="number">32</span>,</span><br><span class="line"> numExpandFilter=<span class="number">128</span>)</span><br><span class="line">pool_4 = mx.sym.Pooling(data=fire_4, kernel=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">stride=(<span class="number">2</span>, <span class="number">2</span>), pool_type=<span class="string">"max"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #5-8: (FIRE * 4) =&gt; POOL</span></span><br><span class="line">fire_5 = MxSqueezeNet.fire(pool_4, numSqueezeFilter=<span class="number">32</span>,</span><br><span class="line">numExpandFilter=<span class="number">128</span>)</span><br><span class="line">fire_6 = MxSqueezeNet.fire(fire_5, numSqueezeFilter=<span class="number">48</span>,</span><br><span class="line">numExpandFilter=<span class="number">192</span>)</span><br><span class="line">fire_7 = MxSqueezeNet.fire(fire_6, numSqueezeFilter=<span class="number">48</span>,</span><br><span class="line">numExpandFilter=<span class="number">192</span>)</span><br><span class="line">fire_8 = MxSqueezeNet.fire(fire_7, numSqueezeFilter=<span class="number">64</span>,</span><br><span class="line">numExpandFilter=<span class="number">256</span>)</span><br><span class="line">pool_8 = mx.sym.Pooling(data=fire_8, kernel=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">stride=(<span class="number">2</span>, <span class="number">2</span>), pool_type=<span class="string">"max"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #9-10: FIRE =&gt; DROPOUT =&gt; CONV =&gt; RELU =&gt; POOL</span></span><br><span class="line">fire_9 = MxSqueezeNet.fire(pool_8, numSqueezeFilter=<span class="number">64</span>,</span><br><span class="line">numExpandFilter=<span class="number">256</span>)</span><br><span class="line">do_9 = mx.sym.Dropout(data=fire_9, p=<span class="number">0.5</span>)</span><br><span class="line">conv_10 = mx.sym.Convolution(data=do_9, num_filter=classes,</span><br><span class="line">kernel=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">relu_10 = mx.sym.LeakyReLU(data=conv_10, act_type=<span class="string">"elu"</span>)</span><br><span class="line">pool_10 = mx.sym.Pooling(data=relu_10, kernel=(<span class="number">13</span>, <span class="number">13</span>),</span><br><span class="line">pool_type=<span class="string">"avg"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># softmax classifier</span></span><br><span class="line">flatten = mx.sym.Flatten(data=pool_10)</span><br><span class="line">model = mx.sym.SoftmaxOutput(data=flatten, name=<span class="string">"softmax"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># return the network architecture</span></span><br><span class="line"><span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><blockquote><p><strong>几点注意点：</strong></p><ol><li>使用ELU替代了ReLU激活函数；在ImageNet数据集中，ELU表现效果由于ReLU；</li><li>3x3 expand中有个pad=（1，1）</li><li>最有使用的全局平均池化层，kernel=（13，13）</li><li>全局池化输出被flatten之后直接丢给softmax</li></ol></blockquote><h3 id="SqueezeNet的TensorFLow实现"><a href="#SqueezeNet的TensorFLow实现" class="headerlink" title="SqueezeNet的TensorFLow实现"></a>SqueezeNet的TensorFLow实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SqueezeNet</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, inputs, nb_classes=<span class="number">1000</span>, is_training=True)</span>:</span></span><br><span class="line">        <span class="comment"># conv1</span></span><br><span class="line">        net = tf.layers.conv2d(inputs, <span class="number">96</span>, [<span class="number">7</span>, <span class="number">7</span>], strides=[<span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">                                 padding=<span class="string">"SAME"</span>, activation=tf.nn.relu,</span><br><span class="line">                                 name=<span class="string">"conv1"</span>)</span><br><span class="line">        <span class="comment"># maxpool1</span></span><br><span class="line">        net = tf.layers.max_pooling2d(net, [<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">                                      name=<span class="string">"maxpool1"</span>)</span><br><span class="line">        <span class="comment"># fire2</span></span><br><span class="line">        net = self._fire(net, <span class="number">16</span>, <span class="number">64</span>, <span class="string">"fire2"</span>)</span><br><span class="line">        <span class="comment"># fire3</span></span><br><span class="line">        net = self._fire(net, <span class="number">16</span>, <span class="number">64</span>, <span class="string">"fire3"</span>)</span><br><span class="line">        <span class="comment"># fire4</span></span><br><span class="line">        net = self._fire(net, <span class="number">32</span>, <span class="number">128</span>, <span class="string">"fire4"</span>)</span><br><span class="line">        <span class="comment"># maxpool4</span></span><br><span class="line">        net = tf.layers.max_pooling2d(net, [<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">                                      name=<span class="string">"maxpool4"</span>)</span><br><span class="line">        <span class="comment"># fire5</span></span><br><span class="line">        net = self._fire(net, <span class="number">32</span>, <span class="number">128</span>, <span class="string">"fire5"</span>)</span><br><span class="line">        <span class="comment"># fire6</span></span><br><span class="line">        net = self._fire(net, <span class="number">48</span>, <span class="number">192</span>, <span class="string">"fire6"</span>)</span><br><span class="line">        <span class="comment"># fire7</span></span><br><span class="line">        net = self._fire(net, <span class="number">48</span>, <span class="number">192</span>, <span class="string">"fire7"</span>)</span><br><span class="line">        <span class="comment"># fire8</span></span><br><span class="line">        net = self._fire(net, <span class="number">64</span>, <span class="number">256</span>, <span class="string">"fire8"</span>)</span><br><span class="line">        <span class="comment"># maxpool8</span></span><br><span class="line">        net = tf.layers.max_pooling2d(net, [<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">                                      name=<span class="string">"maxpool8"</span>)</span><br><span class="line">        <span class="comment"># fire9</span></span><br><span class="line">        net = self._fire(net, <span class="number">64</span>, <span class="number">256</span>, <span class="string">"fire9"</span>)</span><br><span class="line">        <span class="comment"># dropout</span></span><br><span class="line">        net = tf.layers.dropout(net, <span class="number">0.5</span>, training=is_training)</span><br><span class="line">        <span class="comment"># conv10</span></span><br><span class="line">        net = tf.layers.conv2d(net, <span class="number">1000</span>, [<span class="number">1</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                               padding=<span class="string">"SAME"</span>, activation=tf.nn.relu,</span><br><span class="line">                               name=<span class="string">"conv10"</span>)</span><br><span class="line">        <span class="comment"># avgpool10</span></span><br><span class="line">        net = tf.layers.average_pooling2d(net, [<span class="number">13</span>, <span class="number">13</span>], strides=[<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                                          name=<span class="string">"avgpool10"</span>)</span><br><span class="line">        <span class="comment"># squeeze the axis</span></span><br><span class="line">        net = tf.squeeze(net, axis=[<span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">        self.logits = net</span><br><span class="line">        self.prediction = tf.nn.softmax(net)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_fire</span><span class="params">(self, inputs, squeeze_depth, expand_depth, scope)</span>:</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(scope):</span><br><span class="line">            squeeze = tf.layers.conv2d(inputs, squeeze_depth, [<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                                       strides=[<span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">"SAME"</span>,</span><br><span class="line">                                       activation=tf.nn.relu, name=<span class="string">"squeeze"</span>)</span><br><span class="line">            <span class="comment"># squeeze</span></span><br><span class="line">            expand_1x1 = tf.layers.conv2d(squeeze, expand_depth, [<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                                          strides=[<span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">"SAME"</span>,</span><br><span class="line">                                          activation=tf.nn.relu, name=<span class="string">"expand_1x1"</span>)</span><br><span class="line">            expand_3x3 = tf.layers.conv2d(squeeze, expand_depth, [<span class="number">3</span>, <span class="number">3</span>],</span><br><span class="line">                                          strides=[<span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">"SAME"</span>,</span><br><span class="line">                                          activation=tf.nn.relu, name=<span class="string">"expand_3x3"</span>)</span><br><span class="line">            <span class="keyword">return</span> tf.concat([expand_1x1, expand_3x3], axis=<span class="number">3</span>)</span><br></pre></td></tr></table></figure><h3 id="训练SqueezeNet"><a href="#训练SqueezeNet" class="headerlink" title="训练SqueezeNet"></a>训练SqueezeNet</h3><p>训练用的脚本和前面几个网络一致。</p><blockquote><p><strong>几个注意点：</strong></p><ol><li><code>batchSize = config.BATCH_SIZE * config.NUM_DEVICES</code>; 使用k80 12GB先存，选择batchSzie=128；</li><li>优化算法使用SGD，初始学习率为1e-2，动量0.9，L2权重正则化参数0.0002；rescale参数尤为关键，根据批的大小放大梯度：rescale_grad=1.0 / batchSize；</li><li>model中的<code>ctx</code>参数用于指定用于训练的GPU；</li><li>使用了Xavier进行参数初始化，与原模型略有不同，Xavier是目前CNN网络常采用的参数初始化方式；initializer=mx.initializer.Xavier()；</li><li>In Keras, the ELU activation uses a default α value of 1.0. • But in mxnet, the ELU α value defaults to 0.25.</li></ol></blockquote><h4 id="学习率的控制"><a href="#学习率的控制" class="headerlink" title="学习率的控制"></a>学习率的控制</h4><div class="table-container"><table><thead><tr><th>Epoch</th><th>学习率</th></tr></thead><tbody><tr><td>1-64</td><td>1e-2</td></tr><tr><td>65-80</td><td>1e-3</td></tr><tr><td>81-89</td><td>1e-4</td></tr><tr><td>90-100</td><td>1e-5</td></tr></tbody></table></div><blockquote><ol><li>控制每轮学习率修改的观察窗口要在10-15个epoch之后再下结论，确定该阶段验证集准确率饱和了再行降低学习率；</li><li>调整学习率 <code>python train_alexnet.py --checkpoints checkpoints --prefix alexnet \ --start-epoch 50</code></li><li>在8个GPU上，每轮用时1000多秒；</li></ol></blockquote><ol><li><p>第一遍训练采用1e-2的学习率训练75轮，发现65轮以后，验证集准确率已经不再增加；为此在65轮之后调整学习率为1e-3；</p><p><img src="/qnsource/images/2018-07-12-经典网络复现之SqueezeNet/0-86-accuracy.png" alt="0-86-accuracy"></p><p><img src="/qnsource/images/2018-07-12-经典网络复现之SqueezeNet/0-86-loss.png" alt="0-86-loss"></p></li><li><p>将学习率调整到1e-3之后，验证集准确率有大幅提升，代表调整有效，80轮之后再度饱和，降低学习率到1e-4;到89轮验证集结果如下：</p><p><img src="/qnsource/images/2018-07-12-经典网络复现之SqueezeNet/0-89-accuracy.png" alt="0-89-accuracy"></p><p><img src="/qnsource/images/2018-07-12-经典网络复现之SqueezeNet/0-89-loss.png" alt="0-89-loss"></p><p>​</p></li><li><p>进一步降低学习率到1e-5，发现整个网络没有性能提升，结束该批次参数训练过程。</p></li></ol><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><ol><li>初始学习率的选择</li></ol><p>   <img src="/qnsource/images/2018-07-12-经典网络复现之SqueezeNet/lr=0.04.PNG" alt="lr=0.04"></p><ol><li><p>BN的效果</p><p>在SqueezeNet中没有效果</p></li><li><p>ReLU vs ELU ？</p><p>用ELU替代ReLU，提升1-2%的性能；</p></li><li><p>选取90轮的训练结果，在测试集数据上进行验证，结果如下：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-attr">[INFO]</span> <span class="selector-tag">rank-1</span>: 55<span class="selector-class">.44</span>%</span><br><span class="line"><span class="selector-attr">[INFO]</span> <span class="selector-tag">rank-5</span>: 78<span class="selector-class">.10</span>%</span><br></pre></td></tr></table></figure></li></ol><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>今天终于完成了所有预定神经网络的训练过程，虽然有些网络由于本身对网络结构的认知或者是实际训练过程中没有很好的把握节奏，导致训练效果不是十分理想，但从这次的训练过程中还是学到了很多东西。整个过程大概持续了半个月左右的时间，得益于AWS上8 GPU的资源，使得很多网络的训练比原想进度要快很多，但费用也是惊人，看了下账单，发生在虚拟机上的费用大概有1万3千多，主要由于8 GPU服务器要85元人民币每个小时的费用不是所有人都可以承受的起的。所以我一直认为短期内，深度学习还是很难真正产业化的一个泡沫，很难有应用业务可以抵消这个昂贵的训练成本。我这只是复现网络，真实训练一个产品级的网络、所需要测试的参数十倍百倍于此。</p><p><img src="/qnsource/images/2018-07-12-经典网络复现之SqueezeNet/cost_AWS.png" alt="cost_AWS"></p><p>付了昂贵的学费，学习的动力也更加充足，将几种网络的训练过程进行一下简单的横向比较，同时总结一下大型网络训练过程中注意的主要内容。</p><h3 id="几种网络在训练过程的简单比较"><a href="#几种网络在训练过程的简单比较" class="headerlink" title="几种网络在训练过程的简单比较"></a>几种网络在训练过程的简单比较</h3><div class="table-container"><table><thead><tr><th>网络名称</th><th>模型大小</th><th>每轮训练时间（8GPU Tesla K80）</th><th>总迭代数+训练时间</th><th>初始化参数选择</th><th>初始学习率</th><th>激活函数</th><th>最终测试集准确率（Top-1/Top-5）</th></tr></thead><tbody><tr><td>AlexNet</td><td>239MB</td><td>~670s</td><td>~1.5天</td><td>Xavier</td><td>1e-2,动量0.9，L2 0.0005</td><td>ELU</td><td>60.20%/81.99%</td></tr><tr><td>VGG-16</td><td>529MB</td><td>~</td><td>~10天</td><td>MSRA</td><td>1e-2,动量0.9，L2 0.0005</td><td>PReLU</td><td></td></tr><tr><td>GoogLeNet</td><td>28MB</td><td>~1200s</td><td>~2天</td><td>Xavier</td><td>1e-3，Adam，L2 0.0002</td><td>ReLU</td><td>69.58%/89.01%</td></tr><tr><td>ResNet</td><td>98MB</td><td>~3500s</td><td>~3天</td><td>MSRA</td><td>1e-1,动量0.9，L2 0.0001</td><td>ReLU</td><td>71.49%/89.96%</td></tr><tr><td>SqueezeNet</td><td>5MB</td><td>~1060s</td><td>~1.5天</td><td>Xavier</td><td>1e-2，动量0.9，L2 0.0002</td><td>ELU</td><td>55.44%/78.10%</td></tr></tbody></table></div><h3 id="训练心得"><a href="#训练心得" class="headerlink" title="训练心得"></a>训练心得</h3><ol><li>训练一个大型数据集的深度神经网络是个费时费力的活，为了获得最优的参数，一般需要进行10-100次参数实验，需要极大的耐心和计算资源；</li><li><strong>原则：</strong>训练深度神经网络的目的不是找寻全局最优解，因为一般很难找到这个解，我们只是在探寻一个比上次效果更好的模型；</li><li>网络参数如何入手？<ol><li>逆机器学习流程的思考：在机器学习算法的应用逻辑里，我们总是强调要快速的开始搭建第一个模型，设定测试的基准，然后再迭代更新模型。而训练大型神经网络，由于训练过程对时间和资源消耗十分巨大，为充分利用资源，切不可盲目起步；</li><li>由于可调参数终端，所以必须要想办法缩小可调参数范围，优先选择重要参数进行调试，同时通过查阅相似数据集文献中使用的参数来进一步缩小自己调试参数的范围；</li></ol></li><li>初始学习率选择：<ol><li>学习率参数是整个参数空间中最重要的一个，如果你只想调试一个参数，那么请选择它；</li><li>初始学习率需要根据网络模型的特点来决定，一般而言1e-2可能是一个合适的学习率，但不是对所有的网络都是最佳的学习率，比如ResNet支持更大的学习率，比如1e-1,GoogLeNet而言，1e-2有点太大，验证集准确率会发生比较大的震荡；</li></ol></li><li>学习率控制：<ol><li>初始学习率选择好以后，需要在第一次迭代中让网络多运行一段时间，观察验证集上的表现决定是否变更学习率，一般当验证集误差出现阻塞或者出现明显过拟合现象时，需要停止训练，调整学习率，从打断位置或前面位置继续训练；</li><li>学习率手段衰减一般采取对数衰减的策略，比如每次衰减十倍；</li></ol></li><li>优化算法选择：<ol><li>关于优化算法的选择，一般先从尝试经典的SGD算法、配合动量设置开始训练看网络是否能够有效学习参数空间信息；</li><li>进一步的可以调整为Adam来加快梯度的更新；</li><li>在大型网络训练中还经常使用梯度的rescale操作，根据batchsize大小，放大梯度：rescale_grad=1.0 / batchSize；</li></ol></li><li>激活函数选择：先使用ReLU作为激活函数获得baseline，再选择提花为ELU来获得提升；</li><li>初始化参数选择：训练深层网络时，考虑使用Xavier,MSRA/HE的初始化参数，并配合PReLU一起使用，效果更好。</li><li>训练过程的控制：<ol><li>训练过程要利用callback机制，随时记录训练参数、checkpoints；</li><li>通过Tensorboard等工具观察训练过程的精度、误差、损失函数变化情况；</li><li>有些网络需要预训练过程，通过预训练可以加速网络学习；</li></ol></li><li>参数调优的其它技巧：<ol><li>BN</li><li>DropOut</li><li>Data Augmentation</li><li>计算框架：TensorFlow or MxNet</li><li>论文阅读与讨论</li><li>​…</li></ol></li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">ImageNet Classification with Deep Convolutional Neural Networks</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/qnsource/images/2018-07-12-经典网络复现之SqueezeNet/Fire-Module.PNG&quot; alt=&quot;Fire-Module&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 本文记录利用ImageNet数据集复现经典网络SqueezeNet的过程，并记录在大型数据集训练过程中需要考虑的问题。&lt;/p&gt;
    
    </summary>
    
      <category term="动手实践营" scheme="http://blog.a-stack.com/categories/%E5%8A%A8%E6%89%8B%E5%AE%9E%E8%B7%B5%E8%90%A5/"/>
    
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="网络复现" scheme="http://blog.a-stack.com/tags/%E7%BD%91%E7%BB%9C%E5%A4%8D%E7%8E%B0/"/>
    
  </entry>
  
  <entry>
    <title>经典网络复现之AlexNet</title>
    <link href="http://blog.a-stack.com/2018/07/08/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E5%A4%8D%E7%8E%B0%E4%B9%8BAlexNet/"/>
    <id>http://blog.a-stack.com/2018/07/08/经典网络复现之AlexNet/</id>
    <published>2018-07-08T05:58:12.000Z</published>
    <updated>2018-07-20T15:52:42.648Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://p4ygzcmtw.bkt.clouddn.com/cover/12.jpg" alt="Test Picture"></p><p><strong>摘要：</strong> 本文记录利用ImageNet数据集复现经典网络AlexNet的过程，并记录在大型数据集训练过程中需要考虑的问题。</p><a id="more"></a><p>为了增强对state of the art深度神经网络模型的认知，准备进行一系列模型的复现工作，使用ImageNet的大规模图像分类数据集，从头训练各个经典的神经网络模型，同时结合作者论文对训练过程中的技巧进行归纳总结，主要安排如下几部分内容：</p><ul><li>ImageNet数据集及数据准备</li><li>AlexNet网络</li><li>VGG网络</li><li>GoogLeNet网络</li><li>ResNet网络</li><li>SqueezeNet网络</li></ul><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>2012年的AlexNet是通用CNN的开山之作（早在1986年，Yann LeCun就利用卷积神经网络构建了LeNet并第一次将其运用到了生产环节——邮政编码识别，详见<a href="http://yann.lecun.com/exdb/lenet/a35.html" target="_blank" rel="noopener">http://yann.lecun.com/exdb/lenet/a35.html</a> ，但相关网络结构未能得到充分复制和发展），从此以后，CNN被广泛应用于各种机器视觉比赛、应用之中，得到了空前的发展。本文，主要根据AlexNet论文回顾其网络结构、设计技巧，并利用ImageNet的图像分类数据集复现在2012年ImageNet挑战赛中的结果。</p><ul><li>论文： Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. “ImageNet Classification with Deep Convolutional Neural Networks”. In: Advances in Neural Information Processing Systems 25. Edited by F. Pereira et al. Curran Associates, Inc., 2012, pages 1097–1105. URL: <a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deepconvolutional-neural-networks.pdf" target="_blank" rel="noopener">http://papers.nips.cc/paper/4824-imagenet-classification-with-deepconvolutional-neural-networks.pdf</a></li><li>数据集： ImageNet 2012 ILSRVC数据集（数据集的获取及准备详见<a href="/2018/07/06/ImageNet-DataSet/">ImageNet-DataSet</a>）</li><li>计算框架： MxNet</li><li>算力资源：AWS云主机p2.8xlarge：8个Tesla K80 GPU ($7.20/hour)</li></ul><p><img src="/qnsource/images/2018-07-08-经典网络复现之AlexNet/GPUs.png" alt="GPUs"></p><h2 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h2><p>AlexNet在2012年ImageNet ILSVRC比赛中top-5的错误率未15.3%，领先第二名10.9%个百分点，整个网络架构总共有8层参数网络层，其中5层卷积网络+3层全连接网络。本节将按照AlexNet论文描述的内容，整理AlexNet的特点，和极具借鉴性的创新成果。</p><h3 id="网络架构"><a href="#网络架构" class="headerlink" title="网络架构"></a>网络架构</h3><p><img src="/qnsource/images/2018-07-08-经典网络复现之AlexNet/AlexNet.png" alt="AlexNet"></p><p>AlexNet的网络架构如图所示，输入图像尺寸为（224，224，3），经过5个CNN层，3个FC层输出1000个分类结果，为了便于使网络训练采用GPU，所以整个网络分为上下两部分，分别在两个GPU上进行训练，其中第一层CNN和3个FC层在两个GPU上进行了参数共享。</p><p>AlexNet网络中拥有600万个参数，650 000个神经元。</p><h3 id="GPU的第一次使用"><a href="#GPU的第一次使用" class="headerlink" title="GPU的第一次使用"></a>GPU的第一次使用</h3><p>AlexNet是第一个使用GPU进行训练的深度神经网络，受当时硬件条件限制，使用了2块3GB内存的GTX 580 GPU，同时由于全部的网络参数超过了3GB的显存空间，所以将网络分成了两部分。训练时间上实际比单块GPU没有提升太多，但将错误率降低了1.2个百分点。</p><h3 id="激活函数的选择——从此ReLU函数得到重用"><a href="#激活函数的选择——从此ReLU函数得到重用" class="headerlink" title="激活函数的选择——从此ReLU函数得到重用"></a>激活函数的选择——从此ReLU函数得到重用</h3><p>AlexNet中经过实践测试发现，采用ReLU作为激活函数比tanh要快很多（在CIFAR-10上测试前者速度是后者的6倍多），这也奠定了ReLU称为后来CNN网络的首选。</p><h3 id="解决过拟合"><a href="#解决过拟合" class="headerlink" title="解决过拟合"></a>解决过拟合</h3><p>整个AlexNet都是围绕着计算效率提升和解决过拟合进行优化和尝试。AlexNet中的600万参数增强网络学习能力的同时也带来了潜在的过拟合问题，其中对解决过拟合的诸多尝试在未来的网络发展中被反复验证和使用。</p><h4 id="1-数据增强"><a href="#1-数据增强" class="headerlink" title="1. 数据增强"></a>1. 数据增强</h4><p>AlexNet中数据增强主要采用了两种方式，一种是随机扣取和水平翻转，另一种是白化。</p><ul><li>随机扣取和水平翻转：AlexNet将原始图像处理成256x256大小的统一图像，在训练阶段，随机从原始图像中扣取227x227的像素，并通过水平翻转来提升训练集的差异性，增强网络泛化性能；在测试阶段，对于输入测试图像分别从四个顶角和中心位置获得5张图像，并通过水平翻转形成10张图像，通过评价10张图像的预测结果作为最终输出结果，将网络性能提升了将近1个百分点；</li><li>白化： 利用PCA进行主成分抽取</li></ul><h4 id="2-Dropout"><a href="#2-Dropout" class="headerlink" title="2. Dropout"></a>2. Dropout</h4><p>这是Dropout的第一次正式使用，Dropout本身起到了模型组合的作用，同时起到正则化效果，可以避免过拟合，提升效果。当然代价是网络收敛时间被延长。</p><ul><li>在前两个FC层之后使用了Dropout</li></ul><h3 id="训练参数"><a href="#训练参数" class="headerlink" title="训练参数"></a>训练参数</h3><ul><li>优化算法选择SGD， 动量为0.9；</li><li>batch_size = 128</li><li>权重衰减为0.0005，这个很小的权重衰减对于模型学习起到了不可忽视的作用；</li><li>权重参数初始化为零均值，0.01标准差的高斯分布；</li><li>为了使得初始参数落在ReLU的正值区域，将偏差参数初始化为1；</li><li>初始学习率为0.01，当验证集错误率饱和时以对数形式降低学习率，一共降低3次，即1e-3,1e-4,1e-5；</li><li>训练了90个epoch，总共用时5-6天</li></ul><h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><ul><li>使用5个CNN的组合，top-5错误率为16.4%​</li></ul><h3 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h3><p>AlexNet还使用了局部响应归一化（Local Response Normalization）、重叠池化等优化策略，不过在未来的网络结构中没有得到良好的效果和应用普及。</p><h2 id="重头训练一个AlexNet"><a href="#重头训练一个AlexNet" class="headerlink" title="重头训练一个AlexNet"></a>重头训练一个AlexNet</h2><ol><li><p>ImageNet数据准备参见前序博文</p></li><li><p>由于现在GPU硬件和深度学习计算框架的发展，我们不需要将网络拆成两个部分，单独训练了，所以网络架构进行了微调，详见下图；</p><p><img src="/qnsource/images/2018-07-08-经典网络复现之AlexNet/AlexNet-Details.png" alt="AlexNet-Details"></p><ol><li>使用MxNet训练网络比Keras + TensroFlow要快；</li></ol></li></ol><h3 id="使用MxNet构建AlexNet代码"><a href="#使用MxNet构建AlexNet代码" class="headerlink" title="使用MxNet构建AlexNet代码"></a>使用MxNet构建AlexNet代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MxAlexNet</span>:</span></span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build</span><span class="params">(classes)</span>:</span></span><br><span class="line"><span class="comment"># data input</span></span><br><span class="line">data = mx.sym.Variable(<span class="string">"data"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #1: first CONV =&gt; RELU =&gt; POOL layer set</span></span><br><span class="line">conv1_1 = mx.sym.Convolution(data=data, kernel=(<span class="number">11</span>, <span class="number">11</span>),</span><br><span class="line">stride=(<span class="number">4</span>, <span class="number">4</span>), num_filter=<span class="number">96</span>)</span><br><span class="line">act1_1 = mx.sym.LeakyReLU(data=conv1_1, act_type=<span class="string">"elu"</span>)</span><br><span class="line">bn1_1 = mx.sym.BatchNorm(data=act1_1)</span><br><span class="line">pool1 = mx.sym.Pooling(data=bn1_1, pool_type=<span class="string">"max"</span>,</span><br><span class="line">kernel=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">do1 = mx.sym.Dropout(data=pool1, p=<span class="number">0.25</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #2: second CONV =&gt; RELU =&gt; POOL layer set</span></span><br><span class="line">conv2_1 = mx.sym.Convolution(data=do1, kernel=(<span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">pad=(<span class="number">2</span>, <span class="number">2</span>), num_filter=<span class="number">256</span>)</span><br><span class="line">act2_1 = mx.sym.LeakyReLU(data=conv2_1, act_type=<span class="string">"elu"</span>)</span><br><span class="line">bn2_1 = mx.sym.BatchNorm(data=act2_1)</span><br><span class="line">pool2 = mx.sym.Pooling(data=bn2_1, pool_type=<span class="string">"max"</span>,</span><br><span class="line">kernel=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">do2 = mx.sym.Dropout(data=pool2, p=<span class="number">0.25</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #3: (CONV =&gt; RELU) * 3 =&gt; POOL</span></span><br><span class="line">conv3_1 = mx.sym.Convolution(data=do2, kernel=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">pad=(<span class="number">1</span>, <span class="number">1</span>), num_filter=<span class="number">384</span>)</span><br><span class="line">act3_1 = mx.sym.LeakyReLU(data=conv3_1, act_type=<span class="string">"elu"</span>)</span><br><span class="line">bn3_1 = mx.sym.BatchNorm(data=act3_1)</span><br><span class="line">conv3_2 = mx.sym.Convolution(data=bn3_1, kernel=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">pad=(<span class="number">1</span>, <span class="number">1</span>), num_filter=<span class="number">384</span>)</span><br><span class="line">act3_2 = mx.sym.LeakyReLU(data=conv3_2, act_type=<span class="string">"elu"</span>)</span><br><span class="line">bn3_2 = mx.sym.BatchNorm(data=act3_2)</span><br><span class="line">conv3_3 = mx.sym.Convolution(data=bn3_2, kernel=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">pad=(<span class="number">1</span>, <span class="number">1</span>), num_filter=<span class="number">256</span>)</span><br><span class="line">act3_3 = mx.sym.LeakyReLU(data=conv3_3, act_type=<span class="string">"elu"</span>)</span><br><span class="line">bn3_3 = mx.sym.BatchNorm(data=act3_3)</span><br><span class="line">pool3 = mx.sym.Pooling(data=bn3_3, pool_type=<span class="string">"max"</span>,</span><br><span class="line">kernel=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">do3 = mx.sym.Dropout(data=pool3, p=<span class="number">0.25</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #4: first set of FC =&gt; RELU layers</span></span><br><span class="line">flatten = mx.sym.Flatten(data=do3)</span><br><span class="line">fc1 = mx.sym.FullyConnected(data=flatten, num_hidden=<span class="number">4096</span>)</span><br><span class="line">act4_1 = mx.sym.LeakyReLU(data=fc1, act_type=<span class="string">"elu"</span>)</span><br><span class="line">bn4_1 = mx.sym.BatchNorm(data=act4_1)</span><br><span class="line">do4 = mx.sym.Dropout(data=bn4_1, p=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Block #5: second set of FC =&gt; RELU layers</span></span><br><span class="line">fc2 = mx.sym.FullyConnected(data=do4, num_hidden=<span class="number">4096</span>)</span><br><span class="line">act5_1 = mx.sym.LeakyReLU(data=fc2, act_type=<span class="string">"elu"</span>)</span><br><span class="line">bn5_1 = mx.sym.BatchNorm(data=act5_1)</span><br><span class="line">do5 = mx.sym.Dropout(data=bn5_1, p=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># softmax classifier</span></span><br><span class="line">fc3 = mx.sym.FullyConnected(data=do5, num_hidden=classes)</span><br><span class="line">model = mx.sym.SoftmaxOutput(data=fc3, name=<span class="string">"softmax"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># return the network architecture</span></span><br><span class="line"><span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><blockquote><p><strong>几点注意点：</strong></p><ol><li>主要采用了Caffe中实现的AlexNet版本；</li><li>使用ELU替代了ReLU激活函数；</li><li>每个block都使用了dropout，而不是原文只在两个FC层使用；其中CNN层参数为0.25，FC层为0.5；</li><li>使用了BN层加速网络训练，而且BN在激活函数之后使用；</li></ol></blockquote><h3 id="训练AlexNet"><a href="#训练AlexNet" class="headerlink" title="训练AlexNet"></a>训练AlexNet</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># USAGE</span></span><br><span class="line"><span class="comment"># python train_alexnet.py --checkpoints checkpoints --prefix alexnet</span></span><br><span class="line"><span class="comment"># python train_alexnet.py --checkpoints checkpoints --prefix alexnet --start-epoch 25</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># import the necessary packages</span></span><br><span class="line"><span class="keyword">from</span> config <span class="keyword">import</span> imagenet_alexnet_config <span class="keyword">as</span> config</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.nn.mxconv <span class="keyword">import</span> MxAlexNet</span><br><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># construct the argument parse and parse the arguments</span></span><br><span class="line">ap = argparse.ArgumentParser()</span><br><span class="line">ap.add_argument(<span class="string">"-c"</span>, <span class="string">"--checkpoints"</span>, required=<span class="keyword">True</span>,</span><br><span class="line">help=<span class="string">"path to output checkpoint directory"</span>)</span><br><span class="line">ap.add_argument(<span class="string">"-p"</span>, <span class="string">"--prefix"</span>, required=<span class="keyword">True</span>,</span><br><span class="line">help=<span class="string">"name of model prefix"</span>)</span><br><span class="line">ap.add_argument(<span class="string">"-s"</span>, <span class="string">"--start-epoch"</span>, type=int, default=<span class="number">0</span>,</span><br><span class="line">help=<span class="string">"epoch to restart training at"</span>)</span><br><span class="line">args = vars(ap.parse_args())</span><br><span class="line"></span><br><span class="line"><span class="comment"># set the logging level and output file</span></span><br><span class="line">logging.basicConfig(level=logging.DEBUG,</span><br><span class="line">filename=<span class="string">"training_&#123;&#125;.log"</span>.format(args[<span class="string">"start_epoch"</span>]),</span><br><span class="line">filemode=<span class="string">"w"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># load the RGB means for the training set, then determine the batch</span></span><br><span class="line"><span class="comment"># size</span></span><br><span class="line">means = json.loads(open(config.DATASET_MEAN).read())</span><br><span class="line">batchSize = config.BATCH_SIZE * config.NUM_DEVICES</span><br><span class="line"></span><br><span class="line"><span class="comment"># construct the training image iterator</span></span><br><span class="line">trainIter = mx.io.ImageRecordIter(</span><br><span class="line">path_imgrec=config.TRAIN_MX_REC,</span><br><span class="line">data_shape=(<span class="number">3</span>, <span class="number">227</span>, <span class="number">227</span>),</span><br><span class="line">batch_size=batchSize,</span><br><span class="line">rand_crop=<span class="keyword">True</span>,</span><br><span class="line">rand_mirror=<span class="keyword">True</span>,</span><br><span class="line">rotate=<span class="number">15</span>,</span><br><span class="line">max_shear_ratio=<span class="number">0.1</span>,</span><br><span class="line">mean_r=means[<span class="string">"R"</span>],</span><br><span class="line">mean_g=means[<span class="string">"G"</span>],</span><br><span class="line">mean_b=means[<span class="string">"B"</span>],</span><br><span class="line">preprocess_threads=config.NUM_DEVICES * <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># construct the validation image iterator</span></span><br><span class="line">valIter = mx.io.ImageRecordIter(</span><br><span class="line">path_imgrec=config.VAL_MX_REC,</span><br><span class="line">data_shape=(<span class="number">3</span>, <span class="number">227</span>, <span class="number">227</span>),</span><br><span class="line">batch_size=batchSize,</span><br><span class="line">mean_r=means[<span class="string">"R"</span>],</span><br><span class="line">mean_g=means[<span class="string">"G"</span>],</span><br><span class="line">mean_b=means[<span class="string">"B"</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># initialize the optimizer</span></span><br><span class="line">opt = mx.optimizer.SGD(learning_rate=<span class="number">1e-2</span>, momentum=<span class="number">0.9</span>, wd=<span class="number">0.0005</span>,</span><br><span class="line">rescale_grad=<span class="number">1.0</span> / batchSize)</span><br><span class="line"></span><br><span class="line"><span class="comment"># construct the checkpoints path, initialize the model argument and</span></span><br><span class="line"><span class="comment"># auxiliary parameters</span></span><br><span class="line">checkpointsPath = os.path.sep.join([args[<span class="string">"checkpoints"</span>],</span><br><span class="line">args[<span class="string">"prefix"</span>]])</span><br><span class="line">argParams = <span class="keyword">None</span></span><br><span class="line">auxParams = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># if there is no specific model starting epoch supplied, then</span></span><br><span class="line"><span class="comment"># initialize the network</span></span><br><span class="line"><span class="keyword">if</span> args[<span class="string">"start_epoch"</span>] &lt;= <span class="number">0</span>:</span><br><span class="line"><span class="comment"># build the LeNet architecture</span></span><br><span class="line">print(<span class="string">"[INFO] building network..."</span>)</span><br><span class="line">model = MxAlexNet.build(config.NUM_CLASSES)</span><br><span class="line"></span><br><span class="line"><span class="comment"># otherwise, a specific checkpoint was supplied</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="comment"># load the checkpoint from disk</span></span><br><span class="line">print(<span class="string">"[INFO] loading epoch &#123;&#125;..."</span>.format(args[<span class="string">"start_epoch"</span>]))</span><br><span class="line">model = mx.model.FeedForward.load(checkpointsPath,</span><br><span class="line">args[<span class="string">"start_epoch"</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># update the model and parameters</span></span><br><span class="line">argParams = model.arg_params</span><br><span class="line">auxParams = model.aux_params</span><br><span class="line">model = model.symbol</span><br><span class="line"></span><br><span class="line"><span class="comment"># compile the model</span></span><br><span class="line">model = mx.model.FeedForward(</span><br><span class="line">ctx=[mx.gpu(<span class="number">0</span>), mx.gpu(<span class="number">1</span>), mx.gpu(<span class="number">2</span>), mx.gpu(<span class="number">3</span>), mx.gpu(<span class="number">4</span>), mx.gpu(<span class="number">5</span>), mx.gpu(<span class="number">6</span>), mx.gpu(<span class="number">7</span>)],</span><br><span class="line">symbol=model,</span><br><span class="line">initializer=mx.initializer.Xavier(),</span><br><span class="line">arg_params=argParams,</span><br><span class="line">aux_params=auxParams,</span><br><span class="line">optimizer=opt,</span><br><span class="line">num_epoch=<span class="number">90</span>,</span><br><span class="line">begin_epoch=args[<span class="string">"start_epoch"</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># initialize the callbacks and evaluation metrics</span></span><br><span class="line">batchEndCBs = [mx.callback.Speedometer(batchSize, <span class="number">500</span>)]</span><br><span class="line">epochEndCBs = [mx.callback.do_checkpoint(checkpointsPath)]</span><br><span class="line">metrics = [mx.metric.Accuracy(), mx.metric.TopKAccuracy(top_k=<span class="number">5</span>),</span><br><span class="line">mx.metric.CrossEntropy()]</span><br><span class="line"></span><br><span class="line"><span class="comment"># train the network</span></span><br><span class="line">print(<span class="string">"[INFO] training network..."</span>)</span><br><span class="line">model.fit(</span><br><span class="line">X=trainIter,</span><br><span class="line">eval_data=valIter,</span><br><span class="line">eval_metric=metrics,</span><br><span class="line">batch_end_callback=batchEndCBs,</span><br><span class="line">epoch_end_callback=epochEndCBs)</span><br></pre></td></tr></table></figure><blockquote><p><strong>几个注意点：</strong></p><ol><li><code>batchSize = config.BATCH_SIZE * config.NUM_DEVICES</code>;</li><li>优化算法使用SGD，初始学习率为1e-2，动量0.9，L2权重正则化参数0.0005；rescale参数尤为关键，根据批的大小放大梯度；</li><li>model中的<code>ctx</code>参数用于指定用于训练的GPU；</li><li>使用了Xavier进行参数初始化，与原模型略有不同，Xavier是目前CNN网络常采用的参数初始化方式；</li></ol></blockquote><h4 id="学习率的控制"><a href="#学习率的控制" class="headerlink" title="学习率的控制"></a>学习率的控制</h4><div class="table-container"><table><thead><tr><th>Epoch</th><th>学习率</th></tr></thead><tbody><tr><td>1-80</td><td>1e-2</td></tr><tr><td>81-100</td><td>1e-3</td></tr><tr><td>86-100</td><td>1e-4</td></tr></tbody></table></div><blockquote><ol><li>控制每轮学习率修改的观察窗口要在10-15个epoch之后再下结论，确定该阶段验证集准确率饱和了再行降低学习率；</li><li>调整学习率 <code>python train_alexnet.py --checkpoints checkpoints --prefix alexnet \ --start-epoch 50</code></li><li>在8个GPU上，每轮用时600多秒（当然我batch size设的比较小，这个速度可以提升一个数量级）；</li></ol></blockquote><ol><li><p>第一遍训练采用1e-2的学习率训练90轮，发现80轮以后，验证集准确率已经不再增加；为此在80轮之后调整学习率；80轮的性能参数如下：</p><ul><li><p>INFO:root:Epoch[78] Validation-accuracy=0.517843</p><p>INFO:root:Epoch[78] Validation-top_k_accuracy_5=0.759725</p><p>INFO:root:Epoch[78] Validation-cross-entropy=2.123822</p><p>INFO:root:Saved checkpoint to “checkpoints/1//alexnet01-0080.params”</p></li></ul><p><img src="/qnsource/images/2018-07-08-经典网络复现之AlexNet/1st_try_accuracy.png" alt="1st_try_accuracy"></p><p><img src="/qnsource/images/2018-07-08-经典网络复现之AlexNet/1st_try_loss.png" alt="1st_try_loss"></p></li><li><p>将学习率调整到1e-3之后，验证集准确率有大幅提升，代表调整有效，100轮之后再度饱和，降低学习率到1e-4;105轮验证集结果如下：</p><ul><li><p>INFO:root:Epoch[105] Validation-accuracy=0.564901</p><p>INFO:root:Epoch[105] Validation-top_k_accuracy_5=<strong>0.796509</strong></p><p>INFO:root:Epoch[105] Validation-cross-entropy=1.880376</p></li></ul><p><img src="/qnsource/images/2018-07-08-经典网络复现之AlexNet/105epoch-accuracy.png" alt="105epoch-accuracy"></p><p><img src="/qnsource/images/2018-07-08-经典网络复现之AlexNet/105epoch.png" alt="105epoch"></p></li><li><p>保持1e-4学习率，训练到125轮，进一步降低学习率到1e-5，发现整个网络没有性能提升，结束该批次参数训练过程。</p></li></ol><p><img src="/qnsource/images/2018-07-08-经典网络复现之AlexNet/130epoch-accuracy.png" alt="130epoch-accuracy"></p><p><img src="/qnsource/images/2018-07-08-经典网络复现之AlexNet/130epoch-loss.png" alt="130epoch-loss"></p><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><ol><li><p>BN放在激活之前还是之后？</p><p>调整BN位置，准确率从77.9%—&gt; 79.6%</p></li><li><p>ReLU vs ELU ？</p><p>用ELU替代ReLU，提升1-2%的性能；</p></li><li><p>选取125轮的训练结果，在测试集数据上进行验证，结果如下：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-attr">[INFO]</span> <span class="selector-tag">rank-1</span>: 60<span class="selector-class">.20</span>%</span><br><span class="line"><span class="selector-attr">[INFO]</span> <span class="selector-tag">rank-5</span>: 81<span class="selector-class">.99</span>%</span><br></pre></td></tr></table></figure><p>​</p></li></ol><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ol><li>训练一个大型数据集的深度神经网络是个费时费力的活，为了获得最优的参数，一般需要进行10-100次参数实验，需要极大的耐心和计算资源；</li><li>训练深度神经网络的目的不是找寻全局最优解，因为一般很难找到这个解，我们只是在探寻一个比上次效果更好的模型；</li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">ImageNet Classification with Deep Convolutional Neural Networks</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://p4ygzcmtw.bkt.clouddn.com/cover/12.jpg&quot; alt=&quot;Test Picture&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 本文记录利用ImageNet数据集复现经典网络AlexNet的过程，并记录在大型数据集训练过程中需要考虑的问题。&lt;/p&gt;
    
    </summary>
    
      <category term="动手实践营" scheme="http://blog.a-stack.com/categories/%E5%8A%A8%E6%89%8B%E5%AE%9E%E8%B7%B5%E8%90%A5/"/>
    
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="网络复现" scheme="http://blog.a-stack.com/tags/%E7%BD%91%E7%BB%9C%E5%A4%8D%E7%8E%B0/"/>
    
  </entry>
  
  <entry>
    <title>ImageNet-DataSet</title>
    <link href="http://blog.a-stack.com/2018/07/06/ImageNet-DataSet/"/>
    <id>http://blog.a-stack.com/2018/07/06/ImageNet-DataSet/</id>
    <published>2018-07-06T08:02:00.000Z</published>
    <updated>2018-07-20T15:52:52.732Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://p4ygzcmtw.bkt.clouddn.com/cover/09.jpg" alt="ImageNET"></p><p><strong>摘要：</strong></p><a id="more"></a><h2 id="ImageNet数据集"><a href="#ImageNet数据集" class="headerlink" title="ImageNet数据集"></a>ImageNet数据集</h2><p>ImageNet数据集是伴随着CNN和机器视觉乃至人工智能发展的里程碑式的数据集，虽然利用该数据集大规模机器视觉比赛2017年以后停止举办，但该数据集对整个人工智能产业革命的影响必将持续下去。</p><p><strong>ImageNet</strong> is an image database organized according to the <a href="http://wordnet.princeton.edu/" target="_blank" rel="noopener">WordNet</a> hierarchy (currently only the nouns), in which each node of the hierarchy is depicted by hundreds and thousands of images. Currently we have an average of over five hundred images per node. We hope ImageNet will become a useful resource for researchers, educators, students and all of you who share our passion for pictures. </p><ul><li>22k分类，14M 照片</li></ul><ul><li>网址： <a href="http://image-net.org/" target="_blank" rel="noopener">http://image-net.org/</a></li></ul><blockquote><p>这些数据靠人来标记，需要一个人19年时间；</p><p>使用Amazon的众包服务，调用了167个国家的49000人次在2007-2010年间完成标记</p></blockquote><ul><li>WordNet</li></ul><p><img src="/qnsource/images/2018-07-06-ImageNet-DataSet/imagenet_wordnet.png" alt="imagenet_wordnet"></p><ul><li><p>ImageNet Large Scale Visual Recognition Challenge(ILSVRC)</p><ul><li>Models are trained on ≈ 1.2 million training images with another 50,000 images for validation (50 images per synset) and 100,000 images for testing (100 images per synset).</li><li>分类难度大：比如ImageNet instead includes 120 different breeds of dogs.</li><li>ILSVRC2017主要有三项挑战：<ul><li><a href="">I: Object localization</a></li><li><a href="">II: Object detection</a></li><li><a href="">III: Object detection from video</a></li></ul></li><li>当然，正是由于ImageNet的难度和种类繁多特性，使得在ImageNet训练的模型可以很容易通过迁移学习用到其它领域的图像识别；</li></ul><p><img src="/qnsource/images/2018-07-06-ImageNet-DataSet/ILSVRC.png" alt="ILSVRC"></p></li></ul><h2 id="数据集的获取"><a href="#数据集的获取" class="headerlink" title="数据集的获取"></a>数据集的获取</h2><ul><li>训练数据大小138 GB</li><li>验证数据6.3 GB</li><li>测试数据 13GB</li></ul><p>下载ImageNet数据集需要使用学校邮箱注册一个账号，获得数据下载权限，然后可以登陆<a href="http://image-net.org/challenges/LSVRC/2017/download-images-1p39.php" target="_blank" rel="noopener">数据下载页面</a>如下图下载红色标记部分。</p><p><img src="/qnsource/images/2018-07-06-ImageNet-DataSet/ILSVRC2017.png" alt="ILSVRC2017"></p><blockquote><p>其中Development Kit包含了对数据结构和分类的描述文件，便于我们通过脚本读取图像数据；</p></blockquote><p>可以使用<code>wget</code>命令下载</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget -t 0 -c -i urls -o <span class="built_in">log</span></span><br></pre></td></tr></table></figure><p>其中<code>-c</code>代表端点续传，<code>-t 0</code>代表失败重试，<code>urls</code>文件为所有需要下载目录地址：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">www<span class="selector-class">.image-net</span><span class="selector-class">.org</span>/challenges/LSVRC/<span class="number">2012</span>/nnoupb/ILSVRC2012_img_train.tar</span><br><span class="line">www<span class="selector-class">.image-net</span><span class="selector-class">.org</span>/challenges/LSVRC/<span class="number">2012</span>/nnoupb/ILSVRC2012_img_train_t3.tar</span><br><span class="line">www<span class="selector-class">.image-net</span><span class="selector-class">.org</span>/challenges/LSVRC/<span class="number">2012</span>/nnoupb/ILSVRC2012_img_val.tar</span><br><span class="line">www<span class="selector-class">.image-net</span><span class="selector-class">.org</span>/challenges/LSVRC/<span class="number">2012</span>/nnoupb/ILSVRC2012_img_test.tar</span><br><span class="line">www<span class="selector-class">.image-net</span><span class="selector-class">.org</span>/challenges/LSVRC/<span class="number">2012</span>/nnoupb/ILSVRC2012_bbox_train_v2<span class="selector-class">.tar</span><span class="selector-class">.gz</span></span><br><span class="line">www<span class="selector-class">.image-net</span><span class="selector-class">.org</span>/challenges/LSVRC/<span class="number">2012</span>/nnoupb/ILSVRC2012_bbox_train_dogs<span class="selector-class">.tar</span><span class="selector-class">.gz</span></span><br><span class="line">www<span class="selector-class">.image-net</span><span class="selector-class">.org</span>/challenges/LSVRC/<span class="number">2012</span>/nnoupb/ILSVRC2012_bbox_val_v3.tgz</span><br><span class="line">www<span class="selector-class">.image-net</span><span class="selector-class">.org</span>/challenges/LSVRC/<span class="number">2012</span>/nnoupb/ILSVRC2012_bbox_test_dogs.zip</span><br></pre></td></tr></table></figure><p>实际使用过程中，发现国内网络原因使用这种方法只有50KB-100KB/s左右的速度，整个数据集下载需要12-15天。为了快速下载，可以使用如下磁力链接地址：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">magnet:?xt=urn:btih:A306397CCF9C2EAD27155983C254227C0FD938E2</span><br><span class="line">magnet:?xt=urn:btih:5D6D0DF7ED81EFD49CA99EA4737E0AE5E3A5F2E5</span><br></pre></td></tr></table></figure><h2 id="ImageNet数据的从属权问题"><a href="#ImageNet数据的从属权问题" class="headerlink" title="ImageNet数据的从属权问题"></a>ImageNet数据的从属权问题</h2><ul><li>ImageNet中的每张图片属于提供图片的个人</li><li>ImageNet数据集可以免费用于学术研究和非商业用途</li><li>但不能直接使用这些数据作为产品的一部分</li><li>使用ImageNet训练的模型（自己从头训练）的从属权问题是一个目前<strong>没有答案的问题</strong>，目前从头训练一个模型是可以应用到商业软件中的</li></ul><blockquote><p><strong>官方的给出的介绍性内容如下：</strong></p><p><strong>Does ImageNet own the images? Can I download the images?</strong></p><p>No, ImageNet does not own the copyright of the images. ImageNet only provides thumbnails and URLs of images, in a way similar to what image search engines do. In other words, ImageNet compiles an accurate list of web images for each synset of WordNet. </p><p>For researchers and educators who wish to use the images for non-commercial research and/or educational purposes, we can provide access through our site under certain conditions and terms. </p></blockquote><h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><ul><li>下载数据集中每个文件采用WordNetID的方式命名，比如<code>n01440764</code>；</li><li>每个分类有732~1300张图片</li><li>使用MXNET的<code>.rec</code>格式文件存储数据；</li><li>​</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">dir=./</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> `ls *.tar`</span><br><span class="line">  <span class="keyword">do</span></span><br><span class="line">    filename=`basename <span class="variable">$x</span> .tar`</span><br><span class="line">    mkdir <span class="variable">$filename</span></span><br><span class="line">    tar -xvf <span class="variable">$x</span> -C ./<span class="variable">$filename</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><h3 id="关键文件"><a href="#关键文件" class="headerlink" title="关键文件"></a>关键文件</h3><p><code>map_clsloc.txt</code>: 记录了WordNet ID到分类名称的映射关系，格式如下：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">n02119789 1 kit_fox</span><br><span class="line">n02100735 2 English_setter</span><br><span class="line">n02110185 3 Siberian_husky</span><br><span class="line">n02096294 4 Australian_terrier</span><br><span class="line">n02102040 5 English_springer</span><br><span class="line">n02066245 6 grey_whale</span><br><span class="line">n02509815 7 lesser_panda</span><br><span class="line">n02124075 8 Egyptian_cat</span><br><span class="line">n02417914 9 ibex</span><br><span class="line">n02123394 10 Persian_cat</span><br></pre></td></tr></table></figure><ul><li><p>构建一个<code>.lst</code>文件，包括： [图像ID， 标签， 图像存储的完整地址]</p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ wc -l /raid/datasets/imagenet/lists/*.lst </span><br><span class="line"><span class="symbol">50000 </span>/raid/datasets/imagenet/lists/test.lst </span><br><span class="line"><span class="symbol">1231167 </span>/raid/datasets/imagenet/lists/train.lst </span><br><span class="line"><span class="symbol">48238 </span>/raid/datasets/imagenet/lists/<span class="keyword">val</span>.lst </span><br><span class="line"><span class="symbol">1329405 </span>total</span><br></pre></td></tr></table></figure><p>​</p></li><li><p>去除黑名单数据</p></li><li><p>创建<code>.rec</code> 文件</p></li></ul><p><code>mxnet</code>提供一个工具im2rec来准备训练数据，工具地址如下：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/tools/im2rec.py</span><br></pre></td></tr></table></figure><blockquote><p><strong>关于<code>im2rec</code>的更多用法:</strong></p><p>1) 生成list文件</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; python ~/mxnet/tools/im2rec.py –list True –recursive True –train-ratio 0.9 myData /home/xxx/data/</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><p>&gt;</p><blockquote><p><strong>参数：</strong></p><p><strong>–list</strong>：当要生成list文件时，这个参数一定要设为True，表示当前用来生成的list文件；默认是生成rec文件；</p><p><strong>–recursive</strong>：递归的遍历你的所有数据集，要设为True；</p><p><strong>–train-ratio</strong>：用来将你的全部数据集拆分成两部分：训练集（train）和交叉验证集（val），具体多少作为训练集，多少作为验证集，就由这个参数来确定；</p><p><strong>–test-ratio</strong>：同上，分成训练集和测试集两部分；</p><p><strong>–exts</strong>：这个是你数据的后缀（注，这里我们一般说的图片数据），目前的MXNet只支持两种图片格式：jpg和jpeg</p><p><strong>prefix</strong>：这里指的是你要生成list文件的前缀名，我这里命名为myData；</p><p><strong>root</strong>：这里指的是你的图片数据存放的路径；</p><p>2）生成rec文件</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; python ~/mxnet/tools/im2rec.py –num-thread 4 –pass-through 1 myData /home/xxx/data/</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure><p><strong>参数：</strong></p><p>Options for creating database:<br>  —pass-through        whether to skip transformation and save image as is<br>                        (default: False)<br>  —resize RESIZE       resize the shorter edge of image to the newsize,<br>                        original images will be packed by default.<br>  —center-crop         specify whether to crop the center image to make it<br>                        rectangular. (default: False)<br>  —quality QUALITY     JPEG quality for encoding, 1-100; or PNG compression<br>                        for encoding, 1-9 (default: 95)<br>  —num-thread NUM_THREAD<br>                        number of thread to use for encoding. order of images<br>                        will be different from the input list if &gt;1. the input<br>                        list will be modified to match the resulting order.<br>                        (default: 1)<br>  —color {-1,0,1}      specify the color mode of the loaded image. 1: Loads a<br>                        color image. Any transparency of image will be<br>                        neglected. It is the default flag. 0: Loads image in<br>                        grayscale mode. -1:Loads image as such including alpha<br>                        channel. (default: 1)<br>  —encoding {.jpg,.png}<br>                        specify the encoding of the images. (default: .jpg)<br>  —pack-label          Whether to also pack multi dimensional label in the<br>                        record file (default: False)</p></blockquote><p>使用如下命令分别准备训练集、验证集和测试集数据：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python im2rec.py /home/ubuntu/data/imagenet/lists/val.lst "" --num-thread 16 --resize 256 --encoding '.jpg' --quality 100 </span><br><span class="line"></span><br><span class="line">python im2rec.py /home/ubuntu/data/imagenet/lists/train.lst "" --num-thread 16 --resize 256 --encoding '.jpg' --quality 100</span><br><span class="line"></span><br><span class="line">python im2rec.py /home/ubuntu/data/imagenet/lists/test.lst "" --num-thread 16 --resize 256 --encoding '.jpg' --quality 100</span><br></pre></td></tr></table></figure><h2 id="其它相关内容"><a href="#其它相关内容" class="headerlink" title="其它相关内容"></a>其它相关内容</h2><ol><li><a href="http://image-net.org/challenges/talks_2017/imagenet_ilsvrc2017_v1.0.pdf" target="_blank" rel="noopener">李飞飞在ILSVRC2017的报告</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://p4ygzcmtw.bkt.clouddn.com/cover/09.jpg&quot; alt=&quot;ImageNET&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="动手实践营" scheme="http://blog.a-stack.com/categories/%E5%8A%A8%E6%89%8B%E5%AE%9E%E8%B7%B5%E8%90%A5/"/>
    
      <category term="机器视觉" scheme="http://blog.a-stack.com/categories/%E5%8A%A8%E6%89%8B%E5%AE%9E%E8%B7%B5%E8%90%A5/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="数据集" scheme="http://blog.a-stack.com/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
    
  </entry>
  
  <entry>
    <title>深度学习实践方法论</title>
    <link href="http://blog.a-stack.com/2018/07/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    <id>http://blog.a-stack.com/2018/07/03/深度学习实践方法论/</id>
    <published>2018-07-03T09:34:48.000Z</published>
    <updated>2018-07-20T15:53:03.168Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://p4ygzcmtw.bkt.clouddn.com/cover/04.jpg" alt="Test Picture"></p><p><strong>摘要：</strong> 深度学习实践的方法论是一套靠经验而非算法总结的行之有效的指导，后续随着研究深入将不断更新补充相关内容。</p><a id="more"></a><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>从Cousera学习吴恩达的机器学习、深度学习系列课程便开始希望能够根据课程学习内容，逐步总结深度学习算法在项目实践中应该如何应用，是否能够总结一份最佳实践手册，并通过不断的更新维护，方便日后查阅和指导深度学习工程师的项目开发。最近在看Goodfellow的深度学习圣经——《Deep Learning》，第十一章再次讲到了这个问题，于是便以书中内容为基础，总结这篇深度学习实践的博客。</p><p>正如书中所说要成功地使用深度学习技术，仅仅知道存在哪些算法和解释他们为何有效的原理是不够的。一个优秀的机器学习实践者还需要知道如何针对具体应用挑选一个合适的算法以及如何监控，并根据实验反馈改进机器学习系统。书中建议参考如下几个实践设计流程：</p><ul><li>确定目标——使用什么样的误差度量，并为此误差度量指定目标值。这些目标 和误差度量取决于该应用旨在解决的问题。</li><li>尽快建立一个端到端的工作流程，包括估计合适的性能度量。 </li><li>搭建系统，并确定性能瓶颈。检查哪个部分的性能差于预期，以及是否是因 为过拟合、欠拟合，或者数据或软件缺陷造成的。</li><li>根据具体观察反复地进行增量式的改动，如收集新数据、调整超参数或改进算 法。</li></ul><p><img src="/qnsource/images/2018-07-03-深度学习实践方法论/deeplearning_workflow.png" alt="我们项目实践中使用的流程图"></p><h2 id="问题的定义和描述"><a href="#问题的定义和描述" class="headerlink" title="问题的定义和描述"></a>问题的定义和描述</h2><ul><li>选定误差度量标准；</li></ul><p><img src="/qnsource/images/2018-07-03-深度学习实践方法论/bayes_error.PNG" alt="bayes_error"></p><ul><li>科研中，目标通常是在某个确定基准下探讨哪个算法更好，一般会固定训练集，不允许收集更多的数据。</li><li>性能期望的设计</li><li>度量： 准确率、错误率，召回率，精确率，F1分数，mAP …<ul><li>覆盖（coverage）： 机器学习系统能够产生响应的样本所占的比率；</li></ul></li></ul><h2 id="基准模型"><a href="#基准模型" class="headerlink" title="基准模型"></a>基准模型</h2><ul><li>明确任务的度量和目标之后，需要快速的迭代第一个端到端的系统。</li><li>项目开始时，可能无需使用深度学习，构建一个简单的统计模型可以快速实现原型开发，当然如果问题本身属于“AI-完全”的，如对象识别、语音识别、机器翻译，那么可以根据数据的结构选择从一个基本的CNN/RNN/DNN模型开始。</li><li>优化算法方面，具有衰减学习率以及动量的SGD是优化算法一个合理的选择（流行的衰减方法有，衰减到固定最低学习率的线性衰减、指数衰减，或每次发生验证错误停滞时 将学习率降低 2 − 10 倍，这些衰减方法在不同问题上好坏不一）。<ul><li>也可以直接使用Adam算法</li></ul></li><li>批标准化可以视情况逐步采用；</li><li>如果项目内容和别人已经完成的模型任务很相像，复制现成的网络结构或利用迁移学习fine-tune也是这阶段应该考虑的；</li></ul><h2 id="数据收集"><a href="#数据收集" class="headerlink" title="数据收集"></a>数据收集</h2><ul><li>收集更多数据对于深度学习来说是最直接改观性能的方式，但何时收集，是否应该收集需要评估投入-产出比；</li><li>也许正则化可以弥补模型的误差期望差距，没有必要投入代价更好的数据收集工作；</li></ul><p><img src="/qnsource/images/2018-07-03-深度学习实践方法论/data_split.PNG" alt="data_split"></p><p><img src="/qnsource/images/2018-07-03-深度学习实践方法论/data_split2.PNG" alt="data_split2"></p><ul><li><p>如果收集数据，应该收集多少数据？</p><ul><li><p>如图所示，绘制曲线显示训练集规模和泛化误差之间的关系是很有帮助的。根据走势延伸曲线，可以预测还需要多少训练数据来达到一定的性能。</p><p><img src="/qnsource/images/2018-07-03-深度学习实践方法论/number_of_training_examples.PNG" alt="训练集大小对训练误差的影响"></p></li></ul></li></ul><h2 id="超参选择"><a href="#超参选择" class="headerlink" title="超参选择"></a>超参选择</h2><p>大部分深度学习算法都有许多超参数来控制不同方面的算法表现。有些超参数会影响算法运行的时间和存储成本。有些超参数会影响学习到的模型质量，以及 在新输入上推断正确结果的能力。 有两种选择超参数的基本方法：手动选择和自动选择。</p><h3 id="手动调节超参"><a href="#手动调节超参" class="headerlink" title="手动调节超参"></a>手动调节超参</h3><p>手动搜索超参数的目标通常是最小化受限于运行时间和内存预算的泛化误差。通过调整模型的有效容量以匹配任务的复杂性。有效容量受限于三个因素：</p><ul><li>模型的表示容量</li><li>学习算法成功最小化训练模型代价函数的能力</li><li>代价函数和训练过程正则化模型的程度</li></ul><p>学习率可能是最重要的超参数，如果你只有时间调整一个超参，那就调整学习率。相比其他超参数，它以一种更复杂的方式控制模型的有效容量——当学习率适合优化问题时，模型的有效容量最高，此时学习率是正确的，既不是特别大也不是特别小。学习率关于训练误差具有 U 形曲线，如图所示。当学习率过大时，梯度下降可能会不经意地增加而非减少训练误差。在理想化的二次情况下，如果学习率是最佳值的两倍大时，会发生这种情况 (LeCun et al., 1998b)。当学习率太小，训练不仅慢，还有可能永久停留在一个很高的训练误差。</p><p><img src="/qnsource/images/2018-07-03-深度学习实践方法论/learning_rate.PNG" alt="learning_rate"></p><blockquote><p>实践中能够确保学习有效的暴力方法就是不断提高模型容量和训练 集的大小，直到解决问题。</p></blockquote><h3 id="自动超参优化"><a href="#自动超参优化" class="headerlink" title="自动超参优化"></a>自动超参优化</h3><p>如果我们仔细想想使用者搜索学习算法合适超参数的方式，我们会意识到这其实是一种优化：我们在试图寻找超参数来优化目标函数，例如验证误差，有时还会有一些约束（如训练时间，内存或识别时间的预算）。</p><p><strong>网格搜索（grid search）</strong>是超参选择的常用方法，利用几个小的有限集训练参数模型，从中挑选验证集误差最小的超参。超参范围的设定一般采用对数尺度小挑选合适的值。</p><p>随机搜索： 为每个超参数定义一个边缘分布，或者对数尺度上的均匀分布。与网格搜索不懂，不需要离散化超参数的值。实践证明，随机搜索效率比网格搜索更高。</p><h2 id="调整策略"><a href="#调整策略" class="headerlink" title="调整策略"></a>调整策略</h2><p><img src="/qnsource/images/2018-07-03-深度学习实践方法论/adjust_error.PNG" alt="adjust_error"></p><p><img src="/qnsource/images/2018-07-03-深度学习实践方法论/adjust_error_2.PNG" alt="adjust_error_2"></p><p><img src="/qnsource/images/2018-07-03-深度学习实践方法论/adjust_error_3.PNG" alt="adjust_error_3"></p><h2 id="调试策略"><a href="#调试策略" class="headerlink" title="调试策略"></a>调试策略</h2><ol><li>可视化计算中模型的行为：当训练模型检测图像中的对象时，查看一些模型检测到部分重叠的图像。在训练语音生成模型时，试听一些生成的语音样本。这似乎是显而易见的，但在实际中很容易只注意量化性能度量，如准确率或对数似然。直接观察机器学习模型运行其任务，有助于确定其达到的量化性能数据是否看上去合 理。错误评估模型性能可能是最具破坏性的错误之一，因为它们会使你在系统出问题时误以为系统运行良好。 </li><li>可视化最严重的错误：大多数模型能够输出运行任务时的某种置信度量。例如，基于softmax 函数输出层的分类器给每个类分配一个概率。因此，分配给最有可能的类的概率给出了模型在其分类决定上的置信估计值。通常，相比于正确预测的概率最大似然训练会略有高估。但是由于实际上模型的较小概率不太可能对应着正确 的标签，因此它们在一定意义上还是有些用的。通过查看训练集中很难正确建模的样本，通常可以发现该数据预处理或者标记方式的问题。</li><li>根据训练和测试误差检测软件：我们往往很难确定底层软件是否是正确实现。训练和测试误差能够提供一些线索。如果训练误差较低，但是测试误差较高，那么很有可能训练过程是在正常运行，但模型由于算法原因过拟合了。另一种可能是，测试误差没有被正确地度量，可能是由于训练后保存模型再重载去度量测试集时出现 问题，或者是因为测试数据和训练数据预处理的方式不同。如果训练和测试误差都很高，那么很难确定是软件错误，还是由于算法原因模型欠拟合。这种情况需要进一步的测试。</li><li>拟合极小的数据集：当训练集上有很大的误差时，我们需要确定问题是真正的欠拟合，还是软件错误。通常，即使是小模型也可以保证很好地拟合一个足够小的数据集。例如，只有一个样本的分类数据可以通过正确设置输出层的偏置来拟合。通常，如果不能训练一个分类器来正确标注一个单独的样本，或不能训练一个自编码 器来成功地精准再现一个单独的样本，或不能训练一个生成模型来一致地生成一个单独的样本，那么很有可能是由于软件错误阻止训练集上的成功优化。此测试可以扩展到只有少量样本的小数据集上。 </li><li>比较反向传播导数和数值导数：如果读者正在使用一个需要实现梯度计算的软件框架，或者在添加一个新操作到求导库中，必须定义它的 bprop 方法，那么常见的错误原因是没能正确地实现梯度表达。验证这些求导正确性的一种方法是比较实现的自动求导和通过有限差分（finite difference）计算的导数。</li><li>监控激活函数值和梯度的直方图：可视化神经网络在大量训练迭代后（也许是一个轮）收集到的激活函数值和梯度的统计量往往是有用的。隐藏单元的预激活值可以告诉我们该单元是否饱和，或者它们饱和的频率如何。例如，对于整流器，它们多久关一次？是否有单元一直关闭？对于双曲正切单元而言，预激活绝对值的平均值可以告诉我们该单元的饱和程度。在深度网络中，传播梯度的快速增长或快速消失，可能会阻碍优化过程。最后，比较参数梯度和参数的量级也是有帮助的。正如 (Bottou, 2015) 所建议的，我们希望参数在一个小批量更新中变化的幅度是参数量值 1% 这样的级别，而不是50% 或者0.001%（这会导致参数移动得太慢）。也有可能是某些参数以良好的步长移动，而另一些停滞。如果数据是稀疏的（比如自然语言），有些参数可能很少更新，检测它们变化时应该记住这一点。</li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="http://www.deeplearningbook.org/" target="_blank" rel="noopener">《Deep Learning》Book</a></li><li>Ng, A. (2015). Advice for applying machine <a href="https://see.stanford.edu/materials/aimlcs229/ML-advice.pdf" target="_blank" rel="noopener">https://see.stanford.edu/materials/aimlcs229/ML-advice.pdf</a>. </li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://p4ygzcmtw.bkt.clouddn.com/cover/04.jpg&quot; alt=&quot;Test Picture&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 深度学习实践的方法论是一套靠经验而非算法总结的行之有效的指导，后续随着研究深入将不断更新补充相关内容。&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://blog.a-stack.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="实践" scheme="http://blog.a-stack.com/tags/%E5%AE%9E%E8%B7%B5/"/>
    
  </entry>
  
  <entry>
    <title>Thinking Stats</title>
    <link href="http://blog.a-stack.com/2018/06/20/thinking-stats/"/>
    <id>http://blog.a-stack.com/2018/06/20/thinking-stats/</id>
    <published>2018-06-20T12:09:03.000Z</published>
    <updated>2018-07-20T15:53:25.907Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://p4ygzcmtw.bkt.clouddn.com/cover/06.jpg" alt="Test Picture"></p><a id="more"></a><h2 id="Pandas技巧"><a href="#Pandas技巧" class="headerlink" title="Pandas技巧"></a>Pandas技巧</h2><h3 id="1-统计属性的独立值数目"><a href="#1-统计属性的独立值数目" class="headerlink" title="1. 统计属性的独立值数目"></a>1. 统计属性的独立值数目</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd[<span class="string">"outcome"</span>].value_counts().sort_index()</span><br></pre></td></tr></table></figure><h2 id="数据的相关性"><a href="#数据的相关性" class="headerlink" title="数据的相关性"></a>数据的相关性</h2><p>衡量两组数据或数据的两个变量（维度）线性相关性的方法主要有：</p><ul><li>皮尔逊相关系数</li><li>斯皮尔曼相关系数</li><li>最小二乘拟合</li></ul><h3 id="协方差"><a href="#协方差" class="headerlink" title="协方差"></a>协方差</h3><p><strong>标准分数(standard score):</strong> $z_i = (x_i - \mu)/\sigma$ </p><p>其中$x_i - \mu$称为离差，描述了$x_i$与均值$\mu$的差异，除以方差是为了归一化偏差，这样形成的数据集$Z$就是均值为0，方差为1，且与原数据集$X$同分布，且统一单位为1，不需要再考虑原先不同数据维度的单位不同的问题。</p><p>协方差(covariance)衡量相关变量变化趋势是否相同，定义如下：</p><script type="math/tex; mode=display">Cov(X,Y) = \frac{1}{n}\sum(x_i-\mu_x)(y_i-\mu_y)</script><p>由定义可知，协方差描述了两组数据离差相乘的加和，可以描述两个序列的变化是否一致。</p><p>但由于X,Y本身单位有可能不同，没有被归一化，导致结果很难反应实际的情况。</p><h3 id="皮尔逊相关系数"><a href="#皮尔逊相关系数" class="headerlink" title="皮尔逊相关系数"></a>皮尔逊相关系数</h3><p><strong>皮尔逊相关系数（Pearson’s correlation）:</strong> </p><script type="math/tex; mode=display">\rho = \frac{1}{n}\sum\frac{(x_i-\mu_x)}{\sigma_x} \frac{(y_i-\mu_y)}{\sigma_y}=\frac{Cov(X,Y)}{\sigma_x \sigma_y}</script><p>这样相关系数的单位为1，且取值范围为-1到1。$\rho$决定值的大小描述了两个变量的线性相关程度。当$\rho=1$时，两个变量完全正相关，当$\rho=0$时，两个变量完全负相关。</p><blockquote><p>但是$\rho=0$并不代表着两个变量毫无关系，皮尔逊系数只能衡量两个变量之间的线性关系，如果两个变量是非线性相关，无法通过该系数描述。</p></blockquote><p><img src="/qnsource/images/2018-06-20-thinking-stats/Correlation_examples.png" alt="相关性示意图"></p><p>上图描述了具有一定相关性的示例数据和对应的相关系数，第一行为一组有相关性和无线性相关性的数据，第二组为对应的严格相关数据，第三行为非线性相关数据，但相关系数为0。</p><h3 id="斯皮尔曼秩相关"><a href="#斯皮尔曼秩相关" class="headerlink" title="斯皮尔曼秩相关"></a>斯皮尔曼秩相关</h3><p>是为了解决皮尔逊相关系数对异常值敏感的问题，<strong>斯皮尔曼秩相关系数（Spearman’s Rank Correlation）</strong>可以用在存在异 常值和变量分布非常不对称的情况。</p><p>首先计算序列中数值的秩（rank），即某个数据在序列中大小排序的序号，将序列转换为秩之后再计算皮尔逊相关系数。</p><h3 id="散点图观察数据相关性"><a href="#散点图观察数据相关性" class="headerlink" title="散点图观察数据相关性"></a>散点图观察数据相关性</h3><p>既然皮尔逊系数无法完全表征数据的相关性，我们可以通过画散点图的方法来直观的观察数据的相关性。</p><ul><li>scatter</li><li>hexbin</li><li><todo> 补充相关代码</todo></li></ul><h3 id="最小二乘拟合"><a href="#最小二乘拟合" class="headerlink" title="最小二乘拟合"></a>最小二乘拟合</h3><p>相关系数可以描述两个变量的线性相关性强弱，但无法评估他们的斜率，最小二乘法可以通过数据拟合的方式计算斜率。首先定义数据的预测偏差(残差)：$\epsilon_i = (\alpha + \beta x_i) - y_i$， 通过求解最小化残差的平方和，可以获得相关参数。</p><blockquote><p>选择残差平方和最小作为最优化目标的原因：</p><ol><li>平方能将正残差和负残差都变成正数，这符合我们的目标。 </li><li>平方相当于给残差赋予了一个权重，越大的残差（绝对量）被赋予 的权重越大。但是并不是所有情况下大的残差都应该被赋予大的权 重，因为这样拟合方程就很容易受到异常值的影响。 </li><li>在残差服从均值为 0、方差为$\sigma^2$的正态分布，且在残差与 x 独立的假设下，参数的最小二乘估计结果与极大似然估计量相同。</li></ol></blockquote><p>斜率可以计算为：</p><script type="math/tex; mode=display">\hat\beta = \frac{Cov(X,Y)}{Var(X)}</script><h3 id="相关性不等于因果性"><a href="#相关性不等于因果性" class="headerlink" title="相关性不等于因果性"></a>相关性不等于因果性</h3><p>两个变量的相关关系并不代表他们之间存在因果关系，Correlation does not imply causation。如何确认两个变量的因果关系，一般采用随机对照试验和自然试验(natural experiment)。</p><ul><li>随机对照试验多用于实验研究和药物研发，通过设立实验组和对照组来控制变量；</li><li>自然试验通过尽量控制群体在各方面是相似的，然后对不同群体实施不同的处理。</li></ul><h2 id="估计"><a href="#估计" class="headerlink" title="估计"></a>估计</h2><ul><li>极大似然估计（Maximum Likelihood Estimator，MLE）：根据已有信息获得的最大可能估计；</li><li>最小误差值估计（最小二乘估计）：分布数据均匀，没有且很少有异常值的情况下；</li><li>无偏估计：$\sigma^2$的无偏估计为$S_{n-1}^2$<ul><li>估计是无偏的：估计量的<a href="https://baike.baidu.com/item/%E6%95%B0%E5%AD%A6%E6%9C%9F%E6%9C%9B" target="_blank" rel="noopener">数学期望</a>等于被估计参数的<a href="https://baike.baidu.com/item/%E7%9C%9F%E5%AE%9E%E5%80%BC" target="_blank" rel="noopener">真实值</a>，则称此此估计量为被估计参数的无偏估计，即具有无偏性，是一种用于评价估计量优良性的准则。无偏估计的意义是：在多次重复下，它们的平均数接近所估计的参数真值。</li></ul></li><li>贝叶斯估计<ul><li>贝叶斯置信区间</li></ul></li><li>经典问题： 火车头问题（德国坦克问题）</li></ul><blockquote><p>铁路公司将它所有的火车头都进行了编号，从1到N。有一天 你看见一个编号为60的火车头，那该铁路公司总共有多少火 车头呢？</p></blockquote><p>对于一个给定的估计量$\hat N$ ，观测到编号为 $i(i \le \hat N)$的火车的概率为$1/\hat N$，$i&gt;\hat N$的概率为 0。所以 N的极大似然估计量是$\hat N =i$ 。换言之,如果观测到的火车的编号是 60，而且我们要以最大的概率保证结果的 正确性，那么我们就会猜测铁路公司有 60 辆火车。</p><p>但从均方误差最小化的角度来看，上述结果不理想，我们需要选择一个$\hat N = ai$ 使得估计的均方误差最小：</p><script type="math/tex; mode=display">\min \frac{1}{N}\sum^N_{i=1} (ai-N)^2</script><p>从无偏估计角度出发，令平均误差为零，即</p><script type="math/tex; mode=display">ME = \frac{1}{N}\sum^N_{i=1} (ai-N)=0</script><p>贝叶斯估计</p><p>假如有足够的先验信息，那么所有的估计量将倾向于收敛到同一个值。</p><h2 id="时序数据分析"><a href="#时序数据分析" class="headerlink" title="时序数据分析"></a>时序数据分析</h2><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li>​</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://p4ygzcmtw.bkt.clouddn.com/cover/06.jpg&quot; alt=&quot;Test Picture&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://blog.a-stack.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
  </entry>
  
  <entry>
    <title>Feature_Visualization_in_NN</title>
    <link href="http://blog.a-stack.com/2018/05/22/Feature-Visualization-in-NN/"/>
    <id>http://blog.a-stack.com/2018/05/22/Feature-Visualization-in-NN/</id>
    <published>2018-05-22T02:23:04.000Z</published>
    <updated>2018-07-20T15:53:39.979Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/qnsource/images/2018-05-22-Feature-Visualization-in-NN/features.png" alt="features"></p><p><strong>摘要：</strong></p><a id="more"></a><p><strong>Feature visualization</strong> answers questions about what a network — or parts of a network — are looking for by generating examples.</p><p><strong>Attribution</strong> 1 studies what part of an example is responsible for the network activating a particular way.</p><p>TODO: 根据参考文献整理相关内容和思路。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://distill.pub/2017/feature-visualization/" target="_blank" rel="noopener">Feature Visualization -How neural networks build up their understanding of images</a></li><li><a href="https://distill.pub/2018/building-blocks/" target="_blank" rel="noopener">The Building Blocks of Interpretability</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/qnsource/images/2018-05-22-Feature-Visualization-in-NN/features.png&quot; alt=&quot;features&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://blog.a-stack.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="可视化" scheme="http://blog.a-stack.com/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>经典网络归纳： ResNet</title>
    <link href="http://blog.a-stack.com/2018/05/21/ResNet/"/>
    <id>http://blog.a-stack.com/2018/05/21/ResNet/</id>
    <published>2018-05-21T12:14:49.000Z</published>
    <updated>2018-05-22T01:35:37.537Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://p4ygzcmtw.bkt.clouddn.com/cover/04.jpg" alt="Test Picture"></p><p><strong>摘要：</strong> 作为深度卷积神经网络的里程碑式的作品，ResNet为卷积网络往更深层次扩展指明了方向，本文结合相关论文总结一下ResNet中创造性的想法。</p><a id="more"></a><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>随着网络深度增加，人们发现出现了Degradation问题，这不是过拟合导致的，因为在训练数据集上发现了同样的问题。ResNet解决了深层神经网络难训练的问题，在此之前要训练一个层次较深的网络需要在参数初始化上下功夫，当然还需要一定的运气。</p><p>ResNet网络获得了2015年所有的主流比赛冠军，相关内容被发表在论文《Deep Residual Learning for Image Recognition》中。除了残差网络的引入，在ResNet我们也看到逐渐摒弃了全连接层、池化层。全部网络中只在最开始使用了一个max pooling层，在最后使用了average pooling层。</p><p>2016年，在上述论文的基础上，He发表了第二篇改进的论文 <sup><a href="#fn_2" id="reffn_2">2</a></sup> </p><h2 id="残差网络"><a href="#残差网络" class="headerlink" title="残差网络"></a>残差网络</h2><p><img src="/qnsource/images/2018-05-21-ResNet/residual-Module.PNG" alt="residual-Module"></p><script type="math/tex; mode=display">y = F(x, {W_i}) + x</script><blockquote><p>“F是求和前网络映射，H是从输入到求和后的网络映射。比如把5映射到5.1，那么引入残差前是F’(5)=5.1，引入残差后是H(5)=5.1, H(5)=F(5)+5, F(5)=0.1。这里的F’和F都表示网络参数映射，<strong>引入残差后的映射对输出的变化更敏感</strong>。比如s输出从5.1变到5.2，映射F’的输出增加了1/51=2%，而对于残差结构输出从5.1到5.2，映射F是从0.1到0.2，增加了100%。明显后者输出变化对权重的调整作用更大，所以效果更好。残差的思想都是去掉相同的主体部分，从而突出微小的变化，看到残差网络我第一反应就是差分放大器”</p></blockquote><p>在ResNet中，残差使得网络学习更快，可以使用更高的学习率，比如常用的起始学习率为0.1。</p><p>Boottleneck残差网络中，一般最后一个1x1卷积的filter数目是另外两个的4倍；</p><p>残差网络可以从另一个角度理解，如下图所示，残差网络可以看成是由多种路径组合的一个网络，即，残差网络其实是很多并行子网络的组合。</p><p><img src="/qnsource/images/2018-05-21-ResNet/residual-Module-2.PNG" alt="residual-Module-2"></p><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p><img src="/qnsource/images/2018-05-21-ResNet/network-architect.png" alt="network-architect"></p><h2 id="Highway-Networks"><a href="#Highway-Networks" class="headerlink" title="Highway Networks"></a>Highway Networks</h2><h2 id="ResNet的改进及优化"><a href="#ResNet的改进及优化" class="headerlink" title="ResNet的改进及优化"></a>ResNet的改进及优化</h2><blockquote><p>He在2016年发布论文《Identity Mappings in Deep Residual Networks》，对ResNet中的一些内容进行了进一步的优化及完善，并证明了“identity Mapping” 的最优配置：$h(x_l) = x_l$。</p></blockquote><p><img src="/qnsource/images/2018-05-21-ResNet/new_restnet_block.png" alt="new_restnet_block"></p><p>论文中提出了在ResNet单元中采取“预激活”的方式，参考图（b）中方案，在权重更新之前先进行BN层和ReLU层操作。实践证明，采用这种方式更容易训练深层网络,同时具备更好的泛化性能。采用（b）的误差为6.36%小于(a)的6.61%<resnet-110></resnet-110></p><p>作者使用如下图所示的多种不同的残差单元比较性能，结果表明直连的方式效果最佳。</p><p><img src="/qnsource/images/2018-05-21-ResNet/other-resnet-shortcut.PNG" alt="other-resnet-shortcut"></p><blockquote><p>网络训练时间： 在CIFAR数据集，ResNet-1001，使用2GPU训练27小时； 在ImageNet数据集，ResNet-200使用8块GPU训练3周</p></blockquote><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>Keras中已经包含了ResNet50</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.applications.resnet50 <span class="keyword">import</span> ResNet50</span><br><span class="line">ResNet50(include_top=<span class="keyword">True</span>, weights=<span class="string">'imagenet'</span>, input_tensor=<span class="keyword">None</span>, input_shape=<span class="keyword">None</span>, pooling=<span class="keyword">None</span>, classes=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure><blockquote><p>当 <code>include_top=False</code>时，可以通过<code>input_shape</code> 调整输入图像尺寸，但图像高度不小于197；默认大小为<code>(224,24,3)</code></p><p>pooling: 可选，当 <code>include_top</code> 为 ‘False’ 时，该参数指定了特征提取时的池化方式。</p><ul><li><code>None</code> 代表不池化，直接输出最后一层卷积层的输出，该输出是一个四维张量。</li><li><code>avg</code> 代表全局平均池化（GLobalAveragePool2D），相当于在最后一层卷积层后面再加一层全局平均池化层，输出是一个二维张量。</li><li><code>max</code> 代表全局最大池化</li></ul></blockquote><p>利用ResNet50的迁移学习方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"><span class="keyword">from</span> keras.applications.resnet50 <span class="keyword">import</span> preprocess_input, decode_predictions</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras.applications.resnet50 <span class="keyword">import</span> ResNet50</span><br><span class="line"></span><br><span class="line">model = ResNet50(weights=<span class="string">'imagenet'</span>)</span><br><span class="line"><span class="comment">## 直接使用进行图像分类</span></span><br><span class="line">img_path = <span class="string">'elephant.jpg'</span></span><br><span class="line">img = image.load_img(img_path, target_size=(<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">x = image.img_to_array(img)</span><br><span class="line">x = np.expand_dims(x, axis=<span class="number">0</span>)</span><br><span class="line">x = preprocess_input(x)</span><br><span class="line"></span><br><span class="line">preds = model.predict(x)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 迁移学习1</span></span><br><span class="line">image_input = Input(shape=(<span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">model = ResNet50(input_tensor=image_input, include_top=<span class="keyword">True</span>,weights=<span class="string">'imagenet'</span>)</span><br><span class="line">last_layer = model.get_layer(<span class="string">'avg_pool'</span>).output</span><br><span class="line">x= Flatten(name=<span class="string">'flatten'</span>)(last_layer)</span><br><span class="line">out = Dense(num_classes, activation=<span class="string">'softmax'</span>, name=<span class="string">'output_layer'</span>)(x)</span><br><span class="line">custom_resnet_model = Model(inputs=image_input,outputs= out)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> custom_resnet_model.layers[:<span class="number">-1</span>]:</span><br><span class="line">layer.trainable = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line">custom_resnet_model.compile(loss=<span class="string">'categorical_crossentropy'</span>,optimizer=<span class="string">'adam'</span>,metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">## Fine Tune</span></span><br><span class="line">image_input = Input(shape=(<span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>))</span><br><span class="line">model = ResNet50(weights=<span class="string">'imagenet'</span>,include_top=<span class="keyword">False</span>)</span><br><span class="line">last_layer = model.output</span><br><span class="line"><span class="comment"># add a global spatial average pooling layer</span></span><br><span class="line">x = GlobalAveragePooling2D()(last_layer)</span><br><span class="line"><span class="comment"># add fully-connected &amp; dropout layers</span></span><br><span class="line">x = Dense(<span class="number">512</span>, activation=<span class="string">'relu'</span>,name=<span class="string">'fc-1'</span>)(x)</span><br><span class="line">x = Dropout(<span class="number">0.5</span>)(x)</span><br><span class="line">x = Dense(<span class="number">256</span>, activation=<span class="string">'relu'</span>,name=<span class="string">'fc-2'</span>)(x)</span><br><span class="line">x = Dropout(<span class="number">0.5</span>)(x)</span><br><span class="line"><span class="comment"># a softmax layer for 4 classes</span></span><br><span class="line">out = Dense(num_classes, activation=<span class="string">'softmax'</span>,name=<span class="string">'output_layer'</span>)(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># this is the model we will train</span></span><br><span class="line">custom_resnet_model2 = Model(inputs=model.input, outputs=out)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> custom_resnet_model2.layers[:<span class="number">-6</span>]:</span><br><span class="line">layer.trainable = <span class="keyword">False</span></span><br><span class="line">    </span><br><span class="line">custom_resnet_model2.compile(loss=<span class="string">'categorical_crossentropy'</span>,optimizer=<span class="string">'adam'</span>,metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="http://arxiv.org/abs/1512.03385" target="_blank" rel="noopener">Deep Residual Learning for Image Recognition</a></li><li><a href="https://arxiv.org/abs/1603.05027" target="_blank" rel="noopener">Identity Mappings in Deep Residual Networks</a></li><li><a href="https://keras.io/zh/applications/#resnet50" target="_blank" rel="noopener">Keras实现</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://p4ygzcmtw.bkt.clouddn.com/cover/04.jpg&quot; alt=&quot;Test Picture&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 作为深度卷积神经网络的里程碑式的作品，ResNet为卷积网络往更深层次扩展指明了方向，本文结合相关论文总结一下ResNet中创造性的想法。&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://blog.a-stack.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="机器视觉" scheme="http://blog.a-stack.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="机器视觉" scheme="http://blog.a-stack.com/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
      <category term="图像分类" scheme="http://blog.a-stack.com/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
  </entry>
  
  <entry>
    <title>OpenCV and Python</title>
    <link href="http://blog.a-stack.com/2018/05/19/OpenCV-and-Python/"/>
    <id>http://blog.a-stack.com/2018/05/19/OpenCV-and-Python/</id>
    <published>2018-05-19T14:16:29.000Z</published>
    <updated>2018-05-22T07:07:39.842Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://p4ygzcmtw.bkt.clouddn.com/cover/03.jpg" alt="Ice and Sunshine"></p><p><strong>摘要：</strong> 本文整理了常用的OpenCV图像处理操作的python代码，便于后续使用过程中的速查。</p><a id="more"></a><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p><strong>OpenCV：</strong> is an image and video processing library with bindings in C++, C, Python, and Java. OpenCV is used for all sorts of image and video analysis, like facial recognition and detection, license plate reading, photo editing, advanced robotic vision, optical character recognition, and a whole lot more.</p><p><strong>python-OpenCV:</strong> OpenCV的python版实现</p><blockquote><p><code>python-OpenCV</code> 只是OpenCV部分功能的实现，一个完整的OpenCV包大小超过3G</p></blockquote><h2 id="图像-视频读写"><a href="#图像-视频读写" class="headerlink" title="图像/视频读写"></a>图像/视频读写</h2><ol><li><p>图像读写</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment">#IMREAD_GRAYSCALE（0），IMREAD_COLOR（1），IMREAD_UNCHANGED（-1）</span></span><br><span class="line">img = cv2.imread(<span class="string">'test.jpg'</span>,cv2.IMREAD_GRAYSCALE)</span><br><span class="line">cv2.imshow(<span class="string">'image'</span>,img)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br><span class="line"></span><br><span class="line">plt.imshow(img, cmap = <span class="string">'gray'</span>, interpolation = <span class="string">'bicubic'</span>)</span><br><span class="line"><span class="comment"># write an image</span></span><br><span class="line">cv2.imwrite(<span class="string">'watchgray.png'</span>,img)</span><br></pre></td></tr></table></figure><p>​</p></li><li><p>视频操作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line">cap = cv2.VideoCapture(<span class="number">0</span>)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">while</span>(<span class="keyword">True</span>):</span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)</span><br><span class="line"> </span><br><span class="line">    cv2.imshow(<span class="string">'frame'</span>,gray)</span><br><span class="line">    <span class="keyword">if</span> cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span> == ord(<span class="string">'q'</span>):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">cap.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure><p>保存视频录像：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line">cap = cv2.VideoCapture(<span class="number">1</span>)</span><br><span class="line">fourcc = cv2.VideoWriter_fourcc(*<span class="string">'XVID'</span>)</span><br><span class="line">out = cv2.VideoWriter(<span class="string">'output.avi'</span>,fourcc, <span class="number">20.0</span>, (<span class="number">640</span>,<span class="number">480</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(<span class="keyword">True</span>):</span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)</span><br><span class="line">    out.write(frame)</span><br><span class="line">    cv2.imshow(<span class="string">'frame'</span>,gray)</span><br><span class="line">    <span class="keyword">if</span> cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span> == ord(<span class="string">'q'</span>):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">cap.release()</span><br><span class="line">out.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></li></ol><h2 id="画图"><a href="#画图" class="headerlink" title="画图"></a>画图</h2><ol><li><p>Line</p><p><code>cv2.line(img,(0,0),(150,150),(255,255,255),15)</code></p><p>​         对象， 起始点， 结束点， 颜色， 粗细</p></li><li><p>rectangle</p><p><code>cv2.rectangle(img,(15,25),(200,150),(0,0,255),15)</code></p><p>​             对象;起点(x,y); 终点(x,y); 颜色；粗细</p></li><li><p>circle</p><p><code>cv2.circle(img,(100,63), 55, (0,255,0), -1)</code> </p><p>​               中心点；半径； 颜色； 粗细（-1—填充）</p></li><li><p>多边形</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pts = np.array([[<span class="number">10</span>,<span class="number">5</span>],[<span class="number">20</span>,<span class="number">30</span>],[<span class="number">70</span>,<span class="number">20</span>],[<span class="number">50</span>,<span class="number">10</span>]], np.int32)</span><br><span class="line"><span class="comment"># OpenCV documentation had this code, which reshapes the array to a 1 x 2. I did not </span></span><br><span class="line"><span class="comment"># find this necessary, but you may:</span></span><br><span class="line"><span class="comment">#pts = pts.reshape((-1,1,2))</span></span><br><span class="line">cv2.polylines(img, [pts], <span class="keyword">True</span>, (<span class="number">0</span>,<span class="number">255</span>,<span class="number">255</span>), <span class="number">3</span>)</span><br></pre></td></tr></table></figure></li><li><p>添加文字</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">font = cv2.FONT_HERSHEY_SIMPLEX</span><br><span class="line">cv2.putText(img,<span class="string">'OpenCV Tuts!'</span>,(<span class="number">0</span>,<span class="number">130</span>), font, <span class="number">1</span>, (<span class="number">200</span>,<span class="number">255</span>,<span class="number">155</span>), <span class="number">2</span>, cv2.LINE_AA)</span><br><span class="line"><span class="comment">#                                起点        大小      颜色     粗细</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="图像操作"><a href="#图像操作" class="headerlink" title="图像操作"></a>图像操作</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">print(img.shape)</span><br><span class="line">print(img.size)</span><br><span class="line">print(img.dtype)</span><br><span class="line"><span class="comment"># 图像填充</span></span><br><span class="line">img[<span class="number">100</span>:<span class="number">150</span>,<span class="number">100</span>:<span class="number">150</span>] = [<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>]</span><br></pre></td></tr></table></figure><p>叠加图像（png图像效果佳，调整为same size）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 500 x 250</span></span><br><span class="line">img1 = cv2.imread(<span class="string">'3D-Matplotlib.png'</span>)</span><br><span class="line">img2 = cv2.imread(<span class="string">'mainsvmimage.png'</span>)</span><br><span class="line"></span><br><span class="line">add = img1+img2</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">'add'</span>,add)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure><p>与<code>cv2.add(img1,img2)</code>区分，<code>cv2.add()</code>是每个像素大小的求和；可以采用加权求和策略，<code>weighted = cv2.addWeighted(img1, 0.6, img2, 0.4, 0)</code></p><h2 id="图像组合-TODO"><a href="#图像组合-TODO" class="headerlink" title="图像组合(TODO)"></a>图像组合(TODO)</h2><h2 id="Threshold"><a href="#Threshold" class="headerlink" title="Threshold"></a>Threshold</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">retval, threshold = cv2.threshold(grayscaled, <span class="number">10</span>, <span class="number">255</span>, cv2.THRESH_BINARY)</span><br><span class="line"><span class="comment"># adaptive threshold</span></span><br><span class="line">th = cv2.adaptiveThreshold(grayscaled, <span class="number">255</span>, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, <span class="number">115</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><h2 id="模板匹配"><a href="#模板匹配" class="headerlink" title="模板匹配"></a>模板匹配</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">"test.jpg"</span>)</span><br><span class="line">img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">template = cv2.imread(<span class="string">"template.png"</span>,<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">w, h = template.shape</span><br><span class="line">res = cv2.matchTemplate(img_gray,template,cv2.TM_CCOEFF_NORMED)</span><br><span class="line">threshold = <span class="number">0.8</span></span><br><span class="line">loc = np.where( res &gt;= threshold)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> pt <span class="keyword">in</span> zip(*loc[::<span class="number">-1</span>]):</span><br><span class="line">    cv2.rectangle(img, pt, (pt[<span class="number">0</span>] + w, pt[<span class="number">1</span>] + h), (<span class="number">0</span>,<span class="number">255</span>,<span class="number">255</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">'Detected'</span>,img)</span><br></pre></td></tr></table></figure><h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://pythonprogramming.net/loading-images-python-opencv-tutorial/" target="_blank" rel="noopener">OpenCV with Python Intro and loading Images tutorial</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://p4ygzcmtw.bkt.clouddn.com/cover/03.jpg&quot; alt=&quot;Ice and Sunshine&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 本文整理了常用的OpenCV图像处理操作的python代码，便于后续使用过程中的速查。&lt;/p&gt;
    
    </summary>
    
      <category term="工具" scheme="http://blog.a-stack.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="机器视觉" scheme="http://blog.a-stack.com/categories/%E5%B7%A5%E5%85%B7/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="工具" scheme="http://blog.a-stack.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="OpenCV" scheme="http://blog.a-stack.com/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>cs231n课程笔记:（Lecture 6-7）Training Neural Networks</title>
    <link href="http://blog.a-stack.com/2018/05/07/cs231n-lecture-6/"/>
    <id>http://blog.a-stack.com/2018/05/07/cs231n-lecture-6/</id>
    <published>2018-05-07T08:50:26.000Z</published>
    <updated>2018-05-16T14:00:03.181Z</updated>
    
    <content type="html"><![CDATA[<p><strong>摘要：</strong> 计划花一个月的时间刷一遍斯坦福的机器视觉课程cs231n，并做笔记记录每天学习到的内容。</p><!-- excerpt --><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>cs231n是斯坦福在深度学习和机器视觉领域的入门经典课程，相关资源如下：</p><ul><li>课程主页： <a href="http://cs231n.stanford.edu/" target="_blank" rel="noopener">http://cs231n.stanford.edu/</a></li><li>课程Notes：<a href="http://cs231n.github.io/" target="_blank" rel="noopener">http://cs231n.github.io/</a></li></ul><div class="table-container"><table><thead><tr><th>Lecture 6</th><th>Thursday April 19</th><th><strong>Training Neural Networks, part I</strong> Activation functions, initialization, dropout, batch normalization</th><th><a href="http://cs231n.stanford.edu/slides/2018/cs231n_2018_lecture06.pdf" target="_blank" rel="noopener">[slides]</a> <a href="http://cs231n.github.io/neural-networks-1/" target="_blank" rel="noopener">Neural Nets notes 1</a><a href="http://cs231n.github.io/neural-networks-2/" target="_blank" rel="noopener">Neural Nets notes 2</a><a href="http://cs231n.github.io/neural-networks-3/" target="_blank" rel="noopener">Neural Nets notes 3</a>tips/tricks: <a href="http://research.microsoft.com/pubs/192769/tricks-2012.pdf" target="_blank" rel="noopener">[1]</a>, <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf" target="_blank" rel="noopener">[2]</a>, <a href="http://arxiv.org/pdf/1206.5533v2.pdf" target="_blank" rel="noopener">[3]</a> (optional) <a href="http://www.nature.com/nature/journal/v521/n7553/full/nature14539.html" target="_blank" rel="noopener">Deep Learning [Nature]</a> (optional)</th></tr></thead><tbody><tr><td>Discussion Section</td><td>Friday April 20</td><td><strong>Tips and tricks for tuning NNs</strong></td><td><a href="https://docs.google.com/presentation/d/183aCHcSq-YsaokZrqI3khuy_zPbehG-XgkyA6L5W4t4/edit?usp=sharing" target="_blank" rel="noopener">[slides]</a></td></tr><tr><td>Lecture 7</td><td>Tuesday April 24</td><td><strong>Training Neural Networks, part II</strong> Update rules, ensembles, data augmentation, transfer learning</td><td><a href="http://cs231n.stanford.edu/slides/2018/cs231n_2018_lecture07.pdf" target="_blank" rel="noopener">[slides]</a> <a href="http://cs231n.github.io/neural-networks-3/" target="_blank" rel="noopener">Neural Nets notes 3</a></td></tr></tbody></table></div><h2 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h2><ol><li><p>Batch Normalization的计算</p><script type="math/tex; mode=display">\begin{align}\mu_i = \frac{1}{m} \sum_{k \in S_i} x_k\\\sigma_i = \sqrt{\frac{1}{m}\sum_{k\in S_i} (x_k-\mu_i)^2 + \epsilon}\\y_i = \lambda \hat x_i + \beta\end{align}</script><p>由于BN会受到batch size大小的影响，如果batch size太小，算出的均值和方差就会不准确，太大存储可能不够用。所以衍生出了几种优化表达。</p></li><li><p>其它归一化方法与BN的区别</p><p><img src="/qnsource/images/2018-04-28-cs231n-notes/normalization_methods.png" alt="normalization_methods"></p></li></ol><ul><li>BatchNorm： batch方向做归一化，计算 <code>N*H*W</code> 的均值；</li><li>LayerNorm： channel方向做归一化，计算<code>C*H*W</code> 的均值；</li><li>InstanceNorm： 一个channel内做归一化，计算<code>H*W</code>的均值；</li><li>GroupNorm： 将Channel方向分为Group，然后每个Group内做归一化，计算<code>(C//G)*H*W</code>的均值</li></ul><blockquote><p>当G=C时，GroupNorm为LayerNorm，当G=1时，GroupNorm为InstanceNorm</p></blockquote><h2 id="训练过程的网络优化技巧"><a href="#训练过程的网络优化技巧" class="headerlink" title="训练过程的网络优化技巧"></a>训练过程的网络优化技巧</h2><blockquote><p>Parammeter tuning is more of an art.</p></blockquote><h3 id="网络优化-提升网络性能方法"><a href="#网络优化-提升网络性能方法" class="headerlink" title="网络优化/提升网络性能方法"></a>网络优化/提升网络性能方法</h3><ul><li>获取更多训练数据</li><li>增加网络复杂度</li><li>选择更多优化算法</li><li>训练更长时间</li><li>修改批大小</li><li>尝试正则化</li><li>权衡过拟合/欠拟合</li><li>…</li></ul><h3 id="参数调优"><a href="#参数调优" class="headerlink" title="参数调优"></a>参数调优</h3><p><strong>输入（超参）：</strong></p><ul><li>系统架构</li><li>学习率、优化算法</li><li>正则化（Dropout）</li><li>批处理/批量归一化（BN）</li></ul><p><strong>输出（分析图表）：</strong></p><ul><li>损失曲线</li><li>梯度基准</li><li>准确率</li><li>训练/验证数据集性能</li><li>其它</li></ul><h3 id="架构选择与设计"><a href="#架构选择与设计" class="headerlink" title="架构选择与设计"></a>架构选择与设计</h3><ul><li>架构选择<ul><li>分类问题：AlexNet,VGG, ResNet,DenseNet, …</li><li>语义分割：FCN, Dilated Convolution, Mask RCNN</li><li>识别： Faster-RCNN, YOLO, SSD</li><li>图像生成： UNet, Dilated Convolution, DCGAN, WGAN</li><li>…</li></ul></li><li>输入适配</li></ul><p><img src="/qnsource/images/2018-04-28-cs231n-notes/architecture_input.png" alt="architecture_input"></p><ul><li>数据集适配</li></ul><p><img src="/qnsource/images/2018-04-28-cs231n-notes/architecture_dataset.png" alt="architecture_dataset"></p><ul><li>输出任务适配</li></ul><p><img src="/qnsource/images/2018-04-28-cs231n-notes/architecture_output.png" alt="architecture_output"></p><h3 id="输出结果分析"><a href="#输出结果分析" class="headerlink" title="输出结果分析"></a>输出结果分析</h3><ol><li>Loss不变化，网络没有学到任何信息：梯度没有应用到权重上，或者不匹配</li></ol><p><img src="/qnsource/images/2018-04-28-cs231n-notes/tuning_tricks_not_learning.png" alt="tuning_tricks_not_learning"></p><ol><li><p>过拟合</p><p><img src="/qnsource/images/2018-04-28-cs231n-notes/tuning_tricks_overfitting_1.png" alt="tuning_tricks_overfitting_1"></p></li><li><p>不收敛：训练时间不足/学习率过低</p><p><img src="/qnsource/images/2018-04-28-cs231n-notes/tuning_tricks_not_converged.png" alt="tuning_tricks_not_converged"></p></li><li><p>慢启动</p><p><img src="/qnsource/images/2018-04-28-cs231n-notes/tuning_tricks_slow_start.png" alt="tuning_tricks_slow_start"></p></li><li><p>梯度更新方向错误</p><p><img src="/qnsource/images/2018-04-28-cs231n-notes/tuning_tricks_wrong_gradients.png" alt="tuning_tricks_wrong_gradients"></p></li><li><p>数据未打乱</p><p><img src="/qnsource/images/2018-04-28-cs231n-notes/tuning_tricks_not_shuffling_data.png" alt="tuning_tricks_not_shuffling_data"></p></li><li><p>损失函数出现<code>nans</code>值：模型中数据不稳定/较高的学习率</p><p><img src="/qnsource/images/2018-04-28-cs231n-notes/tuning_tricks_nans_loss.png" alt="tuning_tricks_nans_loss"></p></li><li><p>验证集效果优于训练集：验证集太小或分布异常</p><p><img src="/qnsource/images/2018-04-28-cs231n-notes/tuning_tricks_val_samll.png" alt="tuning_tricks_val_samll"></p></li></ol><h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><ol><li><p>DropOut本质上也是一种模型组合学习</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train</span></span><br><span class="line">H = np.maximum(<span class="number">0</span>, np.dot(W,X) + b)</span><br><span class="line">U = (np.random.rand(*H.shape) &lt; p) / p</span><br><span class="line">H *= U</span><br></pre></td></tr></table></figure><p>​</p></li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li>Fei,Nish, Tips and tricks for tuning NNs</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 计划花一个月的时间刷一遍斯坦福的机器视觉课程cs231n，并做笔记记录每天学习到的内容。&lt;/p&gt;
&lt;!-- excerpt --&gt;
&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title
      
    
    </summary>
    
      <category term="读书笔记" scheme="http://blog.a-stack.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="课程笔记" scheme="http://blog.a-stack.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="机器视觉" scheme="http://blog.a-stack.com/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
      <category term="笔记" scheme="http://blog.a-stack.com/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>cs231n课程笔记:（Lecture 5）CNN基础</title>
    <link href="http://blog.a-stack.com/2018/05/03/cs231n-lecture-5/"/>
    <id>http://blog.a-stack.com/2018/05/03/cs231n-lecture-5/</id>
    <published>2018-05-03T08:55:26.000Z</published>
    <updated>2018-05-16T13:59:54.044Z</updated>
    
    <content type="html"><![CDATA[<p><strong>摘要：</strong> 计划花一个月的时间刷一遍斯坦福的机器视觉课程cs231n，并做笔记记录每天学习到的内容。</p><!-- excerpt --><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>cs231n是斯坦福在深度学习和机器视觉领域的入门经典课程，相关资源如下：</p><ul><li>课程主页： <a href="http://cs231n.stanford.edu/" target="_blank" rel="noopener">http://cs231n.stanford.edu/</a></li><li>课程Notes：<a href="http://cs231n.github.io/" target="_blank" rel="noopener">http://cs231n.github.io/</a></li></ul><div class="table-container"><table><thead><tr><th>Event Type</th><th>Date</th><th>Description</th><th>Course Materials</th></tr></thead><tbody><tr><td>Lecture 5</td><td>Tuesday April 17</td><td><strong>Convolutional Neural Networks</strong> History Convolution and pooling ConvNets outside vision</td><td><a href="http://cs231n.stanford.edu/slides/2018/cs231n_2018_lecture05.pdf" target="_blank" rel="noopener">[slides]</a> <a href="http://cs231n.github.io/convolutional-networks/" target="_blank" rel="noopener">ConvNet notes</a></td></tr></tbody></table></div><h2 id="Convolutional-Neural-Network-CNN-ConvNet"><a href="#Convolutional-Neural-Network-CNN-ConvNet" class="headerlink" title="Convolutional Neural Network(CNN/ConvNet)"></a>Convolutional Neural Network(CNN/ConvNet)</h2><blockquote><p>更多内容参见<sup><a href="#fn_4" id="reffn_4">4</a></sup></p></blockquote><p><strong>FCN vs CNN</strong> </p><p><img src="/qnsource/images/2018-04-28-cs231n-notes/FCN_CNN.png" alt="FCN_CNN"></p><p><strong>CNN的层次结构</strong></p><p><img src="/qnsource/images/2018-04-28-cs231n-notes/convnet.jpeg" alt="convnet"></p><p><strong>The brain view</strong>. If you’re a fan of the brain/neuron analogies, every entry in the 3D output volume can also be interpreted as an output of a neuron that looks at only a small region in the input and shares parameters with all neurons to the left and right spatially (since these numbers all result from applying the same filter). </p><p><strong>Local Connectivity.</strong> filter 大小的区域内容，卷积层的每个神经元只与前一层filter中的神经元保持连接，深度为上一层网络的深度。</p><p><img src="/qnsource/images/2018-04-28-cs231n-notes/depthcol.jpeg" alt="depthcol"></p><p><strong>卷积层的输出：</strong></p><script type="math/tex; mode=display">\frac{W - F + 2P}{S} + 1</script><p>其中，</p><ul><li>$W$ 代表输入层大小；</li><li>$F$ filter的大小；</li><li>$P$ Zero-Padding的大小；</li><li>$S$ 滑动窗口滑动步长</li></ul><p>当$S=1$, $P=(F-1)/2$ 时，输入输出网络具有相同的大小。</p><p><strong>参数共享：</strong></p><ul><li>卷积神经网络<strong>每一层</strong>共享同一套权重参数（W，b），降低参数总量。</li><li>全部参数数目为：$(F\cdot F \cdot D_1 +1)* K$,其中 $D_1$ 为上一层的深度，$K$ 为filter个数。</li></ul><blockquote><p>直观解释，在一个图像一个filter区域学到的特征（比如纹理），在图像其它地方用来匹配纹理特征也奏效</p></blockquote><h4 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h4><p><img src="/qnsource/images/2018-04-28-cs231n-notes/max-pooling.png" alt="max-pooling"></p><ul><li>一般max pooling常采用的参数为$F=3,S=2$ (Overlapping pooling),$F=2, S=2$ (Max Pooling);</li><li>反向传播时，对于$max(x,y)$ 形式，梯度传递最大的激活值；</li><li>一般很少使用$F \gt 3$ 的filter</li><li>目前很多新的论文中已经尽量避免使用池化操作，构建全卷积的神经网络架构，除了最后一层采用全局池化层。</li></ul><h4 id="FC和CNN可以相互转换"><a href="#FC和CNN可以相互转换" class="headerlink" title="FC和CNN可以相互转换"></a>FC和CNN可以相互转换</h4><ul><li>FC表示CNN： 使用一个很大的参数矩阵，矩阵中多数单元为0少数表征本地连接的地方为非0，同时很多单元的权重相同（参数共享的描述）；</li><li>CNN表示FC： 使用K层的1x1卷积网络可以描述K个节点的FC。</li></ul><h4 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">INPUT: [<span class="number">224</span>x224x3]        memory:  <span class="number">224</span>*<span class="number">224</span>*<span class="number">3</span>=<span class="number">150</span>K   weights: <span class="number">0</span></span><br><span class="line">CONV3<span class="number">-64</span>: [<span class="number">224</span>x224x64]  memory:  <span class="number">224</span>*<span class="number">224</span>*<span class="number">64</span>=<span class="number">3.2</span>M   weights: (<span class="number">3</span>*<span class="number">3</span>*<span class="number">3</span>)*<span class="number">64</span> = <span class="number">1</span>,<span class="number">728</span></span><br><span class="line">CONV3<span class="number">-64</span>: [<span class="number">224</span>x224x64]  memory:  <span class="number">224</span>*<span class="number">224</span>*<span class="number">64</span>=<span class="number">3.2</span>M   weights: (<span class="number">3</span>*<span class="number">3</span>*<span class="number">64</span>)*<span class="number">64</span> = <span class="number">36</span>,<span class="number">864</span></span><br><span class="line">POOL2: [<span class="number">112</span>x112x64]  memory:  <span class="number">112</span>*<span class="number">112</span>*<span class="number">64</span>=<span class="number">800</span>K   weights: <span class="number">0</span></span><br><span class="line">CONV3<span class="number">-128</span>: [<span class="number">112</span>x112x128]  memory:  <span class="number">112</span>*<span class="number">112</span>*<span class="number">128</span>=<span class="number">1.6</span>M   weights: (<span class="number">3</span>*<span class="number">3</span>*<span class="number">64</span>)*<span class="number">128</span> = <span class="number">73</span>,<span class="number">728</span></span><br><span class="line">CONV3<span class="number">-128</span>: [<span class="number">112</span>x112x128]  memory:  <span class="number">112</span>*<span class="number">112</span>*<span class="number">128</span>=<span class="number">1.6</span>M   weights: (<span class="number">3</span>*<span class="number">3</span>*<span class="number">128</span>)*<span class="number">128</span> = <span class="number">147</span>,<span class="number">456</span></span><br><span class="line">POOL2: [<span class="number">56</span>x56x128]  memory:  <span class="number">56</span>*<span class="number">56</span>*<span class="number">128</span>=<span class="number">400</span>K   weights: <span class="number">0</span></span><br><span class="line">CONV3<span class="number">-256</span>: [<span class="number">56</span>x56x256]  memory:  <span class="number">56</span>*<span class="number">56</span>*<span class="number">256</span>=<span class="number">800</span>K   weights: (<span class="number">3</span>*<span class="number">3</span>*<span class="number">128</span>)*<span class="number">256</span> = <span class="number">294</span>,<span class="number">912</span></span><br><span class="line">CONV3<span class="number">-256</span>: [<span class="number">56</span>x56x256]  memory:  <span class="number">56</span>*<span class="number">56</span>*<span class="number">256</span>=<span class="number">800</span>K   weights: (<span class="number">3</span>*<span class="number">3</span>*<span class="number">256</span>)*<span class="number">256</span> = <span class="number">589</span>,<span class="number">824</span></span><br><span class="line">CONV3<span class="number">-256</span>: [<span class="number">56</span>x56x256]  memory:  <span class="number">56</span>*<span class="number">56</span>*<span class="number">256</span>=<span class="number">800</span>K   weights: (<span class="number">3</span>*<span class="number">3</span>*<span class="number">256</span>)*<span class="number">256</span> = <span class="number">589</span>,<span class="number">824</span></span><br><span class="line">POOL2: [<span class="number">28</span>x28x256]  memory:  <span class="number">28</span>*<span class="number">28</span>*<span class="number">256</span>=<span class="number">200</span>K   weights: <span class="number">0</span></span><br><span class="line">CONV3<span class="number">-512</span>: [<span class="number">28</span>x28x512]  memory:  <span class="number">28</span>*<span class="number">28</span>*<span class="number">512</span>=<span class="number">400</span>K   weights: (<span class="number">3</span>*<span class="number">3</span>*<span class="number">256</span>)*<span class="number">512</span> = <span class="number">1</span>,<span class="number">179</span>,<span class="number">648</span></span><br><span class="line">CONV3<span class="number">-512</span>: [<span class="number">28</span>x28x512]  memory:  <span class="number">28</span>*<span class="number">28</span>*<span class="number">512</span>=<span class="number">400</span>K   weights: (<span class="number">3</span>*<span class="number">3</span>*<span class="number">512</span>)*<span class="number">512</span> = <span class="number">2</span>,<span class="number">359</span>,<span class="number">296</span></span><br><span class="line">CONV3<span class="number">-512</span>: [<span class="number">28</span>x28x512]  memory:  <span class="number">28</span>*<span class="number">28</span>*<span class="number">512</span>=<span class="number">400</span>K   weights: (<span class="number">3</span>*<span class="number">3</span>*<span class="number">512</span>)*<span class="number">512</span> = <span class="number">2</span>,<span class="number">359</span>,<span class="number">296</span></span><br><span class="line">POOL2: [<span class="number">14</span>x14x512]  memory:  <span class="number">14</span>*<span class="number">14</span>*<span class="number">512</span>=<span class="number">100</span>K   weights: <span class="number">0</span></span><br><span class="line">CONV3<span class="number">-512</span>: [<span class="number">14</span>x14x512]  memory:  <span class="number">14</span>*<span class="number">14</span>*<span class="number">512</span>=<span class="number">100</span>K   weights: (<span class="number">3</span>*<span class="number">3</span>*<span class="number">512</span>)*<span class="number">512</span> = <span class="number">2</span>,<span class="number">359</span>,<span class="number">296</span></span><br><span class="line">CONV3<span class="number">-512</span>: [<span class="number">14</span>x14x512]  memory:  <span class="number">14</span>*<span class="number">14</span>*<span class="number">512</span>=<span class="number">100</span>K   weights: (<span class="number">3</span>*<span class="number">3</span>*<span class="number">512</span>)*<span class="number">512</span> = <span class="number">2</span>,<span class="number">359</span>,<span class="number">296</span></span><br><span class="line">CONV3<span class="number">-512</span>: [<span class="number">14</span>x14x512]  memory:  <span class="number">14</span>*<span class="number">14</span>*<span class="number">512</span>=<span class="number">100</span>K   weights: (<span class="number">3</span>*<span class="number">3</span>*<span class="number">512</span>)*<span class="number">512</span> = <span class="number">2</span>,<span class="number">359</span>,<span class="number">296</span></span><br><span class="line">POOL2: [<span class="number">7</span>x7x512]  memory:  <span class="number">7</span>*<span class="number">7</span>*<span class="number">512</span>=<span class="number">25</span>K  weights: <span class="number">0</span></span><br><span class="line">FC: [<span class="number">1</span>x1x4096]  memory:  <span class="number">4096</span>  weights: <span class="number">7</span>*<span class="number">7</span>*<span class="number">512</span>*<span class="number">4096</span> = <span class="number">102</span>,<span class="number">760</span>,<span class="number">448</span></span><br><span class="line">FC: [<span class="number">1</span>x1x4096]  memory:  <span class="number">4096</span>  weights: <span class="number">4096</span>*<span class="number">4096</span> = <span class="number">16</span>,<span class="number">777</span>,<span class="number">216</span></span><br><span class="line">FC: [<span class="number">1</span>x1x1000]  memory:  <span class="number">1000</span> weights: <span class="number">4096</span>*<span class="number">1000</span> = <span class="number">4</span>,<span class="number">096</span>,<span class="number">000</span></span><br><span class="line"></span><br><span class="line">TOTAL memory: <span class="number">24</span>M * <span class="number">4</span> bytes ~= <span class="number">93</span>MB / image (only forward! ~*<span class="number">2</span> <span class="keyword">for</span> bwd)</span><br><span class="line">TOTAL params: <span class="number">138</span>M parameters</span><br></pre></td></tr></table></figure><blockquote><p>存储空间的使用主要是前面几层中间变量的存储；权重数目主要集中在后面几个全联通网络中。</p></blockquote><ul><li>存储空间的计算：数据个数 x 4(bytes)</li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote id="fn_4"><sup>4</sup>. <a href="http://cs231n.github.io/convolutional-networks/" target="_blank" rel="noopener">cs231n notes: CNN</a><a href="#reffn_4" title="Jump back to footnote [4] in the text."> &#8617;</a></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 计划花一个月的时间刷一遍斯坦福的机器视觉课程cs231n，并做笔记记录每天学习到的内容。&lt;/p&gt;
&lt;!-- excerpt --&gt;
&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title
      
    
    </summary>
    
      <category term="读书笔记" scheme="http://blog.a-stack.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="课程笔记" scheme="http://blog.a-stack.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="机器视觉" scheme="http://blog.a-stack.com/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
      <category term="笔记" scheme="http://blog.a-stack.com/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>cs231n课程笔记：（Lecture 4）神经网络基础</title>
    <link href="http://blog.a-stack.com/2018/05/03/cs231n-lecture-4/"/>
    <id>http://blog.a-stack.com/2018/05/03/cs231n-lecture-4/</id>
    <published>2018-05-03T08:52:26.000Z</published>
    <updated>2018-05-16T13:59:45.204Z</updated>
    
    <content type="html"><![CDATA[<p><strong>摘要：</strong> 计划花一个月的时间刷一遍斯坦福的机器视觉课程cs231n，并做笔记记录每天学习到的内容。</p><!-- excerpt --><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>cs231n是斯坦福在深度学习和机器视觉领域的入门经典课程，相关资源如下：</p><ul><li>课程主页： <a href="http://cs231n.stanford.edu/" target="_blank" rel="noopener">http://cs231n.stanford.edu/</a></li><li>课程Notes：<a href="http://cs231n.github.io/" target="_blank" rel="noopener">http://cs231n.github.io/</a></li></ul><div class="table-container"><table><thead><tr><th>Event Type</th><th>Date</th><th>Description</th><th>Course Materials</th></tr></thead><tbody><tr><td>Lecture 4</td><td>Thursday April 12</td><td><strong>Introduction to Neural Networks</strong> BackpropagationMulti-layer PerceptronsThe neural viewpoint</td><td><a href="http://cs231n.stanford.edu/slides/2018/cs231n_2018_lecture04.pdf" target="_blank" rel="noopener">[slides]</a> <a href="http://cs231n.github.io/optimization-2" target="_blank" rel="noopener">[backprop notes]</a><a href="http://cs231n.stanford.edu/handouts/linear-backprop.pdf" target="_blank" rel="noopener">[linear backprop example]</a><a href="http://cs231n.stanford.edu/handouts/derivatives.pdf" target="_blank" rel="noopener">[derivatives notes]</a> (optional) <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf" target="_blank" rel="noopener">[Efficient BackProp]</a> (optional)related: <a href="http://colah.github.io/posts/2015-08-Backprop/" target="_blank" rel="noopener">[1]</a>, <a href="http://neuralnetworksanddeeplearning.com/chap2.html" target="_blank" rel="noopener">[2]</a>, <a href="https://www.youtube.com/watch?v=q0pm3BrIUFo" target="_blank" rel="noopener">[3]</a> (optional)</td></tr><tr><td>Discussion Section</td><td>Friday April 13</td><td><strong>Backpropagation</strong></td><td><a href="http://cs231n.stanford.edu/slides/2018/cs231n_2018_ds02.pdf" target="_blank" rel="noopener">[slides]</a></td></tr></tbody></table></div><h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><blockquote><p>更多内容参见<sup><a href="#fn_1" id="reffn_1">1</a></sup><sup><a href="#fn_2" id="reffn_2">2</a></sup><sup><a href="#fn_3" id="reffn_3">3</a></sup></p><p>这课程的大多数内容也综合了Lecture 6和Lecutre 7的内容，所以那两节课不单独写博客了。</p></blockquote><ul><li>一个人的神经系统大概有860亿个神经元，形成$10^{14}-10^{15}$ 个神经元链接；</li></ul><p><img src="/qnsource/images/2018-04-28-cs231n-notes/neuron_model.png" alt="neuron_model"></p><blockquote><p><strong>Coarse model.</strong> It’s important to stress that this model of a biological neuron is very coarse: For example, there are many different types of neurons, each with different properties. The dendrites in biological neurons perform complex nonlinear computations. The synapses are not just a single weight, they’re a complex non-linear dynamical system. The exact timing of the output spikes in many systems is known to be important, suggesting that the rate code approximation may not hold. Due to all these and many other simplifications, be prepared to hear groaning sounds from anyone with some neuroscience background if you draw analogies between Neural Networks and real brains. See this <a href="https://physics.ucsd.edu/neurophysics/courses/physics_171/annurev.neuro.28.061604.135703.pdf" target="_blank" rel="noopener">review</a> (pdf), or more recently this <a href="http://www.sciencedirect.com/science/article/pii/S0959438814000130" target="_blank" rel="noopener">review</a> if you are interested.</p></blockquote><ul><li><p><strong>激活函数</strong></p><p><img src="/qnsource/images/2018-04-28-cs231n-notes/activation_functions.png" alt="activation_functions"></p><ul><li>Sigmoid： $\sigma(x) = 1 / (1 + e^{-x})$<ul><li>1)梯度饱和；2)函数形式不是中心对称的（这个特性会导致后面网络层的输入也不是零中心的，进而影响梯度下降的运作）；</li></ul></li><li>Tanh: $\tanh(x) = 2 \sigma(2x) -1$<ul><li>1)梯度饱和；2）中心对称[-1,1]；</li></ul></li><li>ReLU:  $f(x) = \max(0, x)$<ul><li>1)线性非饱和的形式使得其收敛速度是Tanh的6倍； 2）计算代价低；3）难训练，容易陷入”死区”，需要严格配置合适的学习率；</li></ul></li><li>Leaky ReLU： $f(x) = \mathbb{1}(x &lt; 0) (\alpha x) + \mathbb{1}(x&gt;=0) (x)$<ul><li>另一种泛化形势为参数ReLU</li><li>另一种ELU</li></ul></li><li><strong>Maxout</strong>: $\max(w_1^Tx+b_1, w_2^Tx + b_2)$<ul><li>ReLU和Leaky ReLU是其特例；</li></ul></li></ul></li><li><p>关于网络规模大小</p><ul><li>一般浅层神经网络训练过程中容易陷入局部极小值，很难训练；</li><li>所以及时过拟合，也尽量不采用过小的神经网络（可以采用其它手段处理过拟合问题）</li></ul></li></ul><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><ol><li>均值处理（中心化）：<code>X -= np.mean(X, axis = 0)</code></li><li>归一化：<code>X /= np.std(X, axis = 0)</code></li></ol><blockquote><p>使用归一化需要注意： 只有在不同变量的大小对于输出同等重要的情况下采用归一化；图像中由于所有变量都已经在区间[0,255]范围之中，所以没有必要采用归一化</p></blockquote><p><img src="/qnsource/images/2018-04-28-cs231n-notes/prepro1.jpeg" alt="prepro1"></p><ol><li>PCA和白化</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Assume input data matrix X of size [N x D]</span></span><br><span class="line">X -= np.mean(X, axis = <span class="number">0</span>) <span class="comment"># zero-center the data (important)</span></span><br><span class="line">cov = np.dot(X.T, X) / X.shape[<span class="number">0</span>] <span class="comment"># get the data covariance matrix</span></span><br><span class="line"></span><br><span class="line">U，S, V = np.linalg.svd(cov)</span><br><span class="line">Xrot = np.dot(X, U) <span class="comment"># decorrelate the data</span></span><br><span class="line"><span class="comment"># 1. PCA</span></span><br><span class="line">Xrot_reduced = np.dot(X, U[:,:<span class="number">100</span>]) <span class="comment"># Xrot_reduced becomes [N x 100]</span></span><br><span class="line"><span class="comment">#2 . whiten the data:</span></span><br><span class="line"><span class="comment"># divide by the eigenvalues (which are square roots of the singular values)</span></span><br><span class="line">Xwhite = Xrot / np.sqrt(S + <span class="number">1e-5</span>)</span><br></pre></td></tr></table></figure><blockquote><p>U为正交特征向量，我们可以只选择top N重要的特征向量来进行降维处理；</p><p>PCA： 下图所示，数据中心对齐，以特征向量方向旋转对齐；</p><p>白化操作：如果输入数据为多元高斯分布，白化结果为高斯零均值独立协方差矩阵</p></blockquote><p><img src="/qnsource/images/2018-04-28-cs231n-notes/prepro2.jpeg" alt="prepro2"></p><p>以CIFAR-10为例，处理之后效果见下图，第2张为取3072个特征中前144个特征：</p><p><img src="/qnsource/images/2018-04-28-cs231n-notes/cifar10pca.jpeg" alt="cifar10pca"></p><blockquote><p>所有预处理过程仅作用到训练数据中，并记录相关参数，验证数据和测试数据采用训练数据的结果进行预处理</p></blockquote><h3 id="参数初始化"><a href="#参数初始化" class="headerlink" title="参数初始化"></a>参数初始化</h3><ul><li><code>W = 0.01* np.random.randn(D,H)</code></li><li><code>w = np.random.randn(n) / sqrt(2.0/n)</code></li></ul><blockquote><p><code>randn</code> 产生零均值单位方差高斯分布<br>w参数不能全部初始化为零（对称效应导致网络激活不更新），bias参数一般初始化为零<br>第二个公式为了解决输出随n的增加而比例增加的问题</p></blockquote><script type="math/tex; mode=display">\begin{align}\text{Var}(s) &= \text{Var}(\sum_i^n w_ix_i) \\&= \sum_i^n \text{Var}(w_ix_i) \\&= \sum_i^n [E(w_i)]^2\text{Var}(x_i) + E[(x_i)]^2\text{Var}(w_i) + \text{Var}(x_i)\text{Var}(w_i) \\&= \sum_i^n \text{Var}(x_i)\text{Var}(w_i) \\&= \left( n \text{Var}(w) \right) \text{Var}(x)\end{align}</script><h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><ul><li>L2正则化对于峰值权重增加比较大的惩罚，对平滑的权重矩阵更加友好；</li><li>L1正则化的一个效果是使得输入参数稀疏化，从而过滤输入中的噪声数据；</li><li>最大基准门限：$\Vert \vec{w} \Vert_2 &lt; c$</li><li>Dropout: 在预测阶段不要使用<ul><li>inverted dropout</li><li>一般 $p=0.5$</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">""" </span></span><br><span class="line"><span class="string">Inverted Dropout: Recommended implementation example.</span></span><br><span class="line"><span class="string">We drop and scale at train time and don't do anything at test time.</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line">p = <span class="number">0.5</span> <span class="comment"># probability of keeping a unit active. higher = less dropout</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(X)</span>:</span></span><br><span class="line">  <span class="comment"># forward pass for example 3-layer neural network</span></span><br><span class="line">  H1 = np.maximum(<span class="number">0</span>, np.dot(W1, X) + b1)</span><br><span class="line">  U1 = (np.random.rand(*H1.shape) &lt; p) / p <span class="comment"># first dropout mask. Notice /p!</span></span><br><span class="line">  H1 *= U1 <span class="comment"># drop!</span></span><br><span class="line">  H2 = np.maximum(<span class="number">0</span>, np.dot(W2, H1) + b2)</span><br><span class="line">  U2 = (np.random.rand(*H2.shape) &lt; p) / p <span class="comment"># second dropout mask. Notice /p!</span></span><br><span class="line">  H2 *= U2 <span class="comment"># drop!</span></span><br><span class="line">  out = np.dot(W3, H2) + b3</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># backward pass: compute gradients... (not shown)</span></span><br><span class="line">  <span class="comment"># perform parameter update... (not shown)</span></span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(X)</span>:</span></span><br><span class="line">  <span class="comment"># ensembled forward pass</span></span><br><span class="line">  H1 = np.maximum(<span class="number">0</span>, np.dot(W1, X) + b1) <span class="comment"># no scaling necessary</span></span><br><span class="line">  H2 = np.maximum(<span class="number">0</span>, np.dot(W2, H1) + b2)</span><br><span class="line">  out = np.dot(W3, H2) + b3</span><br></pre></td></tr></table></figure><h3 id="代价函数（data-loss）"><a href="#代价函数（data-loss）" class="headerlink" title="代价函数（data loss）"></a>代价函数（data loss）</h3><ol><li>分类问题</li></ol><ul><li><p>SVM代价函数(合页损失函数)</p><script type="math/tex; mode=display">L_i = \sum_{j\neq y_i} \max(0, f_j - f_{y_i} + 1)</script></li><li><p>交叉熵损失函数</p><script type="math/tex; mode=display">L_i = -\log\left(\frac{e^{f_{y_i}}}{ \sum_j e^{f_j} }\right)</script></li></ul><blockquote><p>当分类数目特别大时，可采用层次Softmax</p></blockquote><ol><li><p>多属性分类</p><p>如果一个分类目标对应多个正确的结果，比如对一张图片分类，可能同时有多个正确标签。可以对每个属性构建一个二元分类器：</p></li></ol><script type="math/tex; mode=display">L_i = \sum_j \max(0, 1 - y_{ij} f_j)</script><p>​    其中，j为某个分类，$y_{ij}$ 为+1或-1，表示第i个样本是否含有第j个属性；$f_i$ 为正代表预测正确；</p><p>​    第二种方法是对每个属性应用逻辑回归分类器：</p><script type="math/tex; mode=display">L_i = \sum_j y_{ij} \log(\sigma(f_j)) + (1 - y_{ij}) \log(1 - \sigma(f_j))</script><p>​    $\partial{L<em>i} / \partial{f_j} = y</em>{ij} - \sigma(f_j)$。</p><ol><li>回归问题</li></ol><ul><li><p>L2: $L_i = \Vert f - y_i \Vert_2^2$</p><p>​</p></li><li><p>L1: $L_i = \Vert f - y_i \Vert_1 = \sum_j \mid f_j - (y_i)_j \mid$</p><p>​</p></li></ul><h3 id="训练3"><a href="#训练3" class="headerlink" title="训练3"></a>训练<sup><a href="#fn_3" id="reffn_3">3</a></sup></h3><h4 id="梯度校验"><a href="#梯度校验" class="headerlink" title="梯度校验"></a>梯度校验</h4><script type="math/tex; mode=display">\frac{df(x)}{dx} = \frac{f(x + h) - f(x - h)}{2h} \hspace{0.1in}</script><blockquote><p>h可以设置为1e-5</p></blockquote><ol><li>可以使用如下值来判断校验结果：</li></ol><script type="math/tex; mode=display">\frac{\mid f'_a - f'_n \mid}{\max(\mid f'_a \mid, \mid f'_n \mid)}</script><blockquote><ul><li>relative error &gt; 1e-2 usually means the gradient is probably wrong</li><li>1e-2 &gt; relative error &gt; 1e-4 should make you feel uncomfortable</li><li>1e-4 &gt; relative error is usually okay for objectives with kinks. But if there are no kinks (e.g. use of tanh nonlinearities and softmax), then 1e-4 is too high.</li><li>1e-7 and less you should be happy.</li><li>网络层数越多，相对误差值越大</li></ul></blockquote><ol><li>进行梯度校验，关闭dropout、数据放大(或使用random seed)</li></ol><h4 id="Sanity-Checks"><a href="#Sanity-Checks" class="headerlink" title="Sanity Checks"></a>Sanity Checks</h4><ul><li>Loss函数的初始化输出值是否合理；<ul><li>增加正则化参数，loss是否增加</li></ul></li><li>使用小数据集测试是否能够达到数据过拟合（<strong>零Loss值</strong>）<ul><li>注意关闭正则化</li></ul></li></ul><h4 id="训练过程监测"><a href="#训练过程监测" class="headerlink" title="训练过程监测"></a>训练过程监测</h4><ol><li>代价函数</li></ol><p><img src="/qnsource/images/2018-04-28-cs231n-notes/learningrates.jpeg" alt="learningrates"></p><ol><li>训练/验证集准确率</li></ol><p><img src="/qnsource/images/2018-04-28-cs231n-notes/accuracies.jpeg" alt="accuracies"></p><ol><li>更新参数比例</li></ol><blockquote><p>A rough heuristic is that this ratio should be somewhere around 1e-3. If it is lower than this then the learning rate might be too low. If it is higher then the learning rate is likely too high.</p></blockquote><p>​    </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># assume parameter vector W and its gradient vector dW</span></span><br><span class="line">param_scale = np.linalg.norm(W.ravel())</span><br><span class="line">update = -learning_rate*dW <span class="comment"># simple SGD update</span></span><br><span class="line">update_scale = np.linalg.norm(update.ravel())</span><br><span class="line">W += update <span class="comment"># the actual update</span></span><br><span class="line"><span class="keyword">print</span> update_scale / param_scale <span class="comment"># want ~1e-3</span></span><br></pre></td></tr></table></figure><h4 id="超参优化"><a href="#超参优化" class="headerlink" title="超参优化"></a>超参优化</h4><ul><li><code>learning_rate = 10 ** uniform(-6, 1)</code></li><li>random serach &gt; grid search<img src="/qnsource/images/2018-04-28-cs231n-notes/gridsearchbad.jpeg" alt="gridsearchbad"></li></ul><h4 id="模型组合"><a href="#模型组合" class="headerlink" title="模型组合"></a>模型组合</h4><ul><li><strong>Same model, different initializations</strong>. Use cross-validation to determine the best hyperparameters, then train multiple models with the best set of hyperparameters but with different random initialization. The danger with this approach is that the variety is only due to initialization.</li><li><strong>Top models discovered during cross-validation</strong>. Use cross-validation to determine the best hyperparameters, then pick the top few (e.g. 10) models to form the ensemble. This improves the variety of the ensemble but has the danger of including suboptimal models. In practice, this can be easier to perform since it doesn’t require additional retraining of models after cross-validation</li><li><strong>Different checkpoints of a single model</strong>. If training is very expensive, some people have had limited success in taking different checkpoints of a single network over time (for example after every epoch) and using those to form an ensemble. Clearly, this suffers from some lack of variety, but can still work reasonably well in practice. The advantage of this approach is that is very cheap.</li><li><strong>Running average of parameters during training</strong>. Related to the last point, a cheap way of almost always getting an extra percent or two of performance is to maintain a second copy of the network’s weights in memory that maintains an exponentially decaying sum of previous weights during training. This way you’re averaging the state of the network over last several iterations. You will find that this “smoothed” version of the weights over last few steps almost always achieves better validation error. The rough intuition to have in mind is that the objective is bowl-shaped and your network is jumping around the mode, so the average has a higher chance of being somewhere nearer the mode.</li></ul><h3 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h3><ol><li><strong>Cache forward pass variables</strong>. To compute the backward pass it is very helpful to have some of the variables that were used in the forward pass. In practice you want to structure your code so that you cache these variables, and so that they are available during backpropagation. If this is too difficult, it is possible (but wasteful) to recompute them.</li><li><strong>Gradients add up at forks</strong>. The forward expression involves the variables <strong>x,y</strong> multiple times, so when we perform backpropagation we must be careful to use <code>+=</code> instead of <code>=</code> to accumulate the gradient on these variables (otherwise we would overwrite it). This follows the <em>multivariable chain rule</em> in Calculus, which states that if a variable branches out to different parts of the circuit, then the gradients that flow back to it will add.</li></ol><h3 id="实现-lt-代码-gt"><a href="#实现-lt-代码-gt" class="headerlink" title="实现 &lt;代码&gt;"></a>实现 &lt;代码&gt;</h3><blockquote><p>配合Assignment 1： Implement a Neural Network整理一个从头训练2层全联通网络的例子。</p></blockquote><ol><li>网络结构（只有一个隐层的全联同神经网络）,其中输入训练样本为X (N x D), 第一个隐层由H个节点组成，输出层由C个节点组成：</li></ol><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">input  - fully connected layer - ReLU - fully connected layer - softmax</span><br><span class="line">（<span class="keyword">N</span>,<span class="keyword">D</span>）           H                             <span class="keyword">C</span></span><br></pre></td></tr></table></figure><p>各参数的大小如下：</p><ul><li>input: X (N x D)</li><li>W1 (H x D) ; b1 (H,)</li><li>W2 (C x H);  b2 (C,)</li></ul><ol><li><p>参数初始化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">H = <span class="number">100</span></span><br><span class="line">C = <span class="number">10</span></span><br><span class="line">N,D = X.shape</span><br><span class="line"></span><br><span class="line">W1 = std * np.random.randn(input_size, hidden_size)</span><br><span class="line">b1 = np.zeros(hidden_size)</span><br><span class="line">W2 = std * np.random.randn(hidden_size, output_size)</span><br><span class="line">b2 = np.zeros(output_size)</span><br></pre></td></tr></table></figure></li><li><p>前向传播，计算得分函数和代价函数</p><script type="math/tex; mode=display">hiddenLayer = ReLU(X*W1 + b1) \\ReLU(x) = \max(0, x)</script><script type="math/tex; mode=display">scores = hidden\_layer * W2 + b2</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hidden_layer = np.maximum(<span class="number">0</span>, np.dot(X, W1) + b1)   <span class="comment"># N x H</span></span><br><span class="line">socres = np.dot(hidden_layer, W2) + b2     <span class="comment"># N x C</span></span><br></pre></td></tr></table></figure><p>代价函数使用交叉熵损失函数：</p><script type="math/tex; mode=display">L_i = -\log\left(\frac{e^{f_{y_i}}}{ \sum_j e^{f_j} }\right) \hspace{0.5in} \text{or equivalently} \hspace{0.5in} L_i = -f_{y_i} + \log\sum_j e^{f_j}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">exp_scores = np.exp(scores)</span><br><span class="line">probs = exp_scores / np.sum(exp_scores, axis=<span class="number">1</span>, keepdims=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">correct_logprobs = -np.log(probs[range(N), y])</span><br><span class="line">loss = np.sum(correct_logprobs) / N</span><br><span class="line">loss += <span class="number">0.5</span>*reg*(np.sum(W1*W1) + np.sum(W2*W2))</span><br></pre></td></tr></table></figure></li><li><p>反向传播，计算梯度</p><p>梯度的计算利用反向传播，从后往前逐步推导：</p><p>首先计算<code>dscores</code></p><script type="math/tex; mode=display">\begin{equation}  \frac{\partial L}{\partial scores} =\left\{  \begin{array}{lr}  -1 + \frac{e^{\hat f_{y_i}}}{\sum_j e^{f_j}}, &  j=i\\  \frac{e^{\hat f_{y_i}}}{\sum_j e^{f_j}}, &   j \neq i \end{array}  \right.  \end{equation}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dscores = probs</span><br><span class="line">dscores[range(N), y] -=<span class="number">1</span></span><br><span class="line">dscores /= N</span><br></pre></td></tr></table></figure></li></ol><script type="math/tex; mode=display">dW2 = H^T*dscores + 2\lambda*W2 \\db2 = dscores</script>   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dW2 = np.dot(h1.T, dscores) + <span class="number">2</span>*reg * W2</span><br><span class="line">db2 = np.sum(dscores, axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>   接着计算隐层的偏导,其中激活函数由于使用ReLU，在$x&lt;0$时，导数为0</p>   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dh1 = np.dot(dscores, W2.T)</span><br><span class="line">dh1[h1 &lt;= <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">dW1 = np.dot(X.T, dh1) + <span class="number">2</span>*reg * W1</span><br><span class="line">db1 = np.sum(dh1, axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><ul><li>学习率的设计一般在<code>[1e-3, 1e-5]</code>,<code>10**uniform(-3,-6)</code></li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote id="fn_1"><sup>1</sup>. <a href="http://cs231n.github.io/neural-networks-1/" target="_blank" rel="noopener">cs231n notes: Neural Network</a><a href="#reffn_1" title="Jump back to footnote [1] in the text."> &#8617;</a></blockquote><blockquote id="fn_2"><sup>2</sup>. <a href="http://cs231n.github.io/neural-networks-2/" target="_blank" rel="noopener">cs231n notes: Setting up the Data and Loss</a><a href="#reffn_2" title="Jump back to footnote [2] in the text."> &#8617;</a></blockquote><blockquote id="fn_3"><sup>3</sup>. <a href="http://cs231n.github.io/neural-networks-3/" target="_blank" rel="noopener">cs231n notes: Learning and Evaluation</a><a href="#reffn_3" title="Jump back to footnote [3] in the text."> &#8617;</a></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 计划花一个月的时间刷一遍斯坦福的机器视觉课程cs231n，并做笔记记录每天学习到的内容。&lt;/p&gt;
&lt;!-- excerpt --&gt;
&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title
      
    
    </summary>
    
      <category term="读书笔记" scheme="http://blog.a-stack.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="课程笔记" scheme="http://blog.a-stack.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="机器视觉" scheme="http://blog.a-stack.com/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
      <category term="笔记" scheme="http://blog.a-stack.com/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>cs231n课程笔记:（Lecture 3）线性分类器和优化方法</title>
    <link href="http://blog.a-stack.com/2018/05/03/cs231n-lecture-3/"/>
    <id>http://blog.a-stack.com/2018/05/03/cs231n-lecture-3/</id>
    <published>2018-05-03T08:51:26.000Z</published>
    <updated>2018-05-16T13:59:35.315Z</updated>
    
    <content type="html"><![CDATA[<p><strong>摘要：</strong> 计划花一个月的时间刷一遍斯坦福的机器视觉课程cs231n，并做笔记记录每天学习到的内容。</p><a id="more"></a><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>cs231n是斯坦福在深度学习和机器视觉领域的入门经典课程，相关资源如下：</p><ul><li>课程主页： <a href="http://cs231n.stanford.edu/" target="_blank" rel="noopener">http://cs231n.stanford.edu/</a></li><li>课程Notes：<a href="http://cs231n.github.io/" target="_blank" rel="noopener">http://cs231n.github.io/</a></li></ul><div class="table-container"><table><thead><tr><th>Event Type</th><th>Date</th><th>Description</th><th>Course Materials</th></tr></thead><tbody><tr><td>Lecture 3</td><td>Tuesday April 10</td><td><strong>Loss Functions and Optimization</strong> Linear classification IIHigher-level representations, image featuresOptimization, stochastic gradient descent</td><td><a href="http://cs231n.stanford.edu/slides/2018/cs231n_2018_lecture03.pdf" target="_blank" rel="noopener">[slides]</a> <a href="http://cs231n.github.io/linear-classify" target="_blank" rel="noopener">[linear classification notes]</a><a href="http://cs231n.github.io/optimization-1" target="_blank" rel="noopener">[optimization notes]</a></td></tr></tbody></table></div><h2 id="线性分类器-2"><a href="#线性分类器-2" class="headerlink" title="线性分类器 2"></a>线性分类器 <sup><a href="#fn_2" id="reffn_2">2</a></sup></h2><p><img src="/qnsource/images/2018-04-28-cs231n-notes/linear_classification.png" alt="linear_classification"></p><p><strong>Interpretation of linear classifiers as template matching.</strong> Another interpretation for the weights WW is that each row of WW corresponds to a <em>template</em> (or sometimes also called a <em>prototype</em>) for one of the classes. The score of each class for an image is then obtained by comparing each template with the image using an <em>inner product</em> (or <em>dot product</em>) one by one to find the one that “fits” best. With this terminology, the linear classifier is doing template matching, where the templates are learned. Another way to think of it is that we are still effectively doing Nearest Neighbor, but instead of having thousands of training images we are only using a single image per class (although we will learn it, and it does not necessarily have to be one of the images in the training set), and we use the (negative) inner product as the distance instead of the L1 or L2 distance.</p><p>线性分类器本质上可以理解为一种模板匹配算法，匹配与分类模板最相近的模板，但由于线性分类器的简单性质，导致每个类最终只能学习到一个模板，如果目标类别有较大的差异，就需要把这些差异平均化。（这也是神经网络层次特性的优越性）</p><p><img src="/qnsource/images/2018-04-28-cs231n-notes/linear_classification_3view_points.png" alt="linear_classification_3view_points"></p><h3 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h3><h4 id="多分类SVM代价函数5"><a href="#多分类SVM代价函数5" class="headerlink" title="多分类SVM代价函数5"></a>多分类SVM代价函数<sup><a href="#fn_5" id="reffn_5">5</a></sup></h4><p>SVM的目标函数定义：</p><script type="math/tex; mode=display">\begin{equation}\min_{ {w},\xi_n}\frac{1}{2} {w}^T {w}+C\sum_{n=1}^N\xi_n  \\s.t.  {w}^T {x}_ny_n\ge1-\xi_n \ \forall n \\ \xi_n \ge 0 \ \forall n \end{equation}</script><p>为计算方便，其中偏移量已经被包含在权重之中。</p><p>上述问题的优化问题对等如下问题(L1-SVM)：</p><script type="math/tex; mode=display">\min_{\bold{w}}\frac{1}{2}\bold{w}^T\bold{w}+C\sum_{n=1}^N \max(1-\bold{w}^T \bold{x_n}y_n, 0)</script><p>和L2-SVM：</p><script type="math/tex; mode=display">\min_{\bold{w}}\frac{1}{2}\bold{w}^T\bold{w}+C\sum_{n=1}^N \max(1-\bold{w}^T \bold{x_n}y_n, 0)^2</script><p>对于第i个样本，多分类SVM代价函数定义为：</p><script type="math/tex; mode=display">L_i = \sum_{j\neq y_i} \max(0, s_j - s_{y_i} + \Delta)</script><blockquote><p>合页损失函数（hinge loss），一般我们令$\Delta =1$</p><p>其中$s_{y_i}$ 为预测值</p><p>$j \neq y_i$ 的意思是只有错误的分类才叠加损失，正确的分类不对损失产生影响</p></blockquote><p><strong>带正则化的损失函数</strong></p><script type="math/tex; mode=display">L =  \underbrace{ \frac{1}{N} \sum_i L_i }_\text{data loss} + \underbrace{ \lambda R(W) }_\text{regularization loss}</script><script type="math/tex; mode=display">L = \frac{1}{N} \sum_i \sum_{j\neq y_i} \left[ \max(0, f(x_i; W)_j - f(x_i; W)_{y_i} + \Delta) \right] + \lambda \sum_k\sum_l W_{k,l}^2</script><blockquote><p>Note that biases do not have the same effect since, unlike the weights, they do not control the strength of influence of an input dimension. Therefore, it is common to only regularize the weights $W$ but not the biases $b$. </p><p>$\Delta=1.0$ 即可，由于权重可以比例调节，所以实际上$\Delta$ 等于1和100意义是一样的；</p></blockquote><p><strong>与SVM线性分类器关系</strong></p><p>SVM线性分类器是多分类的一个特例，</p><script type="math/tex; mode=display">L_i = C \max(0, 1 - y_i w^Tx_i) + R(W)</script><h4 id="引申阅读-SVM4"><a href="#引申阅读-SVM4" class="headerlink" title="[引申阅读]SVM4"></a>[<strong>引申阅读</strong>]SVM<sup><a href="#fn_4" id="reffn_4">4</a></sup></h4><blockquote><p>单独摘成一篇博文吧，要想彻底搞清楚SVM内容实在是有点多</p></blockquote><h4 id="Softmax-分类器"><a href="#Softmax-分类器" class="headerlink" title="Softmax 分类器"></a>Softmax 分类器</h4><p>在Softmax中使用交叉熵(cross-entropy loss)损失函数，</p><script type="math/tex; mode=display">L_i = -\log\left(\frac{e^{f_{y_i}}}{ \sum_j e^{f_j} }\right) \hspace{0.5in} \text{or equivalently} \hspace{0.5in} L_i = -f_{y_i} + \log\sum_j e^{f_j}</script><p>其中函数$f_j(z) = \frac{e^{z_j}}{\sum_k e^{z_k}}$ 为Softmax函数,给出了分类结果的概率分布描述。</p><p><strong>梯度计算公式：</strong></p><script type="math/tex; mode=display">\begin{equation}  dW=\left\{               \begin{array}{lr}               (-1 + \frac{e^{\hat f_{y_i}}}{\sum_j e^{f_j}})x_i, &  j=i\\                \frac{e^{\hat f_{y_i}}}{\sum_j e^{f_j}}x_i, &   j \neq i              \end{array}  \right.  \end{equation}</script><p><strong>向量化实现：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">score = X.dot(W)  <span class="comment"># N x C</span></span><br><span class="line">N = X.shape[<span class="number">0</span>]</span><br><span class="line">correct_score = score[np.arange(N),y].reshape(N,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">exp_sum = np.sum(np.exp(score),axis=<span class="number">1</span>).reshape(N,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">loss += np.sum(np.log(exp_sum) - correct_score)</span><br><span class="line"></span><br><span class="line">loss /= N</span><br><span class="line">loss += reg * <span class="number">0.5</span> * np.sum(W*W)</span><br><span class="line"></span><br><span class="line">margin = np.exp(score)/exp_sum</span><br><span class="line">margin[np.arange(N),y] -= <span class="number">1</span></span><br><span class="line">dW = X.T.dot(margin)</span><br><span class="line"></span><br><span class="line">dW /=N</span><br><span class="line">dW += reg*W</span><br></pre></td></tr></table></figure><p><strong>交叉熵函数：</strong></p><p>真实分类的分布$p$ 和估计分布$q$ 的交叉熵定义为：</p><script type="math/tex; mode=display">H(p,q) = - \sum_x p(x) \log q(x)</script><blockquote><p>Softmax 最小化交叉熵或最大化极大似然函数来求解问题；SVM通过寻找最大界面距离来优化目标。</p></blockquote><h2 id="优化算法3"><a href="#优化算法3" class="headerlink" title="优化算法3"></a>优化算法<sup><a href="#fn_3" id="reffn_3">3</a></sup></h2><ol><li><p>梯度数值解（梯度校验）</p><script type="math/tex; mode=display">\frac{df(x)}{dx} = \lim_{h\ \to 0} \frac{f(x + h) - f(x)}{h}</script><p>$[f(x+h) - f(x-h)] / 2 h$ 是一种更好的实现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">eval_numerical_gradient</span><span class="params">(f, x)</span>:</span></span><br><span class="line">  <span class="string">""" </span></span><br><span class="line"><span class="string">  a naive implementation of numerical gradient of f at x </span></span><br><span class="line"><span class="string">  - f should be a function that takes a single argument</span></span><br><span class="line"><span class="string">  - x is the point (numpy array) to evaluate the gradient at</span></span><br><span class="line"><span class="string">  """</span> </span><br><span class="line"></span><br><span class="line">  fx = f(x) <span class="comment"># evaluate function value at original point</span></span><br><span class="line">  grad = np.zeros(x.shape)</span><br><span class="line">  h = <span class="number">0.00001</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># iterate over all indexes in x</span></span><br><span class="line">  it = np.nditer(x, flags=[<span class="string">'multi_index'</span>], op_flags=[<span class="string">'readwrite'</span>])</span><br><span class="line">  <span class="keyword">while</span> <span class="keyword">not</span> it.finished:</span><br><span class="line"></span><br><span class="line">    <span class="comment"># evaluate function at x+h</span></span><br><span class="line">    ix = it.multi_index</span><br><span class="line">    old_value = x[ix]</span><br><span class="line">    x[ix] = old_value + h <span class="comment"># increment by h</span></span><br><span class="line">    fxh = f(x) <span class="comment"># evalute f(x + h)</span></span><br><span class="line">    x[ix] = old_value <span class="comment"># restore to previous value (very important!)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute the partial derivative</span></span><br><span class="line">    grad[ix] = (fxh - fx) / h <span class="comment"># the slope</span></span><br><span class="line">    it.iternext() <span class="comment"># step to next dimension</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> grad</span><br></pre></td></tr></table></figure></li><li><p>当适应SVM代价函数：</p><script type="math/tex; mode=display">L_i = \sum_{j\neq y_i} \left[ \max(0, w_j^Tx_i - w_{y_i}^Tx_i + \Delta) \right]</script><p>代价函数关于权重的偏导为：</p><script type="math/tex; mode=display">\nabla_{w_{y_i}} L_i = - \left( \sum_{j\neq y_i} \mathbb{1}(w_j^Tx_i - w_{y_i}^Tx_i + \Delta > 0) \right) x_i</script><script type="math/tex; mode=display">\nabla_{w_j} L_i = \mathbb{1}(w_j^Tx_i - w_{y_i}^Tx_i + \Delta > 0) x_i</script></li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote id="fn_2"><sup>2</sup>. <a href="http://cs231n.github.io/linear-classify/" target="_blank" rel="noopener">CS231n Notes:linear classify</a><a href="#reffn_2" title="Jump back to footnote [2] in the text."> &#8617;</a></blockquote><blockquote id="fn_3"><sup>3</sup>. <a href="http://cs231n.github.io/optimization-1/" target="_blank" rel="noopener">CS231n Notes:Optimization</a><a href="#reffn_3" title="Jump back to footnote [3] in the text."> &#8617;</a></blockquote><blockquote id="fn_4"><sup>4</sup>. <a href="http://cs229.stanford.edu/notes/cs229-notes3.pdf" target="_blank" rel="noopener">CS229 Lecture Notes: SVM</a><a href="#reffn_4" title="Jump back to footnote [4] in the text."> &#8617;</a></blockquote><blockquote id="fn_5"><sup>5</sup>. <a href="http://arxiv.org/abs/1306.0239" target="_blank" rel="noopener">Deep Learning using Linear Support Vector Machines</a> from Charlie Tang 2013 presents some results claiming that the L2SVM outperforms Softmax.<a href="#reffn_5" title="Jump back to footnote [5] in the text."> &#8617;</a></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 计划花一个月的时间刷一遍斯坦福的机器视觉课程cs231n，并做笔记记录每天学习到的内容。&lt;/p&gt;
    
    </summary>
    
      <category term="读书笔记" scheme="http://blog.a-stack.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="课程笔记" scheme="http://blog.a-stack.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="机器视觉" scheme="http://blog.a-stack.com/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
      <category term="笔记" scheme="http://blog.a-stack.com/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>cs231n课程笔记:（Lecture 2）图像分类</title>
    <link href="http://blog.a-stack.com/2018/05/03/cs231n-lecture-2/"/>
    <id>http://blog.a-stack.com/2018/05/03/cs231n-lecture-2/</id>
    <published>2018-05-03T08:50:26.000Z</published>
    <updated>2018-05-16T13:59:22.970Z</updated>
    
    <content type="html"><![CDATA[<p><strong>摘要：</strong> 计划花一个月的时间刷一遍斯坦福的机器视觉课程cs231n，并做笔记记录每天学习到的内容。</p><!-- excerpt --><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>cs231n是斯坦福在深度学习和机器视觉领域的入门经典课程，相关资源如下：</p><ul><li>课程主页： <a href="http://cs231n.stanford.edu/" target="_blank" rel="noopener">http://cs231n.stanford.edu/</a></li><li>课程Notes：<a href="http://cs231n.github.io/" target="_blank" rel="noopener">http://cs231n.github.io/</a></li></ul><div class="table-container"><table><thead><tr><th>Event Type</th><th>Date</th><th>Description</th><th>Course Materials</th></tr></thead><tbody><tr><td>Lecture 2</td><td>Thursday April 5</td><td><strong>Image Classification</strong> The data-driven approach K-nearest neighbor Linear classification I</td><td><a href="http://cs231n.stanford.edu/slides/2018/cs231n_2018_lecture02.pdf" target="_blank" rel="noopener">[slides]</a> <a href="http://cs231n.github.io/python-numpy-tutorial" target="_blank" rel="noopener">[python/numpy tutorial]</a><a href="http://cs231n.github.io/classification" target="_blank" rel="noopener">[image classification notes]</a><a href="http://cs231n.github.io/linear-classify" target="_blank" rel="noopener">[linear classification notes]</a></td></tr></tbody></table></div><h2 id="Python-Numpy-Tutorial"><a href="#Python-Numpy-Tutorial" class="headerlink" title="Python/Numpy Tutorial"></a>Python/Numpy Tutorial</h2><ul><li>Note that unlike many languages, Python does not have unary increment (<code>x++</code>) or decrement (<code>x--</code>) operators.</li><li>字符串操作</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">"hello"</span></span><br><span class="line">print(s.capitalize())  <span class="comment"># Capitalize a string; prints "Hello"</span></span><br><span class="line">print(s.upper())       <span class="comment"># Convert a string to uppercase; prints "HELLO"</span></span><br><span class="line">print(s.rjust(<span class="number">7</span>))      <span class="comment"># Right-justify a string, padding with spaces; prints "  hello"</span></span><br><span class="line">print(s.center(<span class="number">7</span>))     <span class="comment"># Center a string, padding with spaces; prints " hello "</span></span><br><span class="line">print(s.replace(<span class="string">'l'</span>, <span class="string">'(ell)'</span>))  <span class="comment"># Replace all instances of one substring with another;</span></span><br><span class="line">                                <span class="comment"># prints "he(ell)(ell)o"</span></span><br><span class="line">print(<span class="string">'  world '</span>.strip())  <span class="comment"># Strip leading and trailing whitespace; prints "world"</span></span><br></pre></td></tr></table></figure><ul><li>List操作</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nums = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">even_squares = [x ** <span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> nums <span class="keyword">if</span> x % <span class="number">2</span> == <span class="number">0</span>]</span><br><span class="line">print(even_squares)  <span class="comment"># Prints "[0, 4, 16]"</span></span><br></pre></td></tr></table></figure><ul><li>字典操作</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">d = &#123;<span class="string">'person'</span>: <span class="number">2</span>, <span class="string">'cat'</span>: <span class="number">4</span>, <span class="string">'spider'</span>: <span class="number">8</span>&#125;</span><br><span class="line"><span class="keyword">for</span> animal, legs <span class="keyword">in</span> d.items():</span><br><span class="line">    print(<span class="string">'A %s has %d legs'</span> % (animal, legs))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nums = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">even_num_to_square = &#123;x: x ** <span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> nums <span class="keyword">if</span> x % <span class="number">2</span> == <span class="number">0</span>&#125;</span><br></pre></td></tr></table></figure><h3 id="Numpy"><a href="#Numpy" class="headerlink" title="Numpy"></a>Numpy</h3><blockquote><p>更多内容参见：<a href="https://docs.scipy.org/doc/numpy/reference/" target="_blank" rel="noopener">NumPy Reference</a></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数值乘</span></span><br><span class="line">print(x * y)</span><br><span class="line">print(np.multiply(x, y))</span><br><span class="line"><span class="comment"># 矩阵乘</span></span><br><span class="line">print(v.dot(w))</span><br><span class="line">print(np.dot(v, w))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line"></span><br><span class="line">print(np.sum(x))  <span class="comment"># Compute sum of all elements; prints "10"</span></span><br><span class="line">print(np.sum(x, axis=<span class="number">0</span>))  <span class="comment"># Compute sum of each column; prints "[4 6]"</span></span><br><span class="line">print(np.sum(x, axis=<span class="number">1</span>))  <span class="comment"># Compute sum of each row; prints "[3 7]"</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#转置</span></span><br><span class="line">x.T</span><br></pre></td></tr></table></figure><h2 id="SciPy"><a href="#SciPy" class="headerlink" title="SciPy"></a>SciPy</h2><blockquote><p>更多内容参见: <a href="https://docs.scipy.org/doc/scipy/reference/index.html" target="_blank" rel="noopener">SciPy Tutorial</a></p></blockquote><h3 id="Image-Operations"><a href="#Image-Operations" class="headerlink" title="Image Operations"></a>Image Operations</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Image Operations</span></span><br><span class="line"><span class="keyword">from</span> scipy.misc <span class="keyword">import</span> imread, imsave, imresize</span><br><span class="line"></span><br><span class="line"><span class="comment"># Read an JPEG image into a numpy array</span></span><br><span class="line">img = imread(<span class="string">'assets/cat.jpg'</span>)</span><br><span class="line">print(img.dtype, img.shape)  <span class="comment"># Prints "uint8 (400, 248, 3)"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># We can tint the image by scaling each of the color channels</span></span><br><span class="line"><span class="comment"># by a different scalar constant. The image has shape (400, 248, 3);</span></span><br><span class="line"><span class="comment"># we multiply it by the array [1, 0.95, 0.9] of shape (3,);</span></span><br><span class="line"><span class="comment"># numpy broadcasting means that this leaves the red channel unchanged,</span></span><br><span class="line"><span class="comment"># and multiplies the green and blue channels by 0.95 and 0.9</span></span><br><span class="line"><span class="comment"># respectively.</span></span><br><span class="line">img_tinted = img * [<span class="number">1</span>, <span class="number">0.95</span>, <span class="number">0.9</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Resize the tinted image to be 300 by 300 pixels.</span></span><br><span class="line">img_tinted = imresize(img_tinted, (<span class="number">300</span>, <span class="number">300</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Write the tinted image back to disk</span></span><br><span class="line">imsave(<span class="string">'assets/cat_tinted.jpg'</span>, img_tinted)</span><br></pre></td></tr></table></figure><h3 id="Distance-between-points"><a href="#Distance-between-points" class="headerlink" title="Distance between points"></a>Distance between points</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.spatial.distance <span class="keyword">import</span> pdist, squareform</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the following array where each row is a point in 2D space:</span></span><br><span class="line"><span class="comment"># [[0 1]</span></span><br><span class="line"><span class="comment">#  [1 0]</span></span><br><span class="line"><span class="comment">#  [2 0]]</span></span><br><span class="line">x = np.array([[<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">2</span>, <span class="number">0</span>]])</span><br><span class="line">print(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the Euclidean distance between all rows of x.</span></span><br><span class="line"><span class="comment"># d[i, j] is the Euclidean distance between x[i, :] and x[j, :],</span></span><br><span class="line"><span class="comment"># and d is the following array:</span></span><br><span class="line"><span class="comment"># [[ 0.          1.41421356  2.23606798]</span></span><br><span class="line"><span class="comment">#  [ 1.41421356  0.          1.        ]</span></span><br><span class="line"><span class="comment">#  [ 2.23606798  1.          0.        ]]</span></span><br><span class="line">d = squareform(pdist(x, <span class="string">'euclidean'</span>))</span><br><span class="line">print(d)</span><br></pre></td></tr></table></figure><h2 id="图像分类-Notes1"><a href="#图像分类-Notes1" class="headerlink" title="图像分类 Notes1"></a>图像分类 Notes<sup><a href="#fn_1" id="reffn_1">1</a></sup></h2><p><img src="/qnsource/images/2018-04-28-cs231n-notes/classify.png" alt="classify"></p><blockquote><p>The task in Image Classification is to predict a single label (or a distribution over labels as shown here to indicate our confidence) for a given image. Images are 3-dimensional arrays of integers from 0 to 255, of size Width x Height x 3. The 3 represents the three color channels Red, Green, Blue.</p></blockquote><p><strong>面临的挑战：</strong></p><ul><li><strong>不同视角</strong>. A single instance of an object can be oriented in many ways with respect to the camera.</li><li><strong>尺寸变换</strong>. Visual classes often exhibit variation in their size (size in the real world, not only in terms of their extent in the image).</li><li><strong>变形</strong>. Many objects of interest are not rigid bodies and can be deformed in extreme ways.</li><li><strong>遮挡</strong>. The objects of interest can be occluded. Sometimes only a small portion of an object (as little as few pixels) could be visible.</li><li><strong>不同光照条件</strong>. The effects of illumination are drastic on the pixel level.</li><li><strong>背景干扰</strong>. The objects of interest may <em>blend</em> into their environment, making them hard to identify.</li><li><strong>类内差异</strong>. The classes of interest can often be relatively broad, such as <em>chair</em>. There are many different types of these objects, each with their own appearance.</li></ul><p><img src="/qnsource/images/2018-04-28-cs231n-notes/challenges.jpeg" alt="challenges"></p><blockquote><p><strong>Semantic Gap</strong>: 语义鸿沟，对于人类而言，图像分类十分简答，但对于计算机系统从像素中提取特征特别难。</p></blockquote><h3 id="数据驱动的方式来实现图像分类"><a href="#数据驱动的方式来实现图像分类" class="headerlink" title="数据驱动的方式来实现图像分类"></a>数据驱动的方式来实现图像分类</h3><blockquote><p><a href="http://vision.stanford.edu/teaching/cs231n-demos/knn/" target="_blank" rel="noopener">KNN Demo</a></p></blockquote><p>传统特征提取方法很难有质的提升和泛化的性能，尤其直接根据特征进行分类，不如利用大量标记数据训练一个模型，然后利用该模型对未知数据进行预测。</p><h3 id="近邻优化算法处理图像分类"><a href="#近邻优化算法处理图像分类" class="headerlink" title="近邻优化算法处理图像分类"></a>近邻优化算法处理图像分类</h3><ol><li>在训练阶段，NN什么都不做，知识把训练数据加载到内存中；$O(1)$</li><li>预测阶段，将未知数据与所有训练数据进行比较，取最近距离的图像所在的类别作为预测类别；$O(N)$</li></ol><p><strong>缺点：</strong> </p><ul><li>计算量大(每预测一个图片都需要与所有训练数据计算一遍距离)，准确率低（~40%准确率在 CIFAR-10）；</li><li>图像的三维特征和边缘特性，导致仅从像素力度上很难进行比对，维度越好，NN算法就越无能为力</li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote id="fn_1"><sup>1</sup>. <a href="http://cs231n.github.io/classification/" target="_blank" rel="noopener">CS231n Notes:Classification</a><a href="#reffn_1" title="Jump back to footnote [1] in the text."> &#8617;</a></blockquote><blockquote id="fn_2"><sup>2</sup>. <a href="http://cs231n.github.io/linear-classify/" target="_blank" rel="noopener">CS231n Notes:linear classify</a><a href="#reffn_2" title="Jump back to footnote [2] in the text."> &#8617;</a></blockquote><blockquote id="fn_3"><sup>3</sup>. <a href="https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf" target="_blank" rel="noopener">A Few Useful Things to Know About Machine Learning</a><a href="#reffn_3" title="Jump back to footnote [3] in the text."> &#8617;</a></blockquote><blockquote id="fn_4"><sup>4</sup>. <a href="http://cs229.stanford.edu/notes/cs229-notes3.pdf" target="_blank" rel="noopener">CS229 Lecture Notes: SVM</a><a href="#reffn_4" title="Jump back to footnote [4] in the text."> &#8617;</a></blockquote><blockquote id="fn_5"><sup>5</sup>. <a href="http://arxiv.org/abs/1306.0239" target="_blank" rel="noopener">Deep Learning using Linear Support Vector Machines</a> from Charlie Tang 2013 presents some results claiming that the L2SVM outperforms Softmax.<a href="#reffn_5" title="Jump back to footnote [5] in the text."> &#8617;</a></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 计划花一个月的时间刷一遍斯坦福的机器视觉课程cs231n，并做笔记记录每天学习到的内容。&lt;/p&gt;
&lt;!-- excerpt --&gt;
&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title
      
    
    </summary>
    
      <category term="读书笔记" scheme="http://blog.a-stack.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="课程笔记" scheme="http://blog.a-stack.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="机器视觉" scheme="http://blog.a-stack.com/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
      <category term="笔记" scheme="http://blog.a-stack.com/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习圣经</title>
    <link href="http://blog.a-stack.com/2018/04/30/Holy-Bible-of-Machine-Learning/"/>
    <id>http://blog.a-stack.com/2018/04/30/Holy-Bible-of-Machine-Learning/</id>
    <published>2018-04-30T04:31:21.000Z</published>
    <updated>2018-05-15T09:14:33.416Z</updated>
    
    <content type="html"><![CDATA[<p><strong>摘要：</strong> 机器学习中充满很多难以理解的技巧和方法，姑且利用摄影中无忌77条那样的摄影圣经来称之为机器学习圣经吧。<br><a id="more"></a></p><p>@[toc]</p><p>这篇文章的内容主要来自Pedro Domingos的论文《A Few Useful Things to Know About Machine Learning》<sup><a href="#fn_1" id="reffn_1">1</a></sup> ，作为一篇读书笔记。同时Pedro也是畅销书《The Master Algorithm》（中文译为《终极算法:机器学习和人工智能如何重塑世界》）的作者。</p><p>机器学习中充满很多难以理解的技巧和方法，Pedro称之为<code>black art</code>，姑且利用摄影中无忌77条那样的摄影圣经来称之为机器学习圣经吧。</p><h2 id="机器学习圣经1"><a href="#机器学习圣经1" class="headerlink" title="机器学习圣经1"></a>机器学习圣经<sup><a href="#fn_1" id="reffn_1">1</a></sup></h2><blockquote><p>《The Master Algorithm》的作者</p></blockquote><ol><li><strong>学习=表示+评价+优化</strong> (Learning = Representation + Evaluation + optimization)</li></ol><p><img src="/qnsource/images/2018-04-28-cs231n-notes/machine_learning_1.png" alt="machine_learning"></p><ol><li><p><strong>泛化</strong></p><p>模型的泛化性能是机器学习算法追求的最终目标。所有设计良好的训练数据、验证数据和测试数据尤为关键。在早期的机器学习系统中，由于学习器学到的模型表示十分有限，所以训练集和测试集的误差不是十分显现。</p></li><li><p><strong>只有数据还不够</strong></p><p>​除了数据，我们还需要知识（归纳+推理）和假设（一致性、同分布、独立性），来实现模型的泛化特征。</p></li><li><p><strong>过拟合的多个方面</strong></p><ul><li>bias和variance</li></ul></li></ol><blockquote><p>Bias is a learner’s tendency to consistently learn the same wrong thing. Variance is the tendency to learn random things irrespective of the real signal.</p></blockquote><p><img src="/qnsource/images/2018-04-28-cs231n-notes/bias_variance.png" alt="bias_variance"></p><ol><li><p><strong>维度灾难</strong></p><p>随着维度增加，数据之间差异会变小，泛化将指数级的变难。</p></li><li><p><strong>理论上的保证</strong></p><p>归纳与演绎；</p><p><strong>边界保证</strong>，给定一个足够大的训练集，告诉你在很大的概率上你的学习器会返回一个成功泛化的假设，还是无法找到一个保持正确的假设。</p><p><strong>渐进保证</strong>是，给定无穷数据，学习器将保证输出正确的分类器。</p><p>机器学习中理论保证的主要作用并不是在实践中作为决策的标准，最多是在算法设计时给些提示。</p></li><li><p><strong>特征工程</strong></p><p>特征工程之所以比学习还要复杂，是因为它是和领域相关的，机器学习算法是通用的。</p></li><li><p><strong>更多的数据绝对比一个更好的算法有效</strong></p><p>问题的本质其实是时间、计算资源和数据，哪个是瓶颈的问题。本质的瓶颈是人力！</p><p>没有免费午餐定律告诉我们，只要数据充分，简单的算法也可以实现和复杂算法等效的效果。</p></li><li><p><strong>模型组合</strong></p><p>与尝试N多模型，选择其中最好的相比，组合多个不同的模型（model ensembles）效果往往更好。常见组合有bagging，boosting，stacking。模型组合与贝叶斯模型平均的区别：在贝叶斯模型平均方法中，对新样例的预测是对假设空间中的所有分类器的预测取平均得到的，每个分类器会根据它解释训练数据的能力和我们对它的先验信任度而有不同的权重。模型组合修改了假设空间；贝叶斯模型平均给假设空间添加固定的权重。</p></li></ol><blockquote><p><strong>Jensen’s Inequality</strong>，简森不等式提供了理论依据</p></blockquote><ol><li><p><strong>简单 $\neq$ 准确</strong></p><p>著名的奥坎姆剃刀（<strong>occam’s razor</strong>）原理称：若无必要，勿增实体（entities should not be multi-plied beyond necessity）。但并非总是简单的模型可以获得更好的泛化性能，比如模型组合是在增加模型复杂度换取更好的准确率。模型参数的数量和过拟合之间并无直接的联系。奥坎姆最初的意思是说，开始的时候选择简单的假设，可以修正它，直到效果理想。但是不要一开始从复杂的做起，而不是说要找简单作为最终的学习器。</p></li><li><p><strong>可表示 $\neq$ 可学习</strong></p><p>神经网络的万有逼近原理描述了只需要一个隐层，神经网络可以近似表示所有的函数形式。但一个函数可以被表示并不代表着它可以被很好的学习到。即使假设空间中真实存在这个函数，由于假设空间的范围之大，在有限数据、时间和计算资源的情况下，一般学习算法只能覆盖其中一个子集，在这个子集空间中是否有目标函数，往往跟你采用的表示方法有关。</p><p>这告诉我们，采用不同的表示方法，我们可能需要花费不同的代价（使用更少的数据）来学习到目标函数。很多学习器的工作机制正式将简单的基函数进行线性组合，来降低算法复杂度。</p></li><li><p><strong>相关性 $\neq$ 因果性</strong></p><p>利用机器学习模型进行预测的前提是数据之间的因果性体现而非变量的相关性。​机器学习是基于<strong>观测数据</strong>，而观测数据中是否含有可预测变量是不可控的，这点跟基于<strong>实验数据</strong>的结论不同。因此，如果你能尽量多的获得实验数据，那充分准备足够的实验数据。一般我们认为，数据的相关性是潜在因果性的标志，但因果性是否真的存在没有坚实的依据。</p></li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote id="fn_1"><sup>1</sup>. <a href="https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf" target="_blank" rel="noopener">A Few Useful Things to Know About Machine Learning</a><a href="#reffn_1" title="Jump back to footnote [1] in the text."> &#8617;</a></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 机器学习中充满很多难以理解的技巧和方法，姑且利用摄影中无忌77条那样的摄影圣经来称之为机器学习圣经吧。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://blog.a-stack.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="技巧" scheme="http://blog.a-stack.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="人工智能" scheme="http://blog.a-stack.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="机器学习" scheme="http://blog.a-stack.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Everything-About-SVM</title>
    <link href="http://blog.a-stack.com/2018/04/29/Everything-About-SVM/"/>
    <id>http://blog.a-stack.com/2018/04/29/Everything-About-SVM/</id>
    <published>2018-04-29T13:13:40.000Z</published>
    <updated>2018-05-15T09:14:33.431Z</updated>
    
    <content type="html"><![CDATA[<p><strong>摘要：</strong></p><a id="more"></a><p>@[toc]</p><p>支持向量机SVM，是一种二类分类模型，是定义在特征空间上的间隔最大化化线性分类器，可形式化为求解凸二次规划问题，也等价于正则化的合页损失函数最小化问题。主要涉及如下关键知识点需要后续进一步整理：</p><ul><li>线性可分的支持向量机</li><li>线性支持向量机</li><li>非线性支持向量机</li><li>间隔最大化问题<ul><li>硬间隔最大化</li><li>软间隔最大化</li></ul></li><li>核技巧、核函数、核方法</li><li>Hinge Loss</li><li>快速学习算法——SMO（最小最优化算法）</li><li>多分类问题</li></ul><p>感知机利用误分类最小的策略，求得分离超平面，这时解有无穷多个。线性可分支持向量机利用间隔最大化求得最优分离超平面，这时解是唯一的。</p><p><img src="/qnsource/images/2018-04-29-Everything-About-SVM/SVM_classify.jpg" alt="SVM_classify"></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li>李航，《最统计学习方法》</li><li><a href="http://cs229.stanford.edu/notes/cs229-notes3.pdf" target="_blank" rel="noopener">CS229 Lecture Notes: SVM</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzU4MjQ3MDkwNA==&amp;mid=2247483937&amp;idx=1&amp;sn=84a5acf12e96727b13fd7d456c414c12&amp;chksm=fdb69fb6cac116a02dc68d948958ee731a4ae2b6c3d81196822b665224d9dab21d0f2fccb329&amp;mpshare=1&amp;scene=1&amp;srcid=0510Na4PFa34SpaWZ6pgpBEi#rd" target="_blank" rel="noopener">用一张图理解SVM的脉络</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://blog.a-stack.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="文献" scheme="http://blog.a-stack.com/tags/%E6%96%87%E7%8C%AE/"/>
    
      <category term="支持向量机" scheme="http://blog.a-stack.com/tags/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/"/>
    
  </entry>
  
  <entry>
    <title>《机器学习》课程实验回顾</title>
    <link href="http://blog.a-stack.com/2018/04/26/machinelearning-labs/"/>
    <id>http://blog.a-stack.com/2018/04/26/machinelearning-labs/</id>
    <published>2018-04-26T05:56:28.000Z</published>
    <updated>2018-05-15T09:14:33.479Z</updated>
    
    <content type="html"><![CDATA[<p><strong>摘要：</strong> Cousera上机器学习课程提供了八个实验作业，使用MATLAB进行动手实验，熟悉相关技术，本文对实验中的关键内容进行总结归纳，方便以后及时查找。</p><!-- excerpt --><h2 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h2><ul><li>可以使用Matlab Online进行代码测试，<a href="https://matlab.mathworks.com/" target="_blank" rel="noopener">地址</a>;</li><li>相关代码已经传输至Github： <a href="https://github.com/ddebby/machine_learning_cousera.git" target="_blank" rel="noopener">https://github.com/ddebby/machine_learning_cousera.git</a></li></ul><h2 id="Lab1-线性回归"><a href="#Lab1-线性回归" class="headerlink" title="Lab1: 线性回归"></a>Lab1: 线性回归</h2><h3 id="1-简单线性回归"><a href="#1-简单线性回归" class="headerlink" title="1. 简单线性回归"></a>1. 简单线性回归</h3><p>在第一个实验中提供了单变量线性回归的数据用来预测快餐车的盈利情况，其中输入为城市中的人口信息，输出为该城市快餐车的盈利情况，数据分布情况详见下图：</p><p><img src="/qnsource/images/2018-04-25-machine-learning-notes/linear_regression_01.jpg" alt="linear_regression_01"></p><h4 id="代价函数和梯度更新实现"><a href="#代价函数和梯度更新实现" class="headerlink" title="代价函数和梯度更新实现"></a>代价函数和梯度更新实现</h4><p>计算代价函数 <code>computeCost.m</code> </p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">J</span> = <span class="title">computeCost</span><span class="params">(X, y, theta)</span></span></span><br><span class="line"><span class="comment">%COMPUTECOST Compute cost for linear regression</span></span><br><span class="line"><span class="comment">%   J = COMPUTECOST(X, y, theta) computes the cost of using theta as the</span></span><br><span class="line"><span class="comment">%   parameter for linear regression to fit the data points in X and y</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Initialize some useful values</span></span><br><span class="line">m = <span class="built_in">length</span>(y); <span class="comment">% number of training examples</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% You need to return the following variables correctly </span></span><br><span class="line">J = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% ====================== YOUR CODE HERE ======================</span></span><br><span class="line"><span class="comment">% Instructions: Compute the cost of a particular choice of theta</span></span><br><span class="line"><span class="comment">%               You should set J to the cost.</span></span><br><span class="line">J = <span class="number">1</span>/(<span class="number">2</span>*m) * (X*theta - y)'*(X*theta -y)</span><br><span class="line"><span class="comment">% =========================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>梯度更新 <code>gradientDescent.m</code></p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[theta, J_history]</span> = <span class="title">gradientDescent</span><span class="params">(X, y, theta, alpha, num_iters)</span></span></span><br><span class="line"><span class="comment">%GRADIENTDESCENT Performs gradient descent to learn theta</span></span><br><span class="line"><span class="comment">%   theta = GRADIENTDESCENT(X, y, theta, alpha, num_iters) updates theta by </span></span><br><span class="line"><span class="comment">%   taking num_iters gradient steps with learning rate alpha</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Initialize some useful values</span></span><br><span class="line">m = <span class="built_in">length</span>(y); <span class="comment">% number of training examples</span></span><br><span class="line">J_history = <span class="built_in">zeros</span>(num_iters, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> iter = <span class="number">1</span>:num_iters</span><br><span class="line"></span><br><span class="line">    <span class="comment">% ====================== YOUR CODE HERE ======================</span></span><br><span class="line">    <span class="comment">% Instructions: Perform a single gradient step on the parameter vector</span></span><br><span class="line">    <span class="comment">%               theta. </span></span><br><span class="line">    <span class="comment">%</span></span><br><span class="line">    <span class="comment">% Hint: While debugging, it can be useful to print out the values</span></span><br><span class="line">    <span class="comment">%       of the cost function (computeCost) and gradient here.</span></span><br><span class="line">    <span class="comment">%</span></span><br><span class="line"></span><br><span class="line">    theta = theta - alpha/m * X'*(X*theta - y);</span><br><span class="line"></span><br><span class="line">    <span class="comment">% ============================================================</span></span><br><span class="line">    <span class="comment">% Save the cost J in every iteration    </span></span><br><span class="line">    J_history(iter) = computeCost(X, y, theta);</span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>实现并测试：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">data = load(<span class="string">'ex1data1.txt'</span>);</span><br><span class="line">X = data(:, <span class="number">1</span>); y = data(:, <span class="number">2</span>);</span><br><span class="line">m = <span class="built_in">length</span>(y); <span class="comment">% number of training examples</span></span><br><span class="line"></span><br><span class="line">X = [ones(m, <span class="number">1</span>), data(:,<span class="number">1</span>)]; <span class="comment">% Add a column of ones to x</span></span><br><span class="line">theta = <span class="built_in">zeros</span>(<span class="number">2</span>, <span class="number">1</span>); <span class="comment">% initialize fitting parameters</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Some gradient descent settings</span></span><br><span class="line">iterations = <span class="number">1500</span>;</span><br><span class="line">alpha = <span class="number">0.01</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% compute and display initial cost</span></span><br><span class="line">J = computeCost(X, y, theta);</span><br><span class="line"></span><br><span class="line"><span class="comment">% further testing of the cost function</span></span><br><span class="line">J = computeCost(X, y, [<span class="number">-1</span> ; <span class="number">2</span>]);</span><br><span class="line"></span><br><span class="line"><span class="comment">% run gradient descent</span></span><br><span class="line">theta = gradientDescent(X, y, theta, alpha, iterations);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Plot the linear fit</span></span><br><span class="line">hold on; <span class="comment">% keep previous plot visible</span></span><br><span class="line">plot(X(:,<span class="number">2</span>), X*theta, <span class="string">'-'</span>)</span><br><span class="line">legend(<span class="string">'Training data'</span>, <span class="string">'Linear regression'</span>)</span><br><span class="line">hold off <span class="comment">% don't overlay any more plots on this figure</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Predict values for population sizes of 35,000 and 70,000</span></span><br><span class="line">predict1 = [<span class="number">1</span>, <span class="number">3.5</span>] *theta;</span><br><span class="line">fprintf(<span class="string">'For population = 35,000, we predict a profit of %f\n'</span>,...</span><br><span class="line">    predict1*<span class="number">10000</span>);</span><br><span class="line">predict2 = [<span class="number">1</span>, <span class="number">7</span>] * theta;</span><br><span class="line">fprintf(<span class="string">'For population = 70,000, we predict a profit of %f\n'</span>,...</span><br><span class="line">    predict2*<span class="number">10000</span>);</span><br></pre></td></tr></table></figure><p><img src="/qnsource/images/2018-04-25-machine-learning-notes/linear_regression_02.jpg" alt="linear_regression_02"></p><h4 id="J-theta-的可视化"><a href="#J-theta-的可视化" class="headerlink" title="$J(\theta)$ 的可视化"></a>$J(\theta)$ 的可视化</h4><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% ============= Part 4: Visualizing J(theta_0, theta_1) =============</span></span><br><span class="line">fprintf(<span class="string">'Visualizing J(theta_0, theta_1) ...\n'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">% Grid over which we will calculate J</span></span><br><span class="line">theta0_vals = <span class="built_in">linspace</span>(<span class="number">-10</span>, <span class="number">10</span>, <span class="number">100</span>);</span><br><span class="line">theta1_vals = <span class="built_in">linspace</span>(<span class="number">-1</span>, <span class="number">4</span>, <span class="number">100</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% initialize J_vals to a matrix of 0's</span></span><br><span class="line">J_vals = <span class="built_in">zeros</span>(<span class="built_in">length</span>(theta0_vals), <span class="built_in">length</span>(theta1_vals));</span><br><span class="line"></span><br><span class="line"><span class="comment">% Fill out J_vals</span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:<span class="built_in">length</span>(theta0_vals)</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">1</span>:<span class="built_in">length</span>(theta1_vals)</span><br><span class="line">  t = [theta0_vals(i); theta1_vals(j)];</span><br><span class="line">  J_vals(<span class="built_in">i</span>,<span class="built_in">j</span>) = computeCost(X, y, t);</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Because of the way meshgrids work in the surf command, we need to</span></span><br><span class="line"><span class="comment">% transpose J_vals before calling surf, or else the axes will be flipped</span></span><br><span class="line">J_vals = J_vals';</span><br><span class="line"><span class="comment">% Surface plot</span></span><br><span class="line">figure;</span><br><span class="line">surf(theta0_vals, theta1_vals, J_vals)</span><br><span class="line">xlabel(<span class="string">'\theta_0'</span>); ylabel(<span class="string">'\theta_1'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Contour plot</span></span><br><span class="line">figure;</span><br><span class="line"><span class="comment">% Plot J_vals as 15 contours spaced logarithmically between 0.01 and 100</span></span><br><span class="line">contour(theta0_vals, theta1_vals, J_vals, <span class="built_in">logspace</span>(<span class="number">-2</span>, <span class="number">3</span>, <span class="number">20</span>))</span><br><span class="line">xlabel(<span class="string">'\theta_0'</span>); ylabel(<span class="string">'\theta_1'</span>);</span><br><span class="line">hold on;</span><br><span class="line">plot(theta(<span class="number">1</span>), theta(<span class="number">2</span>), <span class="string">'rx'</span>, <span class="string">'MarkerSize'</span>, <span class="number">10</span>, <span class="string">'LineWidth'</span>, <span class="number">2</span>);</span><br></pre></td></tr></table></figure><p><img src="/qnsource/images/2018-04-25-machine-learning-notes/linear_regression_03.jpg" alt="linear_regression_03"></p><p><img src="/qnsource/images/2018-04-25-machine-learning-notes/linear_regression_04.jpg" alt="linear_regression_04"></p><h3 id="2-多元线性回归"><a href="#2-多元线性回归" class="headerlink" title="2. 多元线性回归"></a>2. 多元线性回归</h3><p>利用多元线性回归预测房价，输入的特征包括房子大小、房间数目，输出为房子价格。</p><h3 id="2-1-特征归一化"><a href="#2-1-特征归一化" class="headerlink" title="2.1 特征归一化"></a>2.1 特征归一化</h3><p><code>featureNormalize.m</code></p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[X_norm, mu, sigma]</span> = <span class="title">featureNormalize</span><span class="params">(X)</span></span></span><br><span class="line"><span class="comment">%FEATURENORMALIZE Normalizes the features in X </span></span><br><span class="line"><span class="comment">%   FEATURENORMALIZE(X) returns a normalized version of X where</span></span><br><span class="line"><span class="comment">%   the mean value of each feature is 0 and the standard deviation</span></span><br><span class="line"><span class="comment">%   is 1. This is often a good preprocessing step to do when</span></span><br><span class="line"><span class="comment">%   working with learning algorithms.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% You need to set these values correctly</span></span><br><span class="line">X_norm = X;</span><br><span class="line">mu = <span class="built_in">zeros</span>(<span class="number">1</span>, <span class="built_in">size</span>(X, <span class="number">2</span>));</span><br><span class="line">sigma = <span class="built_in">zeros</span>(<span class="number">1</span>, <span class="built_in">size</span>(X, <span class="number">2</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">% ====================== YOUR CODE HERE ======================</span></span><br><span class="line"><span class="comment">%       </span></span><br><span class="line">mu = mean(X,<span class="number">1</span>);</span><br><span class="line">sigma = std(X,<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">X_norm = (X - mu)./sigma;</span><br><span class="line"><span class="comment">% ============================================================</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><ul><li>The <code>bsxfun</code> is helpful for applying a function (limited to two arguments) in an element-wise fashion to rows of a matrix using a vector of source values. This is useful for feature normalization. An example you can enter at the octave command line:</li></ul><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Z=[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span>; <span class="number">2</span> <span class="number">2</span> <span class="number">2</span>;];</span><br><span class="line"></span><br><span class="line">v=[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span>];</span><br><span class="line"></span><br><span class="line"><span class="built_in">bsxfun</span>(@minus,Z,v);</span><br><span class="line"></span><br><span class="line"><span class="built_in">ans</span> =</span><br><span class="line"></span><br><span class="line">    <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="number">1</span>   <span class="number">1</span>   <span class="number">1</span></span><br></pre></td></tr></table></figure><ul><li>In this case, the corresponding elements of v are subtracted from each row of Z. The minus(a,b) function is equivalent to computing (a-b).</li></ul><ul><li>代价函数和梯度更新与简单线性回归相同；</li></ul><h3 id="2-2-计算-theta-的数值解"><a href="#2-2-计算-theta-的数值解" class="headerlink" title="2.2 计算 $\theta$ 的数值解"></a>2.2 计算 $\theta$ 的数值解</h3><p><code>normalEqn.m</code></p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[theta]</span> = <span class="title">normalEqn</span><span class="params">(X, y)</span></span></span><br><span class="line"><span class="comment">%NORMALEQN Computes the closed-form solution to linear regression </span></span><br><span class="line"><span class="comment">%   NORMALEQN(X,y) computes the closed-form solution to linear </span></span><br><span class="line"><span class="comment">%   regression using the normal equations.</span></span><br><span class="line"></span><br><span class="line">theta = <span class="built_in">zeros</span>(<span class="built_in">size</span>(X, <span class="number">2</span>), <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% ====================== YOUR CODE HERE ======================</span></span><br><span class="line"><span class="comment">% Instructions: Complete the code to compute the closed form solution</span></span><br><span class="line"><span class="comment">%               to linear regression and put the result in theta.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% ---------------------- Sample Solution ----------------------</span></span><br><span class="line">theta = pinv(X'*X)*X'*y;</span><br><span class="line"></span><br><span class="line"><span class="comment">% -------------------------------------------------------------</span></span><br><span class="line"><span class="comment">% ============================================================</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h2 id="Lab-2-Lab-5"><a href="#Lab-2-Lab-5" class="headerlink" title="Lab 2 - Lab 5:"></a>Lab 2 - Lab 5:</h2><blockquote><p>留作后续更新 …</p></blockquote><h2 id="Lab-6-SVM"><a href="#Lab-6-SVM" class="headerlink" title="Lab 6: SVM"></a>Lab 6: SVM</h2><p>本实验利用SVM实现非线性分类器，核函数选择高斯核函数，高斯核函数的定义如下：</p><script type="math/tex; mode=display">K_{gaussian}(x^{(i)},x^{(j)}) = exp(-\frac{||x^{(i)}-x^{(j)}||^2}{2\sigma^2})</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% ========== Part 5: Training SVM with RBF Kernel (Dataset 2) ==========</span></span><br><span class="line"><span class="comment">%  After you have implemented the kernel, we can now use it to train the </span></span><br><span class="line"><span class="comment">%  SVM classifier.</span></span><br><span class="line"><span class="comment">% </span></span><br><span class="line">load(<span class="string">'ex6data2.mat'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% SVM Parameters</span></span><br><span class="line">C = <span class="number">1</span>; sigma = <span class="number">0.1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% We set the tolerance and max_passes lower here so that the code will run</span></span><br><span class="line"><span class="comment">% faster. However, in practice, you will want to run the training to</span></span><br><span class="line"><span class="comment">% convergence.</span></span><br><span class="line">model= svmTrain(X, y, C, @(x1, x2) gaussianKernel(x1, x2, sigma)); </span><br><span class="line">visualizeBoundary(X, y, model);</span><br></pre></td></tr></table></figure><blockquote><p>由于目前scikit-learn库对各种SVM算法都有比较好的封装，所以也不在进一步深究matlab的实现了。</p></blockquote><h2 id="Lab-7-1-K-Means"><a href="#Lab-7-1-K-Means" class="headerlink" title="Lab 7.1: K-Means"></a>Lab 7.1: K-Means</h2><p>本实验使用K-Means进行图像压缩，K-Means算法的基本实现：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% Initialize centroids</span></span><br><span class="line">centroids = kMeansInitCentroids(X, K);</span><br><span class="line"><span class="keyword">for</span> iter = <span class="number">1</span>:iterations</span><br><span class="line">    <span class="comment">% Cluster assignment step: Assign each data point to the</span></span><br><span class="line">    <span class="comment">% closest centroid. idx(i) corresponds to cˆ(i), the index</span></span><br><span class="line">    <span class="comment">% of the centroid assigned to example i</span></span><br><span class="line">    idx = findClosestCentroids(X, centroids);</span><br><span class="line">    <span class="comment">% Move centroid step: Compute means based on centroid</span></span><br><span class="line">    <span class="comment">% assignments</span></span><br><span class="line">    centroids = computeMeans(X, idx, K);</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>在循环中关键实现两个步骤：1）重新划分聚类；2）计算新的均值及中心点</p><ol><li>寻找最近的聚类中心点，并聚类<script type="math/tex; mode=display">c^{(i)}:=j \ that \ minimizes \ ||x^{(i)} - \mu_j ||^2</script></li></ol><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">idx</span> = <span class="title">findClosestCentroids</span><span class="params">(X, centroids)</span></span></span><br><span class="line"><span class="comment">%FINDCLOSESTCENTROIDS computes the centroid memberships for every example</span></span><br><span class="line"><span class="comment">%   idx = FINDCLOSESTCENTROIDS (X, centroids) returns the closest centroids</span></span><br><span class="line"><span class="comment">%   in idx for a dataset X where each row is a single example. idx = m x 1 </span></span><br><span class="line"><span class="comment">%   vector of centroid assignments (i.e. each entry in range [1..K])</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Set K</span></span><br><span class="line">K = <span class="built_in">size</span>(centroids, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% You need to return the following variables correctly.</span></span><br><span class="line">idx = <span class="built_in">zeros</span>(<span class="built_in">size</span>(X,<span class="number">1</span>), <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Instructions: Go over every example, find its closest centroid, and store</span></span><br><span class="line"><span class="comment">%               the index inside idx at the appropriate location.</span></span><br><span class="line"><span class="comment">%               Concretely, idx(i) should contain the index of the centroid</span></span><br><span class="line"><span class="comment">%               closest to example i. Hence, it should be a value in the </span></span><br><span class="line"><span class="comment">%               range 1..K</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% Note: You can use a for-loop over the examples to compute this.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="built_in">size</span>(X,<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">1</span>: <span class="built_in">size</span>(centroids,<span class="number">1</span>)</span><br><span class="line">         dis(<span class="built_in">j</span>) = sum((centroids(<span class="built_in">j</span>, :) - X(<span class="built_in">i</span>, :)) .^ <span class="number">2</span>, <span class="number">2</span>);  </span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    [t,idx(i)] = min(dis);</span><br><span class="line"><span class="keyword">end</span>  </span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><ol><li>更新聚类中心点位置</li></ol><script type="math/tex; mode=display">\mu_k = \frac{1}{|C_k|} \sum_{i \in C_k} x^{(i)}</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">centroids</span> = <span class="title">computeCentroids</span><span class="params">(X, idx, K)</span></span></span><br><span class="line"><span class="comment">%COMPUTECENTROIDS returns the new centroids by computing the means of the </span></span><br><span class="line"><span class="comment">%data points assigned to each centroid.</span></span><br><span class="line"><span class="comment">%   centroids = COMPUTECENTROIDS(X, idx, K) returns the new centroids by </span></span><br><span class="line"><span class="comment">%   computing the means of the data points assigned to each centroid. It is</span></span><br><span class="line"><span class="comment">%   given a dataset X where each row is a single data point, a vector</span></span><br><span class="line"><span class="comment">%   idx of centroid assignments (i.e. each entry in range [1..K]) for each</span></span><br><span class="line"><span class="comment">%   example, and K, the number of centroids. You should return a matrix</span></span><br><span class="line"><span class="comment">%   centroids, where each row of centroids is the mean of the data points</span></span><br><span class="line"><span class="comment">%   assigned to it.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Useful variables</span></span><br><span class="line">[m n] = <span class="built_in">size</span>(X);</span><br><span class="line"></span><br><span class="line"><span class="comment">% You need to return the following variables correctly.</span></span><br><span class="line">centroids = <span class="built_in">zeros</span>(K, n);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:K</span><br><span class="line">    centroids(<span class="built_in">i</span>,:) = mean(X(<span class="built_in">find</span>(idx==<span class="built_in">i</span>),:));</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p><img src="/qnsource/images/2018-04-26-machinelearning-labs/lab7_01.png" alt="lab7_01"></p><p>3.初始起点的随机选取</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% Randomly reorder the indices of examples </span></span><br><span class="line">randidx = randperm(<span class="built_in">size</span>(X, <span class="number">1</span>)); </span><br><span class="line"><span class="comment">% Take the first K examples as centroids </span></span><br><span class="line">centroids = X(randidx(<span class="number">1</span>:K), :);</span><br></pre></td></tr></table></figure><ol><li>使用K-Means压缩图片</li></ol><p>我们将一张24bit的照片，压缩为4-bit（16个色彩）；对于每个像素点，将选择最近的类簇进行颜色表示。通过压缩将128x128x24=393,216bits的图像压缩为16x24 + 128x128x4=65,920bits（其中需要额外每种颜色需要一个24bit空间存储各个颜色字典）。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% ============= Part 4: K-Means Clustering on Pixels ===============</span></span><br><span class="line"><span class="comment">%  In this exercise, you will use K-Means to compress an image. To do this,</span></span><br><span class="line"><span class="comment">%  you will first run K-Means on the colors of the pixels in the image and</span></span><br><span class="line"><span class="comment">%  then you will map each pixel onto its closest centroid.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%  Load an image of a bird</span></span><br><span class="line">A = double(imread(<span class="string">'bird_small.png'</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">% If imread does not work for you, you can try instead</span></span><br><span class="line"><span class="comment">%   load ('bird_small.mat');</span></span><br><span class="line"></span><br><span class="line">A = A / <span class="number">255</span>; <span class="comment">% Divide by 255 so that all values are in the range 0 - 1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Size of the image</span></span><br><span class="line">img_size = <span class="built_in">size</span>(A);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Reshape the image into an Nx3 matrix where N = number of pixels.</span></span><br><span class="line"><span class="comment">% Each row will contain the Red, Green and Blue pixel values</span></span><br><span class="line"><span class="comment">% This gives us our dataset matrix X that we will use K-Means on.</span></span><br><span class="line">X = <span class="built_in">reshape</span>(A, img_size(<span class="number">1</span>) * img_size(<span class="number">2</span>), <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Run your K-Means algorithm on this data</span></span><br><span class="line"><span class="comment">% You should try different values of K and max_iters here</span></span><br><span class="line">K = <span class="number">16</span>; </span><br><span class="line">max_iters = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% When using K-Means, it is important the initialize the centroids</span></span><br><span class="line"><span class="comment">% randomly. </span></span><br><span class="line"><span class="comment">% You should complete the code in kMeansInitCentroids.m before proceeding</span></span><br><span class="line">initial_centroids = kMeansInitCentroids(X, K);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Run K-Means</span></span><br><span class="line">[centroids, idx] = runkMeans(X, initial_centroids, max_iters);</span><br><span class="line"></span><br><span class="line"><span class="comment">%% ================= Part 5: Image Compression ======================</span></span><br><span class="line"><span class="comment">%  In this part of the exercise, you will use the clusters of K-Means to</span></span><br><span class="line"><span class="comment">%  compress an image. To do this, we first find the closest clusters for</span></span><br><span class="line"><span class="comment">%  each example. After that, we </span></span><br><span class="line"><span class="comment">% Find closest cluster members</span></span><br><span class="line">idx = findClosestCentroids(X, centroids);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Essentially, now we have represented the image X as in terms of the</span></span><br><span class="line"><span class="comment">% indices in idx. </span></span><br><span class="line"></span><br><span class="line"><span class="comment">% We can now recover the image from the indices (idx) by mapping each pixel</span></span><br><span class="line"><span class="comment">% (specified by its index in idx) to the centroid value</span></span><br><span class="line">X_recovered = centroids(idx,:);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Reshape the recovered image into proper dimensions</span></span><br><span class="line">X_recovered = <span class="built_in">reshape</span>(X_recovered, img_size(<span class="number">1</span>), img_size(<span class="number">2</span>), <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Display the original image </span></span><br><span class="line">subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>);</span><br><span class="line">imagesc(A); </span><br><span class="line">title(<span class="string">'Original'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Display compressed image side by side</span></span><br><span class="line">subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>);</span><br><span class="line">imagesc(X_recovered)</span><br><span class="line">title(sprintf(<span class="string">'Compressed, with %d colors.'</span>, K));</span><br></pre></td></tr></table></figure><p><img src="/qnsource/images/2018-04-26-machinelearning-labs/lab7_02.png" alt="lab7_02"></p><h2 id="Lab-7-2：-PCA"><a href="#Lab-7-2：-PCA" class="headerlink" title="Lab 7.2： PCA"></a>Lab 7.2： PCA</h2><p>本实验利用PCA实现数据降维及可视化。</p><p><img src="/qnsource/images/2018-04-26-machinelearning-labs/lab7_03.png" alt="lab7_03"></p><ol><li>数据归一化</li><li>计算协方差和奇异值分解</li></ol><script type="math/tex; mode=display">\Sigma =\frac{1}{m}X^TX</script><script type="math/tex; mode=display">[U, S, V] = svd(\Sigma)</script><p><img src="/qnsource/images/2018-04-26-machinelearning-labs/lab7_04.png" alt="lab7_04"></p><ol><li>降维</li></ol><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Z = X * U(:,<span class="number">1</span>:K);</span><br></pre></td></tr></table></figure><ol><li>数据恢复</li></ol><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_rec = Z * U(:,<span class="number">1</span>:K)';</span><br></pre></td></tr></table></figure><p><img src="/qnsource/images/2018-04-26-machinelearning-labs/lab7_05.png" alt="lab7_05"></p><h3 id="数据可视化的降维显示"><a href="#数据可视化的降维显示" class="headerlink" title="数据可视化的降维显示"></a>数据可视化的降维显示</h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% Use PCA to project this cloud to 2D for visualization</span></span><br><span class="line"><span class="comment">% X (16383,3)</span></span><br><span class="line"><span class="comment">% Subtract the mean to use PCA</span></span><br><span class="line">[X_norm, mu, sigma] = featureNormalize(X);</span><br><span class="line"></span><br><span class="line"><span class="comment">% PCA and project the data to 2D</span></span><br><span class="line">[U, S] = pca(X_norm);</span><br><span class="line">Z = projectData(X_norm, U, <span class="number">2</span>);</span><br></pre></td></tr></table></figure><p><img src="/qnsource/images/2018-04-26-machinelearning-labs/lab7_10.png" alt="lab7_10"></p><p><img src="/qnsource/images/2018-04-26-machinelearning-labs/lab7_09.png" alt="lab7_09"></p><h2 id="Lab-8-1-异常检测"><a href="#Lab-8-1-异常检测" class="headerlink" title="Lab 8.1: 异常检测"></a>Lab 8.1: 异常检测</h2><p>本实验搭建一个异常检测系统，用来检测服务器的异常信息，输入为每台服务器的每分钟吞吐(mb/s)和响应延时（ms），数据提供了m=307组样本数据。期望通过非监督学习的手段来检测异常。</p><p><img src="/qnsource/images/2018-04-26-machinelearning-labs/lab8_01.png" alt="lab8_01"></p><p>为了对数据异常进行检测，首先需要将原始数据拟合到一个分布模型里，我们选择使用多元高斯模型进行数据拟合:</p><script type="math/tex; mode=display">p(x;\mu,\Sigma) = \dfrac{1}{(2\pi)^{n/2} |\Sigma|^{1/2}} exp(-1/2(x-\mu)^T\Sigma^{-1}(x-\mu))</script><ol><li>首先需要对参数$\mu$ ,$\sigma$ 进行估计，参见如下代码：</li></ol><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mu = mean(X, <span class="number">1</span>);</span><br><span class="line">sigma2 = var(X, <span class="number">1</span>);</span><br><span class="line">p = multivariateGaussian(X, mu, sigma2);</span><br><span class="line"><span class="comment">%  Visualize the fit</span></span><br><span class="line">visualizeFit(X,  mu, sigma2);</span><br></pre></td></tr></table></figure><p>拟合高斯分布的轮廓图如下：</p><p><img src="/qnsource/images/2018-04-26-machinelearning-labs/lab8_02.png" alt="lab8_02"></p><p>多元高斯分布函数<code>multivariateGaussian()</code>的定义如下：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">p</span> = <span class="title">multivariateGaussian</span><span class="params">(X, mu, Sigma2)</span></span></span><br><span class="line"><span class="comment">%MULTIVARIATEGAUSSIAN Computes the probability density function of the</span></span><br><span class="line"><span class="comment">%multivariate gaussian distribution.</span></span><br><span class="line"><span class="comment">%    p = MULTIVARIATEGAUSSIAN(X, mu, Sigma2) Computes the probability </span></span><br><span class="line"><span class="comment">%    density function of the examples X under the multivariate gaussian </span></span><br><span class="line"><span class="comment">%    distribution with parameters mu and Sigma2. If Sigma2 is a matrix, it is</span></span><br><span class="line"><span class="comment">%    treated as the covariance matrix. If Sigma2 is a vector, it is treated</span></span><br><span class="line"><span class="comment">%    as the \sigma^2 values of the variances in each dimension (a diagonal</span></span><br><span class="line"><span class="comment">%    covariance matrix)</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line">k = <span class="built_in">length</span>(mu);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">size</span>(Sigma2, <span class="number">2</span>) == <span class="number">1</span>) || (<span class="built_in">size</span>(Sigma2, <span class="number">1</span>) == <span class="number">1</span>)</span><br><span class="line">    Sigma2 = <span class="built_in">diag</span>(Sigma2);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">X = <span class="built_in">bsxfun</span>(@minus, X, mu(:)');</span><br><span class="line">p = (<span class="number">2</span> * <span class="built_in">pi</span>) ^ (- k / <span class="number">2</span>) * det(Sigma2) ^ (<span class="number">-0.5</span>) * ...</span><br><span class="line">    <span class="built_in">exp</span>(<span class="number">-0.5</span> * sum(<span class="built_in">bsxfun</span>(@times, X * pinv(Sigma2), X), <span class="number">2</span>));</span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><ol><li>阈值$\epsilon$ 的选择，通过计算每个阈值的F1得分来评价验证集数据，选择最优得分的阈值：</li></ol><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[bestEpsilon bestF1]</span> = <span class="title">selectThreshold</span><span class="params">(yval, pval)</span></span></span><br><span class="line"><span class="comment">%SELECTTHRESHOLD Find the best threshold (epsilon) to use for selecting</span></span><br><span class="line"><span class="comment">%outliers</span></span><br><span class="line"><span class="comment">%   [bestEpsilon bestF1] = SELECTTHRESHOLD(yval, pval) finds the best</span></span><br><span class="line"><span class="comment">%   threshold to use for selecting outliers based on the results from a</span></span><br><span class="line"><span class="comment">%   validation set (pval) and the ground truth (yval).</span></span><br><span class="line"></span><br><span class="line">bestEpsilon = <span class="number">0</span>;</span><br><span class="line">bestF1 = <span class="number">0</span>;</span><br><span class="line">F1 = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">stepsize = (max(pval) - min(pval)) / <span class="number">1000</span>;</span><br><span class="line"><span class="keyword">for</span> epsilon = min(pval):stepsize:max(pval)</span><br><span class="line">    <span class="comment">% Instructions: Compute the F1 score of choosing epsilon as the</span></span><br><span class="line">    <span class="comment">%               threshold and place the value in F1. The code at the</span></span><br><span class="line">    <span class="comment">%               end of the loop will compare the F1 score for this</span></span><br><span class="line">    <span class="comment">%               choice of epsilon and set it to be the best epsilon if</span></span><br><span class="line">    <span class="comment">%               it is better than the current choice of epsilon.</span></span><br><span class="line">    <span class="comment">%               </span></span><br><span class="line">    <span class="comment">% Note: You can use predictions = (pval &lt; epsilon) to get a binary vector</span></span><br><span class="line">    <span class="comment">%       of 0's and 1's of the outlier predictions</span></span><br><span class="line">    cvPredictions = (pval &lt; epsilon);</span><br><span class="line">    fp = sum((cvPredictions == <span class="number">1</span>)&amp; (yval == <span class="number">0</span>));</span><br><span class="line">    tp = sum((cvPredictions == <span class="number">1</span>)&amp;(yval == <span class="number">1</span>));</span><br><span class="line">    fn = sum((cvPredictions == <span class="number">0</span>)&amp;(yval == <span class="number">1</span>));</span><br><span class="line">    </span><br><span class="line">    prec = tp/(tp + fp);</span><br><span class="line">    rec = tp/(tp + fn);</span><br><span class="line"></span><br><span class="line">    F1 = <span class="number">2</span>*prec*rec/(prec + rec);</span><br><span class="line">    <span class="keyword">if</span> F1 &gt; bestF1</span><br><span class="line">       bestF1 = F1;</span><br><span class="line">       bestEpsilon = epsilon;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">pval = multivariateGaussian(Xval, mu, sigma2);</span><br><span class="line">[epsilon F1] = selectThreshold(yval, pval);</span><br></pre></td></tr></table></figure><p><img src="/qnsource/images/2018-04-26-machinelearning-labs/lab8_03.png" alt="lab8_03"></p><ol><li>在更复杂场景下的应用，示例提供了个输入为11维特征的数据，对其异常数据进行预测，代码片段如下：</li></ol><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%  Apply the same steps to the larger dataset</span></span><br><span class="line">[mu sigma2] = estimateGaussian(X);</span><br><span class="line"></span><br><span class="line"><span class="comment">%  Training set </span></span><br><span class="line">p = multivariateGaussian(X, mu, sigma2);</span><br><span class="line"></span><br><span class="line"><span class="comment">%  Cross-validation set</span></span><br><span class="line">pval = multivariateGaussian(Xval, mu, sigma2);</span><br><span class="line"></span><br><span class="line"><span class="comment">%  Find the best threshold</span></span><br><span class="line">[epsilon F1] = selectThreshold(yval, pval);</span><br><span class="line"></span><br><span class="line">fprintf(<span class="string">'Best epsilon found using cross-validation: %e\n'</span>, epsilon);</span><br><span class="line">fprintf(<span class="string">'Best F1 on Cross Validation Set:  %f\n'</span>, F1);</span><br><span class="line">fprintf(<span class="string">'# Outliers found: %d\n\n'</span>, sum(p &lt; epsilon));</span><br></pre></td></tr></table></figure><p>​</p><h2 id="Lab-8-2：推荐系统"><a href="#Lab-8-2：推荐系统" class="headerlink" title="Lab 8.2：推荐系统"></a>Lab 8.2：推荐系统</h2><p>本实验将实现协同过滤算法，并应用到电影推荐之中。数据集来自943个用户的1682部电影的评分数据，每个评分范围为1-5，可以存在多个未评分数据。</p><ul><li>$X$ 为num_movies x num_features，是电影的特征矩阵</li><li>$Y$ 为num_movies x num_user矩阵，描述了每个评分值$y^{(i,j)}$</li><li>$R$ 为与$Y$ 同维度的二值矩阵，$R(i,j)=1$ 代表用户$j$ 对电影$i$ 进行了评分</li></ul><ol><li>代价函数的定义</li></ol><script type="math/tex; mode=display">J(x,\theta) = \dfrac{1}{2} \displaystyle \sum_{(i,j):r(i,j)=1}((\theta^{(j)})^Tx^{(i)} - y^{(i,j)})^2 + \dfrac{\lambda}{2}\sum_{i=1}^{n_m} \sum_{k=1}^{n} (x_k^{(i)})^2 + \dfrac{\lambda}{2}\sum_{j=1}^{n_u} \sum_{k=1}^{n} (\theta_k^{(j)})^2</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[J, grad]</span> = <span class="title">cofiCostFunc</span><span class="params">(params, Y, R, num_users, num_movies, ...</span></span></span><br><span class="line"><span class="function"><span class="params">                                  num_features, lambda)</span></span></span><br><span class="line"><span class="comment">%COFICOSTFUNC Collaborative filtering cost function</span></span><br><span class="line"><span class="comment">%   [J, grad] = COFICOSTFUNC(params, Y, R, num_users, num_movies, ...</span></span><br><span class="line"><span class="comment">%   num_features, lambda) returns the cost and gradient for the</span></span><br><span class="line"><span class="comment">%   collaborative filtering problem.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Unfold the U and W matrices from params</span></span><br><span class="line">X = <span class="built_in">reshape</span>(params(<span class="number">1</span>:num_movies*num_features), num_movies, num_features);</span><br><span class="line">Theta = <span class="built_in">reshape</span>(params(num_movies*num_features+<span class="number">1</span>:<span class="keyword">end</span>), ...</span><br><span class="line">                num_users, num_features);</span><br><span class="line">            </span><br><span class="line"><span class="comment">% You need to return the following values correctly</span></span><br><span class="line">J = <span class="number">0</span>;</span><br><span class="line">X_grad = <span class="built_in">zeros</span>(<span class="built_in">size</span>(X));</span><br><span class="line">Theta_grad = <span class="built_in">zeros</span>(<span class="built_in">size</span>(Theta));</span><br><span class="line"></span><br><span class="line"><span class="comment">% Instructions: Compute the cost function and gradient for collaborative</span></span><br><span class="line"><span class="comment">%               filtering. </span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% Notes: X - num_movies  x num_features matrix of movie features</span></span><br><span class="line"><span class="comment">%        Theta - num_users  x num_features matrix of user features</span></span><br><span class="line"><span class="comment">%        Y - num_movies x num_users matrix of user ratings of movies</span></span><br><span class="line"><span class="comment">%        R - num_movies x num_users matrix, where R(i, j) = 1 if the </span></span><br><span class="line"><span class="comment">%            i-th movie was rated by the j-th user</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% You should set the following variables correctly:</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">%        X_grad - num_movies x num_features matrix, containing the </span></span><br><span class="line"><span class="comment">%                 partial derivatives w.r.t. to each element of X</span></span><br><span class="line"><span class="comment">%        Theta_grad - num_users x num_features matrix, containing the </span></span><br><span class="line"><span class="comment">%                     partial derivatives w.r.t. to each element of Theta</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line">J = <span class="number">1</span>/<span class="number">2</span> * sum(sum(((X * Theta' - Y).*R).^<span class="number">2</span>));</span><br><span class="line"></span><br><span class="line">X_grad = ((X * Theta' - Y).*R) * Theta;</span><br><span class="line">Theta_grad = ((X*Theta' -Y).*R)' * X;</span><br><span class="line"></span><br><span class="line"><span class="comment">% Regular version</span></span><br><span class="line">J = J + lambda/<span class="number">2</span> * sum(sum(Theta .^<span class="number">2</span>)) + lambda/<span class="number">2</span> * sum(sum(X.^<span class="number">2</span>));</span><br><span class="line"></span><br><span class="line">X_grad = X_grad + lambda * X;</span><br><span class="line">Theta_grad = Theta_grad + lambda * Theta;</span><br><span class="line"></span><br><span class="line">grad = [X_grad(:); Theta_grad(:)];</span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%  Evaluate cost function</span></span><br><span class="line">J = cofiCostFunc([X(:) ; Theta(:)], Y, R, num_users, num_movies, num_features, <span class="number">1.5</span>);</span><br></pre></td></tr></table></figure><ol><li>发起预测，在数据库中加入自己的数据，随便对一部分电影进行打分：</li></ol><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% ============== Part 6: Entering ratings for a new user ===============</span></span><br><span class="line"><span class="comment">%  Before we will train the collaborative filtering model, we will first</span></span><br><span class="line"><span class="comment">%  add ratings that correspond to a new user that we just observed. This</span></span><br><span class="line"><span class="comment">%  part of the code will also allow you to put in your own ratings for the</span></span><br><span class="line"><span class="comment">%  movies in our dataset!</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line">movieList = loadMovieList();</span><br><span class="line"></span><br><span class="line"><span class="comment">%  Initialize my ratings</span></span><br><span class="line">my_ratings = <span class="built_in">zeros</span>(<span class="number">1682</span>, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Check the file movie_idx.txt for id of each movie in our dataset</span></span><br><span class="line"><span class="comment">% For example, Toy Story (1995) has ID 1, so to rate it "4", you can set</span></span><br><span class="line">my_ratings(<span class="number">1</span>) = <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% Or suppose did not enjoy Silence of the Lambs (1991), you can set</span></span><br><span class="line">my_ratings(<span class="number">98</span>) = <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% We have selected a few movies we liked / did not like and the ratings we</span></span><br><span class="line"><span class="comment">% gave are as follows:</span></span><br><span class="line">my_ratings(<span class="number">7</span>) = <span class="number">3</span>;</span><br><span class="line">my_ratings(<span class="number">12</span>)= <span class="number">5</span>;</span><br><span class="line">my_ratings(<span class="number">54</span>) = <span class="number">4</span>;</span><br><span class="line">my_ratings(<span class="number">64</span>)= <span class="number">5</span>;</span><br><span class="line">my_ratings(<span class="number">66</span>)= <span class="number">3</span>;</span><br><span class="line">my_ratings(<span class="number">69</span>) = <span class="number">5</span>;</span><br><span class="line">my_ratings(<span class="number">183</span>) = <span class="number">4</span>;</span><br><span class="line">my_ratings(<span class="number">226</span>) = <span class="number">5</span>;</span><br><span class="line">my_ratings(<span class="number">355</span>)= <span class="number">5</span>;</span><br></pre></td></tr></table></figure><p>我们拥有了一份新的用户对电影打分的数据：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">New user ratings:</span><br><span class="line">Rated 4 <span class="keyword">for</span> Toy Story (1995)</span><br><span class="line">Rated 3 <span class="keyword">for</span> Twelve Monkeys (1995)</span><br><span class="line">Rated 5 <span class="keyword">for</span> Usual Suspects, The (1995)</span><br><span class="line">Rated 4 <span class="keyword">for</span> Outbreak (1995)</span><br><span class="line">Rated 5 <span class="keyword">for</span> Shawshank Redemption, The (1994)</span><br><span class="line">Rated 3 <span class="keyword">for</span> While You Were Sleeping (1995)</span><br><span class="line">Rated 5 <span class="keyword">for</span> Forrest Gump (1994)</span><br><span class="line">Rated 2 <span class="keyword">for</span> Silence of the Lambs, The (1991)</span><br><span class="line">Rated 4 <span class="keyword">for</span> Alien (1979)</span><br><span class="line">Rated 5 <span class="keyword">for</span> Die Hard 2 (1990)</span><br><span class="line">Rated 5 <span class="keyword">for</span> Sphere (1998)</span><br></pre></td></tr></table></figure><ol><li>训练算法</li></ol><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% ================== Part 7: Learning Movie Ratings ====================</span></span><br><span class="line"><span class="comment">%  Now, you will train the collaborative filtering model on a movie rating </span></span><br><span class="line"><span class="comment">%  dataset of 1682 movies and 943 users</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%  Load data</span></span><br><span class="line">load(<span class="string">'ex8_movies.mat'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">%  Add our own ratings to the data matrix</span></span><br><span class="line">Y = [my_ratings Y];</span><br><span class="line">R = [(my_ratings ~= <span class="number">0</span>) R];</span><br><span class="line"></span><br><span class="line"><span class="comment">%  Normalize Ratings</span></span><br><span class="line">[Ynorm, Ymean] = normalizeRatings(Y, R);</span><br><span class="line"></span><br><span class="line"><span class="comment">%  Useful Values</span></span><br><span class="line">num_users = <span class="built_in">size</span>(Y, <span class="number">2</span>);</span><br><span class="line">num_movies = <span class="built_in">size</span>(Y, <span class="number">1</span>);</span><br><span class="line">num_features = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% Set Initial Parameters (Theta, X)</span></span><br><span class="line">X = <span class="built_in">randn</span>(num_movies, num_features);</span><br><span class="line">Theta = <span class="built_in">randn</span>(num_users, num_features);</span><br><span class="line"></span><br><span class="line">initial_parameters = [X(:); Theta(:)];</span><br><span class="line"></span><br><span class="line"><span class="comment">% Set options for fmincg</span></span><br><span class="line">options = optimset(<span class="string">'GradObj'</span>, <span class="string">'on'</span>, <span class="string">'MaxIter'</span>, <span class="number">100</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Set Regularization</span></span><br><span class="line">lambda = <span class="number">10</span>;</span><br><span class="line">theta = fmincg (@(t)(cofiCostFunc(t, Ynorm, R, num_users, num_movies, ...</span><br><span class="line">                                num_features, lambda)), ...</span><br><span class="line">                initial_parameters, options);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Unfold the returned theta back into U and W</span></span><br><span class="line">X = <span class="built_in">reshape</span>(theta(<span class="number">1</span>:num_movies*num_features), num_movies, num_features);</span><br><span class="line">Theta = <span class="built_in">reshape</span>(theta(num_movies*num_features+<span class="number">1</span>:<span class="keyword">end</span>), ...</span><br><span class="line">                num_users, num_features);</span><br><span class="line"></span><br><span class="line">fprintf(<span class="string">'Recommender system learning completed.\n'</span>);</span><br><span class="line"></span><br><span class="line">fprintf(<span class="string">'\nProgram paused. Press enter to continue.\n'</span>);</span><br><span class="line">pause;</span><br></pre></td></tr></table></figure><p>其中，函数<code>normalizeRatings</code> 用于对数据进行归一化，减去均值；函数<code>fmincg</code>为MATLAB自带的优化函数；</p><ol><li>利用算法进行推荐</li></ol><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% ================== Part 8: Recommendation for you ====================</span></span><br><span class="line"><span class="comment">%  After training the model, you can now make recommendations by computing</span></span><br><span class="line"><span class="comment">%  the predictions matrix.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line">p = X * Theta';</span><br><span class="line">my_predictions = p(:,<span class="number">1</span>) + Ymean;</span><br><span class="line"></span><br><span class="line">movieList = loadMovieList();</span><br><span class="line"></span><br><span class="line">[r, ix] = sort(my_predictions, <span class="string">'descend'</span>);</span><br><span class="line">fprintf(<span class="string">'\nTop recommendations for you:\n'</span>);</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="number">10</span></span><br><span class="line">    <span class="built_in">j</span> = ix(<span class="built_in">i</span>);</span><br><span class="line">    fprintf(<span class="string">'Predicting rating %.1f for movie %s\n'</span>, my_predictions(<span class="built_in">j</span>), ...</span><br><span class="line">            movieList&#123;j&#125;);</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Top recommendations <span class="keyword">for</span> you:</span><br><span class="line">Predicting rating 5.0 <span class="keyword">for</span> movie Someone Else<span class="string">'s America (1995)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Aiqing wansui (1994)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Great Day in Harlem, A (1994)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Prefontaine (1997)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie They Made Me a Criminal (1939)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Entertaining Angels: The Dorothy Day Story (1996)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Saint of Fort Washington, The (1993)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Santa with Muscles (1996)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Star Kid (1997)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Marlene Dietrich: Shadow and Light (1996)</span></span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li>​</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; Cousera上机器学习课程提供了八个实验作业，使用MATLAB进行动手实验，熟悉相关技术，本文对实验中的关键内容进行总结归纳，方便以后及时查找。&lt;/p&gt;
&lt;!-- excerpt --&gt;
&lt;h2 id=&quot;概要&quot;&gt;&lt;a href=&quot;
      
    
    </summary>
    
      <category term="动手实践营" scheme="http://blog.a-stack.com/categories/%E5%8A%A8%E6%89%8B%E5%AE%9E%E8%B7%B5%E8%90%A5/"/>
    
    
      <category term="机器学习" scheme="http://blog.a-stack.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="公开课" scheme="http://blog.a-stack.com/tags/%E5%85%AC%E5%BC%80%E8%AF%BE/"/>
    
      <category term="实验" scheme="http://blog.a-stack.com/tags/%E5%AE%9E%E9%AA%8C/"/>
    
      <category term="线性回归" scheme="http://blog.a-stack.com/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    
      <category term="逻辑回归" scheme="http://blog.a-stack.com/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
    
  </entry>
  
  <entry>
    <title>Machine Learning Notes</title>
    <link href="http://blog.a-stack.com/2018/04/26/machinelearning-notes/"/>
    <id>http://blog.a-stack.com/2018/04/26/machinelearning-notes/</id>
    <published>2018-04-26T05:56:13.000Z</published>
    <updated>2018-05-15T09:14:33.448Z</updated>
    
    <content type="html"><![CDATA[<p><strong>摘要：</strong> 最近花了两周时间刷完了吴恩达在Cousera上关于<a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="noopener">机器学习</a>的经典课程, 这已经是近两个月来刷完的第十个Cousera课程了。虽然课程是多年前开设的，但相关机器学习理论和方法内容介绍仍然具备很强的时效性，是机器学习入门的必选课程。</p><!-- excerpt --><p>@[toc]</p><blockquote><p>最近花了两周时间刷完了吴恩达在Cousera上关于<a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="noopener">机器学习</a>的经典课程, 这已经是近两个月来刷完的第十个Cousera课程了。虽然课程是多年前开设的，但相关机器学习理论和方法内容介绍仍然具备很强的时效性，是机器学习入门的必选课程。为了巩固对课程内容和课后实验的理解，将在未来一周实践写几篇总结性笔记，作为对课程内容的回顾和总结。</p></blockquote><h2 id="Lecture-1：-机器学习的定义"><a href="#Lecture-1：-机器学习的定义" class="headerlink" title="Lecture 1： 机器学习的定义"></a>Lecture 1： 机器学习的定义</h2><blockquote><p>Tom Mitchell provides a modern definition: “A computer program is said to learn from experience <strong>E</strong> with respect to some class of tasks <strong>T</strong> and performance measure <strong>P</strong>, if its performance at tasks in <strong>T</strong>, as measured by <strong>P</strong>, improves with experience <strong>E</strong>.”</p></blockquote><ol><li>监督学习的一个主要特点，是在拿到数据的那一刻，我们已经知道正确的输出目标范围；<ul><li>监督学习可以分为分类问题和回归问题；</li></ul></li><li>鸡尾酒会问题及鸡尾酒会算法：<a href="https://en.wikipedia.org/wiki/Cocktail_party_effect" target="_blank" rel="noopener">Wiki</a>, 属于非聚类的非监督问题</li></ol><h2 id="Lecture-2：-线性回归（多属性）"><a href="#Lecture-2：-线性回归（多属性）" class="headerlink" title="Lecture 2： 线性回归（多属性）"></a>Lecture 2： 线性回归（多属性）</h2><h3 id="变量定义"><a href="#变量定义" class="headerlink" title="变量定义"></a>变量定义</h3><p>$x_j^{(i)}$ : 第$i^{th}$训练样本的第$j$个特征向量；</p><p>$x^{(i)}$ : 第$i^{th}$训练样本的特征向量；</p><p>$m$ ： 训练样本数目；</p><p>$n$ ： 特征数目</p><h3 id="多元线性规划模型"><a href="#多元线性规划模型" class="headerlink" title="多元线性规划模型"></a>多元线性规划模型</h3><h4 id="假设函数"><a href="#假设函数" class="headerlink" title="假设函数"></a>假设函数</h4><script type="math/tex; mode=display">\begin{equation} h_\theta (x) = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + \theta_3 x_3 + \cdots + \theta_n x_n = \theta ^T x  \tag{1.a} \end{equation}</script><blockquote><p>以上表达式中对$\theta$ 和 $x$ 进行了维度变换，$x_0=1,for(i\in1,…,m)$</p><p>$\theta .shape = (n+1, 1)$</p><p>$x.shape = (m,n+1)$</p></blockquote><h4 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h4><script type="math/tex; mode=display">J(\theta) = \dfrac {1}{2m} \displaystyle \sum_{i=1}^m \left (h_\theta (x^{(i)}) - y^{(i)} \right)^2 = \dfrac {1}{2m} (X\theta - \vec{y})^{T} (X\theta - \vec{y})</script><h4 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h4><script type="math/tex; mode=display">\theta := \theta - \frac{\alpha}{m} X^{T} (X\theta - \vec{y})</script><h3 id="特征正则化"><a href="#特征正则化" class="headerlink" title="特征正则化"></a>特征正则化</h3><blockquote><ol><li>Feature scaling 和 mean normalization实现;</li><li>归一化的目的，是为了收敛域对其，更容易收敛，梯度下降更容易找到最佳方向；</li><li>吴恩达打了个很好的比喻，两个参数范围不一致，梯度下降是一个椭圆；</li></ol></blockquote><script type="math/tex; mode=display">x_i := \dfrac{x_i - \mu_i}{s_i}</script><h3 id="参数分析"><a href="#参数分析" class="headerlink" title="参数分析"></a>参数分析</h3><script type="math/tex; mode=display">\theta = (X^T X)^{-1}X^T y</script><div class="table-container"><table><thead><tr><th>Gradient Descent</th><th>Normal Equation</th></tr></thead><tbody><tr><td>Need to choose alpha</td><td>No need to choose alpha</td></tr><tr><td>Needs many iterations</td><td>No need to iterate</td></tr><tr><td>$O(kn^2)$</td><td>$O(n^3)$ ,计算复杂度来自$X^TX$ 的计算</td></tr><tr><td>Works well when n is large</td><td>Slow if n is very large</td></tr></tbody></table></div><h2 id="Lecture-3：逻辑回归"><a href="#Lecture-3：逻辑回归" class="headerlink" title="Lecture 3：逻辑回归"></a>Lecture 3：逻辑回归</h2><blockquote><p><strong>逻辑回归名称的由来</strong>：逻辑回归来源于Logistic 分布，虽然名字带回归，但解决的是分类问题。而其密度函数曲线正对应着Sigmoid函数的曲线形状。</p></blockquote><h3 id="假设函数-1"><a href="#假设函数-1" class="headerlink" title="假设函数"></a>假设函数</h3><script type="math/tex; mode=display">\begin{align*} h_\theta (x) =  g ( \theta^T x ) \\ z = \theta^T x \\g(z) = \dfrac{1}{1 + e^{-z}}\end{align*}</script><p>假设函数输出的分类目标的条件概率：</p><script type="math/tex; mode=display">\begin{align*}& h_\theta(x) = P(y=1 | x ; \theta) = 1 - P(y=0 | x ; \theta) \newline& P(y = 0 | x;\theta) + P(y = 1 | x ; \theta) = 1\end{align*}</script><h3 id="代价函数-1"><a href="#代价函数-1" class="headerlink" title="代价函数"></a>代价函数</h3><script type="math/tex; mode=display">\begin{align*}& J(\theta) = \dfrac{1}{m} \sum_{i=1}^m \mathrm{Cost}(h_\theta(x^{(i)}),y^{(i)})=-\frac{1}{m}(y^Tlog(h)+(1-y)^T(1-h)) \newline & \mathrm{Cost}(h_\theta(x),y) = -\log(h_\theta(x)) \; & \text{if y = 1} \newline & \mathrm{Cost}(h_\theta(x),y) = -\log(1-h_\theta(x)) \; & \text{if y = 0}\end{align*}</script><h3 id="梯度-1"><a href="#梯度-1" class="headerlink" title="梯度"></a>梯度</h3><script type="math/tex; mode=display">\theta := \theta - \frac{\alpha}{m} X^{T} (g(X \theta ) - \vec{y})</script><script type="math/tex; mode=display">\sigma(x)'=\sigma(x)(1 - \sigma(x))</script><blockquote><p>一些梯度下降算法之外的选择： 除了梯度下降算法以外，还有一些常被用来令代价函数最小的算法，这些算法更加复杂和优越，而且通常不需要人工选择学习率，通常比梯度下降算法要更加快速。这些算法有：共轭梯度（Conjugate Gradient），局部优化法(Broyden fletcher goldfarb shann,BFGS)和有限内存局部优化法(LBFGS)<br>fminunc是 matlab和octave 中都带的一个最小值优化函数，使用时我们需要提供代价函数和每个参数的求导</p></blockquote><h3 id="多分类：-One-vs-all"><a href="#多分类：-One-vs-all" class="headerlink" title="多分类： One-vs-all"></a>多分类： One-vs-all</h3><p>每个分类目标对应一个分类器，计算分类过程中，取预测值最大的分类器输出作为最终分类结果：</p><script type="math/tex; mode=display">prediction = \max_i( h_\theta ^{(i)}(x) )</script><h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><h3 id="正则化的线性回归"><a href="#正则化的线性回归" class="headerlink" title="正则化的线性回归"></a>正则化的线性回归</h3><script type="math/tex; mode=display">\begin{align*}& \text{Repeat}\ \lbrace \newline& \ \ \ \ \theta_0 := \theta_0 - \alpha\ \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_0^{(i)} \newline& \ \ \ \ \theta_j := \theta_j - \alpha\ \left[ \left( \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \right) + \frac{\lambda}{m}\theta_j \right] &\ \ \ \ \ \ \ \ \ \ j \in \lbrace 1,2...n\rbrace\newline& \rbrace\end{align*}</script><h4 id="添加正则化的数值解"><a href="#添加正则化的数值解" class="headerlink" title="添加正则化的数值解"></a>添加正则化的数值解</h4><script type="math/tex; mode=display">\begin{align*}& \theta = \left( X^TX + \lambda \cdot L \right)^{-1} X^Ty \newline& \text{where}\ \ L = \begin{bmatrix} 0 & & & & \newline & 1 & & & \newline & & 1 & & \newline & & & \ddots & \newline & & & & 1 \newline\end{bmatrix}\end{align*}</script><h3 id="正则化的逻辑回归"><a href="#正则化的逻辑回归" class="headerlink" title="正则化的逻辑回归"></a>正则化的逻辑回归</h3><script type="math/tex; mode=display">J(\theta) = - \frac{1}{m} \sum_{i=1}^m \large[ y^{(i)}\ \log (h_\theta (x^{(i)})) + (1 - y^{(i)})\ \log (1 - h_\theta(x^{(i)}))\large] + \frac{\lambda}{2m}\sum_{j=1}^n \theta_j^2</script><script type="math/tex; mode=display">\begin{array}& \text{Repeat}\ \lbrace \newline& \ \ \ \ \theta_0 := \theta_0 - \alpha\ \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_0^{(i)} \newline& \ \ \ \ \theta_j := \theta_j - \alpha\ \left[ \left( \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \right) + \frac{\lambda}{m}\theta_j \right] &\ \ \ \ \ \ \ \ \ \ j \in \lbrace 1,2...n\rbrace\newline& \rbrace\end{array}</script><h2 id="Lecture-4-5-神经网络"><a href="#Lecture-4-5-神经网络" class="headerlink" title="Lecture 4-5: 神经网络"></a>Lecture 4-5: 神经网络</h2><ul><li>大脑学习的原理举例： 人类失去眼睛，可以学习通过超声来判断物体和方位，具备看的能力；</li></ul><p>If networkhas $s_j$ units in layer j and $s_j +1$ units in layer j+1, then Θ(j) willbe of dimension sj+1×(sj+1).</p><h3 id="多分类"><a href="#多分类" class="headerlink" title="多分类"></a>多分类</h3><script type="math/tex; mode=display">\begin{align*}\begin{bmatrix}x_0 \newline x_1 \newline x_2 \newline\cdots \newline x_n\end{bmatrix} \rightarrow\begin{bmatrix}a_0^{(2)} \newline a_1^{(2)} \newline a_2^{(2)} \newline\cdots\end{bmatrix} \rightarrow\begin{bmatrix}a_0^{(3)} \newline a_1^{(3)} \newline a_2^{(3)} \newline\cdots\end{bmatrix} \rightarrow \cdots \rightarrow\begin{bmatrix}h_\Theta(x)_1 \newline h_\Theta(x)_2 \newline h_\Theta(x)_3 \newline h_\Theta(x)_4 \newline\end{bmatrix} \rightarrow\end{align*}</script><h3 id="代价函数-2"><a href="#代价函数-2" class="headerlink" title="代价函数"></a>代价函数</h3><script type="math/tex; mode=display">\begin{gather*}\large J(\Theta) = - \frac{1}{m} \sum_{i=1}^m \sum_{k=1}^K \left[y^{(i)}_k \log ((h_\Theta (x^{(i)}))_k) + (1 - y^{(i)}_k)\log (1 - (h_\Theta(x^{(i)}))_k)\right] + \frac{\lambda}{2m}\sum_{l=1}^{L-1} \sum_{i=1}^{s_l} \sum_{j=1}^{s_{l+1}} ( \Theta_{j,i}^{(l)})^2\end{gather*}</script><h3 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h3><blockquote><p>参见： <a href="Backpropagation-in-Neural-Network/">Backpropagation-in-Neural-Network</a></p></blockquote><h3 id="梯度校验"><a href="#梯度校验" class="headerlink" title="梯度校验"></a>梯度校验</h3><script type="math/tex; mode=display">\dfrac{\partial}{\partial\Theta_j}J(\Theta) \approx \dfrac{J(\Theta_1, \dots, \Theta_j + \epsilon, \dots, \Theta_n) - J(\Theta_1, \dots, \Theta_j - \epsilon, \dots, \Theta_n)}{2\epsilon}</script><h2 id="Lecture-6：采用机器学习的建议"><a href="#Lecture-6：采用机器学习的建议" class="headerlink" title="Lecture 6：采用机器学习的建议"></a>Lecture 6：采用机器学习的建议</h2><h3 id="bias-与-variance"><a href="#bias-与-variance" class="headerlink" title="bias 与 variance"></a>bias 与 variance</h3><ul><li>高偏差==欠拟合</li><li>高方差==过拟合</li></ul><p><img src="/qnsource/images/2018-04-25-machine-learning-notes/Features-and-polynom-degree.png" alt="Features-and-polynom-degree"></p><p>正则化与偏差/方差：</p><ul><li>大的$\lambda$ :高偏差（欠拟合）；</li><li>小的$\lambda$ :高方差（过拟合）；</li></ul><p><img src="/qnsource/images/2018-04-25-machine-learning-notes/Features-and-polynom-degree-fix.png" alt="Features-and-polynom-degree-fix"></p><blockquote><p>选择合适的正则化参数</p></blockquote><h3 id="学习曲线（Learning-Curves）"><a href="#学习曲线（Learning-Curves）" class="headerlink" title="学习曲线（Learning Curves）"></a>学习曲线（Learning Curves）</h3><blockquote><p>错误率随样本数目变化的曲线；</p><p>如果算法过拟合，增大样本数有助于提升算法性能</p></blockquote><p><img src="/qnsource/images/2018-04-25-machine-learning-notes/Learning2.png" alt="Learning2"></p><p><img src="/qnsource/images/2018-04-25-machine-learning-notes/Learning1.png" alt="Learning1"></p><h2 id="Lecture-7：-SVM"><a href="#Lecture-7：-SVM" class="headerlink" title="Lecture 7： SVM"></a>Lecture 7： SVM</h2><script type="math/tex; mode=display">z = \theta^Tx</script><script type="math/tex; mode=display">\text{cost}_0(z) = \max(0, k(1+z))</script><script type="math/tex; mode=display">\text{cost}_1(z) = \max(0, k(1-z))</script><blockquote><p>更多内容查看WiKi： <a href="https://en.wikipedia.org/wiki/Hinge_loss" target="_blank" rel="noopener">Hingle loss</a></p></blockquote><h3 id="代价函数-3"><a href="#代价函数-3" class="headerlink" title="代价函数"></a>代价函数</h3><script type="math/tex; mode=display">J(\theta) = C\sum_{i=1}^m y^{(i)} \ \text{cost}_1(\theta^Tx^{(i)}) + (1 - y^{(i)}) \ \text{cost}_0(\theta^Tx^{(i)}) + \dfrac{1}{2}\sum_{j=1}^n \Theta^2_j</script><script type="math/tex; mode=display">C = \frac{1}{\lambda}</script><blockquote><p>因为SVM的优化目标为最大化边界举例，所有SVM也叫做Large Margin Classifier</p></blockquote><h3 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h3><p>实现SVM非线性分类的基础，将低维空间点投射到高维空间，定义近似函数：</p><p>高斯核函数(主要参数为 $\sigma$)</p><script type="math/tex; mode=display">f_i = similarity(x, l^{(i)}) = \exp(-\dfrac{\sum^n_{j=1}(x_j-l_j^{(i)})^2}{2\sigma^2})</script><h3 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h3><ol><li><p>$C=\frac{1}{\lambda}$</p><p>如果$C$ 过大，高方差、低偏差；</p><p>如果$C$ 过小，高偏差、低方差；</p></li><li><p>$\sigma^2$</p><p>如果$\sigma^2$ 过大，特征更加平缓，导致高偏差，低方差；</p><p>如果$\sigma^2$ 过小，特征分布更集中，导致高方差，低偏差；</p></li></ol><h2 id="Lecture-8-K-Means-和-PCA"><a href="#Lecture-8-K-Means-和-PCA" class="headerlink" title="Lecture 8: K-Means 和 PCA"></a>Lecture 8: K-Means 和 PCA</h2><h3 id="K-Means"><a href="#K-Means" class="headerlink" title="K-Means"></a>K-Means</h3><p><img src="/qnsource/images/2018-04-25-machine-learning-notes/BILDt.png" alt="BILDt"></p><p>算法实现(<code>Cluster Assignment</code>+<code>Move Centroid</code>)：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Randomly initialize K cluster centroids mu(1), mu(2), ..., mu(K)</span><br><span class="line">Repeat:</span><br><span class="line">   <span class="keyword">for</span> i = 1 to m:</span><br><span class="line">      c(i):= index (from 1 to K) of cluster centroid closest to x(i)</span><br><span class="line">   <span class="keyword">for</span> k = 1 to K:</span><br><span class="line">      mu(k):= average (mean) of points assigned to cluster k</span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">c^{(i)} = argmin_k\ ||x^{(i)} - \mu_k||^2</script><h4 id="优化目标"><a href="#优化目标" class="headerlink" title="优化目标"></a>优化目标</h4><script type="math/tex; mode=display">J(c^{(i)},\dots,c^{(m)},\mu_1,\dots,\mu_K) = \dfrac{1}{m}\sum_{i=1}^m ||x^{(i)} - \mu_{c^{(i)}}||^2</script><h4 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h4><ol><li>K个初始对象的选择应为随机选取k个训练样本；</li><li>为了尽量避免陷入局部极小值，需要进行多次随机初始化求解，选择代价函数最小的解；</li><li>K的选择，可以采用<code>elbow method</code>： Choose K at the point where the cost function starts to flatten out.</li></ol><h3 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h3><p><strong>降维的目的：</strong> 1. 数据压缩；2. 可视化；</p><ul><li>The <strong>goal of PCA</strong> is to <strong>reduce</strong> the average of all the distances of every feature to the projection line. </li><li>PCA与线性回归不同之处在于，计算的各点到分割线的最短距离；</li></ul><h4 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h4><ol><li><p>数据预处理：归一化；</p></li><li><p>计算协方差矩阵</p><script type="math/tex; mode=display">\Sigma = \dfrac{1}{m}\sum^m_{i=1}(x^{(i)})(x^{(i)})^T</script></li><li><p>计算$\Sigma$ 的特征矩阵</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[U,S,V]</span> = svd(Sigma);</span><br></pre></td></tr></table></figure></li><li><p>取$U$ 的前k列计算$z$</p><script type="math/tex; mode=display">z^{(i)} = Ureduce^T \cdot x^{(i)}</script></li></ol><h4 id="恢复"><a href="#恢复" class="headerlink" title="恢复"></a>恢复</h4><script type="math/tex; mode=display">x_{approx}^{(1)} = U_{reduce} \cdot z^{(1)}</script><h4 id="k值的选择"><a href="#k值的选择" class="headerlink" title="k值的选择"></a>k值的选择</h4><script type="math/tex; mode=display">\dfrac{\dfrac{1}{m}\sum^m_{i=1}||x^{(i)} - x_{approx}^{(i)}||^2}{\dfrac{1}{m}\sum^m_{i=1}||x^{(i)}||^2} \leq 0.01</script><blockquote><p>描述了丢失特征的比例</p></blockquote><p>可以通过SVD分解之后的S值来做同样的事情：</p><script type="math/tex; mode=display">\dfrac{\sum_{i=1}^kS_{ii}}{\sum_{i=1}^nS_{ii}} \geq 0.99</script><h2 id="Lecture-9：-应用1-异常检测"><a href="#Lecture-9：-应用1-异常检测" class="headerlink" title="Lecture 9： 应用1-异常检测"></a>Lecture 9： 应用1-异常检测</h2><ul><li>x(i)= features of user i’s activities</li><li>Model p(x) from the data.</li><li>Identify unusual users by checking which have p(x)&lt;ϵ.</li></ul><h4 id="高斯分布"><a href="#高斯分布" class="headerlink" title="高斯分布"></a>高斯分布</h4><p> $x \sim \mathcal{N}(\mu, \sigma^2)$</p><script type="math/tex; mode=display">p(x;\mu,\sigma^2) = \frac{1}{\sigma\sqrt{(2\pi)}}e^{-\frac{1}{2}(\frac{x - \mu}{\sigma})^2}</script><script type="math/tex; mode=display">p(x) = p(x_1;\mu_1,\sigma_1^2)p(x_2;\mu_2,\sigma^2_2)\cdots p(x_n;\mu_n,\sigma^2_n)= \displaystyle \prod^n_{j=1} p(x_j;\mu_j,\sigma_j^2)</script><h4 id="算法流程-1"><a href="#算法流程-1" class="headerlink" title="算法流程"></a>算法流程</h4><ol><li><p>计算均值和方差</p></li><li><p>计算概率分布函数</p><script type="math/tex; mode=display">p(x) = \displaystyle \prod^n_{j=1} p(x_j;\mu_j,\sigma_j^2) = \prod\limits^n_{j=1} \dfrac{1}{\sqrt{2\pi}\sigma_j}exp(-\dfrac{(x_j - \mu_j)^2}{2\sigma^2_j})</script></li><li><p>利用标记数据确定ϵ</p></li></ol><h4 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h4><p>为了满足高斯分布，需要对原始数据进行转换：</p><ul><li>log(x)</li><li>log(x+1)</li><li>log(x+c) for some constant</li><li>$\sqrt x$</li><li>$x^{1/3}$</li></ul><h4 id="多元高斯分布"><a href="#多元高斯分布" class="headerlink" title="多元高斯分布"></a>多元高斯分布</h4><script type="math/tex; mode=display">p(x;\mu,\Sigma) = \dfrac{1}{(2\pi)^{n/2} |\Sigma|^{1/2}} exp(-1/2(x-\mu)^T\Sigma^{-1}(x-\mu))</script><blockquote><p>传统高斯模型乘积是多元多元高斯的一种特例</p></blockquote><p>$\Sigma$ 为协方差矩阵，如何假设$A$ 为非奇异矩阵，进行特征变换：$y=Ax$,则$\Sigma = AA^T$</p><p>多元高斯分布 vs 传统高斯模型</p><ul><li>多元 更能捕获特征之间的关联性；</li><li>多元 计算更耗时；</li><li>多元的前提，样本数 &gt; 特征数；m&gt;10n</li></ul><h2 id="Lecture-10-应用2-推荐系统"><a href="#Lecture-10-应用2-推荐系统" class="headerlink" title="Lecture 10: 应用2-推荐系统"></a>Lecture 10: 应用2-推荐系统</h2><h3 id="问题抽象"><a href="#问题抽象" class="headerlink" title="问题抽象"></a>问题抽象</h3><p>以电影推荐为例，定义如下变量：</p><ul><li>$n_\mu$ = 用户数目</li><li>$n_m$ = 电影数目</li><li>$r(i,j)=1$ = 1,如果用户j对电影i评分</li><li>$y(i,j)=rating_score$ </li></ul><h3 id="基于内容的推荐"><a href="#基于内容的推荐" class="headerlink" title="基于内容的推荐"></a>基于内容的推荐</h3><script type="math/tex; mode=display">min_{\theta^{(1)},\dots,\theta^{(n_u)}} = \dfrac{1}{2}\displaystyle \sum_{j=1}^{n_u}  \sum_{i:r(i,j)=1} ((\theta^{(j)})^T(x^{(i)}) - y^{(i,j)})^2 + \dfrac{\lambda}{2} \sum_{j=1}^{n_u} \sum_{k=1}^n(\theta_k^{(j)})^2</script><h3 id="协同过滤"><a href="#协同过滤" class="headerlink" title="协同过滤"></a>协同过滤</h3><blockquote><p>既学习参数又学习特征表示</p></blockquote><script type="math/tex; mode=display">J(x,\theta) = \dfrac{1}{2} \displaystyle \sum_{(i,j):r(i,j)=1}((\theta^{(j)})^Tx^{(i)} - y^{(i,j)})^2 + \dfrac{\lambda}{2}\sum_{i=1}^{n_m} \sum_{k=1}^{n} (x_k^{(i)})^2 + \dfrac{\lambda}{2}\sum_{j=1}^{n_u} \sum_{k=1}^{n} (\theta_k^{(j)})^2</script><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li>SVM：<a href="http://web.mit.edu/6.034/wwwbob/svm-notes-long-08.pdf" target="_blank" rel="noopener">http://web.mit.edu/6.034/wwwbob/svm-notes-long-08.pdf</a></li><li>​</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt; 最近花了两周时间刷完了吴恩达在Cousera上关于&lt;a href=&quot;https://www.coursera.org/learn/machine-learning&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;机器
      
    
    </summary>
    
      <category term="机器学习" scheme="http://blog.a-stack.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="算法" scheme="http://blog.a-stack.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="机器学习" scheme="http://blog.a-stack.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="线性回归" scheme="http://blog.a-stack.com/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    
      <category term="逻辑回归" scheme="http://blog.a-stack.com/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
    
      <category term="笔记" scheme="http://blog.a-stack.com/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="神经网络" scheme="http://blog.a-stack.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
</feed>
