<!DOCTYPE html>
<html  lang="zh">
<head>
    <meta charset="utf-8" />

<meta name="generator" content="Hexo 3.9.0" />

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

<title>标签: AI - Ebby&#39;s Notes</title>


    <meta name="description" content="记录人工智能学习路径">
<meta name="keywords" content="人工智能, AI, 神经网络, 算法">
<meta property="og:type" content="website">
<meta property="og:title" content="Ebby&#39;s Notes">
<meta property="og:url" content="http://blog.a-stack.com/tags/AI/index.html">
<meta property="og:site_name" content="Ebby&#39;s Notes">
<meta property="og:description" content="记录人工智能学习路径">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://blog.a-stack.com/images/og_image.png">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Ebby&#39;s Notes">
<meta name="twitter:description" content="记录人工智能学习路径">
<meta name="twitter:image" content="http://blog.a-stack.com/images/og_image.png">







<link rel="icon" href="/images/favicon.svg">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/5.4.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/tomorrow-night-eighties.css">


    
    
<style>body>.footer,body>.navbar,body>.section{opacity:0}</style>

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css">

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css">

    
    
    
    
<link rel="stylesheet" href="/css/back-to-top.css">

    
    
    
    <script>
var _hmt = _hmt || [];
(function() {
    var hm = document.createElement("script");
    hm.src = "//hm.baidu.com/hm.js?684368b6943d7a5b6689dba5e7bf30ad";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
})();
</script>
    
    
    
    <link rel="stylesheet" href="/css/progressbar.css">
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
    
    
    


<link rel="stylesheet" href="/css/style.css">
</head>
<body class="is-3-column">
    <nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/">
            
                <img src="/images/logo02.png" alt="Ebby&#39;s Notes" height="28">
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-start">
                
                <a class="navbar-item"
                href="/">主页</a>
                
                <a class="navbar-item"
                href="/archives">归档</a>
                
                <a class="navbar-item"
                href="/categories">分类</a>
                
                <a class="navbar-item"
                href="/tags">标签</a>
                
                <a class="navbar-item"
                href="/reading">读书</a>
                
                <a class="navbar-item"
                href="/resources">资源</a>
                
                <a class="navbar-item"
                href="/notebooks">📝</a>
                
                <a class="navbar-item"
                href="/about">关于</a>
                
            </div>
            
            <div class="navbar-end">
                
                
                
                <a class="navbar-item search" title="搜索" href="javascript:;">
                    <i class="fas fa-search"></i>
                </a>
                
            </div>
        </div>
    </div>
</nav>
    
    <section class="section">
        <div class="container">
            <div class="columns">
                <div class="column is-8-tablet is-8-desktop is-6-widescreen has-order-2 column-main"><div class="card">
    <div class="card-content">
        <nav class="breadcrumb" aria-label="breadcrumbs">
        <ul>
            <li><a href="/tags">标签</a></li>
            <li class="is-active"><a href="#" aria-current="page">AI</a></li>
        </ul>
        </nav>
    </div>
</div>

    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                

                <time class="level-item has-text-grey" datetime="2018-04-20T01:09:14.000Z">2018-04-20</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/深度学习/">深度学习</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/深度学习/基础知识/">基础知识</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    10 分钟 读完 (大约 1486 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2018/04/20/Backpropagation-in-Neural-Network/">Backpropagation in Neural Network</a>
            
        </h1>
        <div class="content">
            <p><strong>摘要：</strong> 反向传播毋庸置疑是整个神经网络的精髓，正是由于它的提出标志着深度神经网络的训练在有限算力基础上成为可能，但反向传播本身的原理同样值得品读和思考。<br><!-- excerpt --></p>
<p>本文主要总结神经网络中反向传播算法的推导流程并挖掘一些深层次的原理。反向传播算法在1970年就已经提出，直到1986年 <a href="http://en.wikipedia.org/wiki/David_Rumelhart">David Rumelhart</a>, <a href="http://www.cs.toronto.edu/~hinton/">Geoffrey Hinton</a>, and <a href="http://en.wikipedia.org/wiki/Ronald_J._Williams">Ronald Williams</a>在一篇<a href="https://www.nature.com/articles/323533a0">论文</a>中对其实现的分析才得以普及。</p>
<h2 id="1-表达式的定义"><a href="#1-表达式的定义" class="headerlink" title="1. 表达式的定义"></a>1. 表达式的定义</h2><ul>
<li>$w_{jk}^l$ 代表第l−1层第k个神经元，与第l层第j个神经元之间的权重（注意j与k的顺序）；</li>
<li>$b_j^l$  代表第l层中第j个神经元的偏移；</li>
<li>$a_j^l$  代表第l层中第j个神经元的激活函数值；</li>
<li>$L$  代表神经网络的总层数；</li>
<li>$J(W,b)$ 简写为$J$ 代表神经网络的代价函数；</li>
</ul>
<p>假设我们有$m$ 个训练样本${(x^{(1)},y^{(1)}),…, (x^{(m)},y^{(m)})}$ ,对于每个训练样本$(x,y)$ 定义代价函数为：</p>
<script type="math/tex; mode=display">
J(W,b;x,y) = \frac{1}{2} ||h_{W,b}(x) - y||^2</script><p>对于$m$个训练样本，总的代价函数为：</p>
<script type="math/tex; mode=display">
J(W,b) = [\frac{1}{m} \sum_{i=1}^m J(W,b;x^{(i)},y^{(i)}] + \frac{\lambda}{2} \sum_{l=1}^{n_l -1}\sum_{i=1}^{s_l}\sum_{j=1}^{s_{l+1}}(W_{ji}^{(l)})^2</script><p>根据神经网络层与层之间关系的定义，我们有如下表达式（<strong>向量形式</strong>）：</p>
<script type="math/tex; mode=display">
z^l = w^l a^{l-1} + b^l,   l=2,3,...,L</script><script type="math/tex; mode=display">
a^l = \sigma (z^l), l=2,3,...,L</script><script type="math/tex; mode=display">
a^1=z^1=X</script><p>其中</p>
<script type="math/tex; mode=display">
z_j^l = \sum_k w_{jk}^l a_k^{l-1} + b_j^l</script><p>利用梯度下降法进行目标优化使用的主要梯度更新公式：</p>
<script type="math/tex; mode=display">
w^l := w^l - \alpha \frac{\partial J}{\partial w^l}</script><script type="math/tex; mode=display">
b^l := b^l - \alpha \frac{\partial J}{\partial b^l}</script><p>因为神经网络的复杂性导致$\frac{\partial J}{\partial w^l}$ 无法直接计算或者计算代价太大（每个权重的计算都需要进行一次前向传播），反向传播的目的在于提供一种更加高效的手段，完成上述梯度的更新操作。</p>
<h2 id="2-反向传播的直观理解"><a href="#2-反向传播的直观理解" class="headerlink" title="2. 反向传播的直观理解"></a>2. 反向传播的直观理解</h2><p>反向传播是用于理解改变网络中的任一权重如何影响网络代价函数的过程。假设神经网络中某个权重$w_{jk}^l$ </p>
<p>产生了轻微的扰动误差 $\Delta w_{jk}^l$ ,扰动误差导致该神经元的输出产生误差 $\Delta z_j^l$ ,这个扰动将使对应的神经元$a_j^l$ 产生一个扰动误差 $\Delta a_j^l$ ，该误差将逐步向后层传递，直至达到输出层，并最终影响代价函数，生成一个代价误差 $\Delta J = \frac{\partial J}{\partial z_j^l}\Delta z_j^l$ 。我们可以给出如下式子来为通过误差近似计算梯度提供方向：</p>
<script type="math/tex; mode=display">
\Delta J \approx \frac{\partial J}{\partial a^L_m} 
  \frac{\partial a^L_m}{\partial a^{L-1}_n}
  \frac{\partial a^{L-1}_n}{\partial a^{L-2}_p} \ldots
  \frac{\partial a^{l+1}_q}{\partial a^l_j}
  \frac{\partial a^l_j}{\partial w^l_{jk}} \Delta w^l_{jk}</script><script type="math/tex; mode=display">
 \frac{\Delta J}{\Delta z_{j}^l}=\delta_j^l=\frac{\partial J}{\partial z_j^l}</script><p>其中，$\delta_j^l$  可以定义为$l$层第$j$个神经元上的误差。</p>
<p>我们先从计算最后一层误差$\delta_j^L$ 开始，</p>
<script type="math/tex; mode=display">
\delta^L_j = \frac{\partial J}{\partial a^L_j} \sigma'(z^L_j)</script><p><strong>公式E1</strong>（向量形式）：</p>
<script type="math/tex; mode=display">
\delta^L = \nabla_a J \odot \sigma'(z^L)</script><p><strong>证明</strong>：</p>
<script type="math/tex; mode=display">
\delta^L_j =\frac{\partial J}{\partial z_j^L}=\frac{\partial J}{\partial a_j^L}.\frac{\partial a_j^L}{\partial z_j^L}= \frac{\partial J}{\partial a^L_j} \sigma'(z^L_j).</script><p>现在把问题转变为如何利用反向传播由后往前逐步计算误差$\delta_j^l$ ，为计算不同层之间误差之间的关系，利用链式法则给出如下推理过程：</p>
<script type="math/tex; mode=display">
\delta^l =\frac{\partial J}{\partial z^l} = \frac{\partial J}{\partial z^{l+1}}.\frac{\partial z^{l+1}}{\partial z^l}=\delta^{l+1}.(\frac{\partial z^{l+1}}{\partial a^l}.\frac{\partial a^l}{\partial z^l})= ((w^{l+1})^T\delta^{l+1})\odot \sigma'(z^l)</script><p>即<strong>公式E2</strong>：</p>
<script type="math/tex; mode=display">
\delta^l = ((w^{l+1})^T \delta^{l+1}) \odot \sigma'(z^l)</script><p>有了以上误差的反向传播计算方法，我们可以利用计算的误差计算权重的梯度如下：</p>
<p><strong>公式E3</strong>：</p>
<script type="math/tex; mode=display">
\frac{\partial J}{\partial b^l_j} =\delta^l_j</script><p><strong>公式E4</strong>：</p>
<script type="math/tex; mode=display">
\frac{\partial J}{\partial w^l_{jk}} = a^{l-1}_k \delta^l_j</script><p>其中公式（4）也可以写成：</p>
<script type="math/tex; mode=display">
\frac{\partial
    J}{\partial w} = a_{\rm in} \delta_{\rm out}</script><p><strong>证明：</strong></p>
<script type="math/tex; mode=display">
\frac{\partial J}{\partial b^l_j} =\frac{\partial J}{\partial z^l_j}.\frac{\partial z^l_j}{\partial b^l_j}=  
  \delta^l_j</script><script type="math/tex; mode=display">
\frac{\partial J}{\partial w^l_{jk}} = \frac{\partial J}{\partial z^l_{jk}}.\frac{\partial z_{jk}^l}{\partial w^l_{jk}}=a^{l-1}_k \delta^l_j</script><h3 id="另一种求解方式"><a href="#另一种求解方式" class="headerlink" title="另一种求解方式"></a>另一种求解方式</h3><script type="math/tex; mode=display">
\dfrac{\partial J}{\partial w_{ij}^l} =\frac{\partial J}{\partial a_j^l}.\frac{\partial a_j^l}{\partial z_j^l}.\frac{\partial z_j^l}{w_{ij}^l}=\frac{\partial J}{\partial a_j^l}.\sigma^{'}(z_j^l)a_i^{l-1}</script><p>如何我们令$\delta_j^l =\frac{\partial J}{\partial a_j^l}$ 也可以按照上述过程类似的方法推到出相关公式</p>
<h2 id="3-反向传播算法的计算流程"><a href="#3-反向传播算法的计算流程" class="headerlink" title="3. 反向传播算法的计算流程"></a>3. 反向传播算法的计算流程</h2><ol>
<li>输入$x$，令$a^1=z^1=x$;</li>
<li>前向传播： 对于每层$l=2,3,…,L$计算$z^l$和$a^l$；</li>
<li>根据公式<strong>E1</strong>计算输出误差：$\delta^L = \nabla_a J \odot \sigma’(z^L)$ ;</li>
<li>反向传播：对于每层$l=L-1,L-2,…,2$ 利用公式<strong>E2</strong>计算误差：$\delta^l = ((w^{l+1})^T \delta^{l+1}) \odot \sigma’(z^l)$ ；</li>
<li>利用公式<strong>E3</strong>和<strong>E4</strong>计算参数梯度；</li>
<li>更新权重</li>
</ol>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a href="http://cs231n.github.io/optimization-2/">CS231n讲义：Backpropagation, Intuitions</a></li>
<li><a href="http://neuralnetworksanddeeplearning.com/chap2.html">Neural Networks and Deep Learning</a></li>
<li><a href="http://deeplearning.stanford.edu/wiki/index.php/Backpropagation_Algorithm">Machine Learning Cousera Course</a></li>
</ol>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                

                <time class="level-item has-text-grey" datetime="2018-04-14T13:16:41.000Z">2018-04-14</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/动手实践营/">动手实践营</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/动手实践营/机器视觉/">机器视觉</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    39 分钟 读完 (大约 5793 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2018/04/14/TensorFlow-Object-Detection-API/">使用TensorFlow Object Detection API识别仪表表盘</a>
            
        </h1>
        <div class="content">
            <p>前面用到了Tensorflow的物体识别API做了一个检测仪表表盘的实践，记录实践过程中的技巧。<br><!-- excerpt --></p>
<blockquote>
<p>Update: 2019/04/16，使用新版Tensorflow接口</p>
</blockquote>
<h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>本文主要介绍如何使用Tensorflow 物体识别API应用自己业务场景进行物体识别。将结合从事的一些实际经验，分享一个仪表表盘识别的案例。我们在一个利用机器视觉技术自动识别仪表表读数的项目中，需要首先识别各种不同类型表盘的显示屏位置。本案例分析将针对面板识别中采用的关键技术进行分析，详细阐述如何利用物体识别技术和已训练好的模型快速实现使用用户数据设计一个面向特定物体识别的深度神经网络。</p>
<p><strong>目标：</strong> 从给定的水表图片中将关键的数字面板给扣取出来。</p>
<p>如下图所示，如果采用通用OCR技术对水表图片面板进行检测，将同时提取很多特征项，对实际的检测值造成比较大的干扰。</p>
<p><img src="/qnsource/images/2018-04-14-TensorFlow-Object-Detection-API/ocr-demo.PNG" alt="ocr-demo"></p>
<h3 id="1-1-模型及算法选型"><a href="#1-1-模型及算法选型" class="headerlink" title="1.1 模型及算法选型"></a>1.1 模型及算法选型</h3><p>在方案设计初期我们分别使用公有云服务、现有的成熟OCR软件、开源的OCR方案对目标对象进行了初步识别及分析。通过实测，现有方案无法满足我们的任务需求。为此希望能够利用深度学习在物体识别领域的成熟方案，构建一个面向水表图片面板识别的神经网络模型。</p>
<ul>
<li><p><strong>计算框架：</strong> Tensorflow (v1.7)</p>
</li>
<li><p><strong>使用接口：</strong> <a href="https://github.com/tensorflow/models/tree/master/research/object_detection">Tensorflow Object Detection API</a><sup><a href="#fn_1" id="reffn_1">1</a></sup></p>
</li>
<li><p><strong>算法模型：</strong> 根据预训练采用的数据集不同，可用的模型列表如下：</p>
<ul>
<li><a href="http://mscoco.org/">COCO dataset</a></li>
</ul>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>Model name</th>
<th>Speed (ms)</th>
<th>COCO mAP<sup><a href="#fn_2" id="reffn_2">2</a></sup></th>
<th>Outputs</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2017_11_17.tar.gz">ssd_mobilenet_v1_coco</a></td>
<td>30</td>
<td>21</td>
<td>Boxes</td>
</tr>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2017_11_17.tar.gz">ssd_inception_v2_coco</a></td>
<td>42</td>
<td>24</td>
<td>Boxes</td>
</tr>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2017_11_08.tar.gz">faster_rcnn_inception_v2_coco</a></td>
<td>58</td>
<td>28</td>
<td>Boxes</td>
</tr>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_coco_2017_11_08.tar.gz">faster_rcnn_resnet50_coco</a></td>
<td>89</td>
<td>30</td>
<td>Boxes</td>
</tr>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_lowproposals_coco_2017_11_08.tar.gz">faster_rcnn_resnet50_lowproposals_coco</a></td>
<td>64</td>
<td></td>
<td>Boxes</td>
</tr>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/rfcn_resnet101_coco_2017_11_08.tar.gz">rfcn_resnet101_coco</a></td>
<td>92</td>
<td>30</td>
<td>Boxes</td>
</tr>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_2017_11_08.tar.gz">faster_rcnn_resnet101_coco</a></td>
<td>106</td>
<td>32</td>
<td>Boxes</td>
</tr>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_lowproposals_coco_2017_11_08.tar.gz">faster_rcnn_resnet101_lowproposals_coco</a></td>
<td>82</td>
<td></td>
<td>Boxes</td>
</tr>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_coco_2017_11_08.tar.gz">faster_rcnn_inception_resnet_v2_atrous_coco</a></td>
<td>620</td>
<td>37</td>
<td>Boxes</td>
</tr>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_lowproposals_coco_2017_11_08.tar.gz">faster_rcnn_inception_resnet_v2_atrous_lowproposals_coco</a></td>
<td>241</td>
<td></td>
<td>Boxes</td>
</tr>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_nas_coco_2017_11_08.tar.gz">faster_rcnn_nas</a></td>
<td>1833</td>
<td>43</td>
<td>Boxes</td>
</tr>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_nas_lowproposals_coco_2017_11_08.tar.gz">faster_rcnn_nas_lowproposals_coco</a></td>
<td>540</td>
<td></td>
<td>Boxes</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li><a href="http://www.cvlibs.net/datasets/kitti/">Kitti dataset</a></li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>Model name</th>
<th>Speed (ms)</th>
<th>Pascal mAP@0.5 (ms)</th>
<th>Outputs</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_kitti_2017_11_08.tar.gz">faster_rcnn_resnet101_kitti</a></td>
<td>79</td>
<td>87</td>
<td>Boxes</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li><a href="https://github.com/openimages/dataset">Open Images dataset</a></li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>Model name</th>
<th>Speed (ms)</th>
<th>Open Images mAP@0.5<sup><a href="#fn_2" id="reffn_2">2</a></sup></th>
<th>Outputs</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_oid_2017_11_08.tar.gz">faster_rcnn_inception_resnet_v2_atrous_oid</a></td>
<td>727</td>
<td>37</td>
<td>Boxes</td>
</tr>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_lowproposals_oid_2017_11_08.tar.gz">faster_rcnn_inception_resnet_v2_atrous_lowproposals_oid</a></td>
<td>347</td>
<td></td>
<td>Boxes</td>
</tr>
</tbody>
</table>
</div>
<p>  几种模型主要在精度和速度方面进行了取舍，如果需要一个高精度的模型可以选择faster R-CNN，如果希望速度快比如实时检测，则可以选择SSD模型。鉴于本方案中设计检测目标特征将为简单，可采用最轻量级的MobileSSD进行优化。</p>
<h2 id="2-实现流程"><a href="#2-实现流程" class="headerlink" title="2. 实现流程"></a>2. 实现流程</h2><h3 id="2-1-数据准备"><a href="#2-1-数据准备" class="headerlink" title="2.1 数据准备"></a>2.1 数据准备</h3><p>数据准备的环节是除了训练过程之外最为耗时的环节，准备数据的质量和数量将直接决定了训练模型的好坏。图片数据最好在光线、角度、清晰度等方面能最大化的泛化实际的业务场景。由于在这个案例中我们只需要输出一个分类对象，而且输入对象被限定在水表图片上，所以整体涉及需要提取的特征参数空间不是很大，少量经过处理好的明显可供辨识的水表图片即可。目前可用水表图片攻击229张，我们采用80%用于训练，20%用于测试的方式进行划分。</p>
<blockquote>
<p>如果分类较多，数据有限，可以选择从互联网上下载或者在开源数据集中获得所需的数据。</p>
<p>另外需要注意图片的大小，图片太大一方面影响训练过程的处理时间，另外大量图片载入内存将很容导致内存溢出，所以如果图像特征粒度不是特别精细可以采用低分辨率图片进行分析。</p>
</blockquote>
<h4 id="数据标记"><a href="#数据标记" class="headerlink" title="数据标记"></a>数据标记</h4><p>对于物体识别而言，数据标记过程是一个相对复杂的过程，目前除了人工标记没有太好的自动或半监督手段，幸好针对图片的标记已经有了几款很好用的工具：</p>
<ul>
<li><p><a href="https://github.com/tzutalin/labelImg">LabelImg</a></p>
<ul>
<li>这是一个可以直接在图片上做注释框自动生成标记信息的软件，注释信息将被保存为PASCAL VOC 格式的XML文件（<a href="http://www.image-net.org/">ImageNet</a>的文件格式）</li>
</ul>
<p><img src="/qnsource/images/2018-04-14-TensorFlow-Object-Detection-API/labelImage.jpg" alt="labelImage"></p>
</li>
<li><p><a href="https://github.com/christopher5106/FastAnnotationTool">FIAT (Fast Image Data Annotation Tool)</a> </p>
<ul>
<li><p>该工具生成csv格式的注释文件</p>
<p><a href="https://camo.githubusercontent.com/c77ea08c2a142680f237371c1a1e5743b877842c/687474703a2f2f6368726973746f70686572353130362e6769746875622e696f2f696d672f616e6e6f7461746f725f65726173652e706e67"><img src="https://camo.githubusercontent.com/c77ea08c2a142680f237371c1a1e5743b877842c/687474703a2f2f6368726973746f70686572353130362e6769746875622e696f2f696d672f616e6e6f7461746f725f65726173652e706e67" alt="data annotation"></a></p>
</li>
</ul>
</li>
<li><p><a href="http://imagemagick.org/#">ImageMagick</a></p>
<ul>
<li>图片预处理工具</li>
<li>Use ImageMagick<a href="http://tarr.uspto.gov/servlet/tarr?regser=serial&amp;entry=78333969">®</a> to create, edit, compose, or convert bitmap images.  It can read and write images in a variety of <a href="http://imagemagick.org/script/formats.php">formats</a> (over 200) including PNG, JPEG, GIF, HEIC, TIFF, <a href="http://imagemagick.org/script/motion-picture.php">DPX</a>, <a href="http://imagemagick.org/script/high-dynamic-range.php">EXR</a>, WebP, Postscript, PDF, and SVG.  Use ImageMagick to resize, flip, mirror, rotate, distort, shear and transform images, adjust image colors, apply various special effects, or draw text, lines, polygons, ellipses and Bézier curves.</li>
</ul>
</li>
</ul>
<p>在本方案中我们使用工具LabelImage将229张水表图片进行了标注，同时生成了PASCAL格式的XML文件，名字为<code>000001.jpg</code>的图片注释格式如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">annotation</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">folder</span>&gt;</span>imgs<span class="tag">&lt;/<span class="name">folder</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">filename</span>&gt;</span>000001.jpg<span class="tag">&lt;/<span class="name">filename</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">source</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">database</span>&gt;</span>VOC<span class="tag">&lt;/<span class="name">database</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">annotation</span>&gt;</span>PASCAL VOC<span class="tag">&lt;/<span class="name">annotation</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">size</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">width</span>&gt;</span>2448<span class="tag">&lt;/<span class="name">width</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">height</span>&gt;</span>3264<span class="tag">&lt;/<span class="name">height</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">depth</span>&gt;</span>3<span class="tag">&lt;/<span class="name">depth</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">size</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">segmented</span>&gt;</span>0<span class="tag">&lt;/<span class="name">segmented</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">object</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>panel<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">pose</span>&gt;</span>Frontal<span class="tag">&lt;/<span class="name">pose</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">truncated</span>&gt;</span>0<span class="tag">&lt;/<span class="name">truncated</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">difficult</span>&gt;</span>0<span class="tag">&lt;/<span class="name">difficult</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">bndbox</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">xmin</span>&gt;</span>739<span class="tag">&lt;/<span class="name">xmin</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">ymin</span>&gt;</span>430<span class="tag">&lt;/<span class="name">ymin</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">xmax</span>&gt;</span>1475<span class="tag">&lt;/<span class="name">xmax</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">ymax</span>&gt;</span>796<span class="tag">&lt;/<span class="name">ymax</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">bndbox</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">object</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">annotation</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>我们在根目录新建一个<code>annotations</code>的文件夹存储229张图片的XML描述文件，同时根目录<code>images</code>文件夹用于存储所有的训练数据和测试数据。</p>
<h4 id="数据描述格式"><a href="#数据描述格式" class="headerlink" title="数据描述格式"></a>数据描述格式</h4><ul>
<li>在TensorFlow 物体检测API中使用 <a href="https://www.tensorflow.org/api_guides/python/python_io#tfrecords_format_details">TFRecord file format</a>格式对图像标记信息进行描述，所以我们无论采取下面的那种标记方式，最终需要生成TFRcord格式的文件格式。</li>
<li><strong>TFRecord</strong>格式要去如下：</li>
</ul>
<blockquote>
<p>For every example in your dataset, you should have the following information:</p>
<ol>
<li>An RGB image for the dataset encoded as jpeg or png.</li>
<li>A list of bounding boxes for the image. Each bounding box should contain:<ol>
<li>A bounding box coordinates (with origin in top left corner) defined by 4floating point numbers [ymin, xmin, ymax, xmax]. Note that we store the<em>normalized</em> coordinates (x / width, y / height) in the TFRecord dataset.</li>
<li>The class of the object in the bounding box.</li>
</ol>
</li>
</ol>
</blockquote>
<ul>
<li><p>TensorFlow针对主流的物体识别类数据集格式提供了<a href="https://github.com/tensorflow/models/tree/master/research/object_detection/dataset_tools">转换工具</a>，包括 <a href="http://host.robots.ox.ac.uk/pascal/VOC/">PASCAL VOC dataset</a> ， <a href="http://www.robots.ox.ac.uk/~vgg/data/pets/">Oxford Pet dataset</a>等；</p>
<ul>
<li>PASCAL VOC </li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># From tensorflow/models/research/</span></span><br><span class="line">wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar</span><br><span class="line">tar -xvf VOCtrainval_11-May-2012.tar</span><br><span class="line">python object_detection/dataset_tools/create_pascal_tf_record.py \</span><br><span class="line">    --label_map_path=object_detection/data/pascal_label_map.pbtxt \</span><br><span class="line">    --data_dir=VOCdevkit --year=VOC2012 --<span class="built_in">set</span>=train \</span><br><span class="line">    --output_path=pascal_train.record</span><br><span class="line">python object_detection/dataset_tools/create_pascal_tf_record.py \</span><br><span class="line">    --label_map_path=object_detection/data/pascal_label_map.pbtxt \</span><br><span class="line">    --data_dir=VOCdevkit --year=VOC2012 --<span class="built_in">set</span>=val \</span><br><span class="line">    --output_path=pascal_val.record</span><br></pre></td></tr></table></figure>
<ul>
<li>Oxford-IIIT Pet</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># From tensorflow/models/research/</span></span><br><span class="line">wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz</span><br><span class="line">wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz</span><br><span class="line">tar -xvf annotations.tar.gz</span><br><span class="line">tar -xvf images.tar.gz</span><br><span class="line">python object_detection/dataset_tools/create_pet_tf_record.py \</span><br><span class="line">    --label_map_path=object_detection/data/pet_label_map.pbtxt \</span><br><span class="line">    --data_dir=`<span class="built_in">pwd</span>` \</span><br><span class="line">    --output_dir=`<span class="built_in">pwd</span>`</span><br></pre></td></tr></table></figure>
</li>
<li><p>如果你使用了自己的格式，可以参考<a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/using_your_own_dataset.md">TensorFlow官方文档</a>完成格式转换；</p>
</li>
</ul>
<p>在本方案中我们采用自己处理的方式来进行格式转换，使用文件<a href="https://github.com/datitran/raccoon_dataset/blob/master/xml_to_csv.py"><code>xml_to_csv.py</code></a>将所有图片的PASCAL格式文件转化为一个csv文件，然后进一步的利用TensorFLow工具<code>generate_tfrecord.py</code>生成TFRecord格式文件：</p>
<ol>
<li><p>执行<code>python xml_to_csv.py</code>,该文件将在根目录的<code>annotations</code>的文件夹下所有的<code>*xml</code>文件，并生成<code>screen_labels.csv</code>文件；</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">xml_to_csv</span><span class="params">(path)</span>:</span></span><br><span class="line">    xml_list = []</span><br><span class="line">    <span class="keyword">for</span> xml_file <span class="keyword">in</span> glob.glob(path + <span class="string">'/*.xml'</span>):</span><br><span class="line">        tree = ET.parse(xml_file)</span><br><span class="line">        root = tree.getroot()</span><br><span class="line">        <span class="keyword">for</span> member <span class="keyword">in</span> root.findall(<span class="string">'object'</span>):</span><br><span class="line">            filename = root.find(<span class="string">'filename'</span>).text</span><br><span class="line">            value = (root.find(<span class="string">'filename'</span>).text,</span><br><span class="line">                     int(root.find(<span class="string">'size'</span>)[<span class="number">0</span>].text),</span><br><span class="line">                     int(root.find(<span class="string">'size'</span>)[<span class="number">1</span>].text),</span><br><span class="line">                     member[<span class="number">0</span>].text,</span><br><span class="line">                     int(member[<span class="number">4</span>][<span class="number">0</span>].text),</span><br><span class="line">                     int(member[<span class="number">4</span>][<span class="number">1</span>].text),</span><br><span class="line">                     int(member[<span class="number">4</span>][<span class="number">2</span>].text),</span><br><span class="line">                     int(member[<span class="number">4</span>][<span class="number">3</span>].text)</span><br><span class="line">                     )</span><br><span class="line">            xml_list.append(value)</span><br><span class="line">    column_name = [<span class="string">'filename'</span>, <span class="string">'width'</span>, <span class="string">'height'</span>, <span class="string">'class'</span>, <span class="string">'xmin'</span>, <span class="string">'ymin'</span>, <span class="string">'xmax'</span>, <span class="string">'ymax'</span>]</span><br><span class="line">    xml_df = pd.DataFrame(xml_list, columns=column_name)</span><br><span class="line">    <span class="keyword">return</span> xml_df</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    image_path = os.path.join(os.getcwd(), <span class="string">'Annotations'</span>) <span class="comment"># Need Changes</span></span><br><span class="line">    xml_df = xml_to_csv(image_path)</span><br><span class="line">    xml_df.to_csv(<span class="string">'screen_labels.csv'</span>, index=<span class="keyword">None</span>) <span class="comment"># Need Changes</span></span><br><span class="line">    print(<span class="string">'Successfully converted xml to csv.'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol>
<li><p>使用如下代码随机生成训练数据和测试数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">np.random.seed(<span class="number">1</span>)</span><br><span class="line">full_labels = pd.read_csv(<span class="string">'screen_labels.csv'</span>)</span><br><span class="line">gb = full_labels.groupby(<span class="string">'filename'</span>)</span><br><span class="line">grouped_list = [gb.get_group(x) <span class="keyword">for</span> x <span class="keyword">in</span> gb.groups]</span><br><span class="line">train_index = np.random.choice(len(grouped_list), size=<span class="number">180</span>, replace=<span class="keyword">False</span>)</span><br><span class="line">test_index = np.setdiff1d(list(range(<span class="number">229</span>)), train_index)</span><br><span class="line">train = pd.concat([grouped_list[i] <span class="keyword">for</span> i <span class="keyword">in</span> train_index])</span><br><span class="line">test = pd.concat([grouped_list[i] <span class="keyword">for</span> i <span class="keyword">in</span> test_index])</span><br><span class="line">train.to_csv(<span class="string">'train_labels.csv'</span>, index=<span class="keyword">None</span>)</span><br><span class="line">test.to_csv(<span class="string">'test_labels.csv'</span>, index=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>分别执行脚本将训练数据和测试数据转换为TFRecord：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># From tensorflow/models/research/</span></span><br><span class="line">protoc object_detection/protos/*.proto --python_out=.</span><br><span class="line"><span class="comment"># Create train data:</span></span><br><span class="line">  python generate_tfrecord.py --csv_input=data/train_labels.csv  --output_path=train.record</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Create test data:</span></span><br><span class="line">  python generate_tfrecord.py --csv_input=data/test_labels.csv  --output_path=test.record</span><br></pre></td></tr></table></figure>
</li>
<li><p>将train.record和test.record的文件存储至根目录的data文件夹下</p>
</li>
<li><p>至此数据准备基本结束，我们创建了如下目录结构</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── annotations</span><br><span class="line">│   ├── 000001.xml</span><br><span class="line">          ...</span><br><span class="line">│   └── 000229.xml</span><br><span class="line">├── data</span><br><span class="line">│   ├── screen_labels.csv</span><br><span class="line">│   ├── test_labels.csv</span><br><span class="line">│   ├── test.record</span><br><span class="line">│   ├── train_labels.csv</span><br><span class="line">│   └── train.record</span><br><span class="line">├── generate_tfrecord.py</span><br><span class="line">├── images</span><br><span class="line">│   ├── 000001.jpg</span><br><span class="line">         ...</span><br><span class="line">│   └── 000229.jpg</span><br><span class="line">├── __init__.py</span><br><span class="line">├── README.md</span><br><span class="line">├── split labels.ipynb</span><br><span class="line">├── test_generate_tfrecord.py</span><br><span class="line">├── test_xml_to_csv.py</span><br><span class="line">└── xml_to_csv.py</span><br><span class="line">​</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="2-2-模型配置-迁移学习"><a href="#2-2-模型配置-迁移学习" class="headerlink" title="2.2 模型配置/迁移学习"></a>2.2 模型配置/迁移学习</h3><blockquote>
<p>完全从头训练一个用于物体检测的模型即使采用大量GPU资源至少也需要数周时间，为了加速模型初期迭代过程，我们选择了一个已经在COCO数据集针对其他多种物体识别场景预训练好的模型，通过重复使用该模型的多数参数来快速生成我们的模型。更多技术内容可以参照迁移学习的技术实现。</p>
</blockquote>
<p>由于没有足够的资源从头训练一个模型，我们将采用迁移学习技术，利用一个已经训练好的模型进行迁移学习及训练。</p>
<p>从测试角度考虑，本测试方案选择了体积最小，速度最快的用于嵌入式设备的SSD模型：<a href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2017_11_17.tar.gz">ssd_mobilenet_v1_coco</a></p>
<p>下载模型包，可以得到如下文件：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── object-detection.pbtxt	</span><br><span class="line">├── ssd_mobilenet_v1_pets.config</span><br><span class="line">├── checkpoint</span><br><span class="line">├── frozen_inference_graph.pb</span><br><span class="line">├── model.ckpt.data-00000-of-00001</span><br><span class="line">├── model.ckpt.index</span><br><span class="line">├── model.ckpt.meta</span><br><span class="line">└── saved_model</span><br><span class="line">    ├── saved_model.pb</span><br><span class="line">    └── variables</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>a graph proto (<code>graph.pbtxt</code>)</li>
<li>a checkpoint (<code>model.ckpt.data-00000-of-00001</code>, <code>model.ckpt.index</code>, <code>model.ckpt.meta</code>)</li>
<li>a frozen graph proto with weights baked into the graph as constants (<code>frozen_inference_graph.pb</code>) to be used for out of the box inference</li>
<li>a config file (<code>pipeline.config</code>) which was used to generate the graph. These directly correspond to a config file in the <a href="https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs">samples/configs</a>) directory but often with a modified score threshold. </li>
</ul>
</blockquote>
<p>我们下载并在根目录解压模型包ssd_mobilenet_v1_coco，同时创建一个training文件，存储如下文件：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">training/</span><br><span class="line">├── object-detection.pbtxt</span><br><span class="line">└── ssd_mobilenet_v1_pets.config</span><br></pre></td></tr></table></figure>
<h4 id="Label-Map"><a href="#Label-Map" class="headerlink" title="Label Map"></a>Label Map</h4><p>其中 <code>object-detection.pbtxt</code>是我们模型所有分类的标签，如下所示，如果有多个分类id从1开始递增，同时给每个标签一个唯一的名称(id为0预留给背景分类)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">item &#123;</span><br><span class="line">  id: 1</span><br><span class="line">  name: <span class="string">'panel'</span></span><br><span class="line">&#125;</span><br><span class="line">item&#123;</span><br><span class="line">  id: 2</span><br><span class="line">  name: <span class="string">'其他分类'</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="配置物体识别训练流程文件"><a href="#配置物体识别训练流程文件" class="headerlink" title="配置物体识别训练流程文件"></a>配置物体识别训练流程文件</h4><blockquote>
<p>更多内容参考：<a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/configuring_jobs.md">https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/configuring_jobs.md</a></p>
</blockquote>
<p>Tensorflow Object Detection API 使用 protobuf 文件来配置训练和检测的流程。通过配置Training Pipleline的参数配置可以决定训练参数的选择，我们将尽量多的利用已经训练好的参数进行训练。</p>
<p>一个配置文件由5部分组成：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">model &#123;</span><br><span class="line">(... Add model config here...)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">train_config : &#123;</span><br><span class="line">(... Add train_config here...)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">train_input_reader: &#123;</span><br><span class="line">(... Add train_input configuration here...)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">eval_config: &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">eval_input_reader: &#123;</span><br><span class="line">(... Add eval_input configuration here...)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<ol>
<li>The <code>model</code> configuration. This defines what type of model will be trained (ie. meta-architecture, feature extractor).</li>
<li>The <code>train_config</code>, which decides what parameters should be used to train model parameters (ie. SGD parameters, input preprocessing and feature extractor initialization values).</li>
<li>The <code>eval_config</code>, which determines what set of metrics will be reported for evaluation (currently we only support the PASCAL VOC metrics).</li>
<li>The <code>train_input_config</code>, which defines what dataset the model should be trained on.</li>
<li>The <code>eval_input_config</code>, which defines what dataset the model will be evaluated on. Typically this should be different than the training input dataset.</li>
</ol>
</blockquote>
<p><code>ssd_mobilenet_v1_pets.config</code>为模型配置文件，我们在样例(详见：object_detection/samples/configs 文件夹)上进行如下修改：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">  ssd &#123;</span><br><span class="line">    num_classes: 1                 <span class="comment">#修改类别为实际类别值</span></span><br><span class="line">    box_coder &#123;</span><br><span class="line">      faster_rcnn_box_coder &#123;</span><br><span class="line">        y_scale: 10.0</span><br><span class="line">        x_scale: 10.0</span><br><span class="line">        height_scale: 5.0</span><br><span class="line">        width_scale: 5.0</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">fine_tune_checkpoint: <span class="string">"ssd_mobilenet_v1_coco_2017_11_17/model.ckpt"</span> <span class="comment">#指向模型文件中的checkpoint文件</span></span><br><span class="line">train_input_reader: &#123;                                               </span><br><span class="line">  tf_record_input_reader &#123;</span><br><span class="line">    input_path: <span class="string">"data/train.record"</span>              <span class="comment">#修改为上一个步骤生成的训练record路径</span></span><br><span class="line">  &#125;</span><br><span class="line">  label_map_path: <span class="string">"data/object-detection.pbtxt"</span>  <span class="comment">#修改为pbtxt文件路径，描述类别标签</span></span><br><span class="line">&#125;</span><br><span class="line">eval_input_reader: &#123;</span><br><span class="line">  tf_record_input_reader &#123;</span><br><span class="line">    input_path: <span class="string">"data/test.record"</span>           <span class="comment">#修改为上一个步骤生成的测试数据record路径</span></span><br><span class="line">  &#125;</span><br><span class="line">  label_map_path: <span class="string">"data/object-detection.pbtxt"</span> <span class="comment">#修改为pbtxt文件路径，描述类别标签</span></span><br><span class="line">  shuffle: <span class="literal">false</span></span><br><span class="line">  num_readers: 1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>train_config</code> provides two fields to specify pre-existing checkpoints: <code>fine_tune_checkpoint</code> and <code>from_detection_checkpoint</code>. <code>fine_tune_checkpoint</code> should provide a path to the pre-existing checkpoint (ie:”/usr/home/username/checkpoint/model.ckpt-#####”). <code>from_detection_checkpoint</code> is a boolean value. If false, it assumes the checkpoint was from an object classification checkpoint. Note that starting from a detection checkpoint will usually result in a faster training job than a classification checkpoint.</p>
<p>The list of provided checkpoints can be found <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md">here</a>.</p>
</blockquote>
<h3 id="2-3-训练"><a href="#2-3-训练" class="headerlink" title="2.3 训练"></a>2.3 训练</h3><h4 id="Tensorflow-Object-Detection-API-安装"><a href="#Tensorflow-Object-Detection-API-安装" class="headerlink" title="Tensorflow Object Detection API 安装"></a>Tensorflow Object Detection API 安装</h4><ol>
<li><p>从GitHub下载Tensorflow Object Detection API</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/tensorflow/models.git</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置基本环境</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># For CPU</span></span><br><span class="line">pip install tensorflow</span><br><span class="line"><span class="comment"># For GPU</span></span><br><span class="line">pip install tensorflow-gpu</span><br><span class="line"></span><br><span class="line">sudo apt-get install protobuf-compiler python-pil python-lxml python-tk</span><br><span class="line">pip install --user Cython</span><br><span class="line">pip install --user contextlib2</span><br><span class="line">pip install --user jupyter</span><br><span class="line">pip install --user matplotlib</span><br></pre></td></tr></table></figure>
</li>
<li><p>COCO API installation</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/cocodataset/cocoapi.git</span><br><span class="line">cd cocoapi/PythonAPI</span><br><span class="line">make</span><br><span class="line">cp -r pycocotools &lt;path_to_tensorflow&gt;/models/research/</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol>
<li>Protobuf 编译</li>
</ol>
<p>Tensorflow通过Google的Protobufs来配置和训练模型，所以在开始使用之前需要对protobuf相关库进行编译。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># From tensorflow/models/research/</span></span><br><span class="line">protoc object_detection/protos/*.proto --python_out=.</span><br></pre></td></tr></table></figure>
<ol>
<li>Add Libraries to PYTHONPATH[<strong>重要</strong>]</li>
</ol>
<p>在路径 <code>tensorflow/models/research/</code> 下添加PYTHONPATH路径，实现全局引用</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># From tensorflow/models/research/</span></span><br><span class="line"><span class="built_in">export</span> PYTHONPATH=<span class="variable">$PYTHONPATH</span>:`<span class="built_in">pwd</span>`:`<span class="built_in">pwd</span>`/slim</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>Note:</strong> This command needs to run from every new terminal you start. If you wish to avoid running this manually, you can add it as a new line to the end of your ~/.bashrc file.</p>
</blockquote>
<ol>
<li><p>测试安装是否成功</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># From tensorflow/models/research/</span></span><br><span class="line">python object_detection/builders/model_builder_test.py</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="启动训练过程"><a href="#启动训练过程" class="headerlink" title="启动训练过程"></a>启动训练过程</h4><ol>
<li><p>将在数据准备和模型配置阶段的文件复制到tensorflow object_detect文件夹下<code>/models/research/object_detection</code>,包括data/文件夹，image/文件夹，training/文件夹，ssd_mobilenet_v1_coco_2017_11_17/原始模型文件夹</p>
</li>
<li><p>执行如下代码启动训练过程：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># From the tensorflow/models/research/ directory</span></span><br><span class="line">PIPELINE_CONFIG_PATH=&#123;path to pipeline config file&#125;</span><br><span class="line">MODEL_DIR=&#123;path to model directory&#125;</span><br><span class="line">NUM_TRAIN_STEPS=50000</span><br><span class="line">SAMPLE_1_OF_N_EVAL_EXAMPLES=1</span><br><span class="line">python object_detection/model_main.py \</span><br><span class="line">    --pipeline_config_path=<span class="variable">$&#123;PIPELINE_CONFIG_PATH&#125;</span> \</span><br><span class="line">    --model_dir=<span class="variable">$&#123;MODEL_DIR&#125;</span> \</span><br><span class="line">    --num_train_steps=<span class="variable">$&#123;NUM_TRAIN_STEPS&#125;</span> \</span><br><span class="line">    --sample_1_of_n_eval_examples=<span class="variable">$SAMPLE_1_OF_N_EVAL_EXAMPLES</span> \</span><br><span class="line">    --alsologtostderr</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="使用TensorBoard-跟踪训练过程"><a href="#使用TensorBoard-跟踪训练过程" class="headerlink" title="使用TensorBoard 跟踪训练过程"></a>使用TensorBoard 跟踪训练过程</h4><p>训练过程会持续几个小时到十几个小时，可以通过tensorboard查看训练的情况</p>
<p>使用一台Azure的CPU虚拟机进行训练~4s进行一次迭代，正常模型有比较不错结果迭代次数大概在10K以上。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir=<span class="variable">$&#123;MODEL_DIR&#125;</span></span><br></pre></td></tr></table></figure>
<p><img src="/qnsource/images/2018-04-14-TensorFlow-Object-Detection-API/tensorboard_loss.PNG" alt="tensorboard_loss"></p>
<h3 id="2-4-导出模型"><a href="#2-4-导出模型" class="headerlink" title="2.4 导出模型"></a>2.4 导出模型</h3><p>模型训练过程中，会每隔一段时间生成一个checkpoint，一个checkpoint至少包括三个文件：</p>
<ul>
<li>model.ckpt-${CHECKPOINT_NUMBER}.data-00000-of-00001</li>
<li>model.ckpt-${CHECKPOINT_NUMBER}.index</li>
<li>model.ckpt-${CHECKPOINT_NUMBER}.meta</li>
</ul>
<p>可以通过如下命令从checkpoints中提取模型：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Example Usage:</span><br><span class="line">--------------</span><br><span class="line">python export_inference_graph \</span><br><span class="line">    --input_type image_tensor \</span><br><span class="line">    --pipeline_config_path path/to/ssd_inception_v2.config \</span><br><span class="line">    --trained_checkpoint_prefix path/to/model.ckpt \</span><br><span class="line">    --output_directory path/to/exported_model_directory</span><br><span class="line">    </span><br><span class="line">    -----</span><br><span class="line">The expected output would be <span class="keyword">in</span> the directory</span><br><span class="line">path/to/exported_model_directory (<span class="built_in">which</span> is created <span class="keyword">if</span> it does not exist)</span><br><span class="line">with contents:</span><br><span class="line"> - graph.pbtxt</span><br><span class="line"> - model.ckpt.data-00000-of-00001</span><br><span class="line"> - model.ckpt.info</span><br><span class="line"> - model.ckpt.meta</span><br><span class="line"> - frozen_inference_graph.pb</span><br><span class="line"> + saved_model (a directory)</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># From tensorflow/models/research/</span></span><br><span class="line"><span class="built_in">export</span> PYTHONPATH=<span class="variable">$PYTHONPATH</span>:`<span class="built_in">pwd</span>`:`<span class="built_in">pwd</span>`/slim</span><br><span class="line">python export_inference_graph.py \</span><br><span class="line">    --input_type image_tensor \</span><br><span class="line">    --pipeline_config_path training/ssd_mobilenet_v1_pets.config \</span><br><span class="line">    --trained_checkpoint_prefix training/model.ckpt-10116 \</span><br><span class="line">    --output_directory water_meter_panel</span><br><span class="line">-----</span><br><span class="line">INPUT_TYPE=image_tensor</span><br><span class="line">PIPELINE_CONFIG_PATH=<span class="string">"object_detection/training/pipeline.config"</span></span><br><span class="line">TRAINED_CKPT_PREFIX=/home/ubuntu/1.objectDetection/training/model.ckpt-14450</span><br><span class="line">EXPORT_DIR=/home/ubuntu/1.objectDetection/<span class="built_in">export</span></span><br><span class="line"></span><br><span class="line">$ python object_detection/export_inference_graph.py \</span><br><span class="line">    --input_type=<span class="variable">$&#123;INPUT_TYPE&#125;</span> \</span><br><span class="line">    --pipeline_config_path=<span class="variable">$&#123;PIPELINE_CONFIG_PATH&#125;</span> \</span><br><span class="line">    --trained_checkpoint_prefix=<span class="variable">$&#123;TRAINED_CKPT_PREFIX&#125;</span> \</span><br><span class="line">    --output_directory=<span class="variable">$&#123;EXPORT_DIR&#125;</span></span><br><span class="line"></span><br><span class="line">-----</span><br><span class="line">WARNING:tensorflow:From /home/gaoc/data/<span class="built_in">test</span>/object_detect/models/research/object_detection/exporter.py:357: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed <span class="keyword">in</span> a future version.</span><br><span class="line">Instructions <span class="keyword">for</span> updating:</span><br><span class="line">Please switch to tf.train.get_or_create_global_step</span><br><span class="line">2018-01-20 06:34:08.551446: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA</span><br><span class="line">2018-01-20 06:34:14.056881: I tensorflow/core/grappler/devices.cc:51] Number of eligible GPUs (core count &gt;= 8): 0</span><br><span class="line">Converted 199 variables to const ops.</span><br></pre></td></tr></table></figure>
<blockquote>
<p>如果<code>Exportor.py</code>文件报bug，请参考<a href="https://github.com/tensorflow/models/issues/2861">https://github.com/tensorflow/models/issues/2861</a> 修复</p>
</blockquote>
<p>运行以上代码，将在<code>water_meter_panel</code>文件夹下生成模型所需的相关文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">gaoc@DataScience:~/data/<span class="built_in">test</span>/object_detect/models/research/object_detection$ ls -l water_meter_panel/</span><br><span class="line">total 44820</span><br><span class="line">-rw-r--r-- 1 gaoc root       77 Jan 20 06:34 checkpoint</span><br><span class="line">-rw-r--r-- 1 gaoc root 22636802 Jan 20 06:34 frozen_inference_graph.pb</span><br><span class="line">-rw-r--r-- 1 gaoc root 22174240 Jan 20 06:34 model.ckpt.data-00000-of-00001</span><br><span class="line">-rw-r--r-- 1 gaoc root     8873 Jan 20 06:34 model.ckpt.index</span><br><span class="line">-rw-r--r-- 1 gaoc root  1058139 Jan 20 06:34 model.ckpt.meta</span><br><span class="line">drwxr-xr-x 3 gaoc root     4096 Jan 20 06:34 saved_model</span><br><span class="line">water_meter_panel/</span><br><span class="line">├── checkpoint</span><br><span class="line">├── frozen_inference_graph.pb</span><br><span class="line">├── model.ckpt.data-00000-of-00001</span><br><span class="line">├── model.ckpt.index</span><br><span class="line">├── model.ckpt.meta</span><br><span class="line">└── saved_model</span><br><span class="line">    ├── saved_model.pb</span><br><span class="line">    └── variables</span><br></pre></td></tr></table></figure>
<h3 id="2-5-测试"><a href="#2-5-测试" class="headerlink" title="2.5 测试"></a>2.5 测试</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># From the tensorflow/models/research/ directory</span></span><br><span class="line">python object_detection/eval.py \</span><br><span class="line">    --logtostderr \</span><br><span class="line">    --pipeline_config_path=<span class="variable">$&#123;PATH_TO_YOUR_PIPELINE_CONFIG&#125;</span> \</span><br><span class="line">    --checkpoint_dir=<span class="variable">$&#123;PATH_TO_TRAIN_DIR&#125;</span> \</span><br><span class="line">    --eval_dir=<span class="variable">$&#123;PATH_TO_EVAL_DIR&#125;</span></span><br></pre></td></tr></table></figure>
<p>物体识别领域的算法性能评价指标多数选择AP和mAP（mean average precision），多个类别物体检测中，每一个类别都可以根据recall和precision绘制一条曲线，AP就是该曲线下的面积，mAP是多个类别AP的平均值</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Average Precision (AP):</span><br><span class="line">AP% AP at IoU=.50:.05:.95 (primary challenge metric) APIoU=.50% AP at IoU=.50 (PASCAL VOC metric) APIoU=.75% AP at IoU=.75 (strict metric) </span><br><span class="line">AP Across Scales:</span><br><span class="line">APsmall% AP <span class="keyword">for</span> small objects: area &lt; 322 APmedium% AP <span class="keyword">for</span> medium objects: 322 &lt; area &lt; 962 APlarge% AP <span class="keyword">for</span> large objects: area &gt; 962 </span><br><span class="line">Average Recall (AR):</span><br><span class="line">ARmax=1% AR given 1 detection per image ARmax=10% AR given 10 detections per image ARmax=100% AR given 100 detections per image </span><br><span class="line">AR Across Scales:</span><br><span class="line">ARsmall% AR <span class="keyword">for</span> small objects: area &lt; 322 ARmedium% AR <span class="keyword">for</span> medium objects: 322 &lt; area &lt; 962 ARlarge% AR <span class="keyword">for</span> large objects: area &gt; 962</span><br></pre></td></tr></table></figure>
<p><img src="/qnsource/images/2018-04-14-TensorFlow-Object-Detection-API/AP_MAP.PNG" alt="AP_MAP"></p>
<p>从性能测试结果来看该模型已经具备96%的检测精度了，具备投入生产环境所需的性能。</p>
<p>预测结果见下图，准确率达到了99%以上。</p>
<p><img src="/qnsource/images/2018-04-14-TensorFlow-Object-Detection-API/detect_demo.png" alt="detect_demo"></p>
<h2 id="3-结论"><a href="#3-结论" class="headerlink" title="3. 结论"></a>3. 结论</h2><ul>
<li>对于简单业务场景的物体识别类案例，可以通过迁移学习利用已有的成熟模型快速迭代生成新的特定模型；</li>
<li>这种迁移的另一个优势是对小数据样本具备很好的适应能力，可以解决前期数据不足和数据质量差的问题；</li>
<li>当然采用这种方式也同时存在一定的弊端，比如由于模型预训练参数较多，模型体积较大，模型的选取需要反复测试和优化。</li>
</ul>
<h3 id="3-1-经验总结"><a href="#3-1-经验总结" class="headerlink" title="3.1 经验总结"></a>3.1 经验总结</h3><ol>
<li><p>虽然Tensorflow Object Detection API提供了丰富的文档介绍相关工作流程，但由于技术、平台和软件版本本身更新较快，实践中还是或多或少会遇到不少问题，静下心来多翻翻Github的issues里一般都有别人的提问及解答；建议还是先根据文档跑通demo，熟悉相关工具和流程再将框架迁移到自己的数据集之上；</p>
</li>
<li><p>建议自己识别的项目文件单独建立一个数据准备文件夹进行数据准备和相关配置脚本的准备，不要跟Github克隆的Object Detection项目混在一起，不容易管理，也不利于重复利用；</p>
</li>
<li><p>TFOD API提供的Tensorflow可视化相当完备，启动训练任务之后，一定要同步启动验证脚本，可以实时跟踪训练进程；</p>
</li>
<li><p>很容易疏忽的一个步骤是关于PYTHON PATH的处理，在执行相关API之前一定要记得EXPORT相关path，可以些一个bash文件，在执行命令的Terminal中source一下；常见错误如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ImportError: No module named ’object_detection’</span><br></pre></td></tr></table></figure>
</li>
<li><p>充分利用GPU和CPU进行训练：</p>
<ol>
<li><p>如果使用CPU训练，控制配置参数中<code>num_examples</code>为一个很小的值（5-10），这样将使用验证数据中的一部分进行验证而不是全部；</p>
</li>
<li><p>配置<code>CUDA_VISIBLE_DEVICES</code>环境变量，选择使用哪个GPU或CPU来分配内存资源：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ export CUDA_VISIBLE_DEVICES="0"</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ export CUDA_VISIBLE_DEVICES="1"</span><br><span class="line">... another scripts</span><br></pre></td></tr></table></figure>
<p>配置为空使用CPU</p>
</li>
</ol>
</li>
<li><p>尽量使用最新版的Tensorflow，在撰写本文时已经是1.7了，当时做实验用的是1.4，复现的时候发现1.4版本已经抛错了…</p>
</li>
</ol>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote id="fn_1">
<sup>1</sup>. The TensorFlow Object Detection API is an open source framework built on top of TensorFlow that makes it easy to construct, train and deploy object detection models.<a href="#reffn_1" title="Jump back to footnote [1] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_2">
<sup>2</sup>. See <a href="http://cocodataset.org/#detections-eval">MSCOCO evaluation protocol</a>.<a href="#reffn_2" title="Jump back to footnote [2] in the text."> &#8617;</a>
</blockquote>
<ol>
<li><a href="https://www.kernix.com/blog/image-classification-with-a-pre-trained-deep-neural-network_p11">Image classification with a pre-trained deep neural network</a></li>
<li><a href="https://towardsdatascience.com/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9">How to train your own Object Detector with TensorFlow’s Object Detector API</a></li>
<li><a href="https://github.com/datitran/raccoon_dataset">https://github.com/datitran/raccoon_dataset</a></li>
</ol>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                

                <time class="level-item has-text-grey" datetime="2018-04-13T06:45:52.000Z">2018-04-13</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/深度学习/">深度学习</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/深度学习/机器视觉/">机器视觉</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    23 分钟 读完 (大约 3385 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2018/04/13/Object-Detection-Faster-RCNN/">物体识别技术之Faster R-CNN</a>
            
        </h1>
        <div class="content">
            <p><strong>摘要:</strong> 2015年提出的Faster R-CNN架构在基于机器视觉的物体识别领域占据重要的地位，从R-CNN到fast R-CNN再到faster R-CNN,乃至后续的Mask-R-CNN形成了一条完整的两步识别的物体识别技术生态。</p>
<!-- excerpt -->
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>物体识别技术一直是机器视觉中业务场景最丰富，关注度最高的一个类别。将花几期来分别对主流的物体识别技术如Faster RCNN，SSD，YOLO，Mask-RCNN进行整理和分析，并利用实践的方式进行强化。</p>
<p>在R-CNN,Fast R-CNN，Faster R-CNN中，物体识别被分为两个步骤实现（与SSD、YOLO的主要差异）：候选区域选择和基于深度网络的物体识别。</p>
<h3 id="传统的物体识别算法"><a href="#传统的物体识别算法" class="headerlink" title="传统的物体识别算法"></a>传统的物体识别算法</h3><p>传统的物体识别技术采用的滑动窗口+图像金字塔+分类器的算法，可以参见前述博文在<a href="/Deep-Learning-Lab-Logo-Detection">基于机器视觉技术的品牌LOGO检测</a>中做的实际测试，原理易于理解，但效率较低，很难达到实时处理的需求：</p>
<ol>
<li>速度慢，效率低：需要利用滑动窗口遍历图像的不同位置；</li>
<li>受图像畸变影响严重：由于CNN的输入必须是固定大小的图像，所以限制了检测目标的长宽比例，比如这种方法不能同时检测矮胖对象和长瘦对象；</li>
<li>错误率高，没法识别图像的全局特征，每个窗口只能看到局部特征，所以检测精度也受到了比较大的影响。</li>
</ol>
<h3 id="物体识别精度的衡量指标"><a href="#物体识别精度的衡量指标" class="headerlink" title="物体识别精度的衡量指标"></a>物体识别精度的衡量指标</h3><ul>
<li><p>IoU(Intersection over Union)</p>
<script type="math/tex; mode=display">
IoU = \frac{Area\ of\ Overlap}{Area\ of\ Union}</script><p><img src="/qnsource/images/2018-04-13-Object-Detection-Faster-RCNN/IoU.png" alt="IoU"></p>
</li>
<li><p>mAP(Mean Average Precision)</p>
<ul>
<li>所有分类的IoU均值；</li>
</ul>
</li>
</ul>
<h3 id="参考论文"><a href="#参考论文" class="headerlink" title="参考论文"></a>参考论文</h3><ol>
<li>R-CNN： Rich feature hierarchies for accurate object detection and semantic segmentation</li>
<li>Faster R-CNN</li>
</ol>
<h2 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h2><blockquote>
<p><strong>论文：</strong> Rich feature hierarchies for accurate object detection and semantic segmentation，2013，Girshick</p>
</blockquote>
<p>问题：解决目标检测网络</p>
<p>R-CNN的实现包括如下图所示的4个主要步骤：</p>
<ol>
<li>接受输入图像；</li>
<li>利用Selective Search算法从图像中抽取大约2000个候选区域；</li>
<li>对每个候选区域利用预训练的CNN进行特征抽取（迁移学习）；</li>
<li>对每个特征抽取区域利用线性SVM进行分类</li>
</ol>
<p><img src="/qnsource/images/2018-04-13-Object-Detection-Faster-RCNN/R-CNN.png" alt="R-CNN"></p>
<p>论文的主要贡献：</p>
<ol>
<li>使用Selective Search替代了特征金字塔和滑动窗口实现的兴趣区域选择，提升了效率；</li>
<li>利用预训练的神经网络进行特征提取替代了手工特征如HOG的特征提取方法，正是由于CNN学习的特征具备的鲁棒性大大提供了系统的泛化性能</li>
</ol>
<p>仍然存在的问题：</p>
<ol>
<li>识别慢，效率低；</li>
<li>不是一个端到端的解决方案</li>
</ol>
<h3 id="Selective-Search算法"><a href="#Selective-Search算法" class="headerlink" title="Selective Search算法"></a>Selective Search算法</h3><blockquote>
<p>论文：<a href="https://koen.me/research/pub/uijlings-ijcv2013-draft.pdf">Selective Search for Object Recognition</a>，2012，J.R.R.Uijings</p>
</blockquote>
<p>之前很多算法都是基于蛮力搜索(Exhaustive Search),对整张图片进行扫描，或者是采用动态窗口的方法，这种方法耗时严重，操作麻烦。J.R.R提出的选择性搜索的方法，在识别前期在整张图片中生成1~3K个proposal的方法，再对每个proposal进行处理。</p>
<p>Selective Search [4], one of the most popular methods, greedily merges superpixels based on engineered low-level features.</p>
<blockquote>
<p>缺点：效率低，计算量大，使用1个CPU处理一张图片，需要2s<sup><a href="#fn_1" id="reffn_1">1</a></sup></p>
</blockquote>
<h2 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h2><p>问题提出：解决端到端训练的问题，提出了Region of Interest（ROI）Pooling</p>
<p>跟R-CNN中使用深度CNN的方式不同，Fast R-CNN中首先将CNN应用到整个图像中进行特征提取，利用一个固定窗口在抽取特征上滑动，分别进行分类预测和回归预测。Fast R-CNN的主要处理流程包括：</p>
<ol>
<li>输入图像和标定的识别框信息；</li>
<li>利用深度卷积神经网络抽取图像特征；</li>
<li>利用ROI pooling获取ROI特征向量；</li>
<li>利用两个全联通层进行分类和回归预测</li>
</ol>
<p><img src="/qnsource/images/2018-04-13-Object-Detection-Faster-RCNN/Fast-RCNN.png" alt="Fast RCNN"></p>
<p>端到端的训练过程源于提出了多任务损失函数，将分类问题和回归问题整合在一起，打通了梯度的更新路径，下图描述了Fast R-CNN的训练和测试过程：</p>
<p><img src="/qnsource/images/2018-04-13-Object-Detection-Faster-RCNN/fast-R-CNN-训练与测试.png" alt="fast R-CNN 训练与测试"></p>
<blockquote>
<p>缺点：仍然没有摆脱Selective Search算法在推理阶段进行候选区域生成。</p>
</blockquote>
<h2 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h2><blockquote>
<p>论文：<a href="https://arxiv.org/abs/1506.01497">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a>, 2015, <a href="https://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1">Shaoqing Ren</a>, <a href="https://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1">Kaiming He</a>, <a href="https://arxiv.org/find/cs/1/au:+Girshick_R/0/1/0/all/0/1">Ross Girshick</a>, <a href="https://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jian Sun</a></p>
<p>实现：<a href="https://github.com/rbgirshick/py-faster-rcnn">Github上作者提供的Python实现</a></p>
<p>商业实现：Pinterests<sup><a href="#fn_2" id="reffn_2">2</a></sup></p>
</blockquote>
<p><strong>问题提出：</strong>在基于候选区域选择的CNN（region-based CNN）物体识别网络中，候选区域选择的效率成为了整个系统的瓶颈；Faster R-CNN中提出了<em>Region Proposal Netwrok</em>与物体识别网络共享网络参数（替代了Fast R-CNN中的Selective Search算法），降低了候选区域选择的时间代价。</p>
<ul>
<li>基础网络（Base Network）：特征抽取（迁移学习），抽取的特征将同时应用于RPN和RoIP阶段</li>
<li>RPN：候选区域选择（利用了网络的Attention机制），用于发掘图像中潜在的可能存在物体的区域</li>
<li>RoIP：兴趣区域特征提取</li>
<li>R-CNN：分类预测和候选框回归</li>
</ul>
<p><img src="/qnsource/images/2018-04-13-Object-Detection-Faster-RCNN/fasterrcnn-architecture.b9035cba.png" alt="fasterrcnn-architecture.b9035cba"></p>
<blockquote>
<p>使用一块GPU，性能大概在7-10 FPS</p>
</blockquote>
<h3 id="基础网络"><a href="#基础网络" class="headerlink" title="基础网络"></a>基础网络</h3><p>基础网络的主要作用是利用迁移学习完成原始图像的特征抽取，在论文中使用了 在ImageNet预训练的<a href="https://arxiv.org/abs/1311.2901">ZF</a> 或 <a href="https://arxiv.org/abs/1409.1556">VGG</a>来完成这一任务。当然根据物体识别任务的不同应用场景可以在模型精度和推理时间上进行折中选择 <a href="https://arxiv.org/abs/1704.04861">MobileNet</a>, ResNet-152， <a href="https://arxiv.org/abs/1608.06993">DenseNet</a>。</p>
<blockquote>
<p>文献中，Faster R-CNN的基础网络在使用VGG作为特征提取网络时，使用<code>conv5/conv5_1</code>层的输出特征；</p>
<p>目前ResNet在很多情况下已经替代了VGG16作为特征提取网络；</p>
<p>为了保证网络是全卷积神经网络架构，需要把全连接层剔除，保证可以输入任意维度的输入图像</p>
</blockquote>
<p><img src="/qnsource/images/2018-04-13-Object-Detection-Faster-RCNN/base-network.png" alt="base-network"></p>
<h3 id="Anchor-Box"><a href="#Anchor-Box" class="headerlink" title="Anchor Box"></a>Anchor Box</h3><blockquote>
<p>替代传统算法的特征金字塔或filter金字塔</p>
</blockquote>
<p>一张图像中被识别目标形状大小各异，这也是在原始算法中加入特征金子塔来对原始图像进行多个维度特征变换的原因。</p>
<p><strong>Anchor Box</strong>也是为了解决上述问题，我们可以不改变图像的形状，通过改变预测每个区域物体的“窗口”来框出不同大小的物体。首先在原始图像中均匀的选取一些Anchor Box中心点，然后在每个中心点上预制多个Anchor Box。</p>
<p><img src="/qnsource/images/2018-04-13-Object-Detection-Faster-RCNN/anchors-centers.141181d6.png" alt="anchors-centers.141181d6"></p>
<p>在Faster R-CNN是使用3个不同形状（1:1, 1:2,2:1）和3个不同大小(128x128,256x256,512x512，按照原图尺寸生成)进行组合共计3x3=9种不同的Anchor box。</p>
<blockquote>
<p>使用VGG16做特征提取的情况下，一张输入图片总共可以刻画为512个窗口区域，生成512x(4+2)x9个输出参数。</p>
</blockquote>
<p><img src="/qnsource/images/2018-04-13-Object-Detection-Faster-RCNN/anchors-progress.119e1e92.png" alt="anchors-progress.119e1e92"></p>
<p>由于直接预测bouding box难以实现，作者将问题转变为预测预测值与真实值之间的偏移，将问题转变为四个偏移值的预测问题。</p>
<h3 id="Region-Proposal-Network-RPN"><a href="#Region-Proposal-Network-RPN" class="headerlink" title="Region Proposal Network(RPN)"></a>Region Proposal Network(RPN)</h3><p>RPN的主要目的是对每个区域是否可能有物体进行打分，基于打分值决定是否进行下一步的分类任务。在基础网络抽取的特征图上使用一个3x3的滑动窗口（512个卷积核），每个滑动窗口的中心点位置为上述Achor Box的中心点区域，在每个滑动窗口区域，将得到两个1x1卷积网络输出，分别为2k的前景/背景预测（该区域是否存在可被预测物体，分类问题）以及4k的位置信息预测（回归问题），四个值分别是 </p>
<script type="math/tex; mode=display">
 \Delta_{center_{x}}, \Delta_{center_{y}}, \Delta_{width}, \Delta_{height}</script><blockquote>
<p>k是Anchor Box的数目</p>
<p>我们将从候选区域中选择打分较高的前N个进行下一轮分析，如果物体打分足够高，下一步将进行非极大抑制和区域选择，如果打分值很低将抛弃这些区域</p>
</blockquote>
<p><img src="/qnsource/images/2018-04-13-Object-Detection-Faster-RCNN/rpn-conv-layers.63c5bf86.png" alt="rpn-conv-layers.63c5bf86"></p>
<h4 id="目标和损失函数"><a href="#目标和损失函数" class="headerlink" title="目标和损失函数"></a>目标和损失函数</h4><p>The RPN does two different type of predictions: the binary classification and the bounding box regression adjustment.</p>
<p>For training, we take all the anchors and put them into two different categories. Those that overlap a ground-truth object with an <a href="https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/">Intersection over Union</a> (IoU) bigger than 0.5 are considered “foreground” and those that don’t overlap any ground truth object or have less than 0.1 IoU with ground-truth objects are considered “background”.</p>
<script type="math/tex; mode=display">
L({p_i}, {t_i}) = \frac{1}{N_{cls}}\sum_iL_{cls}(p_i,p_i^*)+\lambda\frac{1}{N_{reg}}\sum_ip_i^*L_{reg}(t_i,t_i^*)</script><p>其中分类的损失函数为：</p>
<script type="math/tex; mode=display">
L_{cls}(p_i,p_i^*) = -log[p_i^*p_i+(1-p_i^*)(1-p_i)]</script><p>$p_i$为第$i$个参考框是物体的预测概率值，$p_i^*$为实际值，如果anchor是物体的话该值为1，否则为0。</p>
<p>回归损失函数为：</p>
<script type="math/tex; mode=display">
L_{reg}(t_i,t_i^*)=R(t_i-t_i^*)</script><p>其中R为smooth L1平滑方程：</p>
<script type="math/tex; mode=display">
smooth_{L_1}(x)=\left\{  
             \begin{array}{lr}  
             0.5x^2  & if \  |x|<1 \\  
             |x|-0.5 & otherwise.     
             \end{array}  
\right.</script><p>$t_i$与 $ t_i^<em> $ 分别对应四个偏差值。$ t_i $ 是预测框与anchor之间的偏差，$ t_i^</em> $ 是ground truth与anchor之间的偏差</p>
<h4 id="参数选择"><a href="#参数选择" class="headerlink" title="参数选择"></a>参数选择</h4><blockquote>
<p>参数选择与其说是一个技术活倒不如认为是一个经验活，是通过大量实践验证出来的最佳实践，所以有必要分析整理每篇文章对参数选择和优化的技巧。</p>
</blockquote>
<ul>
<li>非极大抑制的IoU阈值一般使用<strong>0.6</strong>；</li>
<li>论文中关于候选区域选择了N=2000,但一般而言比这个小的数目也能取得不错的效果，比如50，100 …</li>
</ul>
<h3 id="Region-of-Interest（ROI）Pooling"><a href="#Region-of-Interest（ROI）Pooling" class="headerlink" title="Region of Interest（ROI）Pooling"></a>Region of Interest（ROI）Pooling</h3><p>ROI阶段的主要作用为使用矩阵操作（Array Slicing）从特征图中捕获N个兴趣区域，并降采样到7x7xD的尺寸，服务于接下来的全联同网络。</p>
<p><img src="/qnsource/images/2018-04-13-Object-Detection-Faster-RCNN/roi.png" alt="roi"></p>
<h3 id="Region-based-CNN"><a href="#Region-based-CNN" class="headerlink" title="Region-based CNN"></a>Region-based CNN</h3><p>使用两个不同的全联通网络（Fully-Connected Network，FC）：</p>
<ul>
<li>A fully-connected layer with N+1units where N is the total number of classes and that extra one is for the background class.</li>
<li>A fully-connected layer with 4N units. We want to have a regression prediction, thus we need $\Delta<em>{center</em>{x}}$, $\Delta<em>{center</em>{y}}$, $\Delta<em>{width}$, $\Delta</em>{height}$ for each of the N possible classes.</li>
</ul>
<p><img src="/qnsource/images/2018-04-13-Object-Detection-Faster-RCNN/rcnn-architecture.6732b9bd.png" alt="rcnn-architecture.6732b9bd"></p>
<p>在这个步骤中同样由两个损失函数构成：Categorical cross-entropy分类损失和Smooth L1回归损失</p>
<h3 id="网络训练"><a href="#网络训练" class="headerlink" title="网络训练"></a>网络训练</h3><ul>
<li>实验表明：联合训练（使用weighted sum）优于单独训练两个网络；<ul>
<li>将每个阶段的4个损失函数（其中RPN阶段2个，R-CNN阶段2个）组合在一起，并赋不同的权重，分类损失需要获得比回归损失更多的权重；</li>
<li>使用L2正则损失</li>
</ul>
</li>
<li>是否单独训练基础网络取悦于目标与预训练网络的差异，这个跟迁移学习类似；</li>
<li>使用带动量的随机梯度下降（SGD with momentum），其中<code>monmentum=0.9</code>，初始学习率<code>lr=0.001</code>， 50k步之后，lr调整为0.0001</li>
</ul>
<h2 id="实践时间"><a href="#实践时间" class="headerlink" title="实践时间"></a>实践时间</h2><h3 id="数据集：LISA交通标志数据库"><a href="#数据集：LISA交通标志数据库" class="headerlink" title="数据集：LISA交通标志数据库"></a>数据集：LISA交通标志数据库</h3><ul>
<li>下载地址：<a href="http://cvrr.ucsd.edu/LISA/lisa-traffic-sign-dataset.html">http://cvrr.ucsd.edu/LISA/lisa-traffic-sign-dataset.html</a></li>
<li>47 US sign types</li>
<li>7855 annotations on 6610 frames.</li>
<li>Sign sizes from 6x6 to 167x168 pixels.</li>
<li>Images obtained from different cameras. Image sizes vary from 640x480 to 1024x522 pixels.</li>
<li>Some images in color and some in grayscale.</li>
<li>Full version of the dataset includes videos for all annotated signs.</li>
<li>Each sign is annotated with sign type, position, size, occluded (yes/no), on side road (yes/no).</li>
<li>All annotations are save in plain text .csv-files.</li>
<li>~7.7GB大小</li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote id="fn_1">
<sup>1</sup>. <a href="https://arxiv.org/abs/1506.01497">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a>, 2015, <a href="https://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1">Shaoqing Ren</a>, <a href="https://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1">Kaiming He</a>, <a href="https://arxiv.org/find/cs/1/au:+Girshick_R/0/1/0/all/0/1">Ross Girshick</a>, <a href="https://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jian Sun</a><a href="#reffn_1" title="Jump back to footnote [1] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_2">
<sup>2</sup>. D. Kislyuk, Y. Liu, D. Liu, E. Tzeng, and Y. Jing, “Human curation and convnets: Powering item-to-item recommendations on pinterest,” arXiv:1511.04003, 2015.<a href="#reffn_2" title="Jump back to footnote [2] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_3">
<sup>3</sup>. <a href="https://tryolabs.com/blog/2018/01/18/faster-r-cnn-down-the-rabbit-hole-of-modern-object-detection/">Faster R-CNN: Down the rabbit hole of modern object detection</a><a href="#reffn_3" title="Jump back to footnote [3] in the text."> &#8617;</a>
</blockquote>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                

                <time class="level-item has-text-grey" datetime="2018-04-11T06:44:58.000Z">2018-04-11</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/动手实践营/">动手实践营</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    17 分钟 读完 (大约 2546 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2018/04/11/Vechicle-identification-by-stanford-car-dataset/">利用迁移学习实现车辆识别</a>
            
        </h1>
        <div class="content">
            <p><strong>摘要：</strong> 利用迁移学习技术训练识别汽车厂商和款式的模型。<br><!-- excerpt --></p>
<p>@[toc]</p>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><h3 id="数据集：-Stanford-Cars-Dataset"><a href="#数据集：-Stanford-Cars-Dataset" class="headerlink" title="数据集： Stanford Cars Dataset"></a>数据集： Stanford Cars Dataset</h3><ul>
<li>数据集组成：包含<strong>196</strong>种车辆的<strong>16,185</strong>张照片；其中训练集8144，测试集8041；</li>
<li>关键特征包括：车辆制造商、款式、生产日期（比如：2012 Tesla Model S）；</li>
<li>下载地址：<a href="https://ai.stanford.edu/~jkrause/cars/car_dataset.html；">https://ai.stanford.edu/~jkrause/cars/car_dataset.html；</a></li>
<li>相关论文：<a href="https://ai.stanford.edu/~jkrause/papers/3drr13.pdf"><strong>3D Object Representations for Fine-Grained Categorization</strong></a>，Jonathan Krause, Michael Stark, Jia Deng, Li Fei-Fei</li>
</ul>
<p><img src="/qnsource/images/2018-04-11-vechicle-identification-by-stanford-car-dataset/car.jpg" alt="car"></p>
<blockquote>
<p><strong>数据集特点：</strong></p>
<ol>
<li>存在明显的数据不平衡问题；</li>
<li>每个分类图像数目过少，无法达到准确预测分类目标的基准；</li>
</ol>
</blockquote>
<p>针对数据集的特点，利用迁移学习Fine-Tune来训练一个在ImageNet上预训练的模型是一个不错的方式，下面我们将从数据的准备开始一步步得完成模型的训练任务。</p>
<h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><p>在这一部分中，我们将读入原始数据，进行基本的数据处理，然后对数据进行统一存储，一般面对大规模的数据集可以选用<code>HDF5</code>或MXNet的.<code>LST</code>格式进行存储。</p>
<blockquote>
<p>通过这种方式进行存储可以解决每张图片读取都要产生一次IO带来的访问时延，同时可以利用存储系统连续读的方式，直接对大规模数据集进行切片操作。</p>
</blockquote>
<h3 id="配置信息"><a href="#配置信息" class="headerlink" title="配置信息"></a>配置信息</h3><p>为了配合后续处理流程方便，新建一个<code>car.config</code>的配置文件，用于对相关配置信息的存储：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> path</span><br><span class="line"></span><br><span class="line"><span class="comment"># define the base path to the cars dataset</span></span><br><span class="line">BASE_PATH = <span class="string">"Path-to-car-dataset"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># based on the base path, derive the images path and meta file path</span></span><br><span class="line">IMAGES_PATH = path.sep.join([BASE_PATH, <span class="string">"car_ims"</span>])</span><br><span class="line">LABELS_PATH = path.sep.join([BASE_PATH, <span class="string">"complete_dataset.csv"</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#define path for HDF5</span></span><br><span class="line">TRAIN_HDF5 = path.sep.join([MX_OUTPUT, <span class="string">"hdf5/train.hdf5"</span>])</span><br><span class="line">VAL_HDF5 = path.sep.join([MX_OUTPUT, <span class="string">"hdf5/val.hdf5"</span>])</span><br><span class="line">TEST_HDF5 = path.sep.join([MX_OUTPUT, <span class="string">"hdf5/test.hdf5"</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#define path for storing Mean R G B data</span></span><br><span class="line">DATASET_MEAN = path.sep.join([BASE_PATH, <span class="string">"output/car_mean.json"</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># define the path to the output directory used for storing plots,</span></span><br><span class="line"><span class="comment"># classification reports, etc.</span></span><br><span class="line">OUTPUT_PATH = <span class="string">"output"</span></span><br><span class="line">MODEL_PATH = path.sep.join([OUTPUT_PATH,<span class="string">"inceptionv3_stanfordcar.hdf5"</span>])</span><br><span class="line">FIG_PATH = path.sep.join([OUTPUT_PATH,<span class="string">"inceptionv3_stanfordcar.png"</span>])</span><br><span class="line">JSON_PATH = path.sep.join([OUTPUT_PATH,<span class="string">"inceptionv3_stanfordcar.json"</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># define the path to the label encoder</span></span><br><span class="line">LABEL_ENCODER_PATH = path.sep.join([BASE_PATH, <span class="string">"output/le.cpickle"</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># define the percentage of validation and testing images relative</span></span><br><span class="line"><span class="comment"># to the number of training images</span></span><br><span class="line">NUM_CLASSES = <span class="number">164</span></span><br><span class="line">NUM_VAL_IMAGES = <span class="number">0.15</span></span><br><span class="line">NUM_TEST_IMAGES = <span class="number">0.15</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># define the batch size</span></span><br><span class="line">BATCH_SIZE = <span class="number">64</span></span><br></pre></td></tr></table></figure>
<p>配置文件中包括<code>HDF5</code>文件的存放位置描述，原始数据和数据描述文件路径，RGB均值存储位置，训练过程中输出的图像和日志存储位置等信息。</p>
<h3 id="数据概览"><a href="#数据概览" class="headerlink" title="数据概览"></a>数据概览</h3><ol>
<li>我们先将数据描述文件<code>complete_dataset.csv</code>导入，了解下数据格式：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># loading image paths and labels</span></span><br><span class="line">df = pd.read_csv(config.LABELS_PATH)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">id</th>
<th>Image FileName</th>
<th>Make</th>
<th>Model</th>
<th>Vechicle Typle</th>
<th>Year</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">0</td>
<td>car_ims/000090.jpg</td>
<td>Acura</td>
<td>RL</td>
<td>Sedan</td>
<td>2012</td>
</tr>
<tr>
<td style="text-align:left">1</td>
<td>car_ims/000091.jpg</td>
<td>Acura</td>
<td>RL</td>
<td>Sedan</td>
<td>2012</td>
</tr>
<tr>
<td style="text-align:left">2</td>
<td>car_ims/000092.jpg</td>
<td>Acura</td>
<td>RL</td>
<td>Sedan</td>
<td>2012</td>
</tr>
<tr>
<td style="text-align:left">3</td>
<td>car_ims/000093.jpg</td>
<td>Acura</td>
<td>RL</td>
<td>Sedan</td>
<td>2012</td>
</tr>
</tbody>
</table>
</div>
<ol>
<li><p>遍历文件列表，将文件地址和样本标签分别进行存储，在本实验中值使用了制造商和款式两种特征，所以构成分类总共有164个：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line">trainPaths = []</span><br><span class="line">trainLabels = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> id,name <span class="keyword">in</span> enumerate(df[<span class="string">"Image Filename"</span>]):</span><br><span class="line">    trainPaths.append(os.sep.join([config.IMAGES_PATH,name]))</span><br><span class="line">    trainLabels.append(<span class="string">"&#123;&#125;:&#123;&#125;"</span>.format(df.iloc[id][<span class="string">"Make"</span>], df.iloc[id][<span class="string">"Model"</span>]))</span><br><span class="line"><span class="comment">#Encoding labels to num</span></span><br><span class="line">le = LabelEncoder()</span><br><span class="line">trainLabels = le.fit_transform(trainLabels)</span><br></pre></td></tr></table></figure>
</li>
<li><p>按照70%，15%，15%切分训练集、验证集和测试集：</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">numVal = int(len(trainPaths)*<span class="number">0.15</span>)</span><br><span class="line">numTest = int(len(trainPaths)*<span class="number">0.15</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># perform sampling from the training set to construct a a validation set</span></span><br><span class="line">split = train_test_split(trainPaths, trainLabels, test_size=numVal,</span><br><span class="line">    stratify=trainLabels)</span><br><span class="line">(trainPaths, valPaths, trainLabels, valLabels) = split</span><br><span class="line"></span><br><span class="line"><span class="comment"># perform stratified sampling from the training set to construct a testing set</span></span><br><span class="line">split = train_test_split(trainPaths, trainLabels, test_size=numTest,</span><br><span class="line">    stratify=trainLabels)</span><br><span class="line">(trainPaths, testPaths, trainLabels, testLabels) = split</span><br></pre></td></tr></table></figure>
</li>
<li><p>初始化相关配置：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># initialize the lists of RGB channel averages</span></span><br><span class="line">(R, G, B) = ([], [], [])</span><br><span class="line"></span><br><span class="line"><span class="comment"># construct a list pairing the training, validation, and testing</span></span><br><span class="line"><span class="comment"># image paths along with their corresponding labels and output list</span></span><br><span class="line"><span class="comment"># files</span></span><br><span class="line">datasets = [</span><br><span class="line">	(<span class="string">"train"</span>, trainPaths, trainLabels, config.TRAIN_HDF5),</span><br><span class="line">	(<span class="string">"val"</span>, valPaths, valLabels, config.VAL_HDF5),</span><br><span class="line">	(<span class="string">"test"</span>, testPaths, testLabels, config.TEST_HDF5)]</span><br></pre></td></tr></table></figure>
</li>
<li><p>遍历数据集并存储至HDF5文件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> HDF5DatasetWriter</span><br><span class="line"><span class="keyword">import</span> AspectAwarePreprocessor</span><br><span class="line"><span class="keyword">import</span> progressbar</span><br><span class="line"></span><br><span class="line"><span class="comment">#resize images to (256,256,3)</span></span><br><span class="line">aap = AspectAwarePreprocessor(<span class="number">256</span>,<span class="number">256</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># loop over the dataset tuples</span></span><br><span class="line"><span class="keyword">for</span> (dType, paths, labels, outputPath) <span class="keyword">in</span> datasets:</span><br><span class="line">    <span class="comment"># create HDF5 writer</span></span><br><span class="line">    print(<span class="string">"[INFO] building &#123;&#125;..."</span>.format(outputPath))</span><br><span class="line">    writer = HDF5DatasetWriter((len(paths), <span class="number">256</span>, <span class="number">256</span>, <span class="number">3</span>), outputPath)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># initialize the progress bar</span></span><br><span class="line">    widgets = [<span class="string">"Building Dataset: "</span>, progressbar.Percentage(), <span class="string">" "</span>,</span><br><span class="line">        progressbar.Bar(), <span class="string">" "</span>, progressbar.ETA()]</span><br><span class="line">    pbar = progressbar.ProgressBar(maxval=len(paths),</span><br><span class="line">        widgets=widgets).start()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># loop over the image paths</span></span><br><span class="line">    <span class="keyword">for</span> (i, (path, label)) <span class="keyword">in</span> enumerate(zip(paths, labels)):</span><br><span class="line">        <span class="comment"># load the image from disk</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            image = cv2.imread(path)</span><br><span class="line">            image = aap.preprocess(image)</span><br><span class="line">            <span class="comment">#print(image.shape)</span></span><br><span class="line">            <span class="comment"># if we are building the training dataset, then compute the</span></span><br><span class="line">            <span class="comment"># mean of each channel in the image, then update the respective lists</span></span><br><span class="line">            <span class="keyword">if</span> dType == <span class="string">"train"</span>:</span><br><span class="line">                (b, g, r) = cv2.mean(image)[:<span class="number">3</span>]</span><br><span class="line">                R.append(r)</span><br><span class="line">                G.append(g)</span><br><span class="line">                B.append(b)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># add the image and label to the HDF5 dataset</span></span><br><span class="line">            writer.add([image], [label])</span><br><span class="line">            pbar.update(i)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            print(path)</span><br><span class="line">            print(label)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># close the HDF5 writer</span></span><br><span class="line">    pbar.finish()</span><br><span class="line">    writer.close()</span><br></pre></td></tr></table></figure>
<blockquote>
<p>我们首先统一将文件调整到(256,256,3)大小，再进行存储，所以在读取文件之后进行了简单的预处理。</p>
</blockquote>
</li>
<li><p>将RGB均值存储至单独文件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="comment"># construct a dictionary of averages, then serialize the means to a JSON file</span></span><br><span class="line">print(<span class="string">"[INFO] serializing means..."</span>)</span><br><span class="line">D = &#123;<span class="string">"R"</span>: np.mean(R), <span class="string">"G"</span>: np.mean(G), <span class="string">"B"</span>: np.mean(B)&#125;</span><br><span class="line">f = open(config.DATASET_MEAN, <span class="string">"w"</span>)</span><br><span class="line">f.write(json.dumps(D))</span><br><span class="line">f.close()</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>至此，我们完成了将图像文件分为三个类别并分别存到了三个HDF5文件之中。</p>
<p>关于HDF5文件存储相关内容，详见后续推出的预处理博客~~</p>
<p>如果使用<code>MXNET</code>的list和rec来构建数据存储集合，在上述步骤3的基础上，按如下步骤：</p>
<ol>
<li><p>构建数据集列表文件’.list’文件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># construct a list pairing the training, validation, and testing</span></span><br><span class="line"><span class="comment"># image paths along with their corresponding labels and output list</span></span><br><span class="line"><span class="comment"># files</span></span><br><span class="line">datasets = [</span><br><span class="line">	(<span class="string">"train"</span>, trainPaths, trainLabels, config.TRAIN_MX_LIST),</span><br><span class="line">	(<span class="string">"val"</span>, valPaths, valLabels, config.VAL_MX_LIST),</span><br><span class="line">	(<span class="string">"test"</span>, testPaths, testLabels, config.TEST_MX_LIST)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># loop over the dataset tuples</span></span><br><span class="line"><span class="keyword">for</span> (dType, paths, labels, outputPath) <span class="keyword">in</span> datasets:</span><br><span class="line">	<span class="comment"># open the output file for writing</span></span><br><span class="line">	print(<span class="string">"[INFO] building &#123;&#125;..."</span>.format(outputPath))</span><br><span class="line">    </span><br><span class="line">	f = open(outputPath, <span class="string">"w"</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># loop over each of the individual images + labels</span></span><br><span class="line">	<span class="keyword">for</span> (i, (path, label)) <span class="keyword">in</span> enumerate(zip(paths, labels)):</span><br><span class="line">		<span class="comment"># write the image index, label, and output path to file</span></span><br><span class="line">		row = <span class="string">"\t"</span>.join([str(i), str(label), path])</span><br><span class="line">		f.write(<span class="string">"&#123;&#125;\n"</span>.format(row))</span><br><span class="line"></span><br><span class="line">	<span class="comment"># close the output file</span></span><br><span class="line">	f.close()</span><br></pre></td></tr></table></figure>
</li>
<li><p>将Label名称序列化存储，便于后续调用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">f = open(config.LABEL_ENCODER_PATH, <span class="string">"wb"</span>)</span><br><span class="line">f.write(pickle.dumps(le))</span><br><span class="line">f.close()</span><br></pre></td></tr></table></figure>
<p>3.利用MXNet工具<code>im2rec</code>创建记录文件</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ /dsvm/tools/mxnet/bin/im2rec ./raid/datasets/cars/lists/train.lst <span class="string">""</span> ./raid/datasets/cars/rec/train.rec resize=256 encoding=<span class="string">'.jpg'</span> quality=100</span><br><span class="line"></span><br><span class="line">$ /dsvm/tools/mxnet/bin/im2rec ./raid/datasets/cars/lists/test.lst <span class="string">""</span> ./raid/datasets/cars/rec/test.rec resize=256 encoding=<span class="string">'.jpg'</span> quality=100</span><br><span class="line"></span><br><span class="line">$ /dsvm/tools/mxnet/bin/im2rec ./raid/datasets/cars/lists/val.lst <span class="string">""</span> ./raid/datasets/cars/rec/val.rec resize=256 encoding=<span class="string">'.jpg'</span> quality=100</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="训练迁移学习网络"><a href="#训练迁移学习网络" class="headerlink" title="训练迁移学习网络"></a>训练迁移学习网络</h2><p>在迁移学习的模型选择上我们选择了基于Keras提供的InceptionV3,可通过<a href="https://keras-cn.readthedocs.io/en/latest/other/application/">Keras官方文档</a>了解更多使用说明。下表列出了在keras中各模型的表现：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>模型</th>
<th>大小</th>
<th>Top1准确率</th>
<th>Top5准确率</th>
<th>参数数目</th>
<th>深度</th>
</tr>
</thead>
<tbody>
<tr>
<td>Xception</td>
<td>88MB</td>
<td>0.790</td>
<td>0.945</td>
<td>22,910,480</td>
<td>126</td>
</tr>
<tr>
<td>VGG16</td>
<td>528MB</td>
<td>0.715</td>
<td>0.901</td>
<td>138,357,544</td>
<td>23</td>
</tr>
<tr>
<td>VGG19</td>
<td>549MB</td>
<td>0.727</td>
<td>0.910</td>
<td>143,667,240</td>
<td>26</td>
</tr>
<tr>
<td>ResNet50</td>
<td>99MB</td>
<td>0.759</td>
<td>0.929</td>
<td>25,636,712</td>
<td>168</td>
</tr>
<tr>
<td><strong>InceptionV3</strong></td>
<td><strong>92MB</strong></td>
<td><strong>0.788</strong></td>
<td><strong>0.944</strong></td>
<td><strong>23,851,784</strong></td>
<td><strong>159</strong></td>
</tr>
<tr>
<td>IncetionResNetV2</td>
<td>215MB</td>
<td>0.804</td>
<td>0.953</td>
<td>55,873,736</td>
<td>572</td>
</tr>
<tr>
<td>MobileNet</td>
<td>17MB</td>
<td>0.665</td>
<td>0.871</td>
<td>4,253,864</td>
<td>88</td>
</tr>
</tbody>
</table>
</div>
<h3 id="数据读入"><a href="#数据读入" class="headerlink" title="数据读入"></a>数据读入</h3><p>输入读入过程主要包括几个关键任务：读取RGB均值文件，对原始数据进行预处理：图像扣取、数据增强、去通道均值、矩阵化等。</p>
<p>这块内容不是本篇重点，只能挖坑留给后续更新。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># construct the training image generator for data augmentation</span></span><br><span class="line">aug = ImageDataGenerator(rotation_range=<span class="number">20</span>, zoom_range=<span class="number">0.15</span>,</span><br><span class="line">	width_shift_range=<span class="number">0.2</span>, height_shift_range=<span class="number">0.2</span>, shear_range=<span class="number">0.15</span>,</span><br><span class="line">	horizontal_flip=<span class="keyword">True</span>, fill_mode=<span class="string">"nearest"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># load the RGB means for the training set</span></span><br><span class="line">means = json.loads(open(config.DATASET_MEAN).read())</span><br><span class="line"></span><br><span class="line"><span class="comment"># initialize the image preprocessors</span></span><br><span class="line">sp = SimplePreprocessor(<span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line">pp = PatchPreprocessor(<span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line">mp = MeanPreprocessor(means[<span class="string">"R"</span>], means[<span class="string">"G"</span>], means[<span class="string">"B"</span>])</span><br><span class="line">iap = ImageToArrayPreprocessor()</span><br><span class="line"></span><br><span class="line"><span class="comment"># initialize the training and validation dataset generators</span></span><br><span class="line">trainGen = HDF5DatasetGenerator(config.TRAIN_HDF5, <span class="number">64</span>, aug=aug,</span><br><span class="line">	preprocessors=[pp, mp, iap], classes=config.NUM_CLASSES)</span><br><span class="line">valGen = HDF5DatasetGenerator(config.VAL_HDF5, <span class="number">64</span>,</span><br><span class="line">	preprocessors=[sp, mp, iap], classes=config.NUM_CLASSES)</span><br></pre></td></tr></table></figure>
<h3 id="模型设计"><a href="#模型设计" class="headerlink" title="模型设计"></a>模型设计</h3><p>模型设计过程参考了Keras官方文档给出的演示，导入没有top的预训练InceptionV3模型，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.applications.inception_v3 <span class="keyword">import</span> InceptionV3</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, GlobalAveragePooling2D</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"></span><br><span class="line"><span class="comment"># load the Inception network, ensuring the head FC layer sets are left off</span></span><br><span class="line">baseModel = InceptionV3(weights=<span class="string">"imagenet"</span>, include_top=<span class="keyword">False</span>,</span><br><span class="line">                        input_tensor=Input(shape=(<span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>)))</span><br><span class="line"><span class="comment"># initialize the new head of the network, a set of FC layers</span></span><br><span class="line"><span class="comment"># followed by a softmax classifier</span></span><br><span class="line">x = baseModel.output</span><br><span class="line">x = GlobalAveragePooling2D()(x)</span><br><span class="line">x = Dense(<span class="number">1024</span>, activation=<span class="string">'relu'</span>)(x)</span><br><span class="line">headModel = Dense(config.NUM_CLASSES, activation=<span class="string">'softmax'</span>)(x)</span><br><span class="line"></span><br><span class="line">model = Model(inputs=baseModel.input, outputs=headModel)</span><br><span class="line"></span><br><span class="line"><span class="comment"># loop over all layers in the base model and freeze them so they</span></span><br><span class="line"><span class="comment"># will *not* be updated during the training process</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> baseModel.layers:</span><br><span class="line">  layer.trainable = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># compile our model (this needs to be done after our setting our</span></span><br><span class="line"><span class="comment"># layers to being non-trainable</span></span><br><span class="line">print(<span class="string">"[INFO] compiling model..."</span>)</span><br><span class="line">opt = SGD(lr=<span class="number">0.005</span>,momentum=<span class="number">0.9</span>)</span><br><span class="line">model.compile(loss=<span class="string">"categorical_crossentropy"</span>, optimizer=opt, metrics=[<span class="string">"accuracy"</span>])</span><br></pre></td></tr></table></figure>
<p>特别注意在迁移学习中，由于新添加增的初始权重是随机生成的，而前面大量网络参数并frozen之后不再发生变化，所以需要一个预测的过程来学习参数到一定水平，需要控制学习率在一个比较小的范围。</p>
<p>这个过程可能需要反复尝试试错。</p>
<h3 id="训练过程优化"><a href="#训练过程优化" class="headerlink" title="训练过程优化"></a>训练过程优化</h3><p>训练过程参考了《Deep Learning for Computer Vison with Python》作者给出的<code>Ctrl+C</code>训练方法，可以随时保存训练现场，调整训练率继续进行训练。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="comment"># construct the argument parse and parse the arguments</span></span><br><span class="line">ap = argparse.ArgumentParser()</span><br><span class="line">ap.add_argument(<span class="string">"-c"</span>, <span class="string">"--checkpoints"</span>, required=<span class="keyword">True</span>, help=<span class="string">"path to output checkpoint directory"</span>)</span><br><span class="line">ap.add_argument(<span class="string">"-m"</span>, <span class="string">"--model"</span>, type=str, help=<span class="string">"path to *specific* model checkpoint to load"</span>)</span><br><span class="line">ap.add_argument(<span class="string">"-s"</span>, <span class="string">"--start-epoch"</span>, type=int, default=<span class="number">0</span>, help=<span class="string">"epoch to restart training at"</span>)</span><br><span class="line">args = vars(ap.parse_args())</span><br><span class="line"></span><br><span class="line"><span class="comment"># set the logging level and output file</span></span><br><span class="line">logging.basicConfig(level=logging.DEBUG,</span><br><span class="line">	filename=<span class="string">"training_&#123;&#125;.log"</span>.format(args[<span class="string">"start_epoch"</span>]), filemode=<span class="string">"w"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> args[<span class="string">"model"</span>] <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line"><span class="comment"># load the VGG16 network, ensuring the head FC layer sets are left off</span></span><br><span class="line"></span><br><span class="line">	...</span><br><span class="line">    <span class="comment">## 实现上一步骤的预训练模型定义和模型预热</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">	print(<span class="string">"[INFO] loading &#123;&#125;..."</span>.format(args[<span class="string">"model"</span>]))</span><br><span class="line">	model = load_model(args[<span class="string">"model"</span>])</span><br><span class="line">	<span class="comment"># update the learning rate</span></span><br><span class="line">	print(<span class="string">"[INFO] old learning rate: &#123;&#125;"</span>.format(K.get_value(model.optimizer.lr)))</span><br><span class="line">	K.set_value(model.optimizer.lr, <span class="number">1e-3</span>)</span><br><span class="line">	print(<span class="string">"[INFO] new learning rate: &#123;&#125;"</span>.format(K.get_value(model.optimizer.lr)))</span><br><span class="line">    </span><br><span class="line"><span class="comment"># construct the set of callbacks</span></span><br><span class="line">callbacks = [</span><br><span class="line">	EpochCheckpoint(args[<span class="string">"checkpoints"</span>], every=<span class="number">5</span>,</span><br><span class="line">		startAt=args[<span class="string">"start_epoch"</span>]),</span><br><span class="line">	TrainingMonitor(config.FIG_PATH, jsonPath=config.JSON_PATH,</span><br><span class="line">		startAt=args[<span class="string">"start_epoch"</span>])]</span><br><span class="line"></span><br><span class="line"><span class="comment"># train the network</span></span><br><span class="line">print(<span class="string">"[INFO] training network..."</span>)</span><br><span class="line">model.fit_generator(</span><br><span class="line">	trainGen.generator(),</span><br><span class="line">	steps_per_epoch=trainGen.numImages // config.BATCH_SIZE,</span><br><span class="line">	validation_data=valGen.generator(),</span><br><span class="line">	validation_steps=valGen.numImages // config.BATCH_SIZE,</span><br><span class="line">	epochs=<span class="number">100</span>,</span><br><span class="line">	max_queue_size=config.BATCH_SIZE * <span class="number">2</span>,</span><br><span class="line">	callbacks=callbacks, verbose=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a href="https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/">deep learning for computer vision with python</a></li>
</ol>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                

                <time class="level-item has-text-grey" datetime="2018-04-09T04:45:13.000Z">2018-04-09</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/动手实践营/">动手实践营</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    37 分钟 读完 (大约 5528 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2018/04/09/Deep-Learning-Lab-Logo-Detection/">基于机器视觉技术的品牌LOGO检测</a>
            
        </h1>
        <div class="content">
            <p>利用Flickr LOGO数据集训练一个检测品牌LOGO的网络，对机器视觉的物体识别技术进行验证。</p>
<!-- excerpt -->
<p>@[toc]</p>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>最近在做一个利用机器视觉技术进行超市物品检点的项目调研分析，需要先寻找一个可行的技术方案验证可行性，Flickr提供的LOGO数据集是一个很好的品牌LOGO识别例子，本文记录利用Flickr LOGO数据集训练一个物体识别的深度神经网络过程。</p>
<p><img src="/qnsource/images/2018-04-09-Deep-Learning-Lab-Logo-Detection/b.gif" alt="b"></p>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>Flickr LOGO数据集提供了三种不同类型的LOGO数据集集合，分别为<a href="http://image.ntua.gr/iva/datasets/flickr_logos/">Flickr Logos 27 dataset</a>，<a href="http://www.multimedia-computing.de/flickrlogos/#flickrlogos47">Datasets: FlickrLogos-32</a>以及<a href="http://www.multimedia-computing.de/flickrlogos/#flickrlogos47">Datasets: FlickrLogos-47</a>。我们先来看一下每种数据集的组成及数据结构：</p>
<ol>
<li><p><a href="http://image.ntua.gr/iva/datasets/flickr_logos/">Flickr Logos 27 dataset</a></p>
<ul>
<li><p>训练集包含27个分类的810张标记照片，每个分类30张照片</p>
</li>
<li><p>分散集包含4207张logo图片</p>
</li>
<li><p>测试集有270张照片，每个分类5张照片，另外有135张分类外照片集</p>
</li>
<li><p>27个分类包括：Adidas, Apple, BMW, Citroen, Coca Cola, DHL, Fedex, Ferrari, Ford, Google, Heineken, HP, McDonalds, Mini, Nbc, Nike, Pepsi, Porsche, Puma, Red Bull, Sprite, Starbucks, Intel, Texaco, Unisef, Vodafone and Yahoo.</p>
</li>
<li><p>下载地址：<a href="http://image.ntua.gr/iva/datasets/flickr_logos/flickr_logos_27_dataset.tar.gz">下载</a></p>
</li>
<li><p>数据格式：下载文件夹中提供一个<code>txt</code>文件用于描述每个文件中LOGO的分类和位置信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  FileName ClassName subset   Coordinates（x1 y1 x2 y2）</span></span><br><span class="line"><span class="number">4763210295.j</span>pg Adidas 	<span class="number">1</span> 		<span class="number">91</span> <span class="number">288</span> <span class="number">125</span> <span class="number">306</span> </span><br><span class="line"><span class="number">4763210295.j</span>pg Adidas 	<span class="number">1</span> 		<span class="number">182</span> <span class="number">63</span> <span class="number">229</span> <span class="number">94</span> </span><br><span class="line"><span class="number">4763210295.j</span>pg Adidas 	<span class="number">1</span> 		<span class="number">192</span> <span class="number">291</span> <span class="number">225</span> <span class="number">306</span> </span><br><span class="line"><span class="number">4763210295.j</span>pg Adidas 	<span class="number">1</span> 		<span class="number">285</span> <span class="number">61</span> <span class="number">317</span> <span class="number">79</span> </span><br><span class="line"><span class="number">4763210295.j</span>pg Adidas 	<span class="number">1</span> 		<span class="number">285</span> <span class="number">298</span> <span class="number">324</span> <span class="number">329</span> </span><br><span class="line"><span class="number">4763210295.j</span>pg Adidas 	<span class="number">1</span> 		<span class="number">377</span> <span class="number">292</span> <span class="number">421</span> <span class="number">324</span> </span><br><span class="line"><span class="number">4763210295.j</span>pg Adidas 	<span class="number">1</span> 		<span class="number">383</span> <span class="number">55</span> <span class="number">416</span> <span class="number">76</span> </span><br><span class="line"><span class="number">1230939811.j</span>pg Adidas 	<span class="number">2</span> 		<span class="number">129</span> <span class="number">326</span> <span class="number">257</span> <span class="number">423</span> </span><br><span class="line"><span class="number">1230939811.j</span>pg Adidas 	<span class="number">2</span> 		<span class="number">137</span> <span class="number">336</span> <span class="number">243</span> <span class="number">395</span></span><br></pre></td></tr></table></figure>
<p><img src="/qnsource/images/2018-04-09-Deep-Learning-Lab-Logo-Detection/dataset1_bboxes.jpg" alt="dataset1_bboxes"></p>
</li>
</ul>
</li>
<li><p><a href="http://www.multimedia-computing.de/flickrlogos/#flickrlogos47">Flickr Logos 32/47 dataset</a></p>
<blockquote>
<p>FlickrLogos-32 was designed for logo retrieval and multi-class logo detection and object recognition. However, the annotations for object detection were often incomplete,since only the most prominent logo instances were labelled. </p>
<p>FlickrLogos-47 uses the same image corpus as FlickrLogos-32 but has been re-annotated specifically for the task of object detection and recognition. </p>
</blockquote>
<p>2.1 Flickr Logos-32</p>
<ul>
<li><p>32个分类包括： <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/adidas.jpg">Adidas</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/aldi.jpg">Aldi</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/apple.jpg">Apple</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/becks.jpg">Becks</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/bmw.jpg">BMW</a>,<a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/carlsberg.jpg">Carlsberg</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/chimay.jpg">Chimay</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/cocacola.jpg">Coca-Cola</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/corona.jpg">Corona</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/dhl.jpg">DHL</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/erdinger.jpg">Erdinger</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/esso.jpg">Esso</a>,<a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/fedex.jpg">Fedex</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/ferrari.jpg">Ferrari</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/ford.jpg">Ford</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/fosters.jpg">Foster’s</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/google.jpg">Google</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/guinness.jpg">Guiness</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/heineken.jpg">Heineken</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/hp.jpg">HP</a>,<a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/milka.jpg">Milka</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/nvidia.jpg">Nvidia</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/paulaner.jpg">Paulaner</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/pepsi.jpg">Pepsi</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/rittersport.jpg">Ritter Sport</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/shell.jpg">Shell</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/singha.jpg">Singha</a>,<a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/starbucks.jpg">Starbucks</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/stellaartois.jpg">Stella Artois</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/texaco.jpg">Texaco</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/tsingtao.jpg">Tsingtao</a> and <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/ups.jpg">UPS</a></p>
</li>
<li><p>数据集被划分为P1,P2,P3三个子集：</p>
</li>
</ul>
</li>
</ol>
<div class="table-container">
<table>
<thead>
<tr>
<th>Partition</th>
<th>Description</th>
<th>Images</th>
<th>#Images</th>
</tr>
</thead>
<tbody>
<tr>
<td>P1 (training set)</td>
<td>Hand-picked images</td>
<td>10 per class</td>
<td>320 images</td>
</tr>
<tr>
<td>P2 (validation set)</td>
<td>Images showing at least a single logo under various views</td>
<td>30 per class + 3000 non-logo images</td>
<td>3960 images</td>
</tr>
<tr>
<td>P3 (test set = query set)</td>
<td>Images showing at least a single logo under various views</td>
<td>30 per class + 3000 non-logo images</td>
<td>3960 images</td>
</tr>
<tr>
<td>/</td>
<td>/</td>
<td>/</td>
<td>8240 images</td>
</tr>
</tbody>
</table>
</div>
<pre><code>2.2 FlickrLogos-47
</code></pre><ul>
<li>47个分类包括：<a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/adidas.jpg">Adidas (Symbol)</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/adidas.jpg">Adidas (Text)</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/aldi.jpg">Aldi</a>,<a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/apple.jpg">Apple</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/becks.jpg">Becks (Symbol)</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/becks.jpg">Becks (Text)</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/bmw.jpg">BMW</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/carlsberg.jpg">Carlsberg (Symbol)</a>,<a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/carlsberg.jpg">Carlsberg (Text)</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/chimay.jpg">Chimay (Symbol)</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/chimay.jpg">Chimay (Text)</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/cocacola.jpg">Coca-Cola</a>,<a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/corona.jpg">Corona (Symbol)</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/corona.jpg">Corona (Text)</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/dhl.jpg">DHL</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/erdinger.jpg">Erdinger (Symbol)</a>,<a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/erdinger.jpg">Erdinger (Text)</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/esso.jpg">Esso (Symbol)</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/esso.jpg">Esso (Text)</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/fedex.jpg">Fedex</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/ferrari.jpg">Ferrari</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/ford.jpg">Ford</a>,<a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/fosters.jpg">Foster’s (Symbol)</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/fosters.jpg">Foster’s (Text)</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/google.jpg">Google</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/guinness.jpg">Guiness (Symbol)</a>,<a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/guinness.jpg">Guiness (Text)</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/heineken.jpg">Heineken</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/hp.jpg">HP</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/milka.jpg">Milka (Symbol)</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/milka.jpg">Milka (Text)</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/nvidia.jpg">Nvidia (Symbol)</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/nvidia.jpg">Nvidia (Text)</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/paulaner.jpg">Paulaner (Symbol)</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/paulaner.jpg">Paulaner (Text)</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/pepsi.jpg">Pepsi (Symbol)</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/pepsi.jpg">Pepsi (Text)</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/rittersport.jpg">Ritter Sport</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/shell.jpg">Shell</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/singha.jpg">Singha (Symbol)</a>,<a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/singha.jpg">Singha (Text)</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/starbucks.jpg">Starbucks</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/stellaartois.jpg">Stella Artois (Symbol)</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/stellaartois.jpg">Stella Artois (Text)</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/texaco.jpg">Texaco</a>, <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/tsingtao.jpg">Tsingtao (Symbol)</a> <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/tsingtao.jpg">Tsingtao (Text)</a> and <a href="http://www.multimedia-computing.de/flickrlogos/images/classes-small/ups.jpg">UPS</a>.</li>
</ul>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul>
<li>Flickr Logo数据集虽然类别数目众多，但具体到每个分类提供的样本数目有限，在数据预处理环节需要配合数据增强手段来扩充数据集的数目；</li>
<li>另外也可以仿照车牌识别的方法，将扣取的LOGO图像添加到不同背景噪声的图像中，生成多种训练数据；</li>
<li>由于LOGO图像包含图像特征有限，同时提供小样本数据，通过迁移学习的方案利用ImageNet训练好的模型进行迁移学习是一种很好的方式，本文将对这种方式进行讨论及实现；</li>
<li>三种数据集面向不同的功能也设计需求，从图像质量上来看Flickr-47质量相对较好，同时在32分类和47分类中提供了对图像语义分割的标定数据；</li>
</ul>
<p>在概览过任务数据集之后，我们将按照深度学习业务处理流程，逐步进行数据的预处理、模型准备、训练和验证等工作。为简化问题处理难度，我们使用Flickr Logo -27来进行本次实验。</p>
<h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><p>数据准备环节主要使用如下基本的工具和库文件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.patches <span class="keyword">as</span> patches</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> imutils</span><br></pre></td></tr></table></figure>
<p>其中，</p>
<ul>
<li><code>numpy</code>用来做基本的矩阵处理；</li>
<li><code>pandas</code>用于读取和分析数据描述文件；</li>
<li><code>matplotlib</code>用于辅助显示预处理结果；</li>
<li><code>cv2</code>是opencv的python封装，进行图像读取、图像分析等操作；</li>
<li><code>imutils</code>是一个很好用的图像处理库，可以满足基本的图像处理需求</li>
</ul>
<p>首先我们先查看从flickr-27上下载的文件<code>flickr_logos_27_dataset_training_set_annotation.txt</code>来了解基本的图像数据信息和分类信息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df=pd.read_csv(<span class="string">"./flickr_logos_27_dataset/flickr_logos_27_dataset_training_set_annotation.txt"</span>,sep=<span class="string">" "</span>, header=<span class="keyword">None</span>)</span><br><span class="line">df.drop(df.columns[<span class="number">-1</span>],axis=<span class="number">1</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line">df.columns=[<span class="string">"Name"</span>,<span class="string">"labels"</span>,<span class="string">"subset"</span>,<span class="string">"x1"</span>,<span class="string">"y1"</span>,<span class="string">"x2"</span>,<span class="string">"y2"</span>]</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">output:&gt;&gt;&gt;&gt;</span><br><span class="line">	     Name      labels subset      x1	y1	x2	y2</span><br><span class="line"><span class="number">0</span>	<span class="number">144503924.j</span>pg	Adidas	<span class="number">1</span>	<span class="number">38</span>	<span class="number">12</span>	<span class="number">234</span>	<span class="number">142</span></span><br><span class="line"><span class="number">1</span>	<span class="number">2451569770.j</span>pg	Adidas	<span class="number">1</span>	<span class="number">242</span>	<span class="number">208</span>	<span class="number">413</span>	<span class="number">331</span></span><br><span class="line"><span class="number">2</span>	<span class="number">390321909.j</span>pg	Adidas	<span class="number">1</span>	<span class="number">13</span>	<span class="number">5</span>	<span class="number">89</span>	<span class="number">60</span></span><br><span class="line"><span class="number">3</span>	<span class="number">4761260517.j</span>pg	Adidas	<span class="number">1</span>	<span class="number">43</span>	<span class="number">122</span>	<span class="number">358</span>	<span class="number">354</span></span><br><span class="line"><span class="number">4</span>	<span class="number">4763210295.j</span>pg	Adidas	<span class="number">1</span>	<span class="number">83</span>	<span class="number">63</span>	<span class="number">130</span>	<span class="number">93</span></span><br></pre></td></tr></table></figure>
<p>在描述文件中总共提供了4536条记录，而实际提供的图像文件只有1000多张，这说明很多文件包括不止一个LOGO。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">len(df)</span><br><span class="line">&gt;&gt;&gt;: <span class="number">4536</span></span><br></pre></td></tr></table></figure>
<p>我们可以利用<code>pandas</code>对文件进行一个简单的shuffle处理，便于快速切分成训练集和测试集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># shuffle the datasets</span></span><br><span class="line">df = df.sample(frac=<span class="number">1</span>).reset_index(drop=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>为了快速查看描述文件提供的标记信息在图像中的显示效果，我们写一个函数来查看一下LOGO标记信息的效果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_image</span><span class="params">(id)</span>:</span></span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    image = os.path.join(<span class="string">"./flickr_logos_27_dataset/flickr_logos_27_dataset_images/"</span>,df.loc[id][<span class="string">"Name"</span>])</span><br><span class="line">    image = cv2.imread(image)</span><br><span class="line">    plt.figure(<span class="number">8</span>)</span><br><span class="line">    plt.imshow(image)</span><br><span class="line">    currentAxis=plt.gca()</span><br><span class="line">    rect=patches.Rectangle((df[<span class="string">"x1"</span>].iloc[id], df[<span class="string">"y1"</span>].iloc[id]),</span><br><span class="line">                           df[<span class="string">"x2"</span>].iloc[id]-df[<span class="string">"x1"</span>].iloc[id],</span><br><span class="line">                           df[<span class="string">"y2"</span>].iloc[id]-df[<span class="string">"y1"</span>].iloc[id],</span><br><span class="line">                           linewidth=<span class="number">2</span>,edgecolor=<span class="string">'r'</span>,facecolor=<span class="string">'none'</span>)</span><br><span class="line">    currentAxis.add_patch(rect)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>其中用到了<code>plt.gca()</code>和matplotlib的<code>patches</code>函数用于图像的叠加显示，当然也可以直接调用<code>cv2.rectangle</code>函数</p>
</blockquote>
<p>随机查看一个标记在图像中的显示效果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line">id = random.randint(<span class="number">0</span>,len(df))</span><br><span class="line">show_image(id)</span><br></pre></td></tr></table></figure>
<p><img src="/qnsource/images/2018-04-09-Deep-Learning-Lab-Logo-Detection/BMW_sample.png" alt="BMW_sample"></p>
<p>下面需要写一个抠图程序，把所有LOGO从原始图像中扣取出来，形成训练用数据集，在保存图像之前进行图像简单的预处理和调整形状：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">crop_img</span><span class="params">(id)</span>:</span></span><br><span class="line">    image = os.path.join(<span class="string">"./flickr_logos_27_dataset/flickr_logos_27_dataset_images/"</span>,df.loc[id][<span class="string">"Name"</span>])</span><br><span class="line">    image = cv2.imread(image)</span><br><span class="line">    crop_image = image[df[<span class="string">"y1"</span>].iloc[id]:df[<span class="string">"y2"</span>].iloc[id],df[<span class="string">"x1"</span>].iloc[id]:df[<span class="string">"x2"</span>].iloc[id]]</span><br><span class="line">    <span class="keyword">return</span> crop_image</span><br><span class="line">  </span><br><span class="line">WIDTH = <span class="number">64</span></span><br><span class="line">HEIGHT = <span class="number">64</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> id, name <span class="keyword">in</span> enumerate(df[<span class="string">"Name"</span>]):</span><br><span class="line">    cropped_image = crop_img(id)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        resized_image = cv2.resize(cropped_image, 	     </span><br><span class="line">                                   (WIDTH,HEIGHT),interpolation=cv2.INTER_CUBIC)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        print(id)</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    image_name = str(id)+<span class="string">"_"</span>+df.iloc[id][<span class="string">"labels"</span>]+<span class="string">".jpg"</span></span><br><span class="line">    cv2.imwrite(os.path.join(<span class="string">"./flickr_logos_27_dataset/cropped/"</span>,image_name),resized_image)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>在图像扣取过程中，有几点需要注意：</p>
<ol>
<li>由于描述问题提供的信息本身的问题，有一些异常数据需要剔除，比如有5条记录提供的x1=x2,或y1=y2，即在原始图像上没有进行标记；</li>
<li>图像缩放其实不应该采用这种傻瓜的压缩方式，应该尽量控制长宽比，保证不产生明显的形变；</li>
</ol>
</blockquote>
<p>处理完成之后，扣取图像将在<code>cropped</code>文件夹中以<code>{id}_{label}.jpg</code>的文件名存储。</p>
<p>图像扣取之后，通过人工核对，我们发现仍然存在一些明显有问题的图像，比如多张puma的图像，其实存在明显的标记问题，需要从数据集中剔除：</p>
<p><img src="/qnsource/images/2018-04-09-Deep-Learning-Lab-Logo-Detection/puma_error_img.png" alt="puma_error_img"></p>
<h3 id="数据集切分"><a href="#数据集切分" class="headerlink" title="数据集切分"></a>数据集切分</h3><p>我们将扣取数据读入进行简单预处理和数据切分：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">data = []</span><br><span class="line">labels = []</span><br><span class="line"><span class="keyword">for</span> img <span class="keyword">in</span> os.listdir(<span class="string">"./flickr_logos_27_dataset/cropped/"</span>):</span><br><span class="line">    img_file = cv2.imread(os.path.join(<span class="string">"./flickr_logos_27_dataset/cropped/"</span>,img))</span><br><span class="line">    data.append(img_file)</span><br><span class="line">    labels.append(img.split(<span class="string">"_"</span>)[<span class="number">1</span>].split(<span class="string">"."</span>)[<span class="number">0</span>])</span><br><span class="line">data = np.stack(data)</span><br><span class="line">labels = np.stack(labels)</span><br><span class="line"></span><br><span class="line">data = data/<span class="number">255</span></span><br></pre></td></tr></table></figure>
<p>将标签数据转变成OneHot矩阵：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelBinarizer</span><br><span class="line">le = LabelBinarizer()</span><br><span class="line">labels = le.fit_transform(labels)</span><br></pre></td></tr></table></figure>
<p>切分数据集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X,testX,y,testy = train_test_split(data, labels,test_size=<span class="number">0.1</span>,stratify=labels,random_state=<span class="number">42</span> )</span><br></pre></td></tr></table></figure>
<h3 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h3><p>数据增强是图像处理中经常采用的一种数据处理方式，由于涉及内容较多，在本篇实战中不单独展开，仅把利用Keras数据增强工具<code>ImageDataGenerator</code>的方法提供一下：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.preprocessing.image import ImageDataGenerator </span><br><span class="line"><span class="comment"># construct the training image generator for data augmentation</span></span><br><span class="line">aug = ImageDataGenerator(<span class="attribute">rotation_range</span>=18, <span class="attribute">zoom_range</span>=0.15,</span><br><span class="line">	<span class="attribute">width_shift_range</span>=0.2, <span class="attribute">height_shift_range</span>=0.2, <span class="attribute">shear_range</span>=0.15,</span><br><span class="line">	<span class="attribute">horizontal_flip</span>=<span class="literal">True</span>, <span class="attribute">fill_mode</span>=<span class="string">"nearest"</span>)</span><br><span class="line"></span><br><span class="line"><span class="attribute">gen_flow</span>=aug.flow(X, y,<span class="attribute">batch_size</span>=64,seed=0)</span><br><span class="line"><span class="attribute">validation</span>=aug.flow(testX,testy,batch_size=32,seed=0)</span><br></pre></td></tr></table></figure>
<h2 id="模型定义"><a href="#模型定义" class="headerlink" title="模型定义"></a>模型定义</h2><p>根据前文对数据的分析，我们分别采取两种方式设计网络模型：从头训练一个深度卷积神经网络和利用迁移学习Fine-Tune一个满足需求的网络模型。</p>
<h3 id="从头训练一个网络模型"><a href="#从头训练一个网络模型" class="headerlink" title="从头训练一个网络模型"></a>从头训练一个网络模型</h3><p>由于问题本质是一个物体识别任务，所以在实现上应该包括图像分类和定位的回归两个子任务，我们可以简化问题通过一个滑动窗口来对输入图像进行扫描，然后针对每个扫描窗口进行图像分类。</p>
<blockquote>
<p>当然实际过程中，问题要远比这复杂，很难选择合适的滑动窗口大小适用现实图像的需求，所以在主流的物体识别模型中一般都采用多种不同大小的Anchor box来回归图像的位置。</p>
</blockquote>
<p>由于LOGO每张图像包含特征有限，我们在本次实验中利用<strong>LeNet</strong>的架构，设计了一个简单的卷积网络模型如下图所示：</p>
<p><img src="/qnsource/images/2018-04-09-Deep-Learning-Lab-Logo-Detection/model.png" alt="model"></p>
<p>模型主体利用三个<code>CONV =&gt; RELU =&gt; POOL</code>结构来抽取图像特征，最后利用全联通网络+Softmax分类器来获得最终27类分类结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> Conv2D</span><br><span class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> MaxPooling2D</span><br><span class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Activation</span><br><span class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Flatten</span><br><span class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">inputShape = (HEIGHT, WIDTH, <span class="number">3</span>)</span><br><span class="line">        <span class="comment"># first set of CONV =&gt; RELU =&gt; POOL layers</span></span><br><span class="line">model.add(Conv2D(<span class="number">16</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>,input_shape=inputShape))</span><br><span class="line">model.add(Activation(<span class="string">"relu"</span>))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># second set of CONV =&gt; RELU =&gt; POOL layers</span></span><br><span class="line">model.add(Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>))</span><br><span class="line">model.add(Activation(<span class="string">"relu"</span>))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># third set of CONV =&gt; RELU =&gt; POOL layers</span></span><br><span class="line">model.add(Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>))</span><br><span class="line">model.add(Activation(<span class="string">"relu"</span>))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># first (and only) set of FC =&gt; RELU layers</span></span><br><span class="line">model.add(Flatten())</span><br><span class="line">model.add(Dense(<span class="number">500</span>))</span><br><span class="line">model.add(Activation(<span class="string">"relu"</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.25</span>))</span><br><span class="line"><span class="comment"># softmax classifier</span></span><br><span class="line">model.add(Dense(len(CLASSNAME)))</span><br><span class="line">model.add(Activation(<span class="string">"softmax"</span>))</span><br></pre></td></tr></table></figure>
<p>定义目标优化函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> Adam,SGD,RMSprop</span><br><span class="line">opt = RMSprop(lr=<span class="number">0.001</span>, rho=<span class="number">0.9</span>)</span><br><span class="line">model.compile(loss=<span class="string">"categorical_crossentropy"</span>, optimizer=opt,metrics=[<span class="string">"accuracy"</span>])</span><br></pre></td></tr></table></figure>
<p>迭代训练100个epoch:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">history=model.fit_generator(</span><br><span class="line">	gen_flow,</span><br><span class="line">	steps_per_epoch=len(X) // <span class="number">32</span>,</span><br><span class="line">	validation_data=aug.flow(testX,testy,batch_size=<span class="number">32</span>,seed=<span class="number">0</span>),</span><br><span class="line">	validation_steps=len(testX) // <span class="number">32</span>,</span><br><span class="line">	epochs=<span class="number">100</span>,</span><br><span class="line">	verbose=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>100轮之后，验证集达到了99.89%的准确率，基本满足了要求，训练过程中训练数据和验证数据的准确率及Loss变化详见下图：</p>
<p><img src="/qnsource/images/2018-04-09-Deep-Learning-Lab-Logo-Detection/accuracy_curve.png" alt="accuracy_curve"></p>
<p><img src="/qnsource/images/2018-04-09-Deep-Learning-Lab-Logo-Detection/loss_curve.png" alt="loss_curve"></p>
<h4 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize = (<span class="number">15</span>,<span class="number">40</span>))</span><br><span class="line"><span class="keyword">for</span> i,test_img <span class="keyword">in</span> enumerate(os.listdir(<span class="string">"./test"</span>)):</span><br><span class="line">    img = cv2.imread(os.path.join(<span class="string">"./test"</span>,test_img))</span><br><span class="line">    img = cv2.resize(img, (WIDTH,HEIGHT),interpolation=cv2.INTER_CUBIC)</span><br><span class="line">    img = np.expand_dims(img,axis=<span class="number">0</span>)</span><br><span class="line">    result = model.predict(img)</span><br><span class="line">    result = le.inverse_transform(result)</span><br><span class="line">    plt.subplot(<span class="number">8</span>,<span class="number">4</span>, i+<span class="number">1</span>)</span><br><span class="line">    img = cv2.cvtColor(img[<span class="number">0</span>],  cv2.COLOR_BGR2RGB)</span><br><span class="line">    plt.imshow(img)</span><br><span class="line">    plt.title(<span class="string">'pred:'</span> + str(result[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure>
<p><img src="/qnsource/images/2018-04-09-Deep-Learning-Lab-Logo-Detection/test_result.png" alt="test_result"></p>
<h3 id="设计滑动窗口和特征金字塔"><a href="#设计滑动窗口和特征金字塔" class="headerlink" title="设计滑动窗口和特征金字塔"></a>设计滑动窗口和特征金字塔</h3><p>其中滑动窗口用来遍历图像，特征金字塔用于实现图像的多尺度变换，保证多种不同大小的LOGO都可以被准确识别。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sliding_window</span><span class="params">(image, step, ws)</span>:</span></span><br><span class="line">	<span class="comment"># slide a window across the image</span></span><br><span class="line">	<span class="keyword">for</span> y <span class="keyword">in</span> range(<span class="number">0</span>, image.shape[<span class="number">0</span>] - ws[<span class="number">1</span>], step):</span><br><span class="line">		<span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">0</span>, image.shape[<span class="number">1</span>] - ws[<span class="number">0</span>], step):</span><br><span class="line">			<span class="comment"># yield the current window</span></span><br><span class="line">			<span class="keyword">yield</span> (x, y, image[y:y + ws[<span class="number">1</span>], x:x + ws[<span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">image_pyramid</span><span class="params">(image, scale=<span class="number">1.5</span>, minSize=<span class="params">(<span class="number">64</span>, <span class="number">64</span>)</span>)</span>:</span></span><br><span class="line">	<span class="comment"># yield the original image</span></span><br><span class="line">	<span class="keyword">yield</span> image</span><br><span class="line"></span><br><span class="line">	<span class="comment"># keep looping over the image pyramid</span></span><br><span class="line">	<span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">		<span class="comment"># compute the dimensions of the next image in the pyramid</span></span><br><span class="line">		w = int(image.shape[<span class="number">1</span>] / scale)</span><br><span class="line">		image = imutils.resize(image, width=w)</span><br><span class="line"></span><br><span class="line">		<span class="comment"># if the resized image does not meet the supplied minimum</span></span><br><span class="line">		<span class="comment"># size, then stop constructing the pyramid</span></span><br><span class="line">		<span class="keyword">if</span> image.shape[<span class="number">0</span>] &lt; minSize[<span class="number">1</span>] <span class="keyword">or</span> image.shape[<span class="number">1</span>] &lt; minSize[<span class="number">0</span>]:</span><br><span class="line">			<span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">		<span class="comment"># yield the next image in the pyramid</span></span><br><span class="line">		<span class="keyword">yield</span> image</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>特征金字塔</strong>：</p>
<p>为了检测不同尺度的目标，依次将原图按比例缩放并送入网络。缺点是需要多次resize图像，繁琐耗时。</p>
</blockquote>
<p>我们定义了输入图像的尺寸为(150,150)，滑动窗口大小与我们前面训练的分类网络的输入一致为(64,64),特征金字塔的缩小比例为1.5倍，这样将在原始图像基础上进行两次缩放；另外定义了滑动窗口的步长为16。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># initialize variables used for the object detection procedure</span></span><br><span class="line">INPUT_SIZE = (<span class="number">150</span>, <span class="number">150</span>)</span><br><span class="line">PYR_SCALE = <span class="number">1.5</span></span><br><span class="line">WIN_STEP = <span class="number">16</span></span><br><span class="line">ROI_SIZE = (<span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">labels = &#123;&#125;</span><br><span class="line">CLASS_NAMES = list(lb.classes_)</span><br></pre></td></tr></table></figure>
<p>为简化后续分析，定义一个预测函数，用于返回图像中预测准确率超过minProb窗口及对象分类：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">logo_prediction</span><span class="params">(model, batchROIs, batchLocs, labels, minProb=<span class="number">0.5</span>,dims=<span class="params">(<span class="number">64</span>, <span class="number">64</span>)</span>)</span>:</span></span><br><span class="line">    preds = model.predict(batchROIs)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,len(preds)):</span><br><span class="line">        prob = np.max(preds[i])</span><br><span class="line">        <span class="keyword">if</span> prob &gt; <span class="number">0.5</span>:</span><br><span class="line">            index = np.argmax(preds[i])</span><br><span class="line">            label = CLASS_NAMES[int(index)]</span><br><span class="line">            <span class="comment"># grab the coordinates of the sliding window for</span></span><br><span class="line">            <span class="comment"># the prediction and construct the bounding box</span></span><br><span class="line">            (pX, pY) = batchLocs[i]</span><br><span class="line">            box = (pX, pY, pX + dims[<span class="number">0</span>], pY + dims[<span class="number">1</span>])</span><br><span class="line">            L = labels.get(label, [])</span><br><span class="line">            L.append((box,prob))</span><br><span class="line">            labels[label] = L</span><br><span class="line">    <span class="keyword">return</span> labels</span><br></pre></td></tr></table></figure>
<p>我们将遍历每个特征金字塔和每个滑动窗口，对识别结果进行预测：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">img_file = <span class="string">"./test/2.jpg"</span></span><br><span class="line">orig = cv2.imread(img_file)</span><br><span class="line"><span class="comment"># resize the input image to be a square</span></span><br><span class="line">resized = cv2.resize(orig, INPUT_SIZE, interpolation=cv2.INTER_CUBIC)</span><br><span class="line"></span><br><span class="line"><span class="comment"># initialize the batch ROIs and (x, y)-coordinates</span></span><br><span class="line">batchROIs = <span class="keyword">None</span></span><br><span class="line">batchLocs = []</span><br><span class="line"><span class="comment"># loop over the image pyramid</span></span><br><span class="line"><span class="keyword">for</span> image <span class="keyword">in</span> image_pyramid(resized, scale=PYR_SCALE,minSize=ROI_SIZE):</span><br><span class="line">    <span class="comment"># loop over the sliding window locations</span></span><br><span class="line">    <span class="keyword">for</span> (x, y, roi) <span class="keyword">in</span> sliding_window(resized, WIN_STEP, ROI_SIZE):</span><br><span class="line">        <span class="comment"># take the ROI and pre-process it so we can later classify the</span></span><br><span class="line">        <span class="comment"># region with Keras</span></span><br><span class="line">        <span class="comment">#roi = img_to_array(roi)</span></span><br><span class="line">        roi = roi/<span class="number">255</span></span><br><span class="line">        roi = np.expand_dims(roi, axis=<span class="number">0</span>)</span><br><span class="line">        <span class="comment"># roi = imagenet_utils.preprocess_input(roi)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># if the batch is None, initialize it</span></span><br><span class="line">        <span class="keyword">if</span> batchROIs <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            batchROIs = roi</span><br><span class="line"></span><br><span class="line">        <span class="comment"># otherwise, add the ROI to the bottom of the batch</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            batchROIs = np.vstack([batchROIs, roi])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># add the (x, y)-coordinates of the sliding window to the batch</span></span><br><span class="line">        batchLocs.append((x, y))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># classify the batch, then reset the batch ROIs and</span></span><br><span class="line">    <span class="comment"># (x, y)-coordinates</span></span><br><span class="line">    model.predict(batchROIs)</span><br><span class="line">    labels = logo_prediction(model, batchROIs, batchLocs,labels, minProb=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>当进行到这步骤才突然发现训练分类中缺了一个很重要的背景分类，将导致在背景上很多信息的预测会出问题，后续等整些背景图片再重新训练网络，😭</p>
</blockquote>
<p>最后一步是预测结果的<strong>极大值抑制</strong>和显示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> imutils.object_detection <span class="keyword">import</span> non_max_suppression</span><br><span class="line"><span class="comment"># loop over the labels for each of detected objects in the image</span></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> labels.keys():</span><br><span class="line">	<span class="comment"># clone the input image so we can draw on it</span></span><br><span class="line">	clone = resized.copy()</span><br><span class="line"></span><br><span class="line">	<span class="comment"># loop over all bounding boxes for the label and draw them on the image</span></span><br><span class="line">	<span class="keyword">for</span> (box, prob) <span class="keyword">in</span> labels[k]:</span><br><span class="line">		(xA, yA, xB, yB) = box</span><br><span class="line">		cv2.rectangle(clone, (xA, yA), (xB, yB), (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># grab the bounding boxes and associated probabilities for each</span></span><br><span class="line">	<span class="comment"># detection, then apply non-maxima suppression to suppress</span></span><br><span class="line">	<span class="comment"># weaker, overlapping detections</span></span><br><span class="line">	boxes = np.array([p[<span class="number">0</span>] <span class="keyword">for</span> p <span class="keyword">in</span> labels[k]])</span><br><span class="line">	proba = np.array([p[<span class="number">1</span>] <span class="keyword">for</span> p <span class="keyword">in</span> labels[k]])</span><br><span class="line">	boxes = non_max_suppression(boxes, proba)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># loop over the bounding boxes again, this time only drawing the</span></span><br><span class="line">	<span class="comment"># ones that were *not* suppressed</span></span><br><span class="line">	<span class="keyword">for</span> (xA, yA, xB, yB) <span class="keyword">in</span> boxes:</span><br><span class="line">		cv2.rectangle(clone, (xA, yA), (xB, yB), (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># show the output image</span></span><br><span class="line">	print(<span class="string">"[INFO] &#123;&#125;: &#123;&#125;"</span>.format(k, len(boxes)))</span><br><span class="line">	plt.imshow(clone)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>极大值抑制是物体识别中很重要的一个环节，相关概念以后在慢慢整理</p>
</blockquote>
<h3 id="利用迁移学习优化一个物体识别网络模型"><a href="#利用迁移学习优化一个物体识别网络模型" class="headerlink" title="利用迁移学习优化一个物体识别网络模型"></a>利用迁移学习优化一个物体识别网络模型</h3><p>上述方法虽然简单容易理解，但存在很大的计算效率问题，每张图片需要进行多次特征提取和多次运算，对计算效率造成很大影响。目前主流的物体识别算法往往都可以应用于实时视频流的分析，显然使用上述方法是不合适的。我们将在后面探讨利用现有的物体识别网络通过迁移学习解决我们的目标识别问题。</p>
<p>由于本篇内容太多，利用迁移学习实现的方法，将单独作为一篇，此处留待插入<strong>链接</strong>。</p>
<p>本文涉及代码详见<a href="https://github.com/ddebby/AI-Lab">Github</a></p>
<h2 id="训练一个二分类网络检查货架上是否有百事可乐"><a href="#训练一个二分类网络检查货架上是否有百事可乐" class="headerlink" title="训练一个二分类网络检查货架上是否有百事可乐"></a>训练一个二分类网络检查货架上是否有百事可乐</h2><blockquote>
<p>参考<a href="https://github.com/Anubhav-Bhargava/Logo-Classifier/blob/master/logo_clf_sliding_window.ipynb">Github实现</a>一个物品检测原型：训练一个二分类分类器</p>
</blockquote>
<ol>
<li>在数据准备阶段与上述过程唯一不同是label的设置，如下：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os, cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data = []</span><br><span class="line">labels = []</span><br><span class="line">HEIGHT = <span class="number">64</span></span><br><span class="line">WIDTH = <span class="number">64</span></span><br><span class="line"><span class="keyword">for</span> img <span class="keyword">in</span> os.listdir(<span class="string">"./flickr_logos_27_dataset/cropped/"</span>):</span><br><span class="line">    img_file = cv2.imread(os.path.join(<span class="string">"./flickr_logos_27_dataset/cropped/"</span>,img))</span><br><span class="line">    data.append(img_file)</span><br><span class="line">    label = img.split(<span class="string">"_"</span>)[<span class="number">1</span>].split(<span class="string">"."</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> label != <span class="string">"Pepsi"</span>:</span><br><span class="line">        label = <span class="string">"Nop"</span></span><br><span class="line">    labels.append(label)</span><br><span class="line">data = np.stack(data)</span><br><span class="line">labels = np.stack(labels)</span><br></pre></td></tr></table></figure>
<ol>
<li><p>由于是二分类问题，所以只需要最后一层使用sigmoid函数构建分类器即可，label的序列话方面使用LabelEncoder转换为0或者1即可：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line">lb = LabelEncoder()</span><br><span class="line">y = lb.fit_transform(labels)</span><br></pre></td></tr></table></figure>
</li>
<li><p>数据增强与前文类似，不再赘言。在网络结构上，只需要修改最后为sigmoid函数输出，优化目标使用<code>binary_crossentropy</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">model.add(Activation(<span class="string">"sigmoid"</span>))</span><br><span class="line">...</span><br><span class="line">model.compile(loss=<span class="string">"binary_crossentropy"</span>, optimizer=opt,</span><br><span class="line">	metrics=[<span class="string">"accuracy"</span>])</span><br></pre></td></tr></table></figure>
<p>由于只有两个分类，所以模型很容易收敛，最后准确率也接近100%。</p>
</li>
<li><p>最后利用一个滑动窗口不停的扫描图像并利用cv2展示结果即可：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (x, y, window) <span class="keyword">in</span> sliding_window(img, stepSize=<span class="number">32</span>, windowSize=(winW, winH)):</span><br><span class="line">    <span class="comment"># if the window does not meet our desired window size, ignore it</span></span><br><span class="line">    <span class="keyword">if</span> window.shape[<span class="number">0</span>] != winH <span class="keyword">or</span> window.shape[<span class="number">1</span>] != winW:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">   </span><br><span class="line">    crop_img=crop_image(sample_path,x, y, x + winW, y + winH)</span><br><span class="line">    crop_img=imresize(crop_img,(<span class="number">64</span>,<span class="number">64</span>))</span><br><span class="line">    crop_img = crop_img/<span class="number">255</span></span><br><span class="line">    prediction=model.predict(crop_img.reshape(<span class="number">1</span>,<span class="number">64</span>,<span class="number">64</span>,<span class="number">3</span>))</span><br><span class="line">    <span class="keyword">if</span> prediction == <span class="number">1</span>:</span><br><span class="line">        pred = <span class="string">'Pepsi'</span>    </span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">    	pred=<span class="string">' '</span></span><br><span class="line">   	</span><br><span class="line">    clone = img.copy()</span><br><span class="line">    cv2.putText(clone, pred, (<span class="number">10</span>, <span class="number">30</span>),cv2.FONT_HERSHEY_SIMPLEX, <span class="number">0.7</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)</span><br><span class="line">    cv2.rectangle(clone, (x, y), (x + winW, y + winH), (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">2</span>)</span><br><span class="line">    clone = cv2.cvtColor(clone,cv2.COLOR_BGR2RGB)</span><br><span class="line">    cv2.imshow(<span class="string">"Window"</span>, clone)</span><br><span class="line">    </span><br><span class="line">    cv2.waitKey(<span class="number">1</span>)</span><br><span class="line">    time.sleep(<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure>
<p>​</p>
</li>
</ol>
<h2 id="Logo检测的应用及分析"><a href="#Logo检测的应用及分析" class="headerlink" title="Logo检测的应用及分析"></a>Logo检测的应用及分析</h2><p><a href="https://blog.deepsense.ai/logo-detection-and-brand-visibility-analytics/">DeepSense.ai</a>给出了一种Logo检测的分析方法，通过分析视频中不同品牌的logo呈现，统计了不同品牌在同一个视频中Logo出现的时间、出现的方式、呈现的效果等，最终提供给客户一个<strong>Logo Visubility Report</strong>。</p>
<p>方案的主要流程如下图所示：</p>
<p><img src="/qnsource/images/2018-04-09-Deep-Learning-Lab-Logo-Detection/logo_detection_overview.jpg" alt="logo_detection_overview"></p>
<p>生成的分析报告参见下图：</p>
<p><img src="/qnsource/images/2018-04-09-Deep-Learning-Lab-Logo-Detection/logo_detection_report.png" alt="logo_detection_report"></p>
<p>针对的分析视频如下：</p>
<div class="video-container"><iframe src="//www.youtube.com/embed/ekaHlWga5yA" frameborder="0" allowfullscreen></iframe></div>
<hr>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a href="http://image.ntua.gr/iva/datasets/flickr_logos/">Flickr Logos 27 dataset</a></li>
<li><a href="http://www.multimedia-computing.de/flickrlogos/#flickrlogos47">Datasets: FlickrLogos-32 / FlickrLogos-47</a></li>
<li>​</li>
</ol>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                

                <time class="level-item has-text-grey" datetime="2018-04-01T07:35:01.000Z">2018-04-01</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/深度学习/">深度学习</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/深度学习/基础知识/">基础知识</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    17 分钟 读完 (大约 2514 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2018/04/01/深度学习基础之优化算法/">深度学习基础之优化算法</a>
            
        </h1>
        <div class="content">
            <p>合适优化算法的选择有助于提升训练效率和收敛的速度，本文对常用的优化算法进行总结。在这章中将归纳SGD、RMSprop、Adam等的基础原理。优化算法的优劣来自于对相关算法的熟悉程度。</p>
        </div>
        
        
        <hr style="height:1px;margin:1rem 0"/>
         <div class="level is-mobile is-flex">
         <div class="level-start">
          
          <div class="level-item is-size-7 is-uppercase">
           <i class="fas fa-tags has-text-grey"></i>&nbsp;
             <a class="has-link-grey -link" href="/tags/AI/">AI</a>,&nbsp;<a class="has-link-grey -link" href="/tags/人工智能/">人工智能</a>,&nbsp;<a class="has-link-grey -link" href="/tags/优化/">优化</a>,&nbsp;<a class="has-link-grey -link" href="/tags/算法/">算法</a>
         </div>
         
         </div>

            <div class="level-start">
                <div class="level-item">
                <a class="button is-size-7 is-light" href="/2018/04/01/深度学习基础之优化算法/#more">阅读更多</a>
                </div>
            </div>
        </div>
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                

                <time class="level-item has-text-grey" datetime="2018-03-30T15:36:52.000Z">2018-03-30</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/算法/">算法</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/算法/迁移学习/">迁移学习</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    7 分钟 读完 (大约 1029 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2018/03/30/Transfer-Learning-Summary/">Transfer Learning Summary</a>
            
        </h1>
        <div class="content">
            <p>本文对迁移学习在机器视觉中的实践技巧进行汇总整理 … …</p>
<!-- excerpt-->
<p>@toc</p>
<h2 id="Feature-Extraction"><a href="#Feature-Extraction" class="headerlink" title="Feature Extraction"></a>Feature Extraction</h2><p>在这种迁移学习模式中，预训练模型将被当作特征提取器（feature extractor）,获得图像的特征表示(feature vactor)。获得特征向量之后，我们只需一个简单的分类器模型，如SVM、逻辑回归分类器、随机森林就可以完成目标分类器的设计。</p>
<blockquote>
<p>VGG16倒数第二层(参数层)的输出维度为: <strong>7x7x512 = 25,088</strong></p>
</blockquote>
<h3 id="HDF5"><a href="#HDF5" class="headerlink" title="HDF5"></a>HDF5</h3><p>抽取特征的高效存储可以选用<code>HDF5</code>。Hierarchical Data Format(HDF)是一种针对大量数据进行组织和存储的文件格式。经历了20多年的发展，HDF格式的最新版本是HDF5，它包含了数据模型，库，和文件格式标准。以其便捷有效，移植性强，灵活可扩展的特点受到了广泛的关注和应用。很多大型机构的数据存储格式都采用了HDF5，比如NASA的地球观测系统，MATLAB的.m文件，流体细算软件CDF，都将HDF5作为标准数据格式。HDF5本身用C实现，可以使用python的库<code>h5py</code>对HDF5文件进行操作。可以像操作Numpy数组一样对大型数据进行操作，比如切片，按行读取</p>
<p>数据在HDF5中采取分层存储方式，很像文件系统管理方式，第一级叫做组，类似于container，每个组中可以创建新的组或数据集，每一个dataset包含两部分的数据，Metadata和Data。其中Metadata包含Data相关的信息，而Data则包含数据本身。 </p>
<p><img src="/qnsource/images/2018-03-30-Transfer-Learning-Summary/HDF5文件存储方式.jpg" alt="HDF5文件存储方式"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line">p = <span class="string">"./datasets/hdf5/features.hdf5"</span></span><br><span class="line"></span><br><span class="line">db = h5py.File(p)</span><br><span class="line">list(db.keys())</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>[u’features’, u’label_names’, u’labels’]</span><br><span class="line">db[<span class="string">"features"</span>].shape</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>(<span class="number">3000</span>, <span class="number">25088</span>)</span><br><span class="line">list(db[<span class="string">"label_name"</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>[<span class="string">'cat'</span>, <span class="string">'dogs'</span>, <span class="string">'panda'</span>]</span><br></pre></td></tr></table></figure>
<h2 id="Fine-Tune"><a href="#Fine-Tune" class="headerlink" title="Fine-Tune"></a>Fine-Tune</h2><ul>
<li><p>一般而言，fine-tune在样本数据足够的情况下训练效果优于特征抽取；</p>
<p><img src="/qnsource/images/2018-03-30-Transfer-Learning-Summary/fine_tune.png" alt="fine_tune"></p>
</li>
</ul>
<blockquote>
<p>学习率要控制的尽量小</p>
</blockquote>
<h3 id="如何取层（Keras）"><a href="#如何取层（Keras）" class="headerlink" title="如何取层（Keras）"></a>如何取层（Keras）</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.applications <span class="keyword">import</span> VGG16</span><br><span class="line">model = VGG16(weights=<span class="string">"imagenet"</span>, include_top=<span class="keyword">False</span>)</span><br><span class="line">model.layers</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">[&lt;keras.engine.topology.InputLayer at <span class="number">0x7ff06cc3b518</span>&gt;,</span><br><span class="line"> &lt;keras.layers.convolutional.Conv2D at <span class="number">0x7ff06cc3b7f0</span>&gt;,</span><br><span class="line"> &lt;keras.layers.convolutional.Conv2D at <span class="number">0x7ff06cc3b7b8</span>&gt;,</span><br><span class="line"> &lt;keras.layers.pooling.MaxPooling2D at <span class="number">0x7ff06cc3bd30</span>&gt;,</span><br><span class="line"> &lt;keras.layers.convolutional.Conv2D at <span class="number">0x7ff06cdb3b00</span>&gt;,</span><br><span class="line"> &lt;keras.layers.convolutional.Conv2D at <span class="number">0x7ff06cdb3748</span>&gt;,</span><br><span class="line"> &lt;keras.layers.pooling.MaxPooling2D at <span class="number">0x7ff06cbbb400</span>&gt;,</span><br><span class="line"> &lt;keras.layers.convolutional.Conv2D at <span class="number">0x7ff06cbcc630</span>&gt;,</span><br><span class="line"> &lt;keras.layers.convolutional.Conv2D at <span class="number">0x7ff06cb5dd68</span>&gt;,</span><br><span class="line"> &lt;keras.layers.convolutional.Conv2D at <span class="number">0x7ff06cb6d208</span>&gt;,</span><br><span class="line"> &lt;keras.layers.pooling.MaxPooling2D at <span class="number">0x7ff06cb7fdd8</span>&gt;,</span><br><span class="line"> &lt;keras.layers.convolutional.Conv2D at <span class="number">0x7ff06cb30fd0</span>&gt;,</span><br><span class="line"> &lt;keras.layers.convolutional.Conv2D at <span class="number">0x7ff06cb30e80</span>&gt;,</span><br><span class="line"> &lt;keras.layers.convolutional.Conv2D at <span class="number">0x7ff06cb52978</span>&gt;,</span><br><span class="line"> &lt;keras.layers.pooling.MaxPooling2D at <span class="number">0x7ff06caf6470</span>&gt;,</span><br><span class="line"> &lt;keras.layers.convolutional.Conv2D at <span class="number">0x7ff06cb076a0</span>&gt;,</span><br><span class="line"> &lt;keras.layers.convolutional.Conv2D at <span class="number">0x7ff06ca98dd8</span>&gt;,</span><br><span class="line"> &lt;keras.layers.convolutional.Conv2D at <span class="number">0x7ff06caaa278</span>&gt;,</span><br><span class="line"> &lt;keras.layers.pooling.MaxPooling2D at <span class="number">0x7ff06cab8e48</span>&gt;]</span><br><span class="line"></span><br><span class="line">model.output</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">&lt;tf.Tensor 'block5_pool/MaxPool:0' shape=(?, ?, ?, 512) dtype=float32&gt;</span><br></pre></td></tr></table></figure>
<h3 id="如何添加层（Keras）"><a href="#如何添加层（Keras）" class="headerlink" title="如何添加层（Keras）"></a>如何添加层（Keras）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># load the VGG16 network, ensuring the head FC layer sets are left # off</span></span><br><span class="line">baseModel = VGG16(weights=<span class="string">"imagenet"</span>, include_top=<span class="keyword">False</span>, input_tensor=Input(shape=(<span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>)))</span><br><span class="line"><span class="comment"># add new layers</span></span><br><span class="line">headModel = baseModel.output</span><br><span class="line">headModel = Flatten(name=<span class="string">"flatten"</span>)(headModel)</span><br><span class="line">headModel = Dense(D_num, activation=<span class="string">"relu"</span>)(headModel)</span><br><span class="line">headModel = Dropout(<span class="number">0.5</span>)(headModel)</span><br><span class="line">headModel = Dense(classes_num, activation=<span class="string">"softmax"</span>)(headModel)</span><br><span class="line"></span><br><span class="line">model = Model(inputs=baseModel.input, outputs=headModel)</span><br><span class="line"><span class="comment">#freeze baseModel layers</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> baseModel.layers:</span><br><span class="line">    layer.trainable = <span class="keyword">False</span></span><br></pre></td></tr></table></figure>
<ol>
<li><p>Typically you’ll allow your own FC head to warmup for <strong>10-30 epochs</strong>, depending on your dataset.使用RMSprop作为优化算法；​</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">opt = RMSprop(lr=<span class="number">0.001</span>)</span><br><span class="line">model.compile(loss=<span class="string">"categorical_crossentropy"</span>, optimizer=opt, metrics=[<span class="string">"accuracy"</span>])</span><br><span class="line"><span class="comment"># train the head of the network for a few epochs (all other # layers are frozen) -- this will allow the new FC layers to</span></span><br><span class="line"><span class="comment"># start to become initialized with actual "learned" values # versus pure random</span></span><br><span class="line">print(<span class="string">"[INFO] training head..."</span>)</span><br><span class="line">model.fit_generator(aug.flow(trainX, trainY, batch_size=<span class="number">32</span>), validation_data=(testX, testY), epochs=<span class="number">25</span>, steps_per_epoch=len(trainX) // <span class="number">32</span>, verbose=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<ol>
<li><p>然后可以适当往前解冻一些层，重新训练，一般会解冻最后一层CONV，使用SGD（lr=0.001）作为优化算法；</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># now that the head FC layers have been trained/initialized, lets # unfreeze the final set of CONV layers and make them trainable </span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> baseModel.layers[<span class="number">15</span>:]: </span><br><span class="line">    layer.trainable = <span class="keyword">True</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># for the changes to the model to take affect we need to recompile # the model, this time using SGD with a *very* small learning rate </span></span><br><span class="line">print(<span class="string">"[INFO] re-compiling model..."</span>) </span><br><span class="line">opt = SGD(lr=<span class="number">0.001</span>)</span><br><span class="line">model.compile(loss=<span class="string">"categorical_crossentropy"</span>, optimizer=opt, metrics=[<span class="string">"accuracy"</span>])</span><br><span class="line"><span class="comment"># train the model again, this time fine-tuning *both* the final set # of CONV layers along with our set of FC layers </span></span><br><span class="line">print(<span class="string">"[INFO] fine-tuning model..."</span>)</span><br><span class="line">model.fit_generator(aug.flow(trainX, trainY, batch_size=<span class="number">32</span>), validation_data=(testX, testY), epochs=<span class="number">100</span>, steps_per_epoch=len(trainX) // <span class="number">32</span>, verbose=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
</ol>
<h2 id="迁移学习的选择"><a href="#迁移学习的选择" class="headerlink" title="迁移学习的选择"></a>迁移学习的选择</h2><p>主要由样本数据量以及训练目标于原目标之间的相似程度决定。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>数据规模</strong></th>
<th><strong>相似数据分布</strong></th>
<th><strong>不同数据分布</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>小样本数据集</td>
<td>特征提取：FC+分类器</td>
<td>特征提取：低层次的Conv+分类器</td>
</tr>
<tr>
<td>大样本数据集</td>
<td>Fine-Tune</td>
<td>从头训练新的网络模型</td>
</tr>
</tbody>
</table>
</div>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                

                <time class="level-item has-text-grey" datetime="2018-03-09T08:37:04.000Z">2018-03-09</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/深度学习/">深度学习</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/深度学习/基础知识/">基础知识</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    10 分钟 读完 (大约 1490 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2018/03/09/神经网络之感知机/">神经网络之感知机（Perceptron）</a>
            
        </h1>
        <div class="content">
            <p>感知机于1957年由Rosenblatt等人提出，是神经网络和支持向量机的基础。</p>
        </div>
        
        
        <hr style="height:1px;margin:1rem 0"/>
         <div class="level is-mobile is-flex">
         <div class="level-start">
          
          <div class="level-item is-size-7 is-uppercase">
           <i class="fas fa-tags has-text-grey"></i>&nbsp;
             <a class="has-link-grey -link" href="/tags/AI/">AI</a>,&nbsp;<a class="has-link-grey -link" href="/tags/人工智能/">人工智能</a>,&nbsp;<a class="has-link-grey -link" href="/tags/感知机/">感知机</a>
         </div>
         
         </div>

            <div class="level-start">
                <div class="level-item">
                <a class="button is-size-7 is-light" href="/2018/03/09/神经网络之感知机/#more">阅读更多</a>
                </div>
            </div>
        </div>
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                

                <time class="level-item has-text-grey" datetime="2018-03-05T08:52:33.000Z">2018-03-05</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/读书笔记/">读书笔记</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/读书笔记/机器视觉/">机器视觉</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    10 分钟 读完 (大约 1462 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2018/03/05/读书笔记：《Practical-Python-and-OpenCV》/">读书笔记：《Practical Python and OpenCV》</a>
            
        </h1>
        <div class="content">
            <p>《Practical Python and OpenCV》读书札记。</p>
<!-- excerpt -->
<h2 id="1-Load，Display-and-Save-an-Image"><a href="#1-Load，Display-and-Save-an-Image" class="headerlink" title="1. Load，Display and Save an Image"></a>1. Load，Display and Save an Image</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># Load the image and show some basic information on it</span></span><br><span class="line">image = cv2.imread(<span class="string">"Path/to/Image"</span>)</span><br><span class="line"><span class="comment"># Show the image and wait for a keypress</span></span><br><span class="line">cv2.imshow(<span class="string">"Image"</span>, image)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line"><span class="comment"># Save the image -- OpenCV handles converting filetypes</span></span><br><span class="line"><span class="comment"># automatically</span></span><br><span class="line">cv2.imwrite(<span class="string">"newimage.jpg"</span>, image)</span><br></pre></td></tr></table></figure>
<h2 id="2-cv2"><a href="#2-cv2" class="headerlink" title="2. cv2"></a>2. cv2</h2><p><strong>图像上添加线条及形状</strong></p>
<ul>
<li><code>cv2.line(image, start_point, stop_point, color, thickness)</code></li>
<li><code>cv2.rectangle(image,top_left, bottom_right, color, thickness)</code><ul>
<li><code>thickness</code> 为负数，填充形状</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Initialize our canvas as a 300x300 with 3 channels,</span></span><br><span class="line"><span class="comment"># Red, Green, and Blue, with a black background</span></span><br><span class="line">canvas = np.zeros((<span class="number">300</span>, <span class="number">300</span>, <span class="number">3</span>), dtype = <span class="string">"uint8"</span>)</span><br><span class="line"><span class="comment"># Draw a green line from the top-left corner of our canvas</span></span><br><span class="line"><span class="comment"># to the bottom-right</span></span><br><span class="line">green = (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>)</span><br><span class="line">cv2.line(canvas, (<span class="number">0</span>, <span class="number">0</span>), (<span class="number">300</span>, <span class="number">300</span>), green)</span><br><span class="line"><span class="comment"># Now, draw a 3 pixel thick red line from the top-right</span></span><br><span class="line"><span class="comment"># corner to the bottom-left</span></span><br><span class="line">red = (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>)</span><br><span class="line">cv2.line(canvas, (<span class="number">300</span>, <span class="number">0</span>), (<span class="number">0</span>, <span class="number">300</span>), red, <span class="number">3</span>)</span><br><span class="line"><span class="comment"># Draw a green 50x50 pixel square, starting at 10x10 and</span></span><br><span class="line"><span class="comment"># ending at 60x60</span></span><br><span class="line">cv2.rectangle(canvas, (<span class="number">10</span>, <span class="number">10</span>), (<span class="number">60</span>, <span class="number">60</span>), green)</span><br><span class="line"><span class="comment"># Draw another rectangle, this time we'll make it red and</span></span><br><span class="line"><span class="comment"># 5 pixels thick</span></span><br><span class="line">cv2.rectangle(canvas, (<span class="number">50</span>, <span class="number">200</span>), (<span class="number">200</span>, <span class="number">225</span>), red, <span class="number">5</span>)</span><br><span class="line"><span class="comment"># Let's draw one last rectangle: blue and filled in</span></span><br><span class="line">blue = (<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">cv2.rectangle(canvas, (<span class="number">200</span>, <span class="number">50</span>), (<span class="number">225</span>, <span class="number">125</span>), blue, <span class="number">-1</span>)</span><br><span class="line">cv2.imshow(<span class="string">"Canvas"</span>, canvas)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/qnsource/images/2018-03-05-读书笔记：《Practical-Python-and-OpenCV》/Line and Rectangle.png" alt="Line and Rectangle"></p>
<p><strong>添加圆形</strong></p>
<ul>
<li><code>cv2.circle(image, (centerX, centerY), r, color,thickness)</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Reset our canvas and draw a white circle at the center</span></span><br><span class="line"><span class="comment"># of the canvas with increasing radii - from 25 pixels to</span></span><br><span class="line"><span class="comment"># 150 pixels</span></span><br><span class="line">canvas = np.zeros((<span class="number">300</span>, <span class="number">300</span>, <span class="number">3</span>), dtype = <span class="string">"uint8"</span>)</span><br><span class="line">(centerX, centerY) = (canvas.shape[<span class="number">1</span>] // <span class="number">2</span>, canvas.shape[<span class="number">0</span>] // <span class="number">2</span>)</span><br><span class="line">white = (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>)</span><br><span class="line"><span class="keyword">for</span> r <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">175</span>, <span class="number">25</span>):</span><br><span class="line">	cv2.circle(canvas, (centerX, centerY), r, white)</span><br><span class="line">cv2.imshow(<span class="string">"Canvas"</span>, canvas)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/qnsource/images/2018-03-05-读书笔记：《Practical-Python-and-OpenCV》/Circles.png" alt="Circles"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Let's go crazy and draw 25 random circles</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">25</span>):</span><br><span class="line">	<span class="comment"># randomly generate a radius size between 5 and 200,</span></span><br><span class="line">	<span class="comment"># generate a random color, and then pick a random</span></span><br><span class="line">	<span class="comment"># point on our canvas where the circle will be drawn</span></span><br><span class="line">	radius = np.random.randint(<span class="number">5</span>, high = <span class="number">200</span>)</span><br><span class="line">	color = np.random.randint(<span class="number">0</span>, high = <span class="number">256</span>, size = (<span class="number">3</span>,)).tolist()</span><br><span class="line">	pt = np.random.randint(<span class="number">0</span>, high = <span class="number">300</span>, size = (<span class="number">2</span>,))</span><br><span class="line"></span><br><span class="line">	<span class="comment"># draw our random circle</span></span><br><span class="line">	cv2.circle(canvas, tuple(pt), radius, color, <span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show our masterpiece</span></span><br><span class="line">cv2.imshow(<span class="string">"Canvas"</span>, canvas)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/qnsource/images/2018-03-05-读书笔记：《Practical-Python-and-OpenCV》/RandomCircles.png" alt="RandomCircles"></p>
<h2 id="3-Image-Processing"><a href="#3-Image-Processing" class="headerlink" title="3. Image Processing"></a>3. Image Processing</h2><ol>
<li><p>平移</p>
<ul>
<li><code>cv2.warpAffine()</code></li>
<li>imutil</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">translate</span><span class="params">(image, x, y)</span>:</span></span><br><span class="line">	<span class="comment"># Define the translation matrix and perform the translation</span></span><br><span class="line">	M = np.float32([[<span class="number">1</span>, <span class="number">0</span>, x], [<span class="number">0</span>, <span class="number">1</span>, y]])</span><br><span class="line">	shifted = cv2.warpAffine(image, M, (image.shape[<span class="number">1</span>], image.shape[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line">	<span class="comment"># Return the translated image</span></span><br><span class="line">	<span class="keyword">return</span> shifted</span><br></pre></td></tr></table></figure>
</li>
<li><p>旋转</p>
<ul>
<li><code>cv2.getRotationMatrix2D</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rotate</span><span class="params">(image, angle, center = None, scale = <span class="number">1.0</span>)</span>:</span></span><br><span class="line">	<span class="comment"># Grab the dimensions of the image</span></span><br><span class="line">	(h, w) = image.shape[:<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">	<span class="comment"># If the center is None, initialize it as the center of</span></span><br><span class="line">	<span class="comment"># the image</span></span><br><span class="line">	<span class="keyword">if</span> center <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">		center = (w / <span class="number">2</span>, h / <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># Perform the rotation</span></span><br><span class="line">	M = cv2.getRotationMatrix2D(center, angle, scale)</span><br><span class="line">	rotated = cv2.warpAffine(image, M, (w, h))</span><br><span class="line"></span><br><span class="line">	<span class="comment"># Return the rotated image</span></span><br><span class="line">	<span class="keyword">return</span> rotated</span><br></pre></td></tr></table></figure>
</li>
<li><p>缩放</p>
<ul>
<li><code>cv2.resize</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resize</span><span class="params">(image, width = None, height = None, inter = cv2.INTER_AREA)</span>:</span></span><br><span class="line">	<span class="comment"># initialize the dimensions of the image to be resized and grab the image size</span></span><br><span class="line">	dim = <span class="keyword">None</span></span><br><span class="line">	(h, w) = image.shape[:<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">	<span class="comment"># if both the width and height are None, then return the original image</span></span><br><span class="line">	<span class="keyword">if</span> width <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">and</span> height <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">		<span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line">	<span class="comment"># check to see if the width is None</span></span><br><span class="line">	<span class="keyword">if</span> width <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">		<span class="comment"># calculate the ratio of the height and construct the dimensions</span></span><br><span class="line">		r = height / float(h)</span><br><span class="line">		dim = (int(w * r), height)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># otherwise, the height is None</span></span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		<span class="comment"># calculate the ratio of the width and construct the dimensions</span></span><br><span class="line">		r = width / float(w)</span><br><span class="line">		dim = (width, int(h * r))</span><br><span class="line"></span><br><span class="line">	<span class="comment"># resize the image</span></span><br><span class="line">	resized = cv2.resize(image, dim, interpolation = inter)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># return the resized image</span></span><br><span class="line">	<span class="keyword">return</span> resized</span><br></pre></td></tr></table></figure>
</li>
<li><p>反转</p>
<ul>
<li><code>cv2.flip(image, num)</code></li>
<li>num=1, 水平反转；num=0，垂直翻转；num为负，对角反转</li>
</ul>
</li>
<li><p>bitwise</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bitwiseAnd = cv2.bitwise_and(rectangle, circle) cv2.imshow(<span class="string">"AND"</span>, bitwiseAnd) </span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>MASKING</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mask = np.zeros(image.shape[:<span class="number">2</span>], dtype = <span class="string">"uint8"</span>) </span><br><span class="line">cv2.circle(mask, (cX, cY), <span class="number">100</span>, <span class="number">255</span>, <span class="number">-1</span>) </span><br><span class="line">masked = cv2.bitwise_and(image, image, mask = mask)  cv2.imshow(<span class="string">"Mask"</span>, mask) </span><br><span class="line">cv2.imshow(<span class="string">"Mask Applied to Image"</span>, masked) </span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>色彩空间变换</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load the image and show it</span></span><br><span class="line">image = cv2.imread(args[<span class="string">"image"</span>])</span><br><span class="line"><span class="comment"># Convert the image to grayscale</span></span><br><span class="line">gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># Convert the image to the HSV (Hue, Saturation, Value)</span></span><br><span class="line"><span class="comment"># color spaces</span></span><br><span class="line">hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)</span><br><span class="line"><span class="comment"># Convert the image to the L*a*b* color spaces</span></span><br><span class="line">lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)</span><br></pre></td></tr></table></figure>
</li>
<li><p>平滑/模糊（blurring）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Averaging Blurring</span></span><br><span class="line">cv2.blur(image, (<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line"><span class="comment"># Gaussian Blurring</span></span><br><span class="line">cv2.GaussianBlur(image, (<span class="number">3</span>, <span class="number">3</span>), <span class="number">0</span>)</span><br><span class="line"><span class="comment"># Median Blurring</span></span><br><span class="line">cv2.medianBlur(image, <span class="number">3</span>)</span><br><span class="line"><span class="comment"># Bilateral Blurring</span></span><br><span class="line">cv2.bilateralFilter(image, <span class="number">5</span>, <span class="number">21</span>, <span class="number">21</span>)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<blockquote>
<p>Traditionally, the median blur method has been most effective when removing salt-and-pepper noise. </p>
</blockquote>
<ol>
<li><p>Threshold</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(T, thresh) = cv2.threshold(blurred, <span class="number">155</span>, <span class="number">255</span>, cv2.THRESH_BINARY) </span><br><span class="line">cv2.imshow(<span class="string">"Threshold Binary"</span>, thresh) </span><br><span class="line">(T, threshInv) = cv2.threshold(blurred, <span class="number">155</span>, <span class="number">255</span>, cv2. THRESH_BINARY_INV)</span><br><span class="line">cv2.bitwise_and(image, image, mask = threshInv)</span><br></pre></td></tr></table></figure>
</li>
<li><p>边缘检测</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">image = cv2.imread(img)</span><br><span class="line">image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</span><br><span class="line">image = cv2.GaussianBlur(image, (<span class="number">5</span>,<span class="number">5</span>), <span class="number">0</span>)</span><br><span class="line">canny = cv2.Canny(image, <span class="number">30</span> ,<span class="number">150</span>)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p><img src="/qnsource/images/2018-03-05-读书笔记：《Practical-Python-and-OpenCV》/canny.jpg" alt="canny"></p>
<ol>
<li><p>轮廓检测</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">image = cv2.imread(img)</span><br><span class="line">image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</span><br><span class="line">image = cv2.GaussianBlur(image, (<span class="number">11</span>,<span class="number">11</span>), <span class="number">0</span>)</span><br><span class="line">canny = cv2.Canny(image, <span class="number">30</span> ,<span class="number">150</span>)</span><br><span class="line">(_, cnts, _) = cv2.findContours(canny.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)</span><br><span class="line">print(<span class="string">"I count &#123;&#125; coins in this image"</span>.format(len(cnts)))</span><br><span class="line">coins = image.copy()</span><br><span class="line">cv2.drawContours(coins, cnts, <span class="number">-1</span>, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">255</span>), <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/qnsource/images/2018-03-05-读书笔记：《Practical-Python-and-OpenCV》/countours.jpg" alt="countours"></p>
<ul>
<li>从图像中将对象扣取</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Now, let's loop over each contour</span></span><br><span class="line"><span class="keyword">for</span> (i, c) <span class="keyword">in</span> enumerate(cnts):</span><br><span class="line">	<span class="comment"># We can compute the 'bounding box' for each contour, which is the rectangle that encloses the contour</span></span><br><span class="line">	(x, y, w, h) = cv2.boundingRect(c)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># Now that we have the contour, let's extract it using array slices</span></span><br><span class="line">	print(<span class="string">"Coin #&#123;&#125;"</span>.format(i + <span class="number">1</span>))</span><br><span class="line">	coin = image[y:y + h, x:x + w]</span><br><span class="line">	cv2.imshow(<span class="string">"Coin"</span>, coin)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># Just for fun, let's construct a mask for the coin by finding The minumum enclosing circle of the contour</span></span><br><span class="line">	mask = np.zeros(image.shape[:<span class="number">2</span>], dtype = <span class="string">"uint8"</span>)</span><br><span class="line">	((centerX, centerY), radius) = cv2.minEnclosingCircle(c)</span><br><span class="line">	cv2.circle(mask, (int(centerX), int(centerY)), int(radius), <span class="number">255</span>, <span class="number">-1</span>)</span><br><span class="line">	mask = mask[y:y + h, x:x + w]</span><br><span class="line">	cv2.imshow(<span class="string">"Masked Coin"</span>, cv2.bitwise_and(coin, coin, mask = mask))</span><br><span class="line">	cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>​</p>
</li>
</ol>
<h2 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h2><ol>
<li><p>为解决python 2.7和python 3中<code>print</code>函数不兼容的问题，可通过导入如下命令解决在python 2.7环境运行python 3中<code>print</code>函数不兼容的问题：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br></pre></td></tr></table></figure>
</li>
<li><p>OpenCV存储RGB信息采用的逆向存储方式，即为BGR; <code>matplotlib.plot</code>中为<code>RGB</code></p>
</li>
<li><p><code>np.random</code></p>
</li>
</ol>
<div class="table-container">
<table>
<thead>
<tr>
<th>Method</th>
<th>Desription</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.rand.html#numpy.random.rand"><code>rand</code></a>(d0, d1, …, dn)</td>
<td>Random values in a given shape.</td>
</tr>
<tr>
<td><a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.randn.html#numpy.random.randn"><code>randn</code></a>(d0, d1, …, dn)</td>
<td>Return a sample (or samples) from the “standard normal” distribution.</td>
</tr>
<tr>
<td><a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.randint.html#numpy.random.randint"><code>randint</code></a>(low[, high, size, dtype])</td>
<td>Return random integers from <em>low</em> (inclusive) to <em>high</em> (exclusive).</td>
</tr>
<tr>
<td><a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.random_integers.html#numpy.random.random_integers"><code>random_integers</code></a>(low[, high, size])</td>
<td>Random integers of type np.int between <em>low</em> and <em>high</em>, inclusive.</td>
</tr>
<tr>
<td><a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.random_sample.html#numpy.random.random_sample"><code>random_sample</code></a>([size])</td>
<td>Return random floats in the half-open interval [0.0, 1.0).</td>
</tr>
<tr>
<td><strong>random([size])</strong></td>
<td>Return random floats in the half-open interval [0.0, 1.0).产生随机矩阵，如random.random([2,3])产生一个2x3维的随机数</td>
</tr>
<tr>
<td><a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.ranf.html#numpy.random.ranf">ranf</a>([size])</td>
<td>Return random floats in the half-open interval [0.0, 1.0).</td>
</tr>
<tr>
<td><a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.sample.html#numpy.random.sample"><code>sample</code></a>([size])</td>
<td>Return random floats in the half-open interval [0.0, 1.0).</td>
</tr>
<tr>
<td><strong>choice(a[, size, replace, p])</strong></td>
<td>Generates a random sample from a given 1-D array</td>
</tr>
<tr>
<td><a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.bytes.html#numpy.random.bytes"><code>bytes</code></a>(length)</td>
<td>Return random bytes.</td>
</tr>
</tbody>
</table>
</div>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                

                <time class="level-item has-text-grey" datetime="2018-03-04T07:35:01.000Z">2018-03-04</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/深度学习/">深度学习</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/深度学习/基础知识/">基础知识</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    11 分钟 读完 (大约 1609 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2018/03/04/深度学习基础之正则化/">深度学习基础之正则化</a>
            
        </h1>
        <div class="content">
            <p>明确任务目标和评价准则对于模型的设计及优化至关重要，本文将总结常用的相关方法和模型性能评价准则。为了简化，本文将主要针对回归问题和分类问题分别予以归纳，其它问题可采取类似的方法及手段。</p>
        </div>
        
        
        <hr style="height:1px;margin:1rem 0"/>
         <div class="level is-mobile is-flex">
         <div class="level-start">
          
          <div class="level-item is-size-7 is-uppercase">
           <i class="fas fa-tags has-text-grey"></i>&nbsp;
             <a class="has-link-grey -link" href="/tags/AI/">AI</a>,&nbsp;<a class="has-link-grey -link" href="/tags/人工智能/">人工智能</a>,&nbsp;<a class="has-link-grey -link" href="/tags/正则化/">正则化</a>
         </div>
         
         </div>

            <div class="level-start">
                <div class="level-item">
                <a class="button is-size-7 is-light" href="/2018/03/04/深度学习基础之正则化/#more">阅读更多</a>
                </div>
            </div>
        </div>
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                

                <time class="level-item has-text-grey" datetime="2018-03-03T14:12:49.000Z">2018-03-03</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/读书笔记/">读书笔记</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/读书笔记/机器视觉/">机器视觉</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    23 分钟 读完 (大约 3439 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2018/03/03/Deep-Learning-for-Computer-Vision/">Deep Learning for Computer Vision</a>
            
        </h1>
        <div class="content">
            <blockquote>
<p>本文记录深度学习书籍《Deep Learning for Computer Vision with Python》的读书笔记。</p>
</blockquote>
<!-- excerpt -->
<p>@toc</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><ul>
<li>深度学习拥有60多年历史，虽然曾经采用过不同的名称和不同的主导技术：“deep learning” has existed since the 1940s undergoing various name changes, including cybernetics, connectionism, and the most familiar, Artificial Neural Networks (ANNs).</li>
<li>神经网络的普适定律：Further research demonstrated that neural networks are universal approximators , capable of approximating any continuous function (but placing <strong>no guarantee</strong> on whether or not the network can actually learn the parameters required to represent a function).</li>
<li>Classic machine learning algorithms for <strong>unsupervised learning</strong> include Principle Component Analysis (PCA) and k-means clustering. Specific to neural networks, we see Autoencoders, Self-Organizing Maps (SOMs), and Adaptive Resonance Theory applied to unsupervised learning. </li>
<li>Popular choices for <strong>semisupervised learning</strong> include label spreading, label propagation, ladder networks, and co-learning/co-training.</li>
</ul>
<h2 id="Image-and-Pixels"><a href="#Image-and-Pixels" class="headerlink" title="Image and Pixels"></a>Image and Pixels</h2><ul>
<li>Pixels are represented in two ways:<ul>
<li>Grayscale: Each pixel is a scalar value between 0 and 255.（0 for “Black” and 255 for “White”），0—&gt;255 dark —&gt; light</li>
<li>Color: RGB color space, (R,G,B), Each Red, Green, and Blue channel can have values defined in the range [0,255] for a total of 256 “shades”, where 0 indicates no representation and 255 demonstrates full representation.</li>
</ul>
</li>
<li>Given that the pixel value only needs to be in the range [0,255], we normally use 8-bit unsigned integers to represent the intensity.</li>
</ul>
<h3 id="Images-as-Numpy-Arrays"><a href="#Images-as-Numpy-Arrays" class="headerlink" title="Images as Numpy Arrays"></a>Images as Numpy Arrays</h3><ul>
<li>(height, width, depth) 表示</li>
</ul>
<blockquote>
<p>height 排第一的主要原因是由于矩阵表示形式中，一般把行放在前面，而图像中height大小表征了行的数目。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">image = cv2.imread(<span class="string">"example.png"</span>) print(image.shape)</span><br><span class="line">cv2.imshow(<span class="string">"Image"</span>, image)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line"><span class="comment">## Access an individual pixel value</span></span><br><span class="line">(b, g, r) = image[<span class="number">20</span>, <span class="number">100</span>] <span class="comment"># accesses pixel at x=100, y=20</span></span><br></pre></td></tr></table></figure>
<blockquote>
<ol>
<li>取像素y在x前面，还是由于矩阵的表示形式；</li>
<li>RGB顺序反的，这是由于OpenCV历史原因导致的表示形式差异: Because the BGR ordering was popular among camera manufacturers and other software developers at the time.</li>
</ol>
</blockquote>
<h3 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h3><p><strong>aspect ratio</strong>: the ratio of the width to the height of the image.</p>
<p>神经网络模型一般都是固定输入，比如32×32, 64×64, 224×224, 227×227, 256×256, and 299×299. 需要对不同大小的图像进行reshape操作，For some datasets you can simply ignore the aspect ratio and squish, distort, and compress your images prior to feeding them through your network. On other datasets, it’s advantageous to preprocess them further by resizing along the shortest dimension and then cropping the center.</p>
<h2 id="Image-Classification"><a href="#Image-Classification" class="headerlink" title="Image Classification"></a>Image Classification</h2><p>图像分类和图像理解是当今技术视觉领域最火的课题。</p>
<h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p><strong>图像分类：</strong> the task of assigning a label to an image from a predefined set ofcategories.</p>
<blockquote>
<p>图像分类的过程是学习图片中的“underlying patterns”</p>
</blockquote>
<p><strong>Semantic Gap：</strong> the difference between how a human perceives the contents of an image versus how an image can be represented in a way a computer can understand the process.</p>
<h3 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h3><p><img src="/qnsource/images/2018-03-03-Deep-Learning-for-Computer-Vision/Challenge for Image Classification.png" alt="Challenge for Image Classification"></p>
<h3 id="数据集-TODO"><a href="#数据集-TODO" class="headerlink" title="数据集(TODO)"></a>数据集(TODO)</h3><ol>
<li><p>MNIST</p>
<ul>
<li><p><strong>目标：</strong> 完成0-9手写字符的识别</p>
</li>
<li><p><strong>说明：</strong></p>
<ul>
<li><code>NIST</code>代表<code>National Institute ofStandards and Technology</code>， <code>M</code>代表<code>Modified</code></li>
<li>深度学习的<code>Hello World</code></li>
<li>包含60,000训练样本，10,000测试样本，每个样本为28x28的灰度图像</li>
</ul>
</li>
<li><p><strong>目前准确度：</strong> &gt;99%</p>
</li>
<li><p><strong>获取地址：</strong> <a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a></p>
<p><img src="/qnsource/images/2018-03-03-Deep-Learning-for-Computer-Vision/MNIST.jpg" alt="MNIST"></p>
</li>
</ul>
</li>
<li><p>Fashion-MNIST</p>
<ul>
<li><p><strong>目标：</strong> 完成10种不同衣服的识别</p>
</li>
<li><p><strong>说明：</strong></p>
<ul>
<li>根据MNIST设计的新的数据集，难度比MNIST略高</li>
<li>包含60,000训练样本，10,000测试样本，每个样本为28x28的灰度图像</li>
</ul>
</li>
<li><p><strong>目前准确度：</strong> &gt;95%</p>
</li>
<li><p><strong>获取地址：</strong> <a href="https://github.com/zalandoresearch/fashion-mnist">https://github.com/zalandoresearch/fashion-mnist</a></p>
<p><img src="/qnsource/images/2018-03-03-Deep-Learning-for-Computer-Vision/Fashion-MNIST.png" alt="Fashion-MNIST"></p>
</li>
</ul>
</li>
<li><p>CIFAR-10</p>
</li>
<li><p>Animals： Dogs，Cat， Pandas</p>
</li>
<li><p>Flowers-17</p>
</li>
<li><p>CALtECH-101</p>
</li>
<li><p>Tiny ImageNet 200</p>
</li>
<li><p>Adience</p>
</li>
<li><p>ImageNet</p>
</li>
<li><p>表情识别(是否笑脸)</p>
<ul>
<li><strong>说明：</strong></li>
<li>共计13165张灰度图片，每张图片大小为64x64</li>
<li>分为笑脸和非笑脸两类，其中笑脸3690张，非笑脸9475张（数据不平衡）</li>
<li><strong>获取地址：</strong><a href="https://github.com/hromi/SMILEsmileD">https://github.com/hromi/SMILEsmileD</a></li>
<li>另外<a href="https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data">fer2013</a>提供了更多表情的训练用数据集</li>
</ul>
</li>
</ol>
<p><img src="/qnsource/images/2018-03-03-Deep-Learning-for-Computer-Vision/Smile Datasets.png" alt="Smile Datasets"></p>
<ol>
<li>性别和年龄数据集</li>
</ol>
<ul>
<li><p>IMDB-WIKI – 500k+ face images with age and gender labels</p>
<ul>
<li><p>获取地址： <a href="https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/">https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/</a></p>
<p><img src="https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/img/pipeline.png" alt="img"></p>
</li>
</ul>
</li>
</ul>
<ol>
<li><p>Indoor CVPR</p>
</li>
<li><p>Stanford Cars</p>
</li>
<li><p>…</p>
</li>
</ol>
<h2 id="神经网络基础"><a href="#神经网络基础" class="headerlink" title="神经网络基础"></a>神经网络基础</h2><h3 id="优化算法（TODO，整合到单独Note）"><a href="#优化算法（TODO，整合到单独Note）" class="headerlink" title="优化算法（TODO，整合到单独Note）"></a>优化算法（TODO，整合到单独Note）</h3><ul>
<li>Chapter 8</li>
</ul>
<h3 id="Regularization-TODO-整合到单独Note"><a href="#Regularization-TODO-整合到单独Note" class="headerlink" title="Regularization (TODO, 整合到单独Note)"></a>Regularization (TODO, 整合到单独Note)</h3><ul>
<li>Chapter 9</li>
<li>chapter 10,激活函数，perception</li>
</ul>
<h3 id="为什么验证损失函数值有时候小于训练损失函数"><a href="#为什么验证损失函数值有时候小于训练损失函数" class="headerlink" title="为什么验证损失函数值有时候小于训练损失函数"></a>为什么验证损失函数值有时候小于训练损失函数</h3><p>这可能是有几方面原因导致的，或多方面原因综合作用的结果，主要的原因包括：</p>
<ol>
<li>训练集和验证集分布不均，导致训练集数据难度大，验证集简单数据分布比例大；</li>
<li>数据放大本身形成了一种规则化，降低了训练集的训练结果；（这本身是规则化的目标，降低在训练集的表现，提升泛化性能）</li>
<li>训练时间或轮数不够；</li>
</ol>
<h3 id="关于学习率"><a href="#关于学习率" class="headerlink" title="关于学习率"></a>关于学习率</h3><ul>
<li><p>keras中提供了<code>decay</code>参数来调节学习率的变化情况：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">opt = SGD(lr=<span class="number">0.01</span>, decay=<span class="number">0.01</span> / <span class="number">40</span>, momentum=<span class="number">0.9</span>, nesterov=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>使用公式：</p>
<script type="math/tex; mode=display">
\alpha_{e+1} = \alpha_e \times 1 /(1+\gamma * e)</script></li>
<li><p>另一种学习率为阶梯学习率：<code>ctrl + c</code></p>
<p>Keras提供一个类：<code>LearningrateScheduler</code>来配置自定义的学习率函数</p>
<p>比如：</p>
<script type="math/tex; mode=display">
\alpha_{E+1} = \alpha_1 \times F^{(1+E)/D}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">step_decay</span><span class="params">(epoch)</span>:</span></span><br><span class="line">    <span class="comment"># initialize the base initial learning rate, drop factor, and epochs to drop every</span></span><br><span class="line">    initAlpha = <span class="number">0.01</span></span><br><span class="line">    factor = <span class="number">0.25</span></span><br><span class="line">    dropEvery = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute learning rate for the current epoch</span></span><br><span class="line">    alpha = initAlpha * (factor ** np.floor((<span class="number">1</span> + epoch) / dropEvery))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># return the learning rate</span></span><br><span class="line">    <span class="keyword">return</span> float(alpha)</span><br><span class="line">  </span><br><span class="line"><span class="comment">##定义callback</span></span><br><span class="line">callbacks = [LearningRateScheduler(step_decay)]</span><br></pre></td></tr></table></figure>
</li>
</ul>
<blockquote>
<p>当定义了学习率之后，SGD中声明的配置信息将被忽略</p>
</blockquote>
<h2 id="网络模型"><a href="#网络模型" class="headerlink" title="网络模型"></a>网络模型</h2><h3 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h3><ul>
<li>所有的卷积层使用同一种卷积核：3X3</li>
<li>堆积多个<code>CONV=&gt;RELU</code>层再进行一次<code>POOL</code>操作</li>
</ul>
<h3 id="MNIST"><a href="#MNIST" class="headerlink" title="MNIST"></a>MNIST</h3><p>Researchers tend to use the MNIST dataset as a benchmark to evaluate new classification algorithms. If their methods cannot obtain &gt; 95% classification accuracy, then there is either a flaw in (1) the logic of the algorithm or (2) the implementation itself.</p>
<h2 id="Case-Study"><a href="#Case-Study" class="headerlink" title="Case Study"></a>Case Study</h2><blockquote>
<p>使用OpenCV的Haar cascade 算法进行人脸检测，提取人脸的ROI(Region of intrest), 通过一个卷积神经网络进行表情识别；</p>
<p>可以结合Github开源的表情识别代码一起研究</p>
</blockquote>
<ul>
<li>路径处理 <code>os.path.sep</code>： 提取路径分隔符</li>
<li>数据不平衡的处理，可以考虑不同分类的权重，在训练时通过赋权调整平衡性，代码如下：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Handle data imbalance</span></span><br><span class="line"><span class="comment"># account for skew in the labeled data</span></span><br><span class="line">classTotals = labels.sum(axis=<span class="number">0</span>)</span><br><span class="line">classWeight = classTotals.max() / classTotals</span><br><span class="line"></span><br><span class="line"><span class="comment">## When training</span></span><br><span class="line">H = model.fit(trainX, trainY, validation_data=(testX, testY),</span><br><span class="line">    class_weight=classWeight, batch_size=<span class="number">64</span>, epochs=<span class="number">15</span>, verbose=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h3 id="手写字的预处理"><a href="#手写字的预处理" class="headerlink" title="手写字的预处理"></a>手写字的预处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span><span class="params">(image, width, height)</span>:</span></span><br><span class="line">    <span class="comment">#grap the dimensions of the image, then initialize the padding values</span></span><br><span class="line">    (h, w) = image.shape[:<span class="number">2</span>]</span><br><span class="line">    <span class="comment">#if width greater than height, resize along the width</span></span><br><span class="line">    <span class="keyword">if</span> w &gt; h:</span><br><span class="line">        image = imutils.resize(iamge, width=width)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        image = imutils.resize(image, height=height)</span><br><span class="line">    <span class="comment">#padding values for w and h to obtain the target dimensions</span></span><br><span class="line">    padW = int((width - image.shape[<span class="number">1</span>])/<span class="number">2.0</span>)</span><br><span class="line">    padH = int((height - image.shape[<span class="number">0</span>])/<span class="number">2.0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#pad the image then apply one more resizing to handle any rounding issues</span></span><br><span class="line">    image = cv2.copyMakeBorder(image, padH, padH, padW, padW, cv2.BORDER_REPLICATE)</span><br><span class="line">    iamge = cv2.resize(image, (width, height))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line">image = cv2.imread(img)</span><br><span class="line">gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</span><br><span class="line">gray = cv2.copyMakeBorder(gray, <span class="number">20</span>,<span class="number">20</span>,<span class="number">20</span>,<span class="number">20</span>, cv2.BORDER_REPLICATE)</span><br><span class="line"><span class="comment"># threshold the image to reveal the digits</span></span><br><span class="line">thresh = cv2.threshold(gray, <span class="number">0</span>, <span class="number">255</span>, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[<span class="number">1</span>]</span><br><span class="line"><span class="comment">#find contours in the image, keeping only the four largest ones</span></span><br><span class="line">cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)</span><br><span class="line">cnts = cnts[<span class="number">0</span>] <span class="keyword">if</span> imutils.is_cv2() <span class="keyword">else</span> cnts[<span class="number">1</span>]</span><br><span class="line">cnts = sorted(cnts, key=cv2.contourArea, reverse=<span class="keyword">True</span>)[:<span class="number">4</span>]</span><br><span class="line">cnts = contours.sort_contours(cnts)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># initialize the output image as a "grayscale" image with 3</span></span><br><span class="line"><span class="comment"># channels along with the output predictions</span></span><br><span class="line">output = cv2.merge([gray] * <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> cnts:</span><br><span class="line">    <span class="comment"># compute the bounding box for the contour then extract the</span></span><br><span class="line">    <span class="comment"># digit</span></span><br><span class="line">    (x, y, w, h) = cv2.boundingRect(c)</span><br><span class="line">    roi = gray[y - <span class="number">5</span>:y + h + <span class="number">5</span>, x - <span class="number">5</span>:x + w + <span class="number">5</span>] </span><br><span class="line">    roi = preprocess(roi, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">    roi = np.expand_dims(img_to_array(roi), axis=<span class="number">0</span>) / <span class="number">255.0</span></span><br><span class="line">    <span class="comment">#pred = model.predict(roi).argmax(axis=1)[0] + 1</span></span><br><span class="line">    <span class="comment">#predictions.append(str(pred))</span></span><br><span class="line">    <span class="comment"># draw the prediction on the output image</span></span><br><span class="line">    cv2.rectangle(output, (x - <span class="number">2</span>, y - <span class="number">2</span>),(x + w + <span class="number">4</span>, y + h + <span class="number">4</span>), (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">1</span>)</span><br><span class="line">    <span class="comment">#cv2.putText(output, str(pred), (x - 5, y - 5),cv2.FONT_HERSHEY_SIMPLEX, 0.55, (0, 255, 0), 2)</span></span><br><span class="line"><span class="comment"># show the output image</span></span><br><span class="line"><span class="comment">#print("[INFO] captcha: &#123;&#125;".format("".join(predictions)))</span></span><br><span class="line"></span><br><span class="line">plt.imshow(output)</span><br><span class="line"><span class="comment">#cv2.waitKey()</span></span><br></pre></td></tr></table></figure>
<h2 id="Useful-Functions"><a href="#Useful-Functions" class="headerlink" title="Useful Functions"></a>Useful Functions</h2><h3 id="图像预处理及加载模板"><a href="#图像预处理及加载模板" class="headerlink" title="图像预处理及加载模板"></a>图像预处理及加载模板</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">File1: Preprocessor</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimplePreporcessor</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, width, height, inter=cv2.INTER_AREA)</span>：</span></span><br><span class="line">        # store the target image width, height, and interpolation method used when resizing</span><br><span class="line">        self.width = width</span><br><span class="line">        self.height = height</span><br><span class="line">        self.inter = inter</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">preprocess</span><span class="params">(self, image)</span>:</span></span><br><span class="line">        <span class="comment"># resize the image to a fixed size, ignoring the aspect ratio</span></span><br><span class="line">        <span class="keyword">return</span> cv2.resize(image, (self.width, self.height), interpolation = self.inter)</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Data Loader</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="comment"># import the necessary packages </span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> cv2 </span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleDatasetLoader</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, preprocessors=None)</span>:</span></span><br><span class="line">        self.preprocessors = preprocessors</span><br><span class="line">        <span class="comment"># if the preprocessors are None, initialize them as an empty list</span></span><br><span class="line">        <span class="keyword">if</span> self.preprocessors <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            self.preprocessors = []</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load</span><span class="params">(self, imagePaths, verbose =<span class="number">-1</span>)</span>:</span></span><br><span class="line">        data = []</span><br><span class="line">        labels = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (i, imagePath) <span class="keyword">in</span> enumerate(imagePaths):</span><br><span class="line">           <span class="comment"># load the image and extract the class label assuming </span></span><br><span class="line">           <span class="comment"># # that our path has the following format: </span></span><br><span class="line">           <span class="comment"># # /path/to/dataset/&#123;class&#125;/&#123;image&#125;.jpg   </span></span><br><span class="line">           image = cv2.imread(imagePath)</span><br><span class="line">           label = imagePath.split(os.path.sep)[<span class="number">-2</span>]</span><br><span class="line"></span><br><span class="line">           <span class="comment"># check to see if our preprocessors are not None</span></span><br><span class="line">           <span class="keyword">if</span> self.preprocessors <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">               <span class="keyword">for</span> p <span class="keyword">in</span> self.preprocessors:</span><br><span class="line">                   image = p.preprocess(image)</span><br><span class="line">            </span><br><span class="line">            data.append(image)</span><br><span class="line">            labels.append(label)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># show an update every ‘verbose‘ images</span></span><br><span class="line">            <span class="keyword">if</span> verbose &gt;<span class="number">0</span> <span class="keyword">and</span> i &gt;<span class="number">0</span> <span class="keyword">and</span> (i+<span class="number">1</span>)%verbose == <span class="number">0</span>:</span><br><span class="line">                print(<span class="string">"[INFON] process &#123;&#125;/&#123;&#125;"</span>).format(i+<span class="number">1</span>,len(imagePaths))</span><br><span class="line">        <span class="comment"># return a tuple of the data and labels</span></span><br><span class="line">        <span class="keyword">return</span> (np.array(data), np.array(labels))</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Main</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="comment"># import the necessary packages</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier </span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder </span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split </span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="keyword">from</span> imutils <span class="keyword">import</span> paths </span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line"><span class="comment"># construct the argument parse and parse the arguments ap = argparse.ArgumentParser()</span></span><br><span class="line">ap.add_argument(<span class="string">"-d"</span>, <span class="string">"--dataset"</span>, required=<span class="keyword">True</span>, help=<span class="string">"path to input dataset"</span>)</span><br><span class="line">ap.add_argument(<span class="string">"-k"</span>, <span class="string">"--neighbors"</span>, type=int, default=<span class="number">1</span>, help=<span class="string">"# of nearest neighbors for classification"</span>)</span><br><span class="line"> ap.add_argument(<span class="string">"-j"</span>, <span class="string">"--jobs"</span>, type=int, default=<span class="number">-1</span>, help=<span class="string">"# of jobs for k-NN distance (-1 uses all available cores)"</span>)</span><br><span class="line">args = vars(ap.parse_args())</span><br><span class="line"></span><br><span class="line">print(<span class="string">"[INFO] loading images ..."</span>)</span><br><span class="line">imagePaths = list(paths.list_images(args[<span class="string">"dataset"</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># initialize the image preprocessor, load the dataset from disk,</span></span><br><span class="line"><span class="comment"># and reshape the data matrix</span></span><br><span class="line">sp = SimplePreporcessor(<span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">sdl = SimpleDatasetLoader(preprocessors=[sp])</span><br><span class="line"></span><br><span class="line">(data, labels) = sdl.load(imagePaths, verbose=<span class="number">500</span>)</span><br><span class="line"><span class="comment">#flatten for use in KNN</span></span><br><span class="line">data = data.reshape((data.shape[<span class="number">0</span>],<span class="number">32</span>*<span class="number">32</span>*<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">print(<span class="string">"[INFO] feature matrix: &#123;:.1f&#125;MB"</span>).format(data.nbytes/(<span class="number">1024</span>*<span class="number">1000.0</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># encode the labels as integers</span></span><br><span class="line">le = LabelEncoder()</span><br><span class="line">labels = le.fit_transform(labels)</span><br><span class="line"></span><br><span class="line">(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=<span class="number">0.25</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># train and evaluate a kNN classifier on raw pixel intensities</span></span><br><span class="line">print(<span class="string">"[INFO] evaluate kNN classifier ..."</span>)</span><br><span class="line">model = KNeighborsClassifier(n_neighbors=args[<span class="string">"neighbors"</span>]), n_jobs=args[<span class="string">"jobs"</span>])</span><br><span class="line">model.fit(trainX, trainY)</span><br><span class="line">print(classification_report(testY, model.predict(testX),target_names==le.classes_))</span><br></pre></td></tr></table></figure>
<h3 id="sklearn-metrics-classification-report"><a href="#sklearn-metrics-classification-report" class="headerlink" title="sklearn.metrics.classification_report"></a><code>sklearn.metrics.classification_report</code></h3><p>sklearn中的classification_report函数用于显示主要分类指标的文本报告．在报告中显示每个类的精确度，召回率，F1值等信息。<br><strong>主要参数:</strong> </p>
<ul>
<li>y_true：1维数组，或标签指示器数组/稀疏矩阵，目标值。 </li>
<li>y_pred：1维数组，或标签指示器数组/稀疏矩阵，分类器返回的估计值。 </li>
<li>labels：array，shape = [n_labels]，报表中包含的标签索引的可选列表。 </li>
<li>target_names：字符串列表，与标签匹配的可选显示名称（相同顺序）。 </li>
<li>sample_weight：类似于shape = [n_samples]的数组，可选项，样本权重。 </li>
<li>digits：int，输出浮点值的位数．</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line">y_true = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>]</span><br><span class="line">y_pred = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>]</span><br><span class="line">target_names = [<span class="string">'class 0'</span>, <span class="string">'class 1'</span>, <span class="string">'class 2'</span>]</span><br><span class="line">print(classification_report(y_true, y_pred, target_names=target_names))</span><br></pre></td></tr></table></figure>
<h3 id="opencv-给图像添加描述"><a href="#opencv-给图像添加描述" class="headerlink" title="opencv 给图像添加描述"></a>opencv 给图像添加描述</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># draw the label with the highest score on the image as our # prediction</span></span><br><span class="line">cv2.putText(orig, <span class="string">"Label: &#123;&#125;"</span>.format(labels[np.argmax(scores)]), (<span class="number">10</span>, <span class="number">30</span>), cv2.FONT_HERSHEY_SIMPLEX, <span class="number">0.9</span>, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<h3 id="Keras中的Checkpoint机制"><a href="#Keras中的Checkpoint机制" class="headerlink" title="Keras中的Checkpoint机制"></a>Keras中的Checkpoint机制</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</span><br><span class="line"></span><br><span class="line"><span class="comment"># construct the callback to save only the *best* model to disk</span></span><br><span class="line"><span class="comment"># based on the validation loss</span></span><br><span class="line">fname = os.path.sep.join([args[<span class="string">"weights"</span>],</span><br><span class="line">	<span class="string">"weights-&#123;epoch:03d&#125;-&#123;val_loss:.4f&#125;.hdf5"</span>])</span><br><span class="line">checkpoint = ModelCheckpoint(fname, monitor=<span class="string">"val_loss"</span>, mode=<span class="string">"min"</span>,</span><br><span class="line">	save_best_only=<span class="keyword">True</span>, verbose=<span class="number">1</span>)</span><br><span class="line">callbacks = [checkpoint]</span><br><span class="line"></span><br><span class="line">print(<span class="string">"[INFO] training network..."</span>)</span><br><span class="line">H = model.fit(trainX, trainY, validation_data=(testX, testY),</span><br><span class="line">	batch_size=<span class="number">64</span>, epochs=<span class="number">40</span>, callbacks=callbacks, verbose=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p><strong>参数：</strong></p>
<ul>
<li>filename：字符串，保存模型的路径</li>
<li>monitor：需要监视的值</li>
<li>verbose：信息展示模式，0或1</li>
<li>save_best_only：当设置为<code>True</code>时，将只保存在验证集上性能最好的模型</li>
<li>mode：‘auto’，‘min’，‘max’之一，在<code>save_best_only=True</code>时决定性能最佳模型的评判准则，例如，当监测值为<code>val_acc</code>时，模式应为<code>max</code>，当检测值为<code>val_loss</code>时，模式应为<code>min</code>。在<code>auto</code>模式下，评价准则由被监测值的名字自动推断。</li>
<li>save_weights_only：若设置为True，则只保存模型权重，否则将保存整个模型（包括模型结构，配置信息等）</li>
<li>period：CheckPoint之间的间隔的epoch数</li>
</ul>
<blockquote>
<ol>
<li>可以monitor loss值也可以是val_acc，train_loss, train_acc;</li>
<li>更多内容参见：<a href="http://keras-cn.readthedocs.io/en/latest/other/callbacks/">http://keras-cn.readthedocs.io/en/latest/other/callbacks/</a></li>
</ol>
</blockquote>
<h3 id="EarlyStopping"><a href="#EarlyStopping" class="headerlink" title="EarlyStopping"></a>EarlyStopping</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.callbacks.EarlyStopping(monitor=<span class="string">'val_loss'</span>, patience=<span class="number">0</span>, verbose=<span class="number">0</span>, mode=<span class="string">'auto'</span>)</span><br></pre></td></tr></table></figure>
<p>当监测值不再改善时，该回调函数将中止训练</p>
<p><strong>参数</strong></p>
<ul>
<li>monitor：需要监视的量</li>
<li>patience：当early stop被激活（如发现loss相比上一个epoch训练没有下降），则经过<code>patience</code>个epoch后停止训练。</li>
<li>verbose：信息展示模式</li>
<li>mode：‘auto’，‘min’，‘max’之一，在<code>min</code>模式下，如果检测值停止下降则中止训练。在<code>max</code>模式下，当检测值不再上升则停止训练。</li>
</ul>
<h3 id="基于keras-callback实现训练过程监控"><a href="#基于keras-callback实现训练过程监控" class="headerlink" title="基于keras callback实现训练过程监控"></a>基于keras callback实现训练过程监控</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import the necessary packages</span></span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> BaseLogger</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TrainingMonitor</span><span class="params">(BaseLogger)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, figPath, jsonPath=None, startAt=<span class="number">0</span>)</span>:</span></span><br><span class="line">        <span class="comment"># store the output path for the figure, the path to the JSON serialized file, and the starting epoch</span></span><br><span class="line">        super(TrainingMonitor, self).__init__()</span><br><span class="line">        self.figPath = figPath</span><br><span class="line">        self.jsonPath = jsonPath</span><br><span class="line">        self.startAt = startAt</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_train_begin</span><span class="params">(self, logs=&#123;&#125;)</span>:</span></span><br><span class="line">        <span class="comment"># initialize the history dictionary</span></span><br><span class="line">        self.H = &#123;&#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># if the JSON history path exists, load the training history</span></span><br><span class="line">        <span class="keyword">if</span> self.jsonPath <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">if</span> os.path.exists(self.jsonPath):</span><br><span class="line">                self.H = json.loads(open(self.jsonPath).read())</span><br><span class="line"></span><br><span class="line">                <span class="comment"># check to see if a starting epoch was supplied</span></span><br><span class="line">                <span class="keyword">if</span> self.startAt &gt; <span class="number">0</span>:</span><br><span class="line">                    <span class="comment"># loop over the entries in the history log and</span></span><br><span class="line">                    <span class="comment"># trim any entries that are past the starting</span></span><br><span class="line">                    <span class="comment"># epoch</span></span><br><span class="line">                    <span class="keyword">for</span> k <span class="keyword">in</span> self.H.keys():</span><br><span class="line">                        self.H[k] = self.H[k][:self.startAt]</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_epoch_end</span><span class="params">(self, epoch, logs=&#123;&#125;)</span>:</span></span><br><span class="line">        <span class="comment"># loop over the logs and update the loss, accuracy, etc.</span></span><br><span class="line">        <span class="comment"># for the entire training process</span></span><br><span class="line">        <span class="keyword">for</span> (k, v) <span class="keyword">in</span> logs.items():</span><br><span class="line">            l = self.H.get(k, [])</span><br><span class="line">            l.append(v)</span><br><span class="line">            self.H[k] = l</span><br><span class="line">        <span class="comment"># check to see if the training history should be serialized</span></span><br><span class="line">        <span class="comment"># to file</span></span><br><span class="line">        <span class="keyword">if</span> self.jsonPath <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            f = open(self.jsonPath, <span class="string">"w"</span>)</span><br><span class="line">            f.write(json.dumps(self.H))</span><br><span class="line">            f.close()</span><br><span class="line">        <span class="comment"># ensure at least two epochs have passed before plotting</span></span><br><span class="line">        <span class="comment"># (epoch starts at zero)</span></span><br><span class="line">        <span class="keyword">if</span> len(self.H[<span class="string">"loss"</span>]) &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="comment">#plot the training loss and accuracy</span></span><br><span class="line">            N = np.arange(<span class="number">0</span>, len(self.H[<span class="string">"loss"</span>]))</span><br><span class="line">            plt.style.use(<span class="string">"ggplot"</span>)</span><br><span class="line">            plt.figure()</span><br><span class="line">            plt.plot(N, self.H[<span class="string">"loss"</span>], label=<span class="string">"train_loss"</span>)</span><br><span class="line">            plt.plot(N, self.H[<span class="string">"val_loss"</span>], label=<span class="string">"val_loss"</span>)</span><br><span class="line">            plt.plot(N, self.H[<span class="string">"acc"</span>], label=<span class="string">"train_acc"</span>)</span><br><span class="line">            plt.plot(N, self.H[<span class="string">"val_acc"</span>], label=<span class="string">"val_acc"</span>)</span><br><span class="line">            plt.title(<span class="string">"Training Loss and Accuracy [Epoch &#123;&#125;]"</span>.format(len(self.H[<span class="string">"loss"</span>])))</span><br><span class="line">            plt.xlabel(<span class="string">"Epoch #"</span>)</span><br><span class="line">            plt.ylabel(<span class="string">"Loss/Accuracy"</span>)</span><br><span class="line">            plt.legend()</span><br><span class="line"></span><br><span class="line">            <span class="comment">#save the figure</span></span><br><span class="line">            plt.savefig(self.figPath)</span><br><span class="line">            plt.close()</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>figPath: The path to the output plot that we can use to visualize loss and accuracy over time.</li>
<li>jsonPath: An optional path used to serialize the loss and accuracy values as a JSON file. This path is useful if you want to use the training history to create custom plots of your own.</li>
<li>startAt: This is the starting epoch that training is resumed at when using ctrl + c training.</li>
</ul>
</blockquote>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2>
        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                

                <time class="level-item has-text-grey" datetime="2018-03-02T07:35:01.000Z">2018-03-02</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/深度学习/">深度学习</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/深度学习/基础知识/">基础知识</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    40 分钟 读完 (大约 6064 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2018/03/02/深度学习基础之目标及评估/">深度学习基础之目标及评估</a>
            
        </h1>
        <div class="content">
            <p>明确任务目标和评价准则对于模型的设计及优化至关重要，本文将总结常用的相关方法和模型性能评价准则。为了简化，本文将主要针对回归问题和分类问题分别予以归纳，其它问题可采取类似的方法及手段。</p>
        </div>
        
        
        <hr style="height:1px;margin:1rem 0"/>
         <div class="level is-mobile is-flex">
         <div class="level-start">
          
          <div class="level-item is-size-7 is-uppercase">
           <i class="fas fa-tags has-text-grey"></i>&nbsp;
             <a class="has-link-grey -link" href="/tags/AI/">AI</a>,&nbsp;<a class="has-link-grey -link" href="/tags/人工智能/">人工智能</a>,&nbsp;<a class="has-link-grey -link" href="/tags/预处理/">预处理</a>
         </div>
         
         </div>

            <div class="level-start">
                <div class="level-item">
                <a class="button is-size-7 is-light" href="/2018/03/02/深度学习基础之目标及评估/#more">阅读更多</a>
                </div>
            </div>
        </div>
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                

                <time class="level-item has-text-grey" datetime="2018-03-01T08:02:01.000Z">2018-03-01</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/深度学习/">深度学习</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/深度学习/基础知识/">基础知识</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    6 分钟 读完 (大约 974 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2018/03/01/深度学习基础之模型压缩/">深度学习基础之模型压缩</a>
            
        </h1>
        <div class="content">
            <p>深度学习中模型压缩关键技术总结。</p>
<!-- excerpt -->
<blockquote>
<p>深度学习基础篇将从几个不同的层面来总结在过去一段时间对于深度学习关键技术的理解，通过知识体系的归纳了解知识体系的不足，提升对核心技术点的认识。所有系列文章将在未来一段时间内容随着掌握了解的深入迭代更新。目前主要希望对如下几个领域进行归纳汇总：</p>
<ol>
<li>问题定义</li>
<li>目标及评估</li>
<li>数据准备与预处理</li>
<li>激活函数的归纳及总结</li>
<li>优化算法的归纳及总结</li>
<li>正则化与泛化性能</li>
<li><strong>模型压缩</strong></li>
<li>数据扩充</li>
</ol>
</blockquote>
<p>为了增加深度学习模型的容量，往往包含了大量的待训练参数和模型规模，以VGG-16为例，参数数目为1亿3千万，占用空间500MB，如果利用VGG-16进行一次图片识别任务，需要进行309亿次的浮点运算（FLOPs）。如此大的模型体积和对算力的依赖，为深度学习模型迁移到嵌入式设备或者利用CPU进行推理带来了很大的难度，为此通过合理的模型压缩技术在保证模型性能没有明显下降的情况下降低模型体积和参数数目成为一个热点的研究问题。</p>
<p>同时，研究发现深度神经网络面临严峻的过参数化问题，需要注意的是，这种冗余在模型训练阶段是十分必要的。因为深度神经网络面临的是一个极其复杂的非凸优化问题，对于现有的基于梯度下降的优化算法而言，这种参数上的冗余保证了网络能够收敛到一个比较好的最优值。因而在一定程度上，网络越深，参数越多，模型越复杂，其最终的效果也往往越好。</p>
<p>按照压缩过程对网络结构的破坏程度，我们将模型压缩技术分为“前端压缩”与“后端压缩”两部分。所谓“前端压缩”，是指不改变原网络结构的压缩技术，主要包括知识蒸馏、紧凑的模型结构设计以及滤波器层面的剪枝等；而“后端压缩”则包括低秩近似、未加限制的剪枝、参数量化以及二值网络等，其目标在于尽可能地减少模型大小，因而会对原始网络结构造成极大程度的改造。其中，由于“前端压缩”未改变原有的网络结构，仅仅只是在原模型的基础上减少了网络的层数或者滤波器的个数，其最终的模型可完美适配现有的深度学习库。相比之下，“后端压缩”为了追求极致的压缩比，不得不对原有的网络结构进行改造，如对参数进行量化表示等，而这样的改造往往是不可逆的。同时，为了获得理想的压缩效果，必须开发相配套的运行库，甚至是专门的硬件设备，其最终的结果往往是一种压缩技术对应于一套运行库，从而带来了巨大的维护成本。</p>
<h2 id="剪枝与稀疏约束"><a href="#剪枝与稀疏约束" class="headerlink" title="剪枝与稀疏约束"></a>剪枝与稀疏约束</h2><h2 id="知识蒸馏"><a href="#知识蒸馏" class="headerlink" title="知识蒸馏"></a>知识蒸馏</h2><h2 id="参数量化"><a href="#参数量化" class="headerlink" title="参数量化"></a>参数量化</h2><h2 id="二值网络"><a href="#二值网络" class="headerlink" title="二值网络"></a>二值网络</h2><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a href="http://lamda.nju.edu.cn/weixs/book/CNN_book.html">《解析卷积神经网络—深度学习实践手册》</a></li>
<li><a href="https://keras.io/">Keras文档</a></li>
</ol>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                

                <time class="level-item has-text-grey" datetime="2018-03-01T06:35:01.000Z">2018-03-01</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/深度学习/">深度学习</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/深度学习/基础知识/">基础知识</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    17 分钟 读完 (大约 2595 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2018/03/01/深度学习基础之数据预处理/">深度学习基础之数据准备与预处理</a>
            
        </h1>
        <div class="content">
            <p>由于人工智能面向的应用和场景的多样性，导致需要分析的数据无论是从维度还是格式上都存在巨大差异，数据准备阶段需要解决数据的数值化、归一化、特征工程等共性的问题。</p>
<!-- excerpt -->
<blockquote>
<p>深度学习基础篇将从几个不同的层面来总结在过去一段时间对于深度学习关键技术的理解，通过知识体系的归纳了解知识体系的不足，提升对核心技术点的认识。所有系列文章将在未来一段时间内容随着掌握了解的深入迭代更新。目前主要希望对如下几个领域进行归纳汇总：</p>
<ol>
<li>问题定义</li>
<li>目标及评估</li>
<li><strong>数据准备与预处理</strong></li>
<li>激活函数的归纳及总结</li>
<li>优化算法的归纳及总结</li>
<li>正则化与泛化性能</li>
<li>模型压缩</li>
<li>数据扩充</li>
</ol>
</blockquote>
<p>由于人工智能面向的应用和场景的多样性，导致需要分析的数据无论是从维度还是格式上都存在巨大差异，数据准备阶段需要解决数据的数值化、归一化、特征工程等共性的问题。</p>
<p>深度学习的端到端学习能力并不意味着在实际的业务处理中把原始数据直接丢进网络模型，与传统的机器学习技术类似必要的数据预处理工作无论是对于提升模型的收敛效率还是提升模型的训练质量都具备十分重要的意义。</p>
<h2 id="数值化"><a href="#数值化" class="headerlink" title="数值化"></a>数值化</h2><p>由于神经网络的输入限定为数值数据，所以对于字符串数据、文本数据、类别数据，在导入网络模型之前需要进行数值化处理，转换为数值数据。其中类别数据可以采用one-hot编码等方式进行编码。</p>
<h2 id="数据归一化"><a href="#数据归一化" class="headerlink" title="数据归一化"></a>数据归一化</h2><p>数据归一化是属于预处理阶段经常采用的一种手段。虽然这里有一系列可行的方法，但是这一步通常是根据数据的具体情况而明确选择的。特征归一化常用的方法包含如下几种：</p>
<ul>
<li>简单缩放</li>
<li>逐样本均值消减(也称为移除直流分量)</li>
<li>特征标准化(使数据集中所有特征都具有零均值和单位方差)</li>
</ul>
<h3 id="简单缩放"><a href="#简单缩放" class="headerlink" title="简单缩放"></a>简单缩放</h3><p>在简单缩放中，我们的目的是通过对数据的每一个维度的值进行重新调节（这些维度可能是相互独立的），使得最终的数据向量落在 [0,1]或[ − 1,1] 的区间内（根据数据情况而定）。这对后续的处理十分重要，因为很多<em>默认</em>参数（如 PCA-白化中的 epsilon）都假定数据已被缩放到合理区间。</p>
<p><strong>例子:</strong>在处理自然图像时，我们获得的像素值在 [0,255] 区间中，常用的处理是将这些像素值除以 255，使它们缩放到 [0,1] 中.</p>
<h3 id="逐样本均值消减"><a href="#逐样本均值消减" class="headerlink" title="逐样本均值消减"></a>逐样本均值消减</h3><p>如果你的数据是<em>平稳</em>的（即数据每一个维度的统计都服从相同分布），那么你可以考虑在每个样本上减去数据的统计平均值(逐样本计算)。</p>
<p><strong>例子：</strong>对于图像，这种归一化可以移除图像的平均亮度值 (intensity)。很多情况下我们对图像的照度并不感兴趣，而更多地关注其内容，这时对每个数据点移除像素的均值是有意义的。<strong>注意：</strong>虽然该方法广泛地应用于图像，但在处理彩色图像时需要格外小心，具体来说，是因为不同色彩通道中的像素并不都存在平稳特性。</p>
<h3 id="特征标准化"><a href="#特征标准化" class="headerlink" title="特征标准化"></a>特征标准化</h3><p>特征标准化指的是（独立地）使得数据的每一个维度具有零均值和单位方差。这是归一化中最常见的方法并被广泛地使用（例如，在使用支持向量机（SVM）时，特征标准化常被建议用作预处理的一部分）。在实际应用中，特征标准化的具体做法是：首先计算每一个维度上数据的均值（使用全体数据计算），之后在每一个维度上都减去该均值。下一步便是在数据的每一维度上除以该维度上数据的标准差。</p>
<p><strong>例子</strong>:处理音频数据时，常用 Mel 倒频系数 <a href="http://en.wikipedia.org/wiki/Mel-frequency_cepstrum">MFCCs</a> 来表征数据。然而MFCC特征的第一个分量（表示直流分量）数值太大，常常会掩盖其他分量。这种情况下，为了平衡各个分量的影响，通常对特征的每个分量独立地使用标准化处理。</p>
<p><strong>原理：</strong> 在每个样本中减去数据的统计平均值，可以移除数据的共同部分，凸显个体差异。</p>
<blockquote>
<p><strong>注意：</strong></p>
<p>数据归一化中采取的统计平均值和均方差值都来源于训练数据，由于理论上不应该从验证集和测试集中获取信息，所以对于验证集和测试集的处理也使用训练集的结果。</p>
</blockquote>
<h2 id="标准流程"><a href="#标准流程" class="headerlink" title="标准流程"></a>标准流程</h2><p>在这一部分中，我们将介绍几种在一些数据集上有良好表现的预处理标准流程.</p>
<h3 id="自然灰度图像"><a href="#自然灰度图像" class="headerlink" title="自然灰度图像"></a>自然灰度图像</h3><p>灰度图像具有平稳特性，我们通常在第一步对每个数据样本分别做均值消减（即减去直流分量），然后采用 PCA/ZCA 白化处理，其中的 <code>epsilon</code> 要足够大以达到低通滤波的效果。</p>
<h3 id="彩色图像"><a href="#彩色图像" class="headerlink" title="彩色图像"></a>彩色图像</h3><p>对于彩色图像，色彩通道间并不存在平稳特性。因此我们通常首先对数据进行特征缩放（使像素值位于 [0,1] 区间），然后使用足够大的 <code>epsilon</code> 来做 PCA/ZCA。注意在进行 PCA 变换前需要对特征进行分量均值归零化。</p>
<h3 id="音频-MFCC-频谱图"><a href="#音频-MFCC-频谱图" class="headerlink" title="音频 (MFCC/频谱图)"></a>音频 (MFCC/频谱图)</h3><p>对于音频数据 (MFCC 和频谱图)，每一维度的取值范围（方差）不同。例如 MFCC 的第一分量是直流分量，通常其幅度远大于其他分量，尤其当特征中包含时域导数 (temporal derivatives) 时（这是音频处理中的常用方法）更是如此。因此，对这类数据的预处理通常从简单的数据标准化开始（即使得数据的每一维度均值为零、方差为 1），然后进行 PCA/ZCA 白化（使用合适的 <code>epsilon</code>）。</p>
<h3 id="MNIST-手写数字"><a href="#MNIST-手写数字" class="headerlink" title="MNIST 手写数字"></a>MNIST 手写数字</h3><p>MNIST 数据集的像素值在 [0,255] 区间中。我们首先将其缩放到 [0,1] 区间。实际上，进行逐样本均值消去也有助于特征学习。<em>注：也可选择以对 MNIST 进行 PCA/ZCA 白化，但这在实践中不常用。</em></p>
<h2 id="图像预处理"><a href="#图像预处理" class="headerlink" title="图像预处理"></a>图像预处理</h2><h3 id="Mean-Subtraction"><a href="#Mean-Subtraction" class="headerlink" title="Mean Subtraction"></a>Mean Subtraction</h3><blockquote>
<p>data normalization</p>
<p>目的：减少不同图片受光照变化的影响。</p>
</blockquote>
<script type="math/tex; mode=display">
R = R - \mu _R</script><script type="math/tex; mode=display">
G = G - \mu _G</script><script type="math/tex; mode=display">
B = B - \mu _B</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MeanPreprocessor</span>:</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, rMean, gMean, bMean)</span>:</span></span><br><span class="line">		<span class="comment"># store the Red, Green, and Blue channel averages across a</span></span><br><span class="line">		<span class="comment"># training set</span></span><br><span class="line">		self.rMean = rMean</span><br><span class="line">		self.gMean = gMean</span><br><span class="line">		self.bMean = bMean</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">preprocess</span><span class="params">(self, image)</span>:</span></span><br><span class="line">		<span class="comment"># split the image into its respective Red, Green, and Blue</span></span><br><span class="line">		<span class="comment"># channels</span></span><br><span class="line">		(B, G, R) = cv2.split(image.astype(<span class="string">"float32"</span>))</span><br><span class="line"></span><br><span class="line">		<span class="comment"># subtract the means for each channel</span></span><br><span class="line">		R -= self.rMean</span><br><span class="line">		G -= self.gMean</span><br><span class="line">		B -= self.bMean</span><br><span class="line"></span><br><span class="line">		<span class="comment"># merge the channels back together and return the image</span></span><br><span class="line">		<span class="keyword">return</span> cv2.merge([B, G, R])</span><br></pre></td></tr></table></figure>
<h3 id="Patch-Extraction"><a href="#Patch-Extraction" class="headerlink" title="Patch Extraction"></a>Patch Extraction</h3><blockquote>
<p>从原始图像中随机采样MxN的区域，当原始图像的稀疏度较高时可以采用该方法。</p>
<p>降低过拟合的概率</p>
<p>256x256 ===&gt; 227x227</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.image <span class="keyword">import</span> extract_patches_2d</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PatchPreprocessor</span>:</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, width, height)</span>:</span></span><br><span class="line">		<span class="comment"># store the target width and height of the image</span></span><br><span class="line">		self.width = width</span><br><span class="line">		self.height = height</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">preprocess</span><span class="params">(self, image)</span>:</span></span><br><span class="line">		<span class="comment"># extract a random crop from the image with the target width</span></span><br><span class="line">		<span class="comment"># and height</span></span><br><span class="line">		<span class="keyword">return</span> extract_patches_2d(image, (self.height, self.width),</span><br><span class="line">			max_patches=<span class="number">1</span>)[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<h3 id="Cropping-Over-Sampling"><a href="#Cropping-Over-Sampling" class="headerlink" title="Cropping(Over-Sampling)"></a>Cropping(Over-Sampling)</h3><blockquote>
<p>使用扣取方法可以从原始图像的四个角+中心位置进行扣取，实验证明该方法可以提升1-2个百分比的分类精度；</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CropPreprocessor</span>:</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, width, height, horiz=True, inter=cv2.INTER_AREA)</span>:</span></span><br><span class="line">		<span class="comment"># store the target image width, height, whether or not</span></span><br><span class="line">		<span class="comment"># horizontal flips should be included, along with the</span></span><br><span class="line">		<span class="comment"># interpolation method used when resizing</span></span><br><span class="line">		self.width = width</span><br><span class="line">		self.height = height</span><br><span class="line">		self.horiz = horiz</span><br><span class="line">		self.inter = inter</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">preprocess</span><span class="params">(self, image)</span>:</span></span><br><span class="line">		<span class="comment"># initialize the list of crops</span></span><br><span class="line">		crops = []</span><br><span class="line"></span><br><span class="line">		<span class="comment"># grab the width and height of the image then use these</span></span><br><span class="line">		<span class="comment"># dimensions to define the corners of the image based</span></span><br><span class="line">		(h, w) = image.shape[:<span class="number">2</span>]</span><br><span class="line">		coords = [</span><br><span class="line">			[<span class="number">0</span>, <span class="number">0</span>, self.width, self.height],</span><br><span class="line">			[w - self.width, <span class="number">0</span>, w, self.height],</span><br><span class="line">			[w - self.width, h - self.height, w, h],</span><br><span class="line">			[<span class="number">0</span>, h - self.height, self.width, h]]</span><br><span class="line"></span><br><span class="line">		<span class="comment"># compute the center crop of the image as well</span></span><br><span class="line">		dW = int(<span class="number">0.5</span> * (w - self.width))</span><br><span class="line">		dH = int(<span class="number">0.5</span> * (h - self.height))</span><br><span class="line">		coords.append([dW, dH, w - dW, h - dH])</span><br><span class="line"></span><br><span class="line">		<span class="comment"># loop over the coordinates, extract each of the crops,</span></span><br><span class="line">		<span class="comment"># and resize each of them to a fixed size</span></span><br><span class="line">		<span class="keyword">for</span> (startX, startY, endX, endY) <span class="keyword">in</span> coords:</span><br><span class="line">			crop = image[startY:endY, startX:endX]</span><br><span class="line">			crop = cv2.resize(crop, (self.width, self.height),</span><br><span class="line">				interpolation=self.inter)</span><br><span class="line">			crops.append(crop)</span><br><span class="line"></span><br><span class="line">		<span class="comment"># check to see if the horizontal flips should be taken</span></span><br><span class="line">		<span class="keyword">if</span> self.horiz:</span><br><span class="line">			<span class="comment"># compute the horizontal mirror flips for each crop</span></span><br><span class="line">			mirrors = [cv2.flip(c, <span class="number">1</span>) <span class="keyword">for</span> c <span class="keyword">in</span> crops]</span><br><span class="line">			crops.extend(mirrors)</span><br><span class="line"></span><br><span class="line">		<span class="comment"># return the set of crops</span></span><br><span class="line">		<span class="keyword">return</span> np.array(crops)</span><br></pre></td></tr></table></figure>
<h2 id="Keras中的数据预处理功能"><a href="#Keras中的数据预处理功能" class="headerlink" title="Keras中的数据预处理功能"></a>Keras中的数据预处理功能</h2><p><a href="http://keras-cn.readthedocs.io/en/latest/preprocessing/sequence/">http://keras-cn.readthedocs.io/en/latest/preprocessing/sequence/</a></p>
<p>A. 设置随机种子 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">1337</span>)  <span class="comment"># for reproducibility</span></span><br></pre></td></tr></table></figure>
<p>B. 输入数据维度规格化，这里每个样本只是size为784的一维数组。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_train = X_train.reshape(<span class="number">60000</span>, <span class="number">784</span>)</span><br></pre></td></tr></table></figure></p>
<p>   将类别标签转换为one-hot encoding， 这一步对多分类是必须的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">one_hot_labels  = keras.utils.np_utils.to_categorical(labels, num_classes=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<p>C. 输入数据类型转换，数值归一化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train = X_train.astype(<span class="string">'float32'</span>)</span><br><span class="line">X_train /= <span class="number">255</span></span><br></pre></td></tr></table></figure>
<h3 id="序列预处理"><a href="#序列预处理" class="headerlink" title="序列预处理"></a>序列预处理</h3><TODO>

<h3 id="文本预处理"><a href="#文本预处理" class="headerlink" title="文本预处理"></a>文本预处理</h3><TODO>

<h3 id="图片预处理"><a href="#图片预处理" class="headerlink" title="图片预处理"></a>图片预处理</h3><TODO>

<h2 id="样本数据序列化为HDF5文件"><a href="#样本数据序列化为HDF5文件" class="headerlink" title="样本数据序列化为HDF5文件"></a>样本数据序列化为HDF5文件</h2><TODO> 

<blockquote>
<p>目的：减少多次IO读取的延时</p>
</blockquote>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a href="http://lamda.nju.edu.cn/weixs/book/CNN_book.html">《解析卷积神经网络—深度学习实践手册》</a></li>
<li><a href="https://keras.io/">Keras文档</a></li>
<li><a href="http://deeplearning.stanford.edu/wiki/index.php/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86">http://deeplearning.stanford.edu/wiki/index.php/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86</a></li>
</ol>
</TODO></TODO></TODO></TODO>
        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                

                <time class="level-item has-text-grey" datetime="2018-02-22T05:20:28.000Z">2018-02-22</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/工具/">工具</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/工具/Keras/">Keras</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    13 分钟 读完 (大约 1882 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2018/02/22/Tips-for-Keras/">Tips for Keras</a>
            
        </h1>
        <div class="content">
            <p>撰写一篇博文用于记录Keras使用过程中的一些关键用法，以方便速查。</p>
        </div>
        
        
        <hr style="height:1px;margin:1rem 0"/>
         <div class="level is-mobile is-flex">
         <div class="level-start">
          
          <div class="level-item is-size-7 is-uppercase">
           <i class="fas fa-tags has-text-grey"></i>&nbsp;
             <a class="has-link-grey -link" href="/tags/AI/">AI</a>,&nbsp;<a class="has-link-grey -link" href="/tags/Keras/">Keras</a>,&nbsp;<a class="has-link-grey -link" href="/tags/人工智能/">人工智能</a>,&nbsp;<a class="has-link-grey -link" href="/tags/技巧/">技巧</a>
         </div>
         
         </div>

            <div class="level-start">
                <div class="level-item">
                <a class="button is-size-7 is-light" href="/2018/02/22/Tips-for-Keras/#more">阅读更多</a>
                </div>
            </div>
        </div>
        
        
    </div>
</div>








</div>
                




<div class="column is-4-tablet is-4-desktop is-3-widescreen  has-order-1 column-left ">
    
        
<div class="card widget">
    <div class="card-content">
        <nav class="level">
            <div class="level-item has-text-centered" style="flex-shrink: 1">
                <div>
                    
                    <figure class="image is-128x128 has-mb-6">
                        <img class="is-rounded" src="/images/photo.jpg" alt="Ebby">
                    </figure>
                    
                    <p class="is-size-4 is-block">
                        Ebby
                    </p>
                    
                    
                    <p class="is-size-6 is-block">
                        AI Learner
                    </p>
                    
                    
                    <p class="is-size-6 is-flex is-flex-center has-text-grey">
                        <i class="fas fa-map-marker-alt has-mr-7"></i>
                        <span>ShangHai</span>
                    </p>
                    
                </div>
            </div>
        </nav>
        <nav class="level is-mobile">
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        文章
                    </p>
                    <a href="/archives">
                        <p class="title has-text-weight-normal">
                            69
                        </p>
                    </a>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        分类
                    </p>
                    <a href="/categories">
                        <p class="title has-text-weight-normal">
                            19
                        </p>
                    </a>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        标签
                    </p>
                    <a href="/tags">
                        <p class="title has-text-weight-normal">
                            70
                        </p>
                    </a>
                </div>
            </div>
        </nav>
        
        <div class="level">
            <a class="level-item button is-link is-rounded" href="https://github.com/ddebby" target="_blank" rel="noopener">
                关注我</a>
        </div>
        
        
        
        <div class="level is-mobile">
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Github" href="https://github.com/ddebby">
                
                <i class="fab fa-github"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Facebook" href="https://facebook.com">
                
                <i class="fab fa-facebook"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Twitter" href="https://twitter.com/ebbydd">
                
                <i class="fab fa-twitter"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Dribbble" href="https://dribbble.com">
                
                <i class="fab fa-dribbble"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="RSS" href="/">
                
                <i class="fas fa-rss"></i>
                
            </a>
            
        </div>
        
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            标签云
        </h3>
        <a href="/tags/AI/" style="font-size: 17px;">AI</a> <a href="/tags/Ceph/" style="font-size: 11px;">Ceph</a> <a href="/tags/Fast-ai/" style="font-size: 10px;">Fast.ai</a> <a href="/tags/FastText/" style="font-size: 10px;">FastText</a> <a href="/tags/Git/" style="font-size: 10px;">Git</a> <a href="/tags/Ipython/" style="font-size: 10px;">Ipython</a> <a href="/tags/JupyterNotebook/" style="font-size: 10px;">JupyterNotebook</a> <a href="/tags/Keras/" style="font-size: 10px;">Keras</a> <a href="/tags/Markdown/" style="font-size: 10px;">Markdown</a> <a href="/tags/Numpy/" style="font-size: 10px;">Numpy</a> <a href="/tags/OpenCV/" style="font-size: 10px;">OpenCV</a> <a href="/tags/Pandas/" style="font-size: 10px;">Pandas</a> <a href="/tags/Prophet/" style="font-size: 10px;">Prophet</a> <a href="/tags/Python/" style="font-size: 10px;">Python</a> <a href="/tags/SARIMA/" style="font-size: 10px;">SARIMA</a> <a href="/tags/Time-Series/" style="font-size: 10px;">Time Series</a> <a href="/tags/word2vec/" style="font-size: 11px;">word2vec</a> <a href="/tags/书籍/" style="font-size: 10px;">书籍</a> <a href="/tags/云存储/" style="font-size: 11px;">云存储</a> <a href="/tags/人工智能/" style="font-size: 20px;">人工智能</a> <a href="/tags/优化/" style="font-size: 10px;">优化</a> <a href="/tags/公开课/" style="font-size: 10px;">公开课</a> <a href="/tags/博客/" style="font-size: 10px;">博客</a> <a href="/tags/原理解析/" style="font-size: 10px;">原理解析</a> <a href="/tags/可视化/" style="font-size: 10px;">可视化</a> <a href="/tags/图像分类/" style="font-size: 11px;">图像分类</a> <a href="/tags/实践/" style="font-size: 12px;">实践</a> <a href="/tags/实验/" style="font-size: 10px;">实验</a> <a href="/tags/工具/" style="font-size: 11px;">工具</a> <a href="/tags/工具使用/" style="font-size: 11px;">工具使用</a> <a href="/tags/工程实践/" style="font-size: 10px;">工程实践</a> <a href="/tags/开放数据集/" style="font-size: 11px;">开放数据集</a> <a href="/tags/开源平台/" style="font-size: 10px;">开源平台</a> <a href="/tags/强化学习/" style="font-size: 10px;">强化学习</a> <a href="/tags/心得体会/" style="font-size: 10px;">心得体会</a> <a href="/tags/总结/" style="font-size: 12px;">总结</a> <a href="/tags/感悟/" style="font-size: 11px;">感悟</a> <a href="/tags/感知机/" style="font-size: 10px;">感知机</a> <a href="/tags/技巧/" style="font-size: 12px;">技巧</a> <a href="/tags/技术/" style="font-size: 11px;">技术</a> <a href="/tags/支持向量机/" style="font-size: 10px;">支持向量机</a> <a href="/tags/教学/" style="font-size: 12px;">教学</a> <a href="/tags/数据/" style="font-size: 10px;">数据</a> <a href="/tags/数据标注/" style="font-size: 10px;">数据标注</a> <a href="/tags/数据集/" style="font-size: 10px;">数据集</a> <a href="/tags/文献/" style="font-size: 18px;">文献</a> <a href="/tags/时序数据/" style="font-size: 11px;">时序数据</a> <a href="/tags/机器学习/" style="font-size: 13px;">机器学习</a> <a href="/tags/机器视觉/" style="font-size: 16px;">机器视觉</a> <a href="/tags/模型/" style="font-size: 11px;">模型</a> <a href="/tags/正则化/" style="font-size: 10px;">正则化</a> <a href="/tags/物体识别/" style="font-size: 12px;">物体识别</a> <a href="/tags/特征抽取/" style="font-size: 10px;">特征抽取</a> <a href="/tags/目标检测/" style="font-size: 10px;">目标检测</a> <a href="/tags/神经网络/" style="font-size: 10px;">神经网络</a> <a href="/tags/笔记/" style="font-size: 15px;">笔记</a> <a href="/tags/策略/" style="font-size: 10px;">策略</a> <a href="/tags/算法/" style="font-size: 19px;">算法</a> <a href="/tags/线性回归/" style="font-size: 11px;">线性回归</a> <a href="/tags/网络复现/" style="font-size: 14px;">网络复现</a> <a href="/tags/计算机视觉/" style="font-size: 11px;">计算机视觉</a> <a href="/tags/词向量/" style="font-size: 10px;">词向量</a> <a href="/tags/词嵌入/" style="font-size: 11px;">词嵌入</a> <a href="/tags/读书笔记/" style="font-size: 14px;">读书笔记</a> <a href="/tags/资源调度/" style="font-size: 10px;">资源调度</a> <a href="/tags/迁移学习/" style="font-size: 10px;">迁移学习</a> <a href="/tags/逻辑回归/" style="font-size: 11px;">逻辑回归</a> <a href="/tags/部署/" style="font-size: 11px;">部署</a> <a href="/tags/配置/" style="font-size: 10px;">配置</a> <a href="/tags/预处理/" style="font-size: 11px;">预处理</a>
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                标签
            </h3>
            <div class="field is-grouped is-grouped-multiline">
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/AI/">
                        <span class="tag">AI</span>
                        <span class="tag is-grey">15</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Ceph/">
                        <span class="tag">Ceph</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Fast-ai/">
                        <span class="tag">Fast.ai</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/FastText/">
                        <span class="tag">FastText</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Git/">
                        <span class="tag">Git</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Ipython/">
                        <span class="tag">Ipython</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/JupyterNotebook/">
                        <span class="tag">JupyterNotebook</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Keras/">
                        <span class="tag">Keras</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Markdown/">
                        <span class="tag">Markdown</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Numpy/">
                        <span class="tag">Numpy</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/OpenCV/">
                        <span class="tag">OpenCV</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Pandas/">
                        <span class="tag">Pandas</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Prophet/">
                        <span class="tag">Prophet</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Python/">
                        <span class="tag">Python</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/SARIMA/">
                        <span class="tag">SARIMA</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Time-Series/">
                        <span class="tag">Time Series</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/word2vec/">
                        <span class="tag">word2vec</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/书籍/">
                        <span class="tag">书籍</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/云存储/">
                        <span class="tag">云存储</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/人工智能/">
                        <span class="tag">人工智能</span>
                        <span class="tag is-grey">53</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/优化/">
                        <span class="tag">优化</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/公开课/">
                        <span class="tag">公开课</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/博客/">
                        <span class="tag">博客</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/原理解析/">
                        <span class="tag">原理解析</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/可视化/">
                        <span class="tag">可视化</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/图像分类/">
                        <span class="tag">图像分类</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/实践/">
                        <span class="tag">实践</span>
                        <span class="tag is-grey">3</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/实验/">
                        <span class="tag">实验</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/工具/">
                        <span class="tag">工具</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/工具使用/">
                        <span class="tag">工具使用</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/工程实践/">
                        <span class="tag">工程实践</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/开放数据集/">
                        <span class="tag">开放数据集</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/开源平台/">
                        <span class="tag">开源平台</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/强化学习/">
                        <span class="tag">强化学习</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/心得体会/">
                        <span class="tag">心得体会</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/总结/">
                        <span class="tag">总结</span>
                        <span class="tag is-grey">3</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/感悟/">
                        <span class="tag">感悟</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/感知机/">
                        <span class="tag">感知机</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/技巧/">
                        <span class="tag">技巧</span>
                        <span class="tag is-grey">3</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/技术/">
                        <span class="tag">技术</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/支持向量机/">
                        <span class="tag">支持向量机</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/教学/">
                        <span class="tag">教学</span>
                        <span class="tag is-grey">3</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/数据/">
                        <span class="tag">数据</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/数据标注/">
                        <span class="tag">数据标注</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/数据集/">
                        <span class="tag">数据集</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/文献/">
                        <span class="tag">文献</span>
                        <span class="tag is-grey">25</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/时序数据/">
                        <span class="tag">时序数据</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/机器学习/">
                        <span class="tag">机器学习</span>
                        <span class="tag is-grey">4</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/机器视觉/">
                        <span class="tag">机器视觉</span>
                        <span class="tag is-grey">10</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/模型/">
                        <span class="tag">模型</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/正则化/">
                        <span class="tag">正则化</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/物体识别/">
                        <span class="tag">物体识别</span>
                        <span class="tag is-grey">3</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/特征抽取/">
                        <span class="tag">特征抽取</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/目标检测/">
                        <span class="tag">目标检测</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/神经网络/">
                        <span class="tag">神经网络</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/笔记/">
                        <span class="tag">笔记</span>
                        <span class="tag is-grey">6</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/策略/">
                        <span class="tag">策略</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/算法/">
                        <span class="tag">算法</span>
                        <span class="tag is-grey">35</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/线性回归/">
                        <span class="tag">线性回归</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/网络复现/">
                        <span class="tag">网络复现</span>
                        <span class="tag is-grey">5</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/计算机视觉/">
                        <span class="tag">计算机视觉</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/词向量/">
                        <span class="tag">词向量</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/词嵌入/">
                        <span class="tag">词嵌入</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/读书笔记/">
                        <span class="tag">读书笔记</span>
                        <span class="tag is-grey">5</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/资源调度/">
                        <span class="tag">资源调度</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/迁移学习/">
                        <span class="tag">迁移学习</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/逻辑回归/">
                        <span class="tag">逻辑回归</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/部署/">
                        <span class="tag">部署</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/配置/">
                        <span class="tag">配置</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/预处理/">
                        <span class="tag">预处理</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
            </div>
        </div>
    </div>
</div>
    
    
        <div class="column-right-shadow is-hidden-widescreen is-sticky">
        
            
        
            <div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            最新文章
        </h3>
        
        <article class="media">
            
            <a href="/2021/01/28/Reinforcement-Learning-Tips-and-Tricks/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/../qnsource/blog/rl.jpg" alt="Reinforcement Learning:Tips and Tricks">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2021-01-28T02:56:30.000Z">2021-01-28</time></div>
                    <a href="/2021/01/28/Reinforcement-Learning-Tips-and-Tricks/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Reinforcement Learning:Tips and Tricks</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/强化学习/">强化学习</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/11/19/pytorch模型的导出与部署/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="pytorch模型的导出与部署">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-11-19T05:00:18.000Z">2020-11-19</time></div>
                    <a href="/2020/11/19/pytorch模型的导出与部署/" class="title has-link-black-ter is-size-6 has-text-weight-normal">pytorch模型的导出与部署</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/深度学习/">深度学习</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/05/04/读书笔记-《神经网络与深度学习》/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/../qnsource/blog/qxp.jpg" alt="读书笔记-《神经网络与深度学习》">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-05-04T13:50:21.000Z">2020-05-04</time></div>
                    <a href="/2020/05/04/读书笔记-《神经网络与深度学习》/" class="title has-link-black-ter is-size-6 has-text-weight-normal">读书笔记-《神经网络与深度学习》</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/深度学习/">深度学习</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/04/19/计算机视觉目标检测研究札记/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/../qnsource/banner/02.jpg" alt="计算机视觉目标检测研究札记">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-04-19T07:10:45.000Z">2020-04-19</time></div>
                    <a href="/2020/04/19/计算机视觉目标检测研究札记/" class="title has-link-black-ter is-size-6 has-text-weight-normal">计算机视觉目标检测研究札记</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/深度学习/">深度学习</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/03/30/目标检测中的Anchor与感受野/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/../qnsource/blog/anchor.jpg" alt="目标检测中的Anchor与感受野">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-03-30T13:14:50.000Z">2020-03-30</time></div>
                    <a href="/2020/03/30/目标检测中的Anchor与感受野/" class="title has-link-black-ter is-size-6 has-text-weight-normal">目标检测中的Anchor与感受野</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/深度学习/">深度学习</a>
                    </p>
                </div>
            </div>
        </article>
        
    </div>
</div>
        
            <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            归档
        </h3>
        <ul class="menu-list">
        
        <li>
            <a class="level is-marginless" href="/archives/2021/01/">
                <span class="level-start">
                    <span class="level-item">一月 2021</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/11/">
                <span class="level-start">
                    <span class="level-item">十一月 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/05/">
                <span class="level-start">
                    <span class="level-item">五月 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/04/">
                <span class="level-start">
                    <span class="level-item">四月 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/03/">
                <span class="level-start">
                    <span class="level-item">三月 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">3</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2019/05/">
                <span class="level-start">
                    <span class="level-item">五月 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2019/02/">
                <span class="level-start">
                    <span class="level-item">二月 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2019/01/">
                <span class="level-start">
                    <span class="level-item">一月 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">3</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/12/">
                <span class="level-start">
                    <span class="level-item">十二月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">5</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/11/">
                <span class="level-start">
                    <span class="level-item">十一月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">4</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/09/">
                <span class="level-start">
                    <span class="level-item">九月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/08/">
                <span class="level-start">
                    <span class="level-item">八月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">7</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/07/">
                <span class="level-start">
                    <span class="level-item">七月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">7</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/06/">
                <span class="level-start">
                    <span class="level-item">六月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/05/">
                <span class="level-start">
                    <span class="level-item">五月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">8</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/04/">
                <span class="level-start">
                    <span class="level-item">四月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">11</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/03/">
                <span class="level-start">
                    <span class="level-item">三月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">8</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/02/">
                <span class="level-start">
                    <span class="level-item">二月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">2</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/01/">
                <span class="level-start">
                    <span class="level-item">一月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2017/02/">
                <span class="level-start">
                    <span class="level-item">二月 2017</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">2</span>
                </span>
            </a>
        </li>
        
        </ul>
        </div>
    </div>
</div>
        
        </div>
    
</div>

                




<div class="column is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only has-order-3 column-right is-sticky">
    
        
    
        <div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            最新文章
        </h3>
        
        <article class="media">
            
            <a href="/2021/01/28/Reinforcement-Learning-Tips-and-Tricks/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/../qnsource/blog/rl.jpg" alt="Reinforcement Learning:Tips and Tricks">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2021-01-28T02:56:30.000Z">2021-01-28</time></div>
                    <a href="/2021/01/28/Reinforcement-Learning-Tips-and-Tricks/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Reinforcement Learning:Tips and Tricks</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/强化学习/">强化学习</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/11/19/pytorch模型的导出与部署/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="pytorch模型的导出与部署">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-11-19T05:00:18.000Z">2020-11-19</time></div>
                    <a href="/2020/11/19/pytorch模型的导出与部署/" class="title has-link-black-ter is-size-6 has-text-weight-normal">pytorch模型的导出与部署</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/深度学习/">深度学习</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/05/04/读书笔记-《神经网络与深度学习》/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/../qnsource/blog/qxp.jpg" alt="读书笔记-《神经网络与深度学习》">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-05-04T13:50:21.000Z">2020-05-04</time></div>
                    <a href="/2020/05/04/读书笔记-《神经网络与深度学习》/" class="title has-link-black-ter is-size-6 has-text-weight-normal">读书笔记-《神经网络与深度学习》</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/深度学习/">深度学习</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/04/19/计算机视觉目标检测研究札记/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/../qnsource/banner/02.jpg" alt="计算机视觉目标检测研究札记">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-04-19T07:10:45.000Z">2020-04-19</time></div>
                    <a href="/2020/04/19/计算机视觉目标检测研究札记/" class="title has-link-black-ter is-size-6 has-text-weight-normal">计算机视觉目标检测研究札记</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/深度学习/">深度学习</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/03/30/目标检测中的Anchor与感受野/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/../qnsource/blog/anchor.jpg" alt="目标检测中的Anchor与感受野">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-03-30T13:14:50.000Z">2020-03-30</time></div>
                    <a href="/2020/03/30/目标检测中的Anchor与感受野/" class="title has-link-black-ter is-size-6 has-text-weight-normal">目标检测中的Anchor与感受野</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/深度学习/">深度学习</a>
                    </p>
                </div>
            </div>
        </article>
        
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            归档
        </h3>
        <ul class="menu-list">
        
        <li>
            <a class="level is-marginless" href="/archives/2021/01/">
                <span class="level-start">
                    <span class="level-item">一月 2021</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/11/">
                <span class="level-start">
                    <span class="level-item">十一月 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/05/">
                <span class="level-start">
                    <span class="level-item">五月 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/04/">
                <span class="level-start">
                    <span class="level-item">四月 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/03/">
                <span class="level-start">
                    <span class="level-item">三月 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">3</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2019/05/">
                <span class="level-start">
                    <span class="level-item">五月 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2019/02/">
                <span class="level-start">
                    <span class="level-item">二月 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2019/01/">
                <span class="level-start">
                    <span class="level-item">一月 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">3</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/12/">
                <span class="level-start">
                    <span class="level-item">十二月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">5</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/11/">
                <span class="level-start">
                    <span class="level-item">十一月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">4</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/09/">
                <span class="level-start">
                    <span class="level-item">九月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/08/">
                <span class="level-start">
                    <span class="level-item">八月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">7</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/07/">
                <span class="level-start">
                    <span class="level-item">七月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">7</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/06/">
                <span class="level-start">
                    <span class="level-item">六月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/05/">
                <span class="level-start">
                    <span class="level-item">五月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">8</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/04/">
                <span class="level-start">
                    <span class="level-item">四月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">11</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/03/">
                <span class="level-start">
                    <span class="level-item">三月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">8</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/02/">
                <span class="level-start">
                    <span class="level-item">二月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">2</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/01/">
                <span class="level-start">
                    <span class="level-item">一月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2017/02/">
                <span class="level-start">
                    <span class="level-item">二月 2017</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">2</span>
                </span>
            </a>
        </li>
        
        </ul>
        </div>
    </div>
</div>
    
    
</div>

            </div>
        </div>
    </section>
    <footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                
                    <img src="/images/logo02.png" alt="Ebby&#39;s Notes" height="28">
                
                </a>
                <p class="is-size-7">
                &copy; 2021 Ebby DD&nbsp;
                Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> & <a
                        href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a>  沪ICP备20005404号
                
                </p>
            </div>
            <div class="level-end">
            
                <div class="field has-addons is-flex-center-mobile has-mt-5-mobile is-flex-wrap is-flex-middle">
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/">
                        
                        <i class="fab fa-creative-commons"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/">
                        
                        <i class="fab fa-creative-commons-by"></i>
                        
                    </a>
                </p>
                
                </div>
            
            </div>
        </div>
    </div>
</footer>
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("zh-CN");</script>


<script>
var IcarusThemeSettings = {
    site: {
        url: 'http://blog.a-stack.com',
        external_link: {"enable":true,"exclude":[]}
    },
    article: {
        highlight: {
            clipboard: true,
            fold: 'unfolded'
        }
    }
};
</script>


<script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script>





<script src="/js/animation.js"></script>



<script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script>
<script src="/js/gallery.js" defer></script>



<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update
            my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        });
    });
</script>


<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    MathJax.Hub.Config({
        'HTML-CSS': {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
});
</script>


<a id="back-to-top" title="回到顶端" href="javascript:;">
    <i class="fas fa-chevron-up"></i>
</a>
<script src="/js/back-to-top.js" defer></script>














<script src="/js/main.js" defer></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="想要查找什么..." />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: '文章',
                PAGES: '页面',
                CATEGORIES: '分类',
                TAGS: '标签',
                UNTITLED: '(无标题)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js" defer></script>
<link rel="stylesheet" href="/css/search.css">
<link rel="stylesheet" href="/css/insight.css">
    
</body>
</html>