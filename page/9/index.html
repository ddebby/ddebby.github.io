<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  <title>Ebby&#39;s Notes</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
    <meta name="keywords" content="人工智能, AI, 神经网络, 算法">
  
  
  
  
  <meta name="description" content="记录人工智能学习路径">
<meta name="keywords" content="人工智能, AI, 神经网络, 算法">
<meta property="og:type" content="website">
<meta property="og:title" content="Ebby&#39;s Notes">
<meta property="og:url" content="http://blog.a-stack.com/page/9/index.html">
<meta property="og:site_name" content="Ebby&#39;s Notes">
<meta property="og:description" content="记录人工智能学习路径">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Ebby&#39;s Notes">
<meta name="twitter:description" content="记录人工智能学习路径">
  
    <link rel="alternate" href="/atom.xml" title="Ebby&#39;s Notes" type="application/atom+xml">
  

  

  <link rel="icon" href="/css/images/logo.png">
  <link rel="apple-touch-icon" href="/css/images/logo.png">
  
    <link href="/qnsource/css/Source+Code+Pro.css" rel="stylesheet" type="text/css">
  
  <link href="/qnsource/css/Open+Sans-Montserrat-700.css" rel="stylesheet" type="text/css">
  <link href="/qnsource/css/Roboto-400-300.css" rel="stylesheet" type="text/css">
  <link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <link rel="stylesheet" href="/css/style.css">

  <script src="/js/jquery-3.1.1.min.js"></script>
  <script src="/js/bootstrap.js"></script>

  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="/css/bootstrap.css">

  
    <link rel="stylesheet" href="/css/home.css">
  

  

  

  
  
  
    <link rel="stylesheet" href="/css/vdonate.css">
  

</head>
</html>


  <body>


  
    <header id="header">

	<!-- 背景图模式 -->
	

    
      <div id="intrologo" class="intro-logo" style="background-position:center; background-repeat:no-repeat; background-image: url(); background-size: auto 100%;">

      <!-- Support rolling -->  
        
        <section class="awSlider">
          <div class="carousel slide carousel-fade " data-ride="carousel">

            <!-- Wrapper for slides -->
            <div class="carousel-inner">
               
                  
                    <div class="item active">
                  
                    <img id="carousel-img0" src="/css/images/23.jpg">
                  </div>

                  <!-- 自适应大图 -->
                  <script>
                      var img0 = new Image();
                      var imageTag0 = document.getElementById("carousel-img0");
                      img0.src = imageTag0.src;
                      img0.onload=function(){
                        if (img0.width / img0.height <= document.body.clientWidth / document.body.clientHeight) {
                          imageTag0.style.width = document.body.clientWidth + "px";
                        } else {
                          imageTag0.style.height = document.body.clientHeight + "px";
                          imageTag0.style.marginLeft = -(document.body.clientHeight * img0.width / img0.height - document.body.clientWidth) / 2 + "px";
                        }
                      };
                  </script>
                
                  
                    <div class="item">
                  
                    <img id="carousel-img1" src="/css/images/17.jpg">
                  </div>

                  <!-- 自适应大图 -->
                  <script>
                      var img1 = new Image();
                      var imageTag1 = document.getElementById("carousel-img1");
                      img1.src = imageTag1.src;
                      img1.onload=function(){
                        if (img1.width / img1.height <= document.body.clientWidth / document.body.clientHeight) {
                          imageTag1.style.width = document.body.clientWidth + "px";
                        } else {
                          imageTag1.style.height = document.body.clientHeight + "px";
                          imageTag1.style.marginLeft = -(document.body.clientHeight * img1.width / img1.height - document.body.clientWidth) / 2 + "px";
                        }
                      };
                  </script>
                
                  
                    <div class="item">
                  
                    <img id="carousel-img2" src="/css/images/home-bg.jpg">
                  </div>

                  <!-- 自适应大图 -->
                  <script>
                      var img2 = new Image();
                      var imageTag2 = document.getElementById("carousel-img2");
                      img2.src = imageTag2.src;
                      img2.onload=function(){
                        if (img2.width / img2.height <= document.body.clientWidth / document.body.clientHeight) {
                          imageTag2.style.width = document.body.clientWidth + "px";
                        } else {
                          imageTag2.style.height = document.body.clientHeight + "px";
                          imageTag2.style.marginLeft = -(document.body.clientHeight * img2.width / img2.height - document.body.clientWidth) / 2 + "px";
                        }
                      };
                  </script>
                
                  
                    <div class="item">
                  
                    <img id="carousel-img3" src="/css/images/sample.jpg">
                  </div>

                  <!-- 自适应大图 -->
                  <script>
                      var img3 = new Image();
                      var imageTag3 = document.getElementById("carousel-img3");
                      img3.src = imageTag3.src;
                      img3.onload=function(){
                        if (img3.width / img3.height <= document.body.clientWidth / document.body.clientHeight) {
                          imageTag3.style.width = document.body.clientWidth + "px";
                        } else {
                          imageTag3.style.height = document.body.clientHeight + "px";
                          imageTag3.style.marginLeft = -(document.body.clientHeight * img3.width / img3.height - document.body.clientWidth) / 2 + "px";
                        }
                      };
                  </script>
                
            </div>

            <!-- Controls -->
            <a class="left carousel-control" href=".carousel" role="button" data-slide="prev">
              <span class="glyphicon glyphicon-chevron-left" aria-hidden="true"></span>
              <span class="sr-only">Geri</span>
            </a>
            <a class="right carousel-control" href=".carousel" role="button" data-slide="next">
              <span class="glyphicon glyphicon-chevron-right" aria-hidden="true"></span>
              <span class="sr-only">İleri</span>
            </a>
          </div>
        </section>
        <script>
          $('section.awSlider .carousel').carousel({
              pause: '',
              interval: 5000
          });
          var startImage = $('section.awSlider .item.active > img').attr('src');
          $('section.awSlider .carousel').on('slid.bs.carousel', function () {
              var bscn = $(this).find('.item.active > img').attr('src');
              $('section.awSlider > img').attr('src', bscn);
          });
        </script>
      

    
 


    <canvas width="100%" height="100%"></canvas>
    <script>
      var c = document.getElementsByTagName('canvas')[0],
          x = c.getContext('2d'),
          w = window.innerWidth,
          h = window.innerHeight,
          pr = window.devicePixelRatio || 1,
          f = 90,
          q,
          m = Math,
          r = 0,
          u = m.PI*2,
          v = m.cos,
          z = m.random
      c.width = w*pr
      c.height = h*pr
      x.scale(pr, pr)
      x.globalAlpha = 0.6

      <!-- 折线Polyline背景 -->
      
    </script>
    

    
      <div id="homelogo" class="homelogo" style="background: rgba(255,255,255,1);"> 
    

        
          <div class="homelogoback"  style="border: 1px solid #404040;" >
            <h1><a href="#content" id="logo">Ebby&#39;s Notes</a></h1>
            <h3>记录人工智能学习路径</h3>
            <h5>Ebby DD</h5>
            <!-- <p><a href="https://github.com/iTimeTraveler" target="_blank">Github</a></p> -->
          </div>
        
    
    </div>
  </div>

  <!-- 自适应主页背景大图 -->
  

 <!-- home_logo_image居中 -->
 
    <script>
        var homelogodiv = document.getElementById("homelogo");
        if (document.all.homelogo.offsetWidth > document.body.clientWidth) {
          homelogodiv.style.width = document.body.clientWidth + "px";
          homelogodiv.style.marginLeft = document.body.clientWidth * -0.5 + "px";
        } else {
          homelogodiv.style.width = homelogodiv.clientWidth  + "px";
          homelogodiv.style.marginLeft = (homelogodiv.clientWidth)  * -0.5 + "px";
        }
    </script>
  

  <div class="intro-navigate">
      <p class="navigater-list">
        
          <a id="beautifont" class="main-nav-link" href="/">首页</a>
        
          <a id="beautifont" class="main-nav-link" href="/archives">归档</a>
        
          <a id="beautifont" class="main-nav-link" href="/categories">分类</a>
        
          <a id="beautifont" class="main-nav-link" href="/tags">标签</a>
        
          <a id="beautifont" class="main-nav-link" href="/about">关于</a>
        
          <a id="beautifont" class="main-nav-link" href="/reading">读书</a>
        
          <a id="beautifont" class="main-nav-link" href="/resources">资源</a>
        
          <a id="beautifont" class="main-nav-link" href="/notebooks">📝</a>
        
      </p>
  </div>

</header>
  
  <div id="container">
    <div id="wrap">
      
            
      <div id="content" class="outer">
        
          <section id="main">
  
    <article id="post-machinelearning-labs"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2018/04/26/machinelearning-labs/">《机器学习》课程实验回顾</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2018/04/26/machinelearning-labs/" class="article-date">
	  <time datetime="2018-04-26T05:56:28.000Z" itemprop="datePublished">2018-04-26</time>
	</a>

      
    <a class="article-category-link" href="/categories/动手实践营/">动手实践营</a>

      
      

    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>摘要：</strong> Cousera上机器学习课程提供了八个实验作业，使用MATLAB进行动手实验，熟悉相关技术，本文对实验中的关键内容进行总结归纳，方便以后及时查找。</p>
      
    </div>
    <footer class="article-footer">

      
      

      
      <!--  -->

      <!--  -->
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/公开课/">公开课</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/实验/">实验</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/线性回归/">线性回归</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/逻辑回归/">逻辑回归</a></li></ul>

    </footer>
  </div>
  
</article>

<!-- Table of Contents -->


  
    <article id="post-machinelearning-notes"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2018/04/26/machinelearning-notes/">Machine Learning Notes</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2018/04/26/machinelearning-notes/" class="article-date">
	  <time datetime="2018-04-26T05:56:13.000Z" itemprop="datePublished">2018-04-26</time>
	</a>

      
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>

      
      

    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>摘要：</strong> 最近花了两周时间刷完了吴恩达在Cousera上关于<a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="noopener">机器学习</a>的经典课程, 这已经是近两个月来刷完的第十个Cousera课程了。虽然课程是多年前开设的，但相关机器学习理论和方法内容介绍仍然具备很强的时效性，是机器学习入门的必选课程。</p>
      
    </div>
    <footer class="article-footer">

      
      

      
      <!--  -->

      <!--  -->
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/神经网络/">神经网络</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/笔记/">笔记</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/算法/">算法</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/线性回归/">线性回归</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/逻辑回归/">逻辑回归</a></li></ul>

    </footer>
  </div>
  
</article>

<!-- Table of Contents -->


  
    <article id="post-机器学习三要素-模型-策略与算法"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2018/04/21/机器学习三要素-模型-策略与算法/">机器学习三要素：模型,策略与算法</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2018/04/21/机器学习三要素-模型-策略与算法/" class="article-date">
	  <time datetime="2018-04-21T15:12:04.000Z" itemprop="datePublished">2018-04-21</time>
	</a>

      
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>

      
      

    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>摘要：</strong> 李航在《统计学习方法》中将统计学习方法的三要素——模型、策略、算法总结为机器学习方法的提纲挈领。这篇博文主要总结归纳《统计学习方法》中对于这三要素的阐述。<br><!-- excerpt --></p>
<p>@[toc]</p>
<p>最近在读李航的《统计学习方法》，作者从统计学习的方法来分析机器学习技术，分析很细致深刻，值得反思，未来将逐步总结相关内容，期待更多共鸣与思考。</p>
<h2 id="什么是统计机器学习"><a href="#什么是统计机器学习" class="headerlink" title="什么是统计机器学习"></a>什么是统计机器学习</h2><p><strong>统计学习</strong>又叫<strong>统计机器学习</strong>，是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的一门学科。</p>
<p>统计学习的对象是具备一定统计规律的数据，同时对数据有一个强假设：数据是独立同分布产生的。学习的模型属于某个函数的集合，称为<strong>假设空间</strong>(hypothesis space)，应用某个<strong>评价准则</strong>(evaluation criterion) 从假设空间中选取一个最优的模型，使它对已知训练数据和未知测试数据在给定评价准则下有最优的预测结果，这个模型的选取过程由<strong>算法</strong>实现。这样统计学习的方法由模型的假设空间、模型选择的准则以及模型的学习算法组成，称为统计机器学习的三要素。</p>
<h3 id="概念定义"><a href="#概念定义" class="headerlink" title="概念定义"></a>概念定义</h3><ul>
<li><strong>输入空间</strong>： 输入变量$X={x_1, x_2, …, x_N}$ 构成的空间；</li>
<li><strong>输出空间</strong>：对于输入变量的真实输出$Y={y_1, y_2,…,y_N}$ 构成的空间；</li>
<li><strong>特征空间</strong>：每个输入变量都可以由一组特征向量表示，这些特征向量构成了特征空间；<ul>
<li>模型实际上都是定义在特征空间上的；</li>
</ul>
</li>
<li><strong>假设空间</strong>： 包含所有可能的映射关系集合 $F={ f|y=f_{\theta}(X), \theta \in R^n}$  <ul>
<li>输入到输出的映射的集合，表示为条件概率分布$\hat P(X|Y)$ 或决策函数 $Y = \hat f(X)$ </li>
</ul>
</li>
<li><strong>参数空间</strong>： 构成假设空间每个映射函数的参数所形成的空间；</li>
<li><strong>监督学习的联合概率分布</strong>：</li>
</ul>
<blockquote>
<p> 监督学习假设输入与输出的随机变量$X$ 和 $Y$ 遵循联合概率分布 $P(X,Y)$ , 机器学习的前提是假设该概率分布存在，但具体定义是未知的（如果知道的话也没必要通过机器学习来获取的了，直接可以通过条件函数来预测未知结果）。训练数据和测试数据被看作是依据联合概率分布$P(X,Y)$ 独立同分布产生的。这是机器学习数据具备一定统计规律的基本假设。</p>
</blockquote>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>如下图所示，在机器学习中，模型描述的是一组从输入到输出的映射关系的函数表示。</p>
<p><img src="/qnsource/images/2018-04-21-机器学习三要素-模型-策略与算法/model.png" alt="model"></p>
<p>在监督学习中，模型就是从假设空间中所要学习条件概率分布$\hat P(X|Y)$ 或决策函数 $Y = \hat f(X)$ 。</p>
<h2 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h2><p>策略描述了学习的目标函数，通过什么样的准则使学习的方向最终逼近最终的优化目标从而能够从假设空间中选取最优的模型。一般采用损失函数或代价函数来对模型的好坏进行度量。损失函数是$f(X)$ 和 $Y$ 的非负实值函数，记作 $L(Y, f(X))$ 。</p>
<p>损失函数数值越小，模型越好，损失函数的期望为：</p>
<script type="math/tex; mode=display">
R_{exp} (f) = E_p [L(Y,f(x))] = \int_{x\times y} L(y,f(x))P(x,y)dxdy</script><p>这是理论上模型$f(X)$ 关于联合分布的平均意义下的损失，称为<strong>风险函数</strong>或<strong>期望损失</strong>。由于$P(X,Y)$ 未知，所以期望损失无法直接计算。因此引入另一个概念：<strong>经验风险（损失）</strong>：</p>
<script type="math/tex; mode=display">
R_{emp} (f) = \frac{1}{N} \sum_{i=1}^NL(y_i,f(x_i))</script><p><strong>经验风险</strong>是模型关于训练样本的平均损失。根据大数定理，当样本容量N趋于无穷时，经验风险趋于期望风险。所以可以用经验风险估计期望风险，但由于现实世界中训练样本数目有限，所以需要对经验风险进行一定的矫正(如正则化)。</p>
<p>当样本容量很小时，经验风险最小化学习会产生过拟合现象，于是引入修正方案：结构风险最小化（SRM）：</p>
<script type="math/tex; mode=display">
R_{emp} (f) = \frac{1}{N} \sum_{i=1}^NL(y_i,f(x_i)) + \lambda J(f)</script><p>结构风险是在经验风险基础上加上表示模型复杂度的正则化项（惩罚项）$J(f)$ ，它描述了模型的复杂度。</p>
<blockquote>
<p><strong>过拟合</strong>：如果在假设空间中存在“真”模型，过拟合可以理解为所选模型复杂度由于比真模型更高，包含了更多的参数，对训练数据预测比”真”模型更好，但对新数据的预测很差。（训练数据中掺杂着噪声，所以即使”真”模型也无法一定完全拟合训练数据）。</p>
</blockquote>
<p>过拟合问题告诉我们，对模型好坏的评价不是完全靠在训练数据上的经验风险或结构风险来决定的，而是学习方法的泛化能力，这是期望损失本身要表达的意思。如果学到一个模型$\hat f$,那么用这个模型对未知数据预测的误差即为<strong>泛化误差</strong>：</p>
<script type="math/tex; mode=display">
R_{exp} (\hat f) = E_p [L(Y,\hat f(x))] = \int_{x\times y} L(y,\hat f(x))P(x,y)dxdy</script><p>泛化误差具备如下性质：</p>
<ol>
<li>它是样本容量的函数，随着样本容量增加，泛化误差上界趋于0；</li>
<li>它是假设空间容量的函数，假设空间越大，模型就越难学，泛化误差上界就越大。</li>
</ol>
<h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p>算法将机器学习问题转换为最优化问题进行求解。设计目标是寻找全局最优解并使得求解过程足够高效。</p>
<hr>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li>​《统计学习方法》</li>
</ol>

      
    </div>
    <footer class="article-footer">

      
      

      
      <!--  -->

      <!--  -->
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/模型/">模型</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/策略/">策略</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/算法/">算法</a></li></ul>

    </footer>
  </div>
  
</article>

<!-- Table of Contents -->


  
    <article id="post-Backpropagation-in-Neural-Network"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2018/04/20/Backpropagation-in-Neural-Network/">Backpropagation in Neural Network</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2018/04/20/Backpropagation-in-Neural-Network/" class="article-date">
	  <time datetime="2018-04-20T01:09:14.000Z" itemprop="datePublished">2018-04-20</time>
	</a>

      
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a><a class="article-category-link" href="/categories/深度学习/基础知识/">基础知识</a>

      
      

    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>摘要：</strong> 反向传播毋庸置疑是整个神经网络的精髓，正是由于它的提出标志着深度神经网络的训练在有限算力基础上成为可能，但反向传播本身的原理同样值得品读和思考。<br><!-- excerpt --></p>
<p>本文主要总结神经网络中反向传播算法的推导流程并挖掘一些深层次的原理。反向传播算法在1970年就已经提出，直到1986年 <a href="http://en.wikipedia.org/wiki/David_Rumelhart" target="_blank" rel="noopener">David Rumelhart</a>, <a href="http://www.cs.toronto.edu/~hinton/" target="_blank" rel="noopener">Geoffrey Hinton</a>, and <a href="http://en.wikipedia.org/wiki/Ronald_J._Williams" target="_blank" rel="noopener">Ronald Williams</a>在一篇<a href="https://www.nature.com/articles/323533a0" target="_blank" rel="noopener">论文</a>中对其实现的分析才得以普及。</p>
<h2 id="1-表达式的定义"><a href="#1-表达式的定义" class="headerlink" title="1. 表达式的定义"></a>1. 表达式的定义</h2><ul>
<li>$w_{jk}^l$ 代表第l−1层第k个神经元，与第l层第j个神经元之间的权重（注意j与k的顺序）；</li>
<li>$b_j^l$  代表第l层中第j个神经元的偏移；</li>
<li>$a_j^l$  代表第l层中第j个神经元的激活函数值；</li>
<li>$L$  代表神经网络的总层数；</li>
<li>$J(W,b)$ 简写为$J$ 代表神经网络的代价函数；</li>
</ul>
<p>假设我们有$m$ 个训练样本${(x^{(1)},y^{(1)}),…, (x^{(m)},y^{(m)})}$ ,对于每个训练样本$(x,y)$ 定义代价函数为：</p>
<script type="math/tex; mode=display">
J(W,b;x,y) = \frac{1}{2} ||h_{W,b}(x) - y||^2</script><p>对于$m$个训练样本，总的代价函数为：</p>
<script type="math/tex; mode=display">
J(W,b) = [\frac{1}{m} \sum_{i=1}^m J(W,b;x^{(i)},y^{(i)}] + \frac{\lambda}{2} \sum_{l=1}^{n_l -1}\sum_{i=1}^{s_l}\sum_{j=1}^{s_{l+1}}(W_{ji}^{(l)})^2</script><p>根据神经网络层与层之间关系的定义，我们有如下表达式（<strong>向量形式</strong>）：</p>
<script type="math/tex; mode=display">
z^l = w^l a^{l-1} + b^l,   l=2,3,...,L</script><script type="math/tex; mode=display">
a^l = \sigma (z^l), l=2,3,...,L</script><script type="math/tex; mode=display">
a^1=z^1=X</script><p>其中</p>
<script type="math/tex; mode=display">
z_j^l = \sum_k w_{jk}^l a_k^{l-1} + b_j^l</script><p>利用梯度下降法进行目标优化使用的主要梯度更新公式：</p>
<script type="math/tex; mode=display">
w^l := w^l - \alpha \frac{\partial J}{\partial w^l}</script><script type="math/tex; mode=display">
b^l := b^l - \alpha \frac{\partial J}{\partial b^l}</script><p>因为神经网络的复杂性导致$\frac{\partial J}{\partial w^l}$ 无法直接计算或者计算代价太大（每个权重的计算都需要进行一次前向传播），反向传播的目的在于提供一种更加高效的手段，完成上述梯度的更新操作。</p>
<h2 id="2-反向传播的直观理解"><a href="#2-反向传播的直观理解" class="headerlink" title="2. 反向传播的直观理解"></a>2. 反向传播的直观理解</h2><p>反向传播是用于理解改变网络中的任一权重如何影响网络代价函数的过程。假设神经网络中某个权重$w_{jk}^l$ </p>
<p>产生了轻微的扰动误差 $\Delta w_{jk}^l$ ,扰动误差导致该神经元的输出产生误差 $\Delta z_j^l$ ,这个扰动将使对应的神经元$a_j^l$ 产生一个扰动误差 $\Delta a_j^l$ ，该误差将逐步向后层传递，直至达到输出层，并最终影响代价函数，生成一个代价误差 $\Delta J = \frac{\partial J}{\partial z_j^l}\Delta z_j^l$ 。我们可以给出如下式子来为通过误差近似计算梯度提供方向：</p>
<script type="math/tex; mode=display">
\Delta J \approx \frac{\partial J}{\partial a^L_m} 
  \frac{\partial a^L_m}{\partial a^{L-1}_n}
  \frac{\partial a^{L-1}_n}{\partial a^{L-2}_p} \ldots
  \frac{\partial a^{l+1}_q}{\partial a^l_j}
  \frac{\partial a^l_j}{\partial w^l_{jk}} \Delta w^l_{jk}</script><script type="math/tex; mode=display">
 \frac{\Delta J}{\Delta z_{j}^l}=\delta_j^l=\frac{\partial J}{\partial z_j^l}</script><p>其中，$\delta_j^l$  可以定义为$l$层第$j$个神经元上的误差。</p>
<p>我们先从计算最后一层误差$\delta_j^L$ 开始，</p>
<script type="math/tex; mode=display">
\delta^L_j = \frac{\partial J}{\partial a^L_j} \sigma'(z^L_j)</script><p><strong>公式E1</strong>（向量形式）：</p>
<script type="math/tex; mode=display">
\delta^L = \nabla_a J \odot \sigma'(z^L)</script><p><strong>证明</strong>：</p>
<script type="math/tex; mode=display">
\delta^L_j =\frac{\partial J}{\partial z_j^L}=\frac{\partial J}{\partial a_j^L}.\frac{\partial a_j^L}{\partial z_j^L}= \frac{\partial J}{\partial a^L_j} \sigma'(z^L_j).</script><p>现在把问题转变为如何利用反向传播由后往前逐步计算误差$\delta_j^l$ ，为计算不同层之间误差之间的关系，利用链式法则给出如下推理过程：</p>
<script type="math/tex; mode=display">
\delta^l =\frac{\partial J}{\partial z^l} = \frac{\partial J}{\partial z^{l+1}}.\frac{\partial z^{l+1}}{\partial z^l}=\delta^{l+1}.(\frac{\partial z^{l+1}}{\partial a^l}.\frac{\partial a^l}{\partial z^l})= ((w^{l+1})^T\delta^{l+1})\odot \sigma'(z^l)</script><p>即<strong>公式E2</strong>：</p>
<script type="math/tex; mode=display">
\delta^l = ((w^{l+1})^T \delta^{l+1}) \odot \sigma'(z^l)</script><p>有了以上误差的反向传播计算方法，我们可以利用计算的误差计算权重的梯度如下：</p>
<p><strong>公式E3</strong>：</p>
<script type="math/tex; mode=display">
\frac{\partial J}{\partial b^l_j} =\delta^l_j</script><p><strong>公式E4</strong>：</p>
<script type="math/tex; mode=display">
\frac{\partial J}{\partial w^l_{jk}} = a^{l-1}_k \delta^l_j</script><p>其中公式（4）也可以写成：</p>
<script type="math/tex; mode=display">
\frac{\partial
    J}{\partial w} = a_{\rm in} \delta_{\rm out}</script><p><strong>证明：</strong></p>
<script type="math/tex; mode=display">
\frac{\partial J}{\partial b^l_j} =\frac{\partial J}{\partial z^l_j}.\frac{\partial z^l_j}{\partial b^l_j}=  
  \delta^l_j</script><script type="math/tex; mode=display">
\frac{\partial J}{\partial w^l_{jk}} = \frac{\partial J}{\partial z^l_{jk}}.\frac{\partial z_{jk}^l}{\partial w^l_{jk}}=a^{l-1}_k \delta^l_j</script><h3 id="另一种求解方式"><a href="#另一种求解方式" class="headerlink" title="另一种求解方式"></a>另一种求解方式</h3><script type="math/tex; mode=display">
\dfrac{\partial J}{\partial w_{ij}^l} =\frac{\partial J}{\partial a_j^l}.\frac{\partial a_j^l}{\partial z_j^l}.\frac{\partial z_j^l}{w_{ij}^l}=\frac{\partial J}{\partial a_j^l}.\sigma^{'}(z_j^l)a_i^{l-1}</script><p>如何我们令$\delta_j^l =\frac{\partial J}{\partial a_j^l}$ 也可以按照上述过程类似的方法推到出相关公式</p>
<h2 id="3-反向传播算法的计算流程"><a href="#3-反向传播算法的计算流程" class="headerlink" title="3. 反向传播算法的计算流程"></a>3. 反向传播算法的计算流程</h2><ol>
<li>输入$x$，令$a^1=z^1=x$;</li>
<li>前向传播： 对于每层$l=2,3,…,L$计算$z^l$和$a^l$；</li>
<li>根据公式<strong>E1</strong>计算输出误差：$\delta^L = \nabla_a J \odot \sigma’(z^L)$ ;</li>
<li>反向传播：对于每层$l=L-1,L-2,…,2$ 利用公式<strong>E2</strong>计算误差：$\delta^l = ((w^{l+1})^T \delta^{l+1}) \odot \sigma’(z^l)$ ；</li>
<li>利用公式<strong>E3</strong>和<strong>E4</strong>计算参数梯度；</li>
<li>更新权重</li>
</ol>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a href="http://cs231n.github.io/optimization-2/" target="_blank" rel="noopener">CS231n讲义：Backpropagation, Intuitions</a></li>
<li><a href="http://neuralnetworksanddeeplearning.com/chap2.html" target="_blank" rel="noopener">Neural Networks and Deep Learning</a></li>
<li><a href="http://deeplearning.stanford.edu/wiki/index.php/Backpropagation_Algorithm" target="_blank" rel="noopener">Machine Learning Cousera Course</a></li>
</ol>

      
    </div>
    <footer class="article-footer">

      
      

      
      <!--  -->

      <!--  -->
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/">AI</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/人工智能/">人工智能</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/文献/">文献</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/算法/">算法</a></li></ul>

    </footer>
  </div>
  
</article>

<!-- Table of Contents -->


  
    <article id="post-TensorFlow-Object-Detection-API"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2018/04/14/TensorFlow-Object-Detection-API/">使用TensorFlow Object Detection API识别仪表表盘</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2018/04/14/TensorFlow-Object-Detection-API/" class="article-date">
	  <time datetime="2018-04-14T13:16:41.000Z" itemprop="datePublished">2018-04-14</time>
	</a>

      
    <a class="article-category-link" href="/categories/动手实践营/">动手实践营</a><a class="article-category-link" href="/categories/动手实践营/机器视觉/">机器视觉</a>

      
      

    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p>前面用到了Tensorflow的物体识别API做了一个检测仪表表盘的实践，记录实践过程中的技巧。<br><!-- excerpt --></p>
<blockquote>
<p>Update: 2019/04/16，使用新版Tensorflow接口</p>
</blockquote>
<h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>本文主要介绍如何使用Tensorflow 物体识别API应用自己业务场景进行物体识别。将结合从事的一些实际经验，分享一个仪表表盘识别的案例。我们在一个利用机器视觉技术自动识别仪表表读数的项目中，需要首先识别各种不同类型表盘的显示屏位置。本案例分析将针对面板识别中采用的关键技术进行分析，详细阐述如何利用物体识别技术和已训练好的模型快速实现使用用户数据设计一个面向特定物体识别的深度神经网络。</p>
<p><strong>目标：</strong> 从给定的水表图片中将关键的数字面板给扣取出来。</p>
<p>如下图所示，如果采用通用OCR技术对水表图片面板进行检测，将同时提取很多特征项，对实际的检测值造成比较大的干扰。</p>
<p><img src="/qnsource/images/2018-04-14-TensorFlow-Object-Detection-API/ocr-demo.PNG" alt="ocr-demo"></p>
<h3 id="1-1-模型及算法选型"><a href="#1-1-模型及算法选型" class="headerlink" title="1.1 模型及算法选型"></a>1.1 模型及算法选型</h3><p>在方案设计初期我们分别使用公有云服务、现有的成熟OCR软件、开源的OCR方案对目标对象进行了初步识别及分析。通过实测，现有方案无法满足我们的任务需求。为此希望能够利用深度学习在物体识别领域的成熟方案，构建一个面向水表图片面板识别的神经网络模型。</p>
<ul>
<li><p><strong>计算框架：</strong> Tensorflow (v1.7)</p>
</li>
<li><p><strong>使用接口：</strong> <a href="https://github.com/tensorflow/models/tree/master/research/object_detection" target="_blank" rel="noopener">Tensorflow Object Detection API</a><sup><a href="#fn_1" id="reffn_1">1</a></sup></p>
</li>
<li><p><strong>算法模型：</strong> 根据预训练采用的数据集不同，可用的模型列表如下：</p>
<ul>
<li><a href="http://mscoco.org/" target="_blank" rel="noopener">COCO dataset</a></li>
</ul>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>Model name</th>
<th>Speed (ms)</th>
<th>COCO mAP<sup><a href="#fn_2" id="reffn_2">2</a></sup></th>
<th>Outputs</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2017_11_17.tar.gz" target="_blank" rel="noopener">ssd_mobilenet_v1_coco</a></td>
<td>30</td>
<td>21</td>
<td>Boxes</td>
</tr>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2017_11_17.tar.gz" target="_blank" rel="noopener">ssd_inception_v2_coco</a></td>
<td>42</td>
<td>24</td>
<td>Boxes</td>
</tr>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2017_11_08.tar.gz" target="_blank" rel="noopener">faster_rcnn_inception_v2_coco</a></td>
<td>58</td>
<td>28</td>
<td>Boxes</td>
</tr>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_coco_2017_11_08.tar.gz" target="_blank" rel="noopener">faster_rcnn_resnet50_coco</a></td>
<td>89</td>
<td>30</td>
<td>Boxes</td>
</tr>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_lowproposals_coco_2017_11_08.tar.gz" target="_blank" rel="noopener">faster_rcnn_resnet50_lowproposals_coco</a></td>
<td>64</td>
<td></td>
<td>Boxes</td>
</tr>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/rfcn_resnet101_coco_2017_11_08.tar.gz" target="_blank" rel="noopener">rfcn_resnet101_coco</a></td>
<td>92</td>
<td>30</td>
<td>Boxes</td>
</tr>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_2017_11_08.tar.gz" target="_blank" rel="noopener">faster_rcnn_resnet101_coco</a></td>
<td>106</td>
<td>32</td>
<td>Boxes</td>
</tr>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_lowproposals_coco_2017_11_08.tar.gz" target="_blank" rel="noopener">faster_rcnn_resnet101_lowproposals_coco</a></td>
<td>82</td>
<td></td>
<td>Boxes</td>
</tr>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_coco_2017_11_08.tar.gz" target="_blank" rel="noopener">faster_rcnn_inception_resnet_v2_atrous_coco</a></td>
<td>620</td>
<td>37</td>
<td>Boxes</td>
</tr>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_lowproposals_coco_2017_11_08.tar.gz" target="_blank" rel="noopener">faster_rcnn_inception_resnet_v2_atrous_lowproposals_coco</a></td>
<td>241</td>
<td></td>
<td>Boxes</td>
</tr>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_nas_coco_2017_11_08.tar.gz" target="_blank" rel="noopener">faster_rcnn_nas</a></td>
<td>1833</td>
<td>43</td>
<td>Boxes</td>
</tr>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_nas_lowproposals_coco_2017_11_08.tar.gz" target="_blank" rel="noopener">faster_rcnn_nas_lowproposals_coco</a></td>
<td>540</td>
<td></td>
<td>Boxes</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li><a href="http://www.cvlibs.net/datasets/kitti/" target="_blank" rel="noopener">Kitti dataset</a></li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>Model name</th>
<th>Speed (ms)</th>
<th>Pascal mAP@0.5 (ms)</th>
<th>Outputs</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_kitti_2017_11_08.tar.gz" target="_blank" rel="noopener">faster_rcnn_resnet101_kitti</a></td>
<td>79</td>
<td>87</td>
<td>Boxes</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li><a href="https://github.com/openimages/dataset" target="_blank" rel="noopener">Open Images dataset</a></li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>Model name</th>
<th>Speed (ms)</th>
<th>Open Images mAP@0.5<sup><a href="#fn_2" id="reffn_2">2</a></sup></th>
<th>Outputs</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_oid_2017_11_08.tar.gz" target="_blank" rel="noopener">faster_rcnn_inception_resnet_v2_atrous_oid</a></td>
<td>727</td>
<td>37</td>
<td>Boxes</td>
</tr>
<tr>
<td><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_lowproposals_oid_2017_11_08.tar.gz" target="_blank" rel="noopener">faster_rcnn_inception_resnet_v2_atrous_lowproposals_oid</a></td>
<td>347</td>
<td></td>
<td>Boxes</td>
</tr>
</tbody>
</table>
</div>
<p>  几种模型主要在精度和速度方面进行了取舍，如果需要一个高精度的模型可以选择faster R-CNN，如果希望速度快比如实时检测，则可以选择SSD模型。鉴于本方案中设计检测目标特征将为简单，可采用最轻量级的MobileSSD进行优化。</p>
<h2 id="2-实现流程"><a href="#2-实现流程" class="headerlink" title="2. 实现流程"></a>2. 实现流程</h2><h3 id="2-1-数据准备"><a href="#2-1-数据准备" class="headerlink" title="2.1 数据准备"></a>2.1 数据准备</h3><p>数据准备的环节是除了训练过程之外最为耗时的环节，准备数据的质量和数量将直接决定了训练模型的好坏。图片数据最好在光线、角度、清晰度等方面能最大化的泛化实际的业务场景。由于在这个案例中我们只需要输出一个分类对象，而且输入对象被限定在水表图片上，所以整体涉及需要提取的特征参数空间不是很大，少量经过处理好的明显可供辨识的水表图片即可。目前可用水表图片攻击229张，我们采用80%用于训练，20%用于测试的方式进行划分。</p>
<blockquote>
<p>如果分类较多，数据有限，可以选择从互联网上下载或者在开源数据集中获得所需的数据。</p>
<p>另外需要注意图片的大小，图片太大一方面影响训练过程的处理时间，另外大量图片载入内存将很容导致内存溢出，所以如果图像特征粒度不是特别精细可以采用低分辨率图片进行分析。</p>
</blockquote>
<h4 id="数据标记"><a href="#数据标记" class="headerlink" title="数据标记"></a>数据标记</h4><p>对于物体识别而言，数据标记过程是一个相对复杂的过程，目前除了人工标记没有太好的自动或半监督手段，幸好针对图片的标记已经有了几款很好用的工具：</p>
<ul>
<li><p><a href="https://github.com/tzutalin/labelImg" target="_blank" rel="noopener">LabelImg</a></p>
<ul>
<li>这是一个可以直接在图片上做注释框自动生成标记信息的软件，注释信息将被保存为PASCAL VOC 格式的XML文件（<a href="http://www.image-net.org/" target="_blank" rel="noopener">ImageNet</a>的文件格式）</li>
</ul>
<p><img src="/qnsource/images/2018-04-14-TensorFlow-Object-Detection-API/labelImage.jpg" alt="labelImage"></p>
</li>
<li><p><a href="https://github.com/christopher5106/FastAnnotationTool" target="_blank" rel="noopener">FIAT (Fast Image Data Annotation Tool)</a> </p>
<ul>
<li><p>该工具生成csv格式的注释文件</p>
<p><a href="https://camo.githubusercontent.com/c77ea08c2a142680f237371c1a1e5743b877842c/687474703a2f2f6368726973746f70686572353130362e6769746875622e696f2f696d672f616e6e6f7461746f725f65726173652e706e67" target="_blank" rel="noopener"><img src="https://camo.githubusercontent.com/c77ea08c2a142680f237371c1a1e5743b877842c/687474703a2f2f6368726973746f70686572353130362e6769746875622e696f2f696d672f616e6e6f7461746f725f65726173652e706e67" alt="data annotation"></a></p>
</li>
</ul>
</li>
<li><p><a href="http://imagemagick.org/#" target="_blank" rel="noopener">ImageMagick</a></p>
<ul>
<li>图片预处理工具</li>
<li>Use ImageMagick<a href="http://tarr.uspto.gov/servlet/tarr?regser=serial&amp;entry=78333969" target="_blank" rel="noopener">®</a> to create, edit, compose, or convert bitmap images.  It can read and write images in a variety of <a href="http://imagemagick.org/script/formats.php" target="_blank" rel="noopener">formats</a> (over 200) including PNG, JPEG, GIF, HEIC, TIFF, <a href="http://imagemagick.org/script/motion-picture.php" target="_blank" rel="noopener">DPX</a>, <a href="http://imagemagick.org/script/high-dynamic-range.php" target="_blank" rel="noopener">EXR</a>, WebP, Postscript, PDF, and SVG.  Use ImageMagick to resize, flip, mirror, rotate, distort, shear and transform images, adjust image colors, apply various special effects, or draw text, lines, polygons, ellipses and Bézier curves.</li>
</ul>
</li>
</ul>
<p>在本方案中我们使用工具LabelImage将229张水表图片进行了标注，同时生成了PASCAL格式的XML文件，名字为<code>000001.jpg</code>的图片注释格式如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">annotation</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">folder</span>&gt;</span>imgs<span class="tag">&lt;/<span class="name">folder</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">filename</span>&gt;</span>000001.jpg<span class="tag">&lt;/<span class="name">filename</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">source</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">database</span>&gt;</span>VOC<span class="tag">&lt;/<span class="name">database</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">annotation</span>&gt;</span>PASCAL VOC<span class="tag">&lt;/<span class="name">annotation</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">size</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">width</span>&gt;</span>2448<span class="tag">&lt;/<span class="name">width</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">height</span>&gt;</span>3264<span class="tag">&lt;/<span class="name">height</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">depth</span>&gt;</span>3<span class="tag">&lt;/<span class="name">depth</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">size</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">segmented</span>&gt;</span>0<span class="tag">&lt;/<span class="name">segmented</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">object</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>panel<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">pose</span>&gt;</span>Frontal<span class="tag">&lt;/<span class="name">pose</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">truncated</span>&gt;</span>0<span class="tag">&lt;/<span class="name">truncated</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">difficult</span>&gt;</span>0<span class="tag">&lt;/<span class="name">difficult</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">bndbox</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">xmin</span>&gt;</span>739<span class="tag">&lt;/<span class="name">xmin</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">ymin</span>&gt;</span>430<span class="tag">&lt;/<span class="name">ymin</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">xmax</span>&gt;</span>1475<span class="tag">&lt;/<span class="name">xmax</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">ymax</span>&gt;</span>796<span class="tag">&lt;/<span class="name">ymax</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">bndbox</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">object</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">annotation</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>我们在根目录新建一个<code>annotations</code>的文件夹存储229张图片的XML描述文件，同时根目录<code>images</code>文件夹用于存储所有的训练数据和测试数据。</p>
<h4 id="数据描述格式"><a href="#数据描述格式" class="headerlink" title="数据描述格式"></a>数据描述格式</h4><ul>
<li>在TensorFlow 物体检测API中使用 <a href="https://www.tensorflow.org/api_guides/python/python_io#tfrecords_format_details" target="_blank" rel="noopener">TFRecord file format</a>格式对图像标记信息进行描述，所以我们无论采取下面的那种标记方式，最终需要生成TFRcord格式的文件格式。</li>
<li><strong>TFRecord</strong>格式要去如下：</li>
</ul>
<blockquote>
<p>For every example in your dataset, you should have the following information:</p>
<ol>
<li>An RGB image for the dataset encoded as jpeg or png.</li>
<li>A list of bounding boxes for the image. Each bounding box should contain:<ol>
<li>A bounding box coordinates (with origin in top left corner) defined by 4floating point numbers [ymin, xmin, ymax, xmax]. Note that we store the<em>normalized</em> coordinates (x / width, y / height) in the TFRecord dataset.</li>
<li>The class of the object in the bounding box.</li>
</ol>
</li>
</ol>
</blockquote>
<ul>
<li><p>TensorFlow针对主流的物体识别类数据集格式提供了<a href="https://github.com/tensorflow/models/tree/master/research/object_detection/dataset_tools" target="_blank" rel="noopener">转换工具</a>，包括 <a href="http://host.robots.ox.ac.uk/pascal/VOC/" target="_blank" rel="noopener">PASCAL VOC dataset</a> ， <a href="http://www.robots.ox.ac.uk/~vgg/data/pets/" target="_blank" rel="noopener">Oxford Pet dataset</a>等；</p>
<ul>
<li>PASCAL VOC </li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># From tensorflow/models/research/</span></span><br><span class="line">wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar</span><br><span class="line">tar -xvf VOCtrainval_11-May-2012.tar</span><br><span class="line">python object_detection/dataset_tools/create_pascal_tf_record.py \</span><br><span class="line">    --label_map_path=object_detection/data/pascal_label_map.pbtxt \</span><br><span class="line">    --data_dir=VOCdevkit --year=VOC2012 --<span class="built_in">set</span>=train \</span><br><span class="line">    --output_path=pascal_train.record</span><br><span class="line">python object_detection/dataset_tools/create_pascal_tf_record.py \</span><br><span class="line">    --label_map_path=object_detection/data/pascal_label_map.pbtxt \</span><br><span class="line">    --data_dir=VOCdevkit --year=VOC2012 --<span class="built_in">set</span>=val \</span><br><span class="line">    --output_path=pascal_val.record</span><br></pre></td></tr></table></figure>
<ul>
<li>Oxford-IIIT Pet</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># From tensorflow/models/research/</span></span><br><span class="line">wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz</span><br><span class="line">wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz</span><br><span class="line">tar -xvf annotations.tar.gz</span><br><span class="line">tar -xvf images.tar.gz</span><br><span class="line">python object_detection/dataset_tools/create_pet_tf_record.py \</span><br><span class="line">    --label_map_path=object_detection/data/pet_label_map.pbtxt \</span><br><span class="line">    --data_dir=`<span class="built_in">pwd</span>` \</span><br><span class="line">    --output_dir=`<span class="built_in">pwd</span>`</span><br></pre></td></tr></table></figure>
</li>
<li><p>如果你使用了自己的格式，可以参考<a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/using_your_own_dataset.md" target="_blank" rel="noopener">TensorFlow官方文档</a>完成格式转换；</p>
</li>
</ul>
<p>在本方案中我们采用自己处理的方式来进行格式转换，使用文件<a href="https://github.com/datitran/raccoon_dataset/blob/master/xml_to_csv.py" target="_blank" rel="noopener"><code>xml_to_csv.py</code></a>将所有图片的PASCAL格式文件转化为一个csv文件，然后进一步的利用TensorFLow工具<code>generate_tfrecord.py</code>生成TFRecord格式文件：</p>
<ol>
<li><p>执行<code>python xml_to_csv.py</code>,该文件将在根目录的<code>annotations</code>的文件夹下所有的<code>*xml</code>文件，并生成<code>screen_labels.csv</code>文件；</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">xml_to_csv</span><span class="params">(path)</span>:</span></span><br><span class="line">    xml_list = []</span><br><span class="line">    <span class="keyword">for</span> xml_file <span class="keyword">in</span> glob.glob(path + <span class="string">'/*.xml'</span>):</span><br><span class="line">        tree = ET.parse(xml_file)</span><br><span class="line">        root = tree.getroot()</span><br><span class="line">        <span class="keyword">for</span> member <span class="keyword">in</span> root.findall(<span class="string">'object'</span>):</span><br><span class="line">            filename = root.find(<span class="string">'filename'</span>).text</span><br><span class="line">            value = (root.find(<span class="string">'filename'</span>).text,</span><br><span class="line">                     int(root.find(<span class="string">'size'</span>)[<span class="number">0</span>].text),</span><br><span class="line">                     int(root.find(<span class="string">'size'</span>)[<span class="number">1</span>].text),</span><br><span class="line">                     member[<span class="number">0</span>].text,</span><br><span class="line">                     int(member[<span class="number">4</span>][<span class="number">0</span>].text),</span><br><span class="line">                     int(member[<span class="number">4</span>][<span class="number">1</span>].text),</span><br><span class="line">                     int(member[<span class="number">4</span>][<span class="number">2</span>].text),</span><br><span class="line">                     int(member[<span class="number">4</span>][<span class="number">3</span>].text)</span><br><span class="line">                     )</span><br><span class="line">            xml_list.append(value)</span><br><span class="line">    column_name = [<span class="string">'filename'</span>, <span class="string">'width'</span>, <span class="string">'height'</span>, <span class="string">'class'</span>, <span class="string">'xmin'</span>, <span class="string">'ymin'</span>, <span class="string">'xmax'</span>, <span class="string">'ymax'</span>]</span><br><span class="line">    xml_df = pd.DataFrame(xml_list, columns=column_name)</span><br><span class="line">    <span class="keyword">return</span> xml_df</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    image_path = os.path.join(os.getcwd(), <span class="string">'Annotations'</span>) <span class="comment"># Need Changes</span></span><br><span class="line">    xml_df = xml_to_csv(image_path)</span><br><span class="line">    xml_df.to_csv(<span class="string">'screen_labels.csv'</span>, index=<span class="keyword">None</span>) <span class="comment"># Need Changes</span></span><br><span class="line">    print(<span class="string">'Successfully converted xml to csv.'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol>
<li><p>使用如下代码随机生成训练数据和测试数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">np.random.seed(<span class="number">1</span>)</span><br><span class="line">full_labels = pd.read_csv(<span class="string">'screen_labels.csv'</span>)</span><br><span class="line">gb = full_labels.groupby(<span class="string">'filename'</span>)</span><br><span class="line">grouped_list = [gb.get_group(x) <span class="keyword">for</span> x <span class="keyword">in</span> gb.groups]</span><br><span class="line">train_index = np.random.choice(len(grouped_list), size=<span class="number">180</span>, replace=<span class="keyword">False</span>)</span><br><span class="line">test_index = np.setdiff1d(list(range(<span class="number">229</span>)), train_index)</span><br><span class="line">train = pd.concat([grouped_list[i] <span class="keyword">for</span> i <span class="keyword">in</span> train_index])</span><br><span class="line">test = pd.concat([grouped_list[i] <span class="keyword">for</span> i <span class="keyword">in</span> test_index])</span><br><span class="line">train.to_csv(<span class="string">'train_labels.csv'</span>, index=<span class="keyword">None</span>)</span><br><span class="line">test.to_csv(<span class="string">'test_labels.csv'</span>, index=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>分别执行脚本将训练数据和测试数据转换为TFRecord：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># From tensorflow/models/research/</span></span><br><span class="line">protoc object_detection/protos/*.proto --python_out=.</span><br><span class="line"><span class="comment"># Create train data:</span></span><br><span class="line">  python generate_tfrecord.py --csv_input=data/train_labels.csv  --output_path=train.record</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Create test data:</span></span><br><span class="line">  python generate_tfrecord.py --csv_input=data/test_labels.csv  --output_path=test.record</span><br></pre></td></tr></table></figure>
</li>
<li><p>将train.record和test.record的文件存储至根目录的data文件夹下</p>
</li>
<li><p>至此数据准备基本结束，我们创建了如下目录结构</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── annotations</span><br><span class="line">│   ├── 000001.xml</span><br><span class="line">          ...</span><br><span class="line">│   └── 000229.xml</span><br><span class="line">├── data</span><br><span class="line">│   ├── screen_labels.csv</span><br><span class="line">│   ├── test_labels.csv</span><br><span class="line">│   ├── test.record</span><br><span class="line">│   ├── train_labels.csv</span><br><span class="line">│   └── train.record</span><br><span class="line">├── generate_tfrecord.py</span><br><span class="line">├── images</span><br><span class="line">│   ├── 000001.jpg</span><br><span class="line">         ...</span><br><span class="line">│   └── 000229.jpg</span><br><span class="line">├── __init__.py</span><br><span class="line">├── README.md</span><br><span class="line">├── split labels.ipynb</span><br><span class="line">├── test_generate_tfrecord.py</span><br><span class="line">├── test_xml_to_csv.py</span><br><span class="line">└── xml_to_csv.py</span><br><span class="line">​</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="2-2-模型配置-迁移学习"><a href="#2-2-模型配置-迁移学习" class="headerlink" title="2.2 模型配置/迁移学习"></a>2.2 模型配置/迁移学习</h3><blockquote>
<p>完全从头训练一个用于物体检测的模型即使采用大量GPU资源至少也需要数周时间，为了加速模型初期迭代过程，我们选择了一个已经在COCO数据集针对其他多种物体识别场景预训练好的模型，通过重复使用该模型的多数参数来快速生成我们的模型。更多技术内容可以参照迁移学习的技术实现。</p>
</blockquote>
<p>由于没有足够的资源从头训练一个模型，我们将采用迁移学习技术，利用一个已经训练好的模型进行迁移学习及训练。</p>
<p>从测试角度考虑，本测试方案选择了体积最小，速度最快的用于嵌入式设备的SSD模型：<a href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2017_11_17.tar.gz" target="_blank" rel="noopener">ssd_mobilenet_v1_coco</a></p>
<p>下载模型包，可以得到如下文件：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── object-detection.pbtxt	</span><br><span class="line">├── ssd_mobilenet_v1_pets.config</span><br><span class="line">├── checkpoint</span><br><span class="line">├── frozen_inference_graph.pb</span><br><span class="line">├── model.ckpt.data-00000-of-00001</span><br><span class="line">├── model.ckpt.index</span><br><span class="line">├── model.ckpt.meta</span><br><span class="line">└── saved_model</span><br><span class="line">    ├── saved_model.pb</span><br><span class="line">    └── variables</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>a graph proto (<code>graph.pbtxt</code>)</li>
<li>a checkpoint (<code>model.ckpt.data-00000-of-00001</code>, <code>model.ckpt.index</code>, <code>model.ckpt.meta</code>)</li>
<li>a frozen graph proto with weights baked into the graph as constants (<code>frozen_inference_graph.pb</code>) to be used for out of the box inference</li>
<li>a config file (<code>pipeline.config</code>) which was used to generate the graph. These directly correspond to a config file in the <a href="https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs" target="_blank" rel="noopener">samples/configs</a>) directory but often with a modified score threshold. </li>
</ul>
</blockquote>
<p>我们下载并在根目录解压模型包ssd_mobilenet_v1_coco，同时创建一个training文件，存储如下文件：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">training/</span><br><span class="line">├── object-detection.pbtxt</span><br><span class="line">└── ssd_mobilenet_v1_pets.config</span><br></pre></td></tr></table></figure>
<h4 id="Label-Map"><a href="#Label-Map" class="headerlink" title="Label Map"></a>Label Map</h4><p>其中 <code>object-detection.pbtxt</code>是我们模型所有分类的标签，如下所示，如果有多个分类id从1开始递增，同时给每个标签一个唯一的名称(id为0预留给背景分类)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">item &#123;</span><br><span class="line">  id: 1</span><br><span class="line">  name: <span class="string">'panel'</span></span><br><span class="line">&#125;</span><br><span class="line">item&#123;</span><br><span class="line">  id: 2</span><br><span class="line">  name: <span class="string">'其他分类'</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="配置物体识别训练流程文件"><a href="#配置物体识别训练流程文件" class="headerlink" title="配置物体识别训练流程文件"></a>配置物体识别训练流程文件</h4><blockquote>
<p>更多内容参考：<a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/configuring_jobs.md" target="_blank" rel="noopener">https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/configuring_jobs.md</a></p>
</blockquote>
<p>Tensorflow Object Detection API 使用 protobuf 文件来配置训练和检测的流程。通过配置Training Pipleline的参数配置可以决定训练参数的选择，我们将尽量多的利用已经训练好的参数进行训练。</p>
<p>一个配置文件由5部分组成：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">model &#123;</span><br><span class="line">(... Add model config here...)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">train_config : &#123;</span><br><span class="line">(... Add train_config here...)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">train_input_reader: &#123;</span><br><span class="line">(... Add train_input configuration here...)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">eval_config: &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">eval_input_reader: &#123;</span><br><span class="line">(... Add eval_input configuration here...)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<ol>
<li>The <code>model</code> configuration. This defines what type of model will be trained (ie. meta-architecture, feature extractor).</li>
<li>The <code>train_config</code>, which decides what parameters should be used to train model parameters (ie. SGD parameters, input preprocessing and feature extractor initialization values).</li>
<li>The <code>eval_config</code>, which determines what set of metrics will be reported for evaluation (currently we only support the PASCAL VOC metrics).</li>
<li>The <code>train_input_config</code>, which defines what dataset the model should be trained on.</li>
<li>The <code>eval_input_config</code>, which defines what dataset the model will be evaluated on. Typically this should be different than the training input dataset.</li>
</ol>
</blockquote>
<p><code>ssd_mobilenet_v1_pets.config</code>为模型配置文件，我们在样例(详见：object_detection/samples/configs 文件夹)上进行如下修改：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">  ssd &#123;</span><br><span class="line">    num_classes: 1                 <span class="comment">#修改类别为实际类别值</span></span><br><span class="line">    box_coder &#123;</span><br><span class="line">      faster_rcnn_box_coder &#123;</span><br><span class="line">        y_scale: 10.0</span><br><span class="line">        x_scale: 10.0</span><br><span class="line">        height_scale: 5.0</span><br><span class="line">        width_scale: 5.0</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">fine_tune_checkpoint: <span class="string">"ssd_mobilenet_v1_coco_2017_11_17/model.ckpt"</span> <span class="comment">#指向模型文件中的checkpoint文件</span></span><br><span class="line">train_input_reader: &#123;                                               </span><br><span class="line">  tf_record_input_reader &#123;</span><br><span class="line">    input_path: <span class="string">"data/train.record"</span>              <span class="comment">#修改为上一个步骤生成的训练record路径</span></span><br><span class="line">  &#125;</span><br><span class="line">  label_map_path: <span class="string">"data/object-detection.pbtxt"</span>  <span class="comment">#修改为pbtxt文件路径，描述类别标签</span></span><br><span class="line">&#125;</span><br><span class="line">eval_input_reader: &#123;</span><br><span class="line">  tf_record_input_reader &#123;</span><br><span class="line">    input_path: <span class="string">"data/test.record"</span>           <span class="comment">#修改为上一个步骤生成的测试数据record路径</span></span><br><span class="line">  &#125;</span><br><span class="line">  label_map_path: <span class="string">"data/object-detection.pbtxt"</span> <span class="comment">#修改为pbtxt文件路径，描述类别标签</span></span><br><span class="line">  shuffle: <span class="literal">false</span></span><br><span class="line">  num_readers: 1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>train_config</code> provides two fields to specify pre-existing checkpoints: <code>fine_tune_checkpoint</code> and <code>from_detection_checkpoint</code>. <code>fine_tune_checkpoint</code> should provide a path to the pre-existing checkpoint (ie:”/usr/home/username/checkpoint/model.ckpt-#####”). <code>from_detection_checkpoint</code> is a boolean value. If false, it assumes the checkpoint was from an object classification checkpoint. Note that starting from a detection checkpoint will usually result in a faster training job than a classification checkpoint.</p>
<p>The list of provided checkpoints can be found <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md" target="_blank" rel="noopener">here</a>.</p>
</blockquote>
<h3 id="2-3-训练"><a href="#2-3-训练" class="headerlink" title="2.3 训练"></a>2.3 训练</h3><h4 id="Tensorflow-Object-Detection-API-安装"><a href="#Tensorflow-Object-Detection-API-安装" class="headerlink" title="Tensorflow Object Detection API 安装"></a>Tensorflow Object Detection API 安装</h4><ol>
<li><p>从GitHub下载Tensorflow Object Detection API</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/tensorflow/models.git</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置基本环境</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># For CPU</span></span><br><span class="line">pip install tensorflow</span><br><span class="line"><span class="comment"># For GPU</span></span><br><span class="line">pip install tensorflow-gpu</span><br><span class="line"></span><br><span class="line">sudo apt-get install protobuf-compiler python-pil python-lxml python-tk</span><br><span class="line">pip install --user Cython</span><br><span class="line">pip install --user contextlib2</span><br><span class="line">pip install --user jupyter</span><br><span class="line">pip install --user matplotlib</span><br></pre></td></tr></table></figure>
</li>
<li><p>COCO API installation</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/cocodataset/cocoapi.git</span><br><span class="line">cd cocoapi/PythonAPI</span><br><span class="line">make</span><br><span class="line">cp -r pycocotools &lt;path_to_tensorflow&gt;/models/research/</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol>
<li>Protobuf 编译</li>
</ol>
<p>Tensorflow通过Google的Protobufs来配置和训练模型，所以在开始使用之前需要对protobuf相关库进行编译。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># From tensorflow/models/research/</span></span><br><span class="line">protoc object_detection/protos/*.proto --python_out=.</span><br></pre></td></tr></table></figure>
<ol>
<li>Add Libraries to PYTHONPATH[<strong>重要</strong>]</li>
</ol>
<p>在路径 <code>tensorflow/models/research/</code> 下添加PYTHONPATH路径，实现全局引用</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># From tensorflow/models/research/</span></span><br><span class="line"><span class="built_in">export</span> PYTHONPATH=<span class="variable">$PYTHONPATH</span>:`<span class="built_in">pwd</span>`:`<span class="built_in">pwd</span>`/slim</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>Note:</strong> This command needs to run from every new terminal you start. If you wish to avoid running this manually, you can add it as a new line to the end of your ~/.bashrc file.</p>
</blockquote>
<ol>
<li><p>测试安装是否成功</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># From tensorflow/models/research/</span></span><br><span class="line">python object_detection/builders/model_builder_test.py</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="启动训练过程"><a href="#启动训练过程" class="headerlink" title="启动训练过程"></a>启动训练过程</h4><ol>
<li><p>将在数据准备和模型配置阶段的文件复制到tensorflow object_detect文件夹下<code>/models/research/object_detection</code>,包括data/文件夹，image/文件夹，training/文件夹，ssd_mobilenet_v1_coco_2017_11_17/原始模型文件夹</p>
</li>
<li><p>执行如下代码启动训练过程：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># From the tensorflow/models/research/ directory</span></span><br><span class="line">PIPELINE_CONFIG_PATH=&#123;path to pipeline config file&#125;</span><br><span class="line">MODEL_DIR=&#123;path to model directory&#125;</span><br><span class="line">NUM_TRAIN_STEPS=50000</span><br><span class="line">SAMPLE_1_OF_N_EVAL_EXAMPLES=1</span><br><span class="line">python object_detection/model_main.py \</span><br><span class="line">    --pipeline_config_path=<span class="variable">$&#123;PIPELINE_CONFIG_PATH&#125;</span> \</span><br><span class="line">    --model_dir=<span class="variable">$&#123;MODEL_DIR&#125;</span> \</span><br><span class="line">    --num_train_steps=<span class="variable">$&#123;NUM_TRAIN_STEPS&#125;</span> \</span><br><span class="line">    --sample_1_of_n_eval_examples=<span class="variable">$SAMPLE_1_OF_N_EVAL_EXAMPLES</span> \</span><br><span class="line">    --alsologtostderr</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="使用TensorBoard-跟踪训练过程"><a href="#使用TensorBoard-跟踪训练过程" class="headerlink" title="使用TensorBoard 跟踪训练过程"></a>使用TensorBoard 跟踪训练过程</h4><p>训练过程会持续几个小时到十几个小时，可以通过tensorboard查看训练的情况</p>
<p>使用一台Azure的CPU虚拟机进行训练~4s进行一次迭代，正常模型有比较不错结果迭代次数大概在10K以上。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir=<span class="variable">$&#123;MODEL_DIR&#125;</span></span><br></pre></td></tr></table></figure>
<p><img src="/qnsource/images/2018-04-14-TensorFlow-Object-Detection-API/tensorboard_loss.PNG" alt="tensorboard_loss"></p>
<h3 id="2-4-导出模型"><a href="#2-4-导出模型" class="headerlink" title="2.4 导出模型"></a>2.4 导出模型</h3><p>模型训练过程中，会每隔一段时间生成一个checkpoint，一个checkpoint至少包括三个文件：</p>
<ul>
<li>model.ckpt-${CHECKPOINT_NUMBER}.data-00000-of-00001</li>
<li>model.ckpt-${CHECKPOINT_NUMBER}.index</li>
<li>model.ckpt-${CHECKPOINT_NUMBER}.meta</li>
</ul>
<p>可以通过如下命令从checkpoints中提取模型：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Example Usage:</span><br><span class="line">--------------</span><br><span class="line">python export_inference_graph \</span><br><span class="line">    --input_type image_tensor \</span><br><span class="line">    --pipeline_config_path path/to/ssd_inception_v2.config \</span><br><span class="line">    --trained_checkpoint_prefix path/to/model.ckpt \</span><br><span class="line">    --output_directory path/to/exported_model_directory</span><br><span class="line">    </span><br><span class="line">    -----</span><br><span class="line">The expected output would be <span class="keyword">in</span> the directory</span><br><span class="line">path/to/exported_model_directory (<span class="built_in">which</span> is created <span class="keyword">if</span> it does not exist)</span><br><span class="line">with contents:</span><br><span class="line"> - graph.pbtxt</span><br><span class="line"> - model.ckpt.data-00000-of-00001</span><br><span class="line"> - model.ckpt.info</span><br><span class="line"> - model.ckpt.meta</span><br><span class="line"> - frozen_inference_graph.pb</span><br><span class="line"> + saved_model (a directory)</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># From tensorflow/models/research/</span></span><br><span class="line"><span class="built_in">export</span> PYTHONPATH=<span class="variable">$PYTHONPATH</span>:`<span class="built_in">pwd</span>`:`<span class="built_in">pwd</span>`/slim</span><br><span class="line">python export_inference_graph.py \</span><br><span class="line">    --input_type image_tensor \</span><br><span class="line">    --pipeline_config_path training/ssd_mobilenet_v1_pets.config \</span><br><span class="line">    --trained_checkpoint_prefix training/model.ckpt-10116 \</span><br><span class="line">    --output_directory water_meter_panel</span><br><span class="line">-----</span><br><span class="line">INPUT_TYPE=image_tensor</span><br><span class="line">PIPELINE_CONFIG_PATH=<span class="string">"object_detection/training/pipeline.config"</span></span><br><span class="line">TRAINED_CKPT_PREFIX=/home/ubuntu/1.objectDetection/training/model.ckpt-14450</span><br><span class="line">EXPORT_DIR=/home/ubuntu/1.objectDetection/<span class="built_in">export</span></span><br><span class="line"></span><br><span class="line">$ python object_detection/export_inference_graph.py \</span><br><span class="line">    --input_type=<span class="variable">$&#123;INPUT_TYPE&#125;</span> \</span><br><span class="line">    --pipeline_config_path=<span class="variable">$&#123;PIPELINE_CONFIG_PATH&#125;</span> \</span><br><span class="line">    --trained_checkpoint_prefix=<span class="variable">$&#123;TRAINED_CKPT_PREFIX&#125;</span> \</span><br><span class="line">    --output_directory=<span class="variable">$&#123;EXPORT_DIR&#125;</span></span><br><span class="line"></span><br><span class="line">-----</span><br><span class="line">WARNING:tensorflow:From /home/gaoc/data/<span class="built_in">test</span>/object_detect/models/research/object_detection/exporter.py:357: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed <span class="keyword">in</span> a future version.</span><br><span class="line">Instructions <span class="keyword">for</span> updating:</span><br><span class="line">Please switch to tf.train.get_or_create_global_step</span><br><span class="line">2018-01-20 06:34:08.551446: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA</span><br><span class="line">2018-01-20 06:34:14.056881: I tensorflow/core/grappler/devices.cc:51] Number of eligible GPUs (core count &gt;= 8): 0</span><br><span class="line">Converted 199 variables to const ops.</span><br></pre></td></tr></table></figure>
<blockquote>
<p>如果<code>Exportor.py</code>文件报bug，请参考<a href="https://github.com/tensorflow/models/issues/2861" target="_blank" rel="noopener">https://github.com/tensorflow/models/issues/2861</a> 修复</p>
</blockquote>
<p>运行以上代码，将在<code>water_meter_panel</code>文件夹下生成模型所需的相关文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">gaoc@DataScience:~/data/<span class="built_in">test</span>/object_detect/models/research/object_detection$ ls -l water_meter_panel/</span><br><span class="line">total 44820</span><br><span class="line">-rw-r--r-- 1 gaoc root       77 Jan 20 06:34 checkpoint</span><br><span class="line">-rw-r--r-- 1 gaoc root 22636802 Jan 20 06:34 frozen_inference_graph.pb</span><br><span class="line">-rw-r--r-- 1 gaoc root 22174240 Jan 20 06:34 model.ckpt.data-00000-of-00001</span><br><span class="line">-rw-r--r-- 1 gaoc root     8873 Jan 20 06:34 model.ckpt.index</span><br><span class="line">-rw-r--r-- 1 gaoc root  1058139 Jan 20 06:34 model.ckpt.meta</span><br><span class="line">drwxr-xr-x 3 gaoc root     4096 Jan 20 06:34 saved_model</span><br><span class="line">water_meter_panel/</span><br><span class="line">├── checkpoint</span><br><span class="line">├── frozen_inference_graph.pb</span><br><span class="line">├── model.ckpt.data-00000-of-00001</span><br><span class="line">├── model.ckpt.index</span><br><span class="line">├── model.ckpt.meta</span><br><span class="line">└── saved_model</span><br><span class="line">    ├── saved_model.pb</span><br><span class="line">    └── variables</span><br></pre></td></tr></table></figure>
<h3 id="2-5-测试"><a href="#2-5-测试" class="headerlink" title="2.5 测试"></a>2.5 测试</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># From the tensorflow/models/research/ directory</span></span><br><span class="line">python object_detection/eval.py \</span><br><span class="line">    --logtostderr \</span><br><span class="line">    --pipeline_config_path=<span class="variable">$&#123;PATH_TO_YOUR_PIPELINE_CONFIG&#125;</span> \</span><br><span class="line">    --checkpoint_dir=<span class="variable">$&#123;PATH_TO_TRAIN_DIR&#125;</span> \</span><br><span class="line">    --eval_dir=<span class="variable">$&#123;PATH_TO_EVAL_DIR&#125;</span></span><br></pre></td></tr></table></figure>
<p>物体识别领域的算法性能评价指标多数选择AP和mAP（mean average precision），多个类别物体检测中，每一个类别都可以根据recall和precision绘制一条曲线，AP就是该曲线下的面积，mAP是多个类别AP的平均值</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Average Precision (AP):</span><br><span class="line">AP% AP at IoU=.50:.05:.95 (primary challenge metric) APIoU=.50% AP at IoU=.50 (PASCAL VOC metric) APIoU=.75% AP at IoU=.75 (strict metric) </span><br><span class="line">AP Across Scales:</span><br><span class="line">APsmall% AP <span class="keyword">for</span> small objects: area &lt; 322 APmedium% AP <span class="keyword">for</span> medium objects: 322 &lt; area &lt; 962 APlarge% AP <span class="keyword">for</span> large objects: area &gt; 962 </span><br><span class="line">Average Recall (AR):</span><br><span class="line">ARmax=1% AR given 1 detection per image ARmax=10% AR given 10 detections per image ARmax=100% AR given 100 detections per image </span><br><span class="line">AR Across Scales:</span><br><span class="line">ARsmall% AR <span class="keyword">for</span> small objects: area &lt; 322 ARmedium% AR <span class="keyword">for</span> medium objects: 322 &lt; area &lt; 962 ARlarge% AR <span class="keyword">for</span> large objects: area &gt; 962</span><br></pre></td></tr></table></figure>
<p><img src="/qnsource/images/2018-04-14-TensorFlow-Object-Detection-API/AP_MAP.PNG" alt="AP_MAP"></p>
<p>从性能测试结果来看该模型已经具备96%的检测精度了，具备投入生产环境所需的性能。</p>
<p>预测结果见下图，准确率达到了99%以上。</p>
<p><img src="/qnsource/images/2018-04-14-TensorFlow-Object-Detection-API/detect_demo.png" alt="detect_demo"></p>
<h2 id="3-结论"><a href="#3-结论" class="headerlink" title="3. 结论"></a>3. 结论</h2><ul>
<li>对于简单业务场景的物体识别类案例，可以通过迁移学习利用已有的成熟模型快速迭代生成新的特定模型；</li>
<li>这种迁移的另一个优势是对小数据样本具备很好的适应能力，可以解决前期数据不足和数据质量差的问题；</li>
<li>当然采用这种方式也同时存在一定的弊端，比如由于模型预训练参数较多，模型体积较大，模型的选取需要反复测试和优化。</li>
</ul>
<h3 id="3-1-经验总结"><a href="#3-1-经验总结" class="headerlink" title="3.1 经验总结"></a>3.1 经验总结</h3><ol>
<li><p>虽然Tensorflow Object Detection API提供了丰富的文档介绍相关工作流程，但由于技术、平台和软件版本本身更新较快，实践中还是或多或少会遇到不少问题，静下心来多翻翻Github的issues里一般都有别人的提问及解答；建议还是先根据文档跑通demo，熟悉相关工具和流程再将框架迁移到自己的数据集之上；</p>
</li>
<li><p>建议自己识别的项目文件单独建立一个数据准备文件夹进行数据准备和相关配置脚本的准备，不要跟Github克隆的Object Detection项目混在一起，不容易管理，也不利于重复利用；</p>
</li>
<li><p>TFOD API提供的Tensorflow可视化相当完备，启动训练任务之后，一定要同步启动验证脚本，可以实时跟踪训练进程；</p>
</li>
<li><p>很容易疏忽的一个步骤是关于PYTHON PATH的处理，在执行相关API之前一定要记得EXPORT相关path，可以些一个bash文件，在执行命令的Terminal中source一下；常见错误如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ImportError: No module named ’object_detection’</span><br></pre></td></tr></table></figure>
</li>
<li><p>充分利用GPU和CPU进行训练：</p>
<ol>
<li><p>如果使用CPU训练，控制配置参数中<code>num_examples</code>为一个很小的值（5-10），这样将使用验证数据中的一部分进行验证而不是全部；</p>
</li>
<li><p>配置<code>CUDA_VISIBLE_DEVICES</code>环境变量，选择使用哪个GPU或CPU来分配内存资源：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ export CUDA_VISIBLE_DEVICES="0"</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ export CUDA_VISIBLE_DEVICES="1"</span><br><span class="line">... another scripts</span><br></pre></td></tr></table></figure>
<p>配置为空使用CPU</p>
</li>
</ol>
</li>
<li><p>尽量使用最新版的Tensorflow，在撰写本文时已经是1.7了，当时做实验用的是1.4，复现的时候发现1.4版本已经抛错了…</p>
</li>
</ol>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote id="fn_1">
<sup>1</sup>. The TensorFlow Object Detection API is an open source framework built on top of TensorFlow that makes it easy to construct, train and deploy object detection models.<a href="#reffn_1" title="Jump back to footnote [1] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_2">
<sup>2</sup>. See <a href="http://cocodataset.org/#detections-eval" target="_blank" rel="noopener">MSCOCO evaluation protocol</a>.<a href="#reffn_2" title="Jump back to footnote [2] in the text."> &#8617;</a>
</blockquote>
<ol>
<li><a href="https://www.kernix.com/blog/image-classification-with-a-pre-trained-deep-neural-network_p11" target="_blank" rel="noopener">Image classification with a pre-trained deep neural network</a></li>
<li><a href="https://towardsdatascience.com/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9" target="_blank" rel="noopener">How to train your own Object Detector with TensorFlow’s Object Detector API</a></li>
<li><a href="https://github.com/datitran/raccoon_dataset" target="_blank" rel="noopener">https://github.com/datitran/raccoon_dataset</a></li>
</ol>

      
    </div>
    <footer class="article-footer">

      
      

      
      <!--  -->

      <!--  -->
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/">AI</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/人工智能/">人工智能</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/实践/">实践</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/工具/">工具</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/物体识别/">物体识别</a></li></ul>

    </footer>
  </div>
  
</article>

<!-- Table of Contents -->


  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/8/">&laquo; 上一页</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><a class="page-number" href="/page/8/">8</a><span class="page-number current">9</span><a class="page-number" href="/page/10/">10</a><a class="page-number" href="/page/11/">11</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><a class="extend next" rel="next" href="/page/10/">下一页 &raquo;</a>
  </nav>

</section>
          <aside id="sidebar">
  
    <div class="widget-wrap">
<h3 class="widget-title">不积跬步无以至千里！</h3>
<div class="widget">
  <canvas id="c" style="background: url(/qnsource/site/window.jpg) no-repeat; 
  background-size: cover;"></canvas>
  <script type="text/javascript">

  	var width = 200,
  	height = 150,
  	physics_accuracy = 3,
	mouse_influence = 20,
	mouse_cut = 5,
	gravity = 1200,
	cloth_height = 29,
	cloth_width = 30,
	start_y = 10,
	spacing = (width-15)/cloth_width,
	tear_distance = 60;

	window.requestAnimFrame = window.requestAnimationFrame || window.webkitRequestAnimationFrame || window.mozRequestAnimationFrame || window.oRequestAnimationFrame || window.msRequestAnimationFrame ||
	function(callback) {
	    window.setTimeout(callback, 1000 / 60);
	};

	var canvas, ctx, cloth, boundsx, boundsy, mouse = {
	    down: false,
	    button: 1,
	    x: 0,
	    y: 0,
	    px: 0,
	    py: 0
	};

	var Point = function(x, y) {

	    this.x = x;
	    this.y = y;
	    this.px = x;
	    this.py = y;
	    this.vx = 0;
	    this.vy = 0;
	    this.pin_x = null;
	    this.pin_y = null;

	    this.constraints = [];
	};

	Point.prototype.update = function(delta) {

	    if (mouse.down) {

	        var diff_x = this.x - mouse.x,
	        diff_y = this.y - mouse.y,
	        dist = Math.sqrt(diff_x * diff_x + diff_y * diff_y);

	        if (mouse.button == 1) {

	            if (dist < mouse_influence) {
	                this.px = this.x - (mouse.x - mouse.px) * 1.8;
	                this.py = this.y - (mouse.y - mouse.py) * 1.8;
	            }

	        } else if (dist < mouse_cut) this.constraints = [];
	    }

	    this.add_force(0, gravity);

	    delta *= delta;
	    nx = this.x + ((this.x - this.px) * .99) + ((this.vx / 2) * delta);
	    ny = this.y + ((this.y - this.py) * .99) + ((this.vy / 2) * delta);

	    this.px = this.x;
	    this.py = this.y;

	    this.x = nx;
	    this.y = ny;

	    this.vy = this.vx = 0
	};

	Point.prototype.draw = function() {

	    if (this.constraints.length <= 0) return;

	    var i = this.constraints.length;
	    while (i--) this.constraints[i].draw();
	};

	Point.prototype.resolve_constraints = function() {

	    if (this.pin_x != null && this.pin_y != null) {

	        this.x = this.pin_x;
	        this.y = this.pin_y;
	        return;
	    }

	    var i = this.constraints.length;
	    while (i--) this.constraints[i].resolve();

	    if (this.x > boundsx) {

	        this.x = 2 * boundsx - this.x;

	    } else if (this.x < 1) {

	        this.x = 2 - this.x;
	    }

	    if (this.y > boundsy) {

	        this.y = 2 * boundsy - this.y;

	    } else if (this.y < 1) {

	        this.y = 2 - this.y;
	    }
	};

	Point.prototype.attach = function(point) {

	    this.constraints.push(new Constraint(this, point));
	};

	Point.prototype.remove_constraint = function(lnk) {

	    var i = this.constraints.length;
	    while (i--) if (this.constraints[i] == lnk) this.constraints.splice(i, 1);
	};

	Point.prototype.add_force = function(x, y) {

	    this.vx += x;
	    this.vy += y;
	};

	Point.prototype.pin = function(pinx, piny) {
	    this.pin_x = pinx;
	    this.pin_y = piny;
	};

	var Constraint = function(p1, p2) {

	    this.p1 = p1;
	    this.p2 = p2;
	    this.length = spacing;
	};

	Constraint.prototype.resolve = function() {

	    var diff_x = this.p1.x - this.p2.x,
	    diff_y = this.p1.y - this.p2.y,
	    dist = Math.sqrt(diff_x * diff_x + diff_y * diff_y),
	    diff = (this.length - dist) / dist;

	    if (dist > tear_distance) this.p1.remove_constraint(this);

	    var px = diff_x * diff * 0.5;
	    var py = diff_y * diff * 0.5;

	    this.p1.x += px;
	    this.p1.y += py;
	    this.p2.x -= px;
	    this.p2.y -= py;
	};

	Constraint.prototype.draw = function() {

	    ctx.moveTo(this.p1.x, this.p1.y);
	    ctx.lineTo(this.p2.x, this.p2.y);
	};

	var Cloth = function() {

	    this.points = [];

	    var start_x = canvas.width / 2 - cloth_width * spacing / 2;

	    for (var y = 0; y <= cloth_height; y++) {

	        for (var x = 0; x <= cloth_width; x++) {

	            var p = new Point(start_x + x * spacing, start_y + y * spacing);

	            x != 0 && p.attach(this.points[this.points.length - 1]);
	            y == 0 && p.pin(p.x, p.y);
	            y != 0 && p.attach(this.points[x + (y - 1) * (cloth_width + 1)])

	            this.points.push(p);
	        }
	    }
	};

	Cloth.prototype.update = function() {

	    var i = physics_accuracy;

	    while (i--) {
	        var p = this.points.length;
	        while (p--) this.points[p].resolve_constraints();
	    }

	    i = this.points.length;
	    while (i--) this.points[i].update(.016);
	};

	Cloth.prototype.draw = function() {

	    ctx.beginPath();

	    var i = cloth.points.length;
	    while (i--) cloth.points[i].draw();

	    ctx.stroke();
	};

	function update() {

	    ctx.clearRect(0, 0, canvas.width, canvas.height);

	    cloth.update();
	    cloth.draw();

	    requestAnimFrame(update);
	}

	function start() {

	    canvas.onmousedown = function(e) {
	        mouse.button = e.which;
	        mouse.px = mouse.x;
	        mouse.py = mouse.y;
	        var rect = canvas.getBoundingClientRect();
	        mouse.x = e.clientX - rect.left,
	        mouse.y = e.clientY - rect.top,
	        mouse.down = true;
	        e.preventDefault();
	    };

	    canvas.onmouseup = function(e) {
	        mouse.down = false;
	        e.preventDefault();
	    };

	    canvas.onmousemove = function(e) {
	        mouse.px = mouse.x;
	        mouse.py = mouse.y;
	        var rect = canvas.getBoundingClientRect();
	        mouse.x = e.clientX - rect.left,
	        mouse.y = e.clientY - rect.top,
	        e.preventDefault();
	    };

	    canvas.oncontextmenu = function(e) {
	        e.preventDefault();
	    };

	    boundsx = canvas.width - 1;
	    boundsy = canvas.height - 1;

	    ctx.strokeStyle = '#fff';
	    cloth = new Cloth();
	    update();
	}

	window.onload = function() {

	    canvas = document.getElementById('c');
	    ctx = canvas.getContext('2d');

	    canvas.width = width;
	    canvas.height = height;

	    start();
	};

  </script>
</div>
</div>
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">关注我</h3>
    <div class="widget widget_athemes_social_icons">

    	<ul class="clearfix widget-social-icons">   
    	
          
     			  <li><a href="https://github.com/ddebby" title="Github"><i class="fa fa-github" aria-hidden="true"></i></a></li> 
          
   		
          
     			  <li><a href="https://weibo.com/ddebby" title="Weibo"><i class="fa fa-weibo" aria-hidden="true"></i></a></li> 
          
   		
          
     			  <li><a href="https://twitter.com/ebbydd" title="Twitter"><i class="fa fa-twitter" aria-hidden="true"></i></a></li> 
          
   		
          
     			  <li><a href="" title="Facebook"><i class="fa fa-facebook" aria-hidden="true"></i></a></li> 
          
   		
          
     			  <li><a href="" title="Google-plus"><i class="fa fa-google-plus" aria-hidden="true"></i></a></li> 
          
   		
          
     			  <li><a href="" title="Instagram"><i class="fa fa-instagram" aria-hidden="true"></i></a></li> 
          
   		
          
     			  <li><a href="" title="Pinterest"><i class="fa fa-pinterest" aria-hidden="true"></i></a></li> 
          
   		
          
     			  <li><a href="" title="Flickr"><i class="fa fa-flickr" aria-hidden="true"></i></a></li> 
          
   		
          
            <li><a href="mailto:ebby.dd@gmail.com?subject=请联系我&body=我能帮你什么" title="email"><i class="fa fa-envelope" aria-hidden="true"></i></a></li> 
          
   		
   		</ul>


   		<!--
   		<ul class="clearfix widget-social-icons">   		
   		<li class="widget-si-twitter"><a href="http://twitter.com" title="Twitter"><i class="ico-twitter"></i></a></li> 
		<li class="widget-si-facebook"><a href="http://facebook.com" title="Facebook"><i class="ico-facebook"></i></a></li>
			<li class="widget-si-gplus"><a href="http://plus.google.com" title="Google+"><i class="ico-gplus"></i></a></li>
			<li class="widget-si-pinterest"><a href="http://pinterest.com" title="Pinterest"><i class="ico-pinterest"></i></a></li>
			<li class="widget-si-flickr"><a href="http://flickr.com" title="Flickr"><i class="ico-flickr"></i></a></li>
			<li class="widget-si-instagram"><a href="http://instagram.com" title="Instagram"><i class="ico-instagram"></i></a></li>
		</ul> -->

    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/云存储/">云存储</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/动手实践营/">动手实践营</a><span class="category-list-count">11</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/动手实践营/机器视觉/">机器视觉</a><span class="category-list-count">2</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/工作总结/">工作总结</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/工具/">工具</a><span class="category-list-count">9</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/工具/Keras/">Keras</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/工具/MarkDown/">MarkDown</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/工具/机器视觉/">机器视觉</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/深度学习/">深度学习</a><span class="category-list-count">14</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/深度学习/基础知识/">基础知识</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/深度学习/机器视觉/">机器视觉</a><span class="category-list-count">2</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法/">算法</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/算法/迁移学习/">迁移学习</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/读书笔记/">读书笔记</a><span class="category-list-count">10</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/读书笔记/机器视觉/">机器视觉</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/读书笔记/课程笔记/">课程笔记</a><span class="category-list-count">5</span></li></ul></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/AI/" style="font-size: 17px;">AI</a> <a href="/tags/Ceph/" style="font-size: 11px;">Ceph</a> <a href="/tags/Fast-ai/" style="font-size: 10px;">Fast.ai</a> <a href="/tags/FastText/" style="font-size: 10px;">FastText</a> <a href="/tags/Git/" style="font-size: 10px;">Git</a> <a href="/tags/Ipython/" style="font-size: 10px;">Ipython</a> <a href="/tags/JupyterNotebook/" style="font-size: 10px;">JupyterNotebook</a> <a href="/tags/Keras/" style="font-size: 10px;">Keras</a> <a href="/tags/Markdown/" style="font-size: 10px;">Markdown</a> <a href="/tags/Numpy/" style="font-size: 10px;">Numpy</a> <a href="/tags/OpenCV/" style="font-size: 10px;">OpenCV</a> <a href="/tags/Pandas/" style="font-size: 10px;">Pandas</a> <a href="/tags/Prophet/" style="font-size: 10px;">Prophet</a> <a href="/tags/Python/" style="font-size: 10px;">Python</a> <a href="/tags/SARIMA/" style="font-size: 10px;">SARIMA</a> <a href="/tags/Time-Series/" style="font-size: 10px;">Time Series</a> <a href="/tags/word2vec/" style="font-size: 11px;">word2vec</a> <a href="/tags/书籍/" style="font-size: 10px;">书籍</a> <a href="/tags/云存储/" style="font-size: 11px;">云存储</a> <a href="/tags/人工智能/" style="font-size: 20px;">人工智能</a> <a href="/tags/优化/" style="font-size: 10px;">优化</a> <a href="/tags/公开课/" style="font-size: 10px;">公开课</a> <a href="/tags/博客/" style="font-size: 10px;">博客</a> <a href="/tags/原理解析/" style="font-size: 10px;">原理解析</a> <a href="/tags/可视化/" style="font-size: 10px;">可视化</a> <a href="/tags/图像分类/" style="font-size: 11px;">图像分类</a> <a href="/tags/实践/" style="font-size: 12px;">实践</a> <a href="/tags/实验/" style="font-size: 10px;">实验</a> <a href="/tags/工具/" style="font-size: 11px;">工具</a> <a href="/tags/工具使用/" style="font-size: 11px;">工具使用</a> <a href="/tags/工程实践/" style="font-size: 10px;">工程实践</a> <a href="/tags/开放数据集/" style="font-size: 11px;">开放数据集</a> <a href="/tags/开源平台/" style="font-size: 10px;">开源平台</a> <a href="/tags/总结/" style="font-size: 11px;">总结</a> <a href="/tags/感悟/" style="font-size: 10px;">感悟</a> <a href="/tags/感知机/" style="font-size: 10px;">感知机</a> <a href="/tags/技巧/" style="font-size: 12px;">技巧</a> <a href="/tags/技术/" style="font-size: 11px;">技术</a> <a href="/tags/支持向量机/" style="font-size: 10px;">支持向量机</a> <a href="/tags/教学/" style="font-size: 12px;">教学</a> <a href="/tags/数据集/" style="font-size: 10px;">数据集</a> <a href="/tags/文献/" style="font-size: 18px;">文献</a> <a href="/tags/时序数据/" style="font-size: 11px;">时序数据</a> <a href="/tags/机器学习/" style="font-size: 13px;">机器学习</a> <a href="/tags/机器视觉/" style="font-size: 16px;">机器视觉</a> <a href="/tags/模型/" style="font-size: 11px;">模型</a> <a href="/tags/正则化/" style="font-size: 10px;">正则化</a> <a href="/tags/物体识别/" style="font-size: 12px;">物体识别</a> <a href="/tags/特征抽取/" style="font-size: 10px;">特征抽取</a> <a href="/tags/神经网络/" style="font-size: 10px;">神经网络</a> <a href="/tags/笔记/" style="font-size: 15px;">笔记</a> <a href="/tags/策略/" style="font-size: 10px;">策略</a> <a href="/tags/算法/" style="font-size: 19px;">算法</a> <a href="/tags/线性回归/" style="font-size: 11px;">线性回归</a> <a href="/tags/网络复现/" style="font-size: 14px;">网络复现</a> <a href="/tags/词向量/" style="font-size: 10px;">词向量</a> <a href="/tags/词嵌入/" style="font-size: 11px;">词嵌入</a> <a href="/tags/读书笔记/" style="font-size: 13px;">读书笔记</a> <a href="/tags/资源调度/" style="font-size: 10px;">资源调度</a> <a href="/tags/迁移学习/" style="font-size: 10px;">迁移学习</a> <a href="/tags/逻辑回归/" style="font-size: 11px;">逻辑回归</a> <a href="/tags/部署/" style="font-size: 11px;">部署</a> <a href="/tags/配置/" style="font-size: 10px;">配置</a> <a href="/tags/预处理/" style="font-size: 11px;">预处理</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>

    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">五月 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">二月 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">一月 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">十二月 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">十一月 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">九月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">八月 2018</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">七月 2018</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">六月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">五月 2018</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">四月 2018</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">三月 2018</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">二月 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">一月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">二月 2017</a><span class="archive-list-count">2</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/05/07/Pathlib-Python的路径管理库/">Pathlib--Python的路径管理库</a>
          </li>
        
          <li>
            <a href="/2019/02/01/从头训练一个图像分类器/">从头训练一个图像分类器</a>
          </li>
        
          <li>
            <a href="/2019/01/24/2018年总结：来自18年的工作感悟/">2018年总结：来自18年的工作感悟</a>
          </li>
        
          <li>
            <a href="/2019/01/12/Batch-Normalization-批量归一化/">Batch-Normalization(批量归一化)</a>
          </li>
        
          <li>
            <a href="/2019/01/02/数据科学工具——Pandas/">数据科学工具——Pandas</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <!--        
        <div align="center" style="margin-top: 30px;"><hr class="hr" style="margin:0px; height:3px;"></div>
       -->
      <footer id="footer">
  

  <div class="container">
      	<div class="row">
	      <p> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/iTimeTraveler/hexo-theme-hiker" target="_blank">Hexo-theme-hiker</a> </p>
	      <p id="copyRightEn">Copyright &copy; 2017 - 2020 Ebby&#39;s Notes All Rights Reserved.</p>
	      
	      
  		   	<p id="copyRightCn">Ebby DD 保留所有权利 沪ICP备20005404号</p>
  		   
		</div>

		
  </div>
</footer>


<!-- min height -->

<script>
    var wrapdiv = document.getElementById("wrap");
    var contentdiv = document.getElementById("content");
    var allheader = document.getElementById("allheader");

    wrapdiv.style.minHeight = document.body.offsetHeight + "px";
    if (allheader != null) {
      contentdiv.style.minHeight = document.body.offsetHeight - allheader.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    } else {
      contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    }
</script>
    </div>    
    <!-- <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
    <a href="/reading" class="mobile-nav-link">Reading</a>
  
    <a href="/resources" class="mobile-nav-link">Resources</a>
  
    <a href="/notebooks" class="mobile-nav-link">📝</a>
  
</nav> -->
    

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">

</script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/scripts.js"></script>


  <script src="/js/home.js"></script>













	<script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?684368b6943d7a5b6689dba5e7bf30ad";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  </div>

  <div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true" style="display: none;">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h2 class="modal-title" id="myModalLabel">设置</h2>
      </div>
      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">


      <div class="modal-body">
          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseOne" onclick="javascript:setFontSize();" aria-expanded="true" aria-controls="collapseOne">
              正文字号大小
            </a>
          </div>
          <div id="collapseOne" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingOne">
          <div class="panel-body">
            您已调整页面字体大小
          </div>
        </div>
      


          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseTwo" onclick="javascript:setBackground();" aria-expanded="true" aria-controls="collapseTwo">
              夜间护眼模式
            </a>
        </div>
          <div id="collapseTwo" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTwo">
          <div class="panel-body">
            夜间模式已经开启，再次单击按钮即可关闭 
          </div>
        </div>

        <div>
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseThree" aria-expanded="true" aria-controls="collapseThree">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关 于&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
        </div>
         <div id="collapseThree" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingThree">
          <div class="panel-body">
            Ebby&#39;s Notes
          </div>
          <div class="panel-body">
            Copyright © 2020 Ebby DD All Rights Reserved.
          </div>
        </div>
      </div>


      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <div class="modal-footer">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
      </div>
    </div>
  </div>
</div>
  
  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
  
</body>
</html>