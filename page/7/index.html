<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Ebby&#39;s Notes</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
    <meta name="keywords" content="‰∫∫Â∑•Êô∫ËÉΩ, AI, Á•ûÁªèÁΩëÁªú, ÁÆóÊ≥ï" />
  
  
  
  
  <meta name="description" content="ËÆ∞ÂΩï‰∫∫Â∑•Êô∫ËÉΩÂ≠¶‰π†Ë∑ØÂæÑ">
<meta name="keywords" content="‰∫∫Â∑•Êô∫ËÉΩ, AI, Á•ûÁªèÁΩëÁªú, ÁÆóÊ≥ï">
<meta property="og:type" content="website">
<meta property="og:title" content="Ebby&#39;s Notes">
<meta property="og:url" content="http://blog.a-stack.com/page/7/index.html">
<meta property="og:site_name" content="Ebby&#39;s Notes">
<meta property="og:description" content="ËÆ∞ÂΩï‰∫∫Â∑•Êô∫ËÉΩÂ≠¶‰π†Ë∑ØÂæÑ">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Ebby&#39;s Notes">
<meta name="twitter:description" content="ËÆ∞ÂΩï‰∫∫Â∑•Êô∫ËÉΩÂ≠¶‰π†Ë∑ØÂæÑ">
  
    <link rel="alternate" href="/atom.xml" title="Ebby&#39;s Notes" type="application/atom+xml">
  

  

  <link rel="icon" href="/css/images/logo.png">
  <link rel="apple-touch-icon" href="/css/images/logo.png">
  
    <link href="/qnsource/css/Source+Code+Pro.css" rel="stylesheet" type="text/css">
  
  <link href="/qnsource/css/Open+Sans-Montserrat-700.css" rel="stylesheet" type="text/css">
  <link href="/qnsource/css/Roboto-400-300.css" rel="stylesheet" type="text/css">
  <link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <link rel="stylesheet" href="/css/style.css">

  <script src="/js/jquery-3.1.1.min.js"></script>
  <script src="/js/bootstrap.js"></script>

  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="/css/bootstrap.css" >

  
    <link rel="stylesheet" href="/css/home.css" >
  

  

  

  
  
  
    <link rel="stylesheet" href="/css/vdonate.css" >
  

</head>



  <body>


  
    <header id="header">

	<!-- ËÉåÊôØÂõæÊ®°Âºè -->
	

    
      <div id="intrologo" class="intro-logo" style="background-position:center; background-repeat:no-repeat; background-image: url(); background-size: auto 100%;">

      <!-- Support rolling -->  
        
        <section class="awSlider">
          <div class="carousel slide carousel-fade " data-ride="carousel">

            <!-- Wrapper for slides -->
            <div class="carousel-inner">
               
                  
                    <div class="item active">
                  
                    <img id="carousel-img0" src="/css/images/23.jpg">
                  </div>

                  <!-- Ëá™ÈÄÇÂ∫îÂ§ßÂõæ -->
                  <script>
                      var img0 = new Image();
                      var imageTag0 = document.getElementById("carousel-img0");
                      img0.src = imageTag0.src;
                      img0.onload=function(){
                        if (img0.width / img0.height <= document.body.clientWidth / document.body.clientHeight) {
                          imageTag0.style.width = document.body.clientWidth + "px";
                        } else {
                          imageTag0.style.height = document.body.clientHeight + "px";
                          imageTag0.style.marginLeft = -(document.body.clientHeight * img0.width / img0.height - document.body.clientWidth) / 2 + "px";
                        }
                      };
                  </script>
                
                  
                    <div class="item">
                  
                    <img id="carousel-img1" src="/css/images/17.jpg">
                  </div>

                  <!-- Ëá™ÈÄÇÂ∫îÂ§ßÂõæ -->
                  <script>
                      var img1 = new Image();
                      var imageTag1 = document.getElementById("carousel-img1");
                      img1.src = imageTag1.src;
                      img1.onload=function(){
                        if (img1.width / img1.height <= document.body.clientWidth / document.body.clientHeight) {
                          imageTag1.style.width = document.body.clientWidth + "px";
                        } else {
                          imageTag1.style.height = document.body.clientHeight + "px";
                          imageTag1.style.marginLeft = -(document.body.clientHeight * img1.width / img1.height - document.body.clientWidth) / 2 + "px";
                        }
                      };
                  </script>
                
                  
                    <div class="item">
                  
                    <img id="carousel-img2" src="/css/images/home-bg.jpg">
                  </div>

                  <!-- Ëá™ÈÄÇÂ∫îÂ§ßÂõæ -->
                  <script>
                      var img2 = new Image();
                      var imageTag2 = document.getElementById("carousel-img2");
                      img2.src = imageTag2.src;
                      img2.onload=function(){
                        if (img2.width / img2.height <= document.body.clientWidth / document.body.clientHeight) {
                          imageTag2.style.width = document.body.clientWidth + "px";
                        } else {
                          imageTag2.style.height = document.body.clientHeight + "px";
                          imageTag2.style.marginLeft = -(document.body.clientHeight * img2.width / img2.height - document.body.clientWidth) / 2 + "px";
                        }
                      };
                  </script>
                
                  
                    <div class="item">
                  
                    <img id="carousel-img3" src="/css/images/sample.jpg">
                  </div>

                  <!-- Ëá™ÈÄÇÂ∫îÂ§ßÂõæ -->
                  <script>
                      var img3 = new Image();
                      var imageTag3 = document.getElementById("carousel-img3");
                      img3.src = imageTag3.src;
                      img3.onload=function(){
                        if (img3.width / img3.height <= document.body.clientWidth / document.body.clientHeight) {
                          imageTag3.style.width = document.body.clientWidth + "px";
                        } else {
                          imageTag3.style.height = document.body.clientHeight + "px";
                          imageTag3.style.marginLeft = -(document.body.clientHeight * img3.width / img3.height - document.body.clientWidth) / 2 + "px";
                        }
                      };
                  </script>
                
            </div>

            <!-- Controls -->
            <a class="left carousel-control" href=".carousel" role="button" data-slide="prev">
              <span class="glyphicon glyphicon-chevron-left" aria-hidden="true"></span>
              <span class="sr-only">Geri</span>
            </a>
            <a class="right carousel-control" href=".carousel" role="button" data-slide="next">
              <span class="glyphicon glyphicon-chevron-right" aria-hidden="true"></span>
              <span class="sr-only">ƒ∞leri</span>
            </a>
          </div>
        </section>
        <script>
          $('section.awSlider .carousel').carousel({
              pause: '',
              interval: 5000
          });
          var startImage = $('section.awSlider .item.active > img').attr('src');
          $('section.awSlider .carousel').on('slid.bs.carousel', function () {
              var bscn = $(this).find('.item.active > img').attr('src');
              $('section.awSlider > img').attr('src', bscn);
          });
        </script>
      

    
 


    <canvas width="100%" height="100%"></canvas>
    <script>
      var c = document.getElementsByTagName('canvas')[0],
          x = c.getContext('2d'),
          w = window.innerWidth,
          h = window.innerHeight,
          pr = window.devicePixelRatio || 1,
          f = 90,
          q,
          m = Math,
          r = 0,
          u = m.PI*2,
          v = m.cos,
          z = m.random
      c.width = w*pr
      c.height = h*pr
      x.scale(pr, pr)
      x.globalAlpha = 0.6

      <!-- ÊäòÁ∫øPolylineËÉåÊôØ -->
      
    </script>
    

    
      <div id="homelogo" class="homelogo" style="background: rgba(255,255,255,1);"> 
    

        
          <div class="homelogoback"  style="border: 1px solid #404040;" >
            <h1><a href="#content" id="logo">Ebby&#39;s Notes</a></h1>
            <h3>ËÆ∞ÂΩï‰∫∫Â∑•Êô∫ËÉΩÂ≠¶‰π†Ë∑ØÂæÑ</h3>
            <h5>Ebby DD</h5>
            <!-- <p><a href="https://github.com/iTimeTraveler" target="_blank">Github</a></p> -->
          </div>
        
    
    </div>
  </div>

  <!-- Ëá™ÈÄÇÂ∫î‰∏ªÈ°µËÉåÊôØÂ§ßÂõæ -->
  

 <!-- home_logo_imageÂ±Ö‰∏≠ -->
 
    <script>
        var homelogodiv = document.getElementById("homelogo");
        if (document.all.homelogo.offsetWidth > document.body.clientWidth) {
          homelogodiv.style.width = document.body.clientWidth + "px";
          homelogodiv.style.marginLeft = document.body.clientWidth * -0.5 + "px";
        } else {
          homelogodiv.style.width = homelogodiv.clientWidth  + "px";
          homelogodiv.style.marginLeft = (homelogodiv.clientWidth)  * -0.5 + "px";
        }
    </script>
  

  <div class="intro-navigate">
      <p class="navigater-list">
        
          <a id="beautifont" class="main-nav-link" href="/">È¶ñÈ°µ</a>
        
          <a id="beautifont" class="main-nav-link" href="/archives">ÂΩíÊ°£</a>
        
          <a id="beautifont" class="main-nav-link" href="/categories">ÂàÜÁ±ª</a>
        
          <a id="beautifont" class="main-nav-link" href="/tags">Ê†áÁ≠æ</a>
        
          <a id="beautifont" class="main-nav-link" href="/about">ÂÖ≥‰∫é</a>
        
          <a id="beautifont" class="main-nav-link" href="/reading">ËØª‰π¶</a>
        
          <a id="beautifont" class="main-nav-link" href="/resources">ËµÑÊ∫ê</a>
        
          <a id="beautifont" class="main-nav-link" href="/notebooks">üìù</a>
        
      </p>
  </div>

</header>
  
  <div id="container">
    <div id="wrap">
      
            
      <div id="content" class="outer">
        
          <section id="main">
  
    <article id="post-cs231n-lecture-2"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2018/05/03/cs231n-lecture-2/">cs231nËØæÁ®ãÁ¨îËÆ∞:ÔºàLecture 2ÔºâÂõæÂÉèÂàÜÁ±ª</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2018/05/03/cs231n-lecture-2/" class="article-date">
	  <time datetime="2018-05-03T08:50:26.000Z" itemprop="datePublished">2018-05-03</time>
	</a>

      
    <a class="article-category-link" href="/categories/ËØª‰π¶Á¨îËÆ∞/">ËØª‰π¶Á¨îËÆ∞</a><a class="article-category-link" href="/categories/ËØª‰π¶Á¨îËÆ∞/ËØæÁ®ãÁ¨îËÆ∞/">ËØæÁ®ãÁ¨îËÆ∞</a>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>ÊëòË¶ÅÔºö</strong> ËÆ°ÂàíËä±‰∏Ä‰∏™ÊúàÁöÑÊó∂Èó¥Âà∑‰∏ÄÈÅçÊñØÂù¶Á¶èÁöÑÊú∫Âô®ËßÜËßâËØæÁ®ãcs231nÔºåÂπ∂ÂÅöÁ¨îËÆ∞ËÆ∞ÂΩïÊØèÂ§©Â≠¶‰π†Âà∞ÁöÑÂÜÖÂÆπ„ÄÇ</p>
<!-- excerpt -->
<h2 id="Ê¶ÇËø∞"><a href="#Ê¶ÇËø∞" class="headerlink" title="Ê¶ÇËø∞"></a>Ê¶ÇËø∞</h2><p>cs231nÊòØÊñØÂù¶Á¶èÂú®Ê∑±Â∫¶Â≠¶‰π†ÂíåÊú∫Âô®ËßÜËßâÈ¢ÜÂüüÁöÑÂÖ•Èó®ÁªèÂÖ∏ËØæÁ®ãÔºåÁõ∏ÂÖ≥ËµÑÊ∫êÂ¶Ç‰∏ãÔºö</p>
<ul>
<li>ËØæÁ®ã‰∏ªÈ°µÔºö <a href="http://cs231n.stanford.edu/" target="_blank" rel="noopener">http://cs231n.stanford.edu/</a></li>
<li>ËØæÁ®ãNotesÔºö<a href="http://cs231n.github.io/" target="_blank" rel="noopener">http://cs231n.github.io/</a></li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>Event Type</th>
<th>Date</th>
<th>Description</th>
<th>Course Materials</th>
</tr>
</thead>
<tbody>
<tr>
<td>Lecture 2</td>
<td>Thursday April 5</td>
<td><strong>Image Classification</strong> The data-driven approach K-nearest neighbor Linear classification I</td>
<td><a href="http://cs231n.stanford.edu/slides/2018/cs231n_2018_lecture02.pdf" target="_blank" rel="noopener">[slides]</a> <a href="http://cs231n.github.io/python-numpy-tutorial" target="_blank" rel="noopener">[python/numpy tutorial]</a><a href="http://cs231n.github.io/classification" target="_blank" rel="noopener">[image classification notes]</a><a href="http://cs231n.github.io/linear-classify" target="_blank" rel="noopener">[linear classification notes]</a></td>
</tr>
</tbody>
</table>
</div>
<h2 id="Python-Numpy-Tutorial"><a href="#Python-Numpy-Tutorial" class="headerlink" title="Python/Numpy Tutorial"></a>Python/Numpy Tutorial</h2><ul>
<li>Note that unlike many languages, Python does not have unary increment (<code>x++</code>) or decrement (<code>x--</code>) operators.</li>
<li>Â≠óÁ¨¶‰∏≤Êìç‰Ωú</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">"hello"</span></span><br><span class="line">print(s.capitalize())  <span class="comment"># Capitalize a string; prints "Hello"</span></span><br><span class="line">print(s.upper())       <span class="comment"># Convert a string to uppercase; prints "HELLO"</span></span><br><span class="line">print(s.rjust(<span class="number">7</span>))      <span class="comment"># Right-justify a string, padding with spaces; prints "  hello"</span></span><br><span class="line">print(s.center(<span class="number">7</span>))     <span class="comment"># Center a string, padding with spaces; prints " hello "</span></span><br><span class="line">print(s.replace(<span class="string">'l'</span>, <span class="string">'(ell)'</span>))  <span class="comment"># Replace all instances of one substring with another;</span></span><br><span class="line">                                <span class="comment"># prints "he(ell)(ell)o"</span></span><br><span class="line">print(<span class="string">'  world '</span>.strip())  <span class="comment"># Strip leading and trailing whitespace; prints "world"</span></span><br></pre></td></tr></table></figure>
<ul>
<li>ListÊìç‰Ωú</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nums = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">even_squares = [x ** <span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> nums <span class="keyword">if</span> x % <span class="number">2</span> == <span class="number">0</span>]</span><br><span class="line">print(even_squares)  <span class="comment"># Prints "[0, 4, 16]"</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Â≠óÂÖ∏Êìç‰Ωú</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">d = &#123;<span class="string">'person'</span>: <span class="number">2</span>, <span class="string">'cat'</span>: <span class="number">4</span>, <span class="string">'spider'</span>: <span class="number">8</span>&#125;</span><br><span class="line"><span class="keyword">for</span> animal, legs <span class="keyword">in</span> d.items():</span><br><span class="line">    print(<span class="string">'A %s has %d legs'</span> % (animal, legs))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nums = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">even_num_to_square = &#123;x: x ** <span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> nums <span class="keyword">if</span> x % <span class="number">2</span> == <span class="number">0</span>&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Numpy"><a href="#Numpy" class="headerlink" title="Numpy"></a>Numpy</h3><blockquote>
<p>Êõ¥Â§öÂÜÖÂÆπÂèÇËßÅÔºö<a href="https://docs.scipy.org/doc/numpy/reference/" target="_blank" rel="noopener">NumPy Reference</a></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Êï∞ÂÄº‰πò</span></span><br><span class="line">print(x * y)</span><br><span class="line">print(np.multiply(x, y))</span><br><span class="line"><span class="comment"># Áü©Èòµ‰πò</span></span><br><span class="line">print(v.dot(w))</span><br><span class="line">print(np.dot(v, w))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line"></span><br><span class="line">print(np.sum(x))  <span class="comment"># Compute sum of all elements; prints "10"</span></span><br><span class="line">print(np.sum(x, axis=<span class="number">0</span>))  <span class="comment"># Compute sum of each column; prints "[4 6]"</span></span><br><span class="line">print(np.sum(x, axis=<span class="number">1</span>))  <span class="comment"># Compute sum of each row; prints "[3 7]"</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#ËΩ¨ÁΩÆ</span></span><br><span class="line">x.T</span><br></pre></td></tr></table></figure>
<h2 id="SciPy"><a href="#SciPy" class="headerlink" title="SciPy"></a>SciPy</h2><blockquote>
<p>Êõ¥Â§öÂÜÖÂÆπÂèÇËßÅ: <a href="https://docs.scipy.org/doc/scipy/reference/index.html" target="_blank" rel="noopener">SciPy Tutorial</a></p>
</blockquote>
<h3 id="Image-Operations"><a href="#Image-Operations" class="headerlink" title="Image Operations"></a>Image Operations</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Image Operations</span></span><br><span class="line"><span class="keyword">from</span> scipy.misc <span class="keyword">import</span> imread, imsave, imresize</span><br><span class="line"></span><br><span class="line"><span class="comment"># Read an JPEG image into a numpy array</span></span><br><span class="line">img = imread(<span class="string">'assets/cat.jpg'</span>)</span><br><span class="line">print(img.dtype, img.shape)  <span class="comment"># Prints "uint8 (400, 248, 3)"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># We can tint the image by scaling each of the color channels</span></span><br><span class="line"><span class="comment"># by a different scalar constant. The image has shape (400, 248, 3);</span></span><br><span class="line"><span class="comment"># we multiply it by the array [1, 0.95, 0.9] of shape (3,);</span></span><br><span class="line"><span class="comment"># numpy broadcasting means that this leaves the red channel unchanged,</span></span><br><span class="line"><span class="comment"># and multiplies the green and blue channels by 0.95 and 0.9</span></span><br><span class="line"><span class="comment"># respectively.</span></span><br><span class="line">img_tinted = img * [<span class="number">1</span>, <span class="number">0.95</span>, <span class="number">0.9</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Resize the tinted image to be 300 by 300 pixels.</span></span><br><span class="line">img_tinted = imresize(img_tinted, (<span class="number">300</span>, <span class="number">300</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Write the tinted image back to disk</span></span><br><span class="line">imsave(<span class="string">'assets/cat_tinted.jpg'</span>, img_tinted)</span><br></pre></td></tr></table></figure>
<h3 id="Distance-between-points"><a href="#Distance-between-points" class="headerlink" title="Distance between points"></a>Distance between points</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.spatial.distance <span class="keyword">import</span> pdist, squareform</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the following array where each row is a point in 2D space:</span></span><br><span class="line"><span class="comment"># [[0 1]</span></span><br><span class="line"><span class="comment">#  [1 0]</span></span><br><span class="line"><span class="comment">#  [2 0]]</span></span><br><span class="line">x = np.array([[<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">2</span>, <span class="number">0</span>]])</span><br><span class="line">print(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the Euclidean distance between all rows of x.</span></span><br><span class="line"><span class="comment"># d[i, j] is the Euclidean distance between x[i, :] and x[j, :],</span></span><br><span class="line"><span class="comment"># and d is the following array:</span></span><br><span class="line"><span class="comment"># [[ 0.          1.41421356  2.23606798]</span></span><br><span class="line"><span class="comment">#  [ 1.41421356  0.          1.        ]</span></span><br><span class="line"><span class="comment">#  [ 2.23606798  1.          0.        ]]</span></span><br><span class="line">d = squareform(pdist(x, <span class="string">'euclidean'</span>))</span><br><span class="line">print(d)</span><br></pre></td></tr></table></figure>
<h2 id="ÂõæÂÉèÂàÜÁ±ª-Notes1"><a href="#ÂõæÂÉèÂàÜÁ±ª-Notes1" class="headerlink" title="ÂõæÂÉèÂàÜÁ±ª Notes1"></a>ÂõæÂÉèÂàÜÁ±ª Notes<sup><a href="#fn_1" id="reffn_1">1</a></sup></h2><p><img src="/qnsource/images/2018-04-28-cs231n-notes/classify.png" alt="classify"></p>
<blockquote>
<p>The task in Image Classification is to predict a single label (or a distribution over labels as shown here to indicate our confidence) for a given image. Images are 3-dimensional arrays of integers from 0 to 255, of size Width x Height x 3. The 3 represents the three color channels Red, Green, Blue.</p>
</blockquote>
<p><strong>Èù¢‰∏¥ÁöÑÊåëÊàòÔºö</strong></p>
<ul>
<li><strong>‰∏çÂêåËßÜËßí</strong>. A single instance of an object can be oriented in many ways with respect to the camera.</li>
<li><strong>Â∞∫ÂØ∏ÂèòÊç¢</strong>. Visual classes often exhibit variation in their size (size in the real world, not only in terms of their extent in the image).</li>
<li><strong>ÂèòÂΩ¢</strong>. Many objects of interest are not rigid bodies and can be deformed in extreme ways.</li>
<li><strong>ÈÅÆÊå°</strong>. The objects of interest can be occluded. Sometimes only a small portion of an object (as little as few pixels) could be visible.</li>
<li><strong>‰∏çÂêåÂÖâÁÖßÊù°‰ª∂</strong>. The effects of illumination are drastic on the pixel level.</li>
<li><strong>ËÉåÊôØÂπ≤Êâ∞</strong>. The objects of interest may <em>blend</em> into their environment, making them hard to identify.</li>
<li><strong>Á±ªÂÜÖÂ∑ÆÂºÇ</strong>. The classes of interest can often be relatively broad, such as <em>chair</em>. There are many different types of these objects, each with their own appearance.</li>
</ul>
<p><img src="/qnsource/images/2018-04-28-cs231n-notes/challenges.jpeg" alt="challenges"></p>
<blockquote>
<p><strong>Semantic Gap</strong>: ËØ≠‰πâÈ∏øÊ≤üÔºåÂØπ‰∫é‰∫∫Á±ªËÄåË®ÄÔºåÂõæÂÉèÂàÜÁ±ªÂçÅÂàÜÁÆÄÁ≠îÔºå‰ΩÜÂØπ‰∫éËÆ°ÁÆóÊú∫Á≥ªÁªü‰ªéÂÉèÁ¥†‰∏≠ÊèêÂèñÁâπÂæÅÁâπÂà´Èöæ„ÄÇ</p>
</blockquote>
<h3 id="Êï∞ÊçÆÈ©±Âä®ÁöÑÊñπÂºèÊù•ÂÆûÁé∞ÂõæÂÉèÂàÜÁ±ª"><a href="#Êï∞ÊçÆÈ©±Âä®ÁöÑÊñπÂºèÊù•ÂÆûÁé∞ÂõæÂÉèÂàÜÁ±ª" class="headerlink" title="Êï∞ÊçÆÈ©±Âä®ÁöÑÊñπÂºèÊù•ÂÆûÁé∞ÂõæÂÉèÂàÜÁ±ª"></a>Êï∞ÊçÆÈ©±Âä®ÁöÑÊñπÂºèÊù•ÂÆûÁé∞ÂõæÂÉèÂàÜÁ±ª</h3><blockquote>
<p><a href="http://vision.stanford.edu/teaching/cs231n-demos/knn/" target="_blank" rel="noopener">KNN Demo</a></p>
</blockquote>
<p>‰º†ÁªüÁâπÂæÅÊèêÂèñÊñπÊ≥ïÂæàÈöæÊúâË¥®ÁöÑÊèêÂçáÂíåÊ≥õÂåñÁöÑÊÄßËÉΩÔºåÂ∞§ÂÖ∂Áõ¥Êé•Ê†πÊçÆÁâπÂæÅËøõË°åÂàÜÁ±ªÔºå‰∏çÂ¶ÇÂà©Áî®Â§ßÈáèÊ†áËÆ∞Êï∞ÊçÆËÆ≠ÁªÉ‰∏Ä‰∏™Ê®°ÂûãÔºåÁÑ∂ÂêéÂà©Áî®ËØ•Ê®°ÂûãÂØπÊú™Áü•Êï∞ÊçÆËøõË°åÈ¢ÑÊµã„ÄÇ</p>
<h3 id="ËøëÈÇª‰ºòÂåñÁÆóÊ≥ïÂ§ÑÁêÜÂõæÂÉèÂàÜÁ±ª"><a href="#ËøëÈÇª‰ºòÂåñÁÆóÊ≥ïÂ§ÑÁêÜÂõæÂÉèÂàÜÁ±ª" class="headerlink" title="ËøëÈÇª‰ºòÂåñÁÆóÊ≥ïÂ§ÑÁêÜÂõæÂÉèÂàÜÁ±ª"></a>ËøëÈÇª‰ºòÂåñÁÆóÊ≥ïÂ§ÑÁêÜÂõæÂÉèÂàÜÁ±ª</h3><ol>
<li>Âú®ËÆ≠ÁªÉÈò∂ÊÆµÔºåNN‰ªÄ‰πàÈÉΩ‰∏çÂÅöÔºåÁü•ËØÜÊääËÆ≠ÁªÉÊï∞ÊçÆÂä†ËΩΩÂà∞ÂÜÖÂ≠ò‰∏≠Ôºõ$O(1)$</li>
<li>È¢ÑÊµãÈò∂ÊÆµÔºåÂ∞ÜÊú™Áü•Êï∞ÊçÆ‰∏éÊâÄÊúâËÆ≠ÁªÉÊï∞ÊçÆËøõË°åÊØîËæÉÔºåÂèñÊúÄËøëË∑ùÁ¶ªÁöÑÂõæÂÉèÊâÄÂú®ÁöÑÁ±ªÂà´‰Ωú‰∏∫È¢ÑÊµãÁ±ªÂà´Ôºõ$O(N)$</li>
</ol>
<p><strong>Áº∫ÁÇπÔºö</strong> </p>
<ul>
<li>ËÆ°ÁÆóÈáèÂ§ß(ÊØèÈ¢ÑÊµã‰∏Ä‰∏™ÂõæÁâáÈÉΩÈúÄË¶Å‰∏éÊâÄÊúâËÆ≠ÁªÉÊï∞ÊçÆËÆ°ÁÆó‰∏ÄÈÅçË∑ùÁ¶ª)ÔºåÂáÜÁ°ÆÁéá‰ΩéÔºà~40%ÂáÜÁ°ÆÁéáÂú® CIFAR-10ÔºâÔºõ</li>
<li>ÂõæÂÉèÁöÑ‰∏âÁª¥ÁâπÂæÅÂíåËæπÁºòÁâπÊÄßÔºåÂØºËá¥‰ªÖ‰ªéÂÉèÁ¥†ÂäõÂ∫¶‰∏äÂæàÈöæËøõË°åÊØîÂØπÔºåÁª¥Â∫¶Ë∂äÂ•ΩÔºåNNÁÆóÊ≥ïÂ∞±Ë∂äÊó†ËÉΩ‰∏∫Âäõ</li>
</ul>
<h2 id="ÂèÇËÄÉ"><a href="#ÂèÇËÄÉ" class="headerlink" title="ÂèÇËÄÉ"></a>ÂèÇËÄÉ</h2><blockquote id="fn_1">
<sup>1</sup>. <a href="http://cs231n.github.io/classification/" target="_blank" rel="noopener">CS231n Notes:Classification</a><a href="#reffn_1" title="Jump back to footnote [1] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_2">
<sup>2</sup>. <a href="http://cs231n.github.io/linear-classify/" target="_blank" rel="noopener">CS231n Notes:linear classify</a><a href="#reffn_2" title="Jump back to footnote [2] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_3">
<sup>3</sup>. <a href="https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf" target="_blank" rel="noopener">A Few Useful Things to Know About Machine Learning</a><a href="#reffn_3" title="Jump back to footnote [3] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_4">
<sup>4</sup>. <a href="http://cs229.stanford.edu/notes/cs229-notes3.pdf" target="_blank" rel="noopener">CS229 Lecture Notes: SVM</a><a href="#reffn_4" title="Jump back to footnote [4] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_5">
<sup>5</sup>. <a href="http://arxiv.org/abs/1306.0239" target="_blank" rel="noopener">Deep Learning using Linear Support Vector Machines</a> from Charlie Tang 2013 presents some results claiming that the L2SVM outperforms Softmax.<a href="#reffn_5" title="Jump back to footnote [5] in the text."> &#8617;</a>
</blockquote>

      
    </div>
    <footer class="article-footer">

      
      

      
      <!--  -->

      <!--  -->
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/‰∫∫Â∑•Êô∫ËÉΩ/">‰∫∫Â∑•Êô∫ËÉΩ</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Êú∫Âô®ËßÜËßâ/">Êú∫Âô®ËßÜËßâ</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Á¨îËÆ∞/">Á¨îËÆ∞</a></li></ul>

    </footer>
  </div>
  
</article>

<!-- Table of Contents -->


  
    <article id="post-Holy-Bible-of-Machine-Learning"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2018/04/30/Holy-Bible-of-Machine-Learning/">Êú∫Âô®Â≠¶‰π†Âú£Áªè</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2018/04/30/Holy-Bible-of-Machine-Learning/" class="article-date">
	  <time datetime="2018-04-30T04:31:21.000Z" itemprop="datePublished">2018-04-30</time>
	</a>

      
    <a class="article-category-link" href="/categories/Êú∫Âô®Â≠¶‰π†/">Êú∫Âô®Â≠¶‰π†</a>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>ÊëòË¶ÅÔºö</strong> Êú∫Âô®Â≠¶‰π†‰∏≠ÂÖÖÊª°ÂæàÂ§öÈöæ‰ª•ÁêÜËß£ÁöÑÊäÄÂ∑ßÂíåÊñπÊ≥ïÔºåÂßë‰∏îÂà©Áî®ÊëÑÂΩ±‰∏≠Êó†Âøå77Êù°ÈÇ£Ê†∑ÁöÑÊëÑÂΩ±Âú£ÁªèÊù•Áß∞‰πã‰∏∫Êú∫Âô®Â≠¶‰π†Âú£ÁªèÂêß„ÄÇ<br></p>
      
    </div>
    <footer class="article-footer">

      
      

      
      <!--  -->

      <!--  -->
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/‰∫∫Â∑•Êô∫ËÉΩ/">‰∫∫Â∑•Êô∫ËÉΩ</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ÊäÄÂ∑ß/">ÊäÄÂ∑ß</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Êú∫Âô®Â≠¶‰π†/">Êú∫Âô®Â≠¶‰π†</a></li></ul>

    </footer>
  </div>
  
</article>

<!-- Table of Contents -->


  
    <article id="post-Everything-About-SVM"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2018/04/29/Everything-About-SVM/">Everything-About-SVM</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2018/04/29/Everything-About-SVM/" class="article-date">
	  <time datetime="2018-04-29T13:13:40.000Z" itemprop="datePublished">2018-04-29</time>
	</a>

      
    <a class="article-category-link" href="/categories/Êú∫Âô®Â≠¶‰π†/">Êú∫Âô®Â≠¶‰π†</a>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>ÊëòË¶ÅÔºö</strong></p>
      
    </div>
    <footer class="article-footer">

      
      

      
      <!--  -->

      <!--  -->
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ÊîØÊåÅÂêëÈáèÊú∫/">ÊîØÊåÅÂêëÈáèÊú∫</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ÊñáÁåÆ/">ÊñáÁåÆ</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ÁÆóÊ≥ï/">ÁÆóÊ≥ï</a></li></ul>

    </footer>
  </div>
  
</article>

<!-- Table of Contents -->


  
    <article id="post-machinelearning-labs"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2018/04/26/machinelearning-labs/">„ÄäÊú∫Âô®Â≠¶‰π†„ÄãËØæÁ®ãÂÆûÈ™åÂõûÈ°æ</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2018/04/26/machinelearning-labs/" class="article-date">
	  <time datetime="2018-04-26T05:56:28.000Z" itemprop="datePublished">2018-04-26</time>
	</a>

      
    <a class="article-category-link" href="/categories/Âä®ÊâãÂÆûË∑µËê•/">Âä®ÊâãÂÆûË∑µËê•</a>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>ÊëòË¶ÅÔºö</strong> Cousera‰∏äÊú∫Âô®Â≠¶‰π†ËØæÁ®ãÊèê‰æõ‰∫ÜÂÖ´‰∏™ÂÆûÈ™å‰Ωú‰∏öÔºå‰ΩøÁî®MATLABËøõË°åÂä®ÊâãÂÆûÈ™åÔºåÁÜüÊÇâÁõ∏ÂÖ≥ÊäÄÊúØÔºåÊú¨ÊñáÂØπÂÆûÈ™å‰∏≠ÁöÑÂÖ≥ÈîÆÂÜÖÂÆπËøõË°åÊÄªÁªìÂΩíÁ∫≥ÔºåÊñπ‰æø‰ª•ÂêéÂèäÊó∂Êü•Êâæ„ÄÇ</p>
<!-- excerpt -->
<h2 id="Ê¶ÇË¶Å"><a href="#Ê¶ÇË¶Å" class="headerlink" title="Ê¶ÇË¶Å"></a>Ê¶ÇË¶Å</h2><ul>
<li>ÂèØ‰ª•‰ΩøÁî®Matlab OnlineËøõË°å‰ª£Á†ÅÊµãËØïÔºå<a href="https://matlab.mathworks.com/" target="_blank" rel="noopener">Âú∞ÂùÄ</a>;</li>
<li>Áõ∏ÂÖ≥‰ª£Á†ÅÂ∑≤Áªè‰º†ËæìËá≥GithubÔºö <a href="https://github.com/ddebby/machine_learning_cousera.git" target="_blank" rel="noopener">https://github.com/ddebby/machine_learning_cousera.git</a></li>
</ul>
<h2 id="Lab1-Á∫øÊÄßÂõûÂΩí"><a href="#Lab1-Á∫øÊÄßÂõûÂΩí" class="headerlink" title="Lab1: Á∫øÊÄßÂõûÂΩí"></a>Lab1: Á∫øÊÄßÂõûÂΩí</h2><h3 id="1-ÁÆÄÂçïÁ∫øÊÄßÂõûÂΩí"><a href="#1-ÁÆÄÂçïÁ∫øÊÄßÂõûÂΩí" class="headerlink" title="1. ÁÆÄÂçïÁ∫øÊÄßÂõûÂΩí"></a>1. ÁÆÄÂçïÁ∫øÊÄßÂõûÂΩí</h3><p>Âú®Á¨¨‰∏Ä‰∏™ÂÆûÈ™å‰∏≠Êèê‰æõ‰∫ÜÂçïÂèòÈáèÁ∫øÊÄßÂõûÂΩíÁöÑÊï∞ÊçÆÁî®Êù•È¢ÑÊµãÂø´È§êËΩ¶ÁöÑÁõàÂà©ÊÉÖÂÜµÔºåÂÖ∂‰∏≠ËæìÂÖ•‰∏∫ÂüéÂ∏Ç‰∏≠ÁöÑ‰∫∫Âè£‰ø°ÊÅØÔºåËæìÂá∫‰∏∫ËØ•ÂüéÂ∏ÇÂø´È§êËΩ¶ÁöÑÁõàÂà©ÊÉÖÂÜµÔºåÊï∞ÊçÆÂàÜÂ∏ÉÊÉÖÂÜµËØ¶ËßÅ‰∏ãÂõæÔºö</p>
<p><img src="/qnsource/images/2018-04-25-machine-learning-notes/linear_regression_01.jpg" alt="linear_regression_01"></p>
<h4 id="‰ª£‰ª∑ÂáΩÊï∞ÂíåÊ¢ØÂ∫¶Êõ¥Êñ∞ÂÆûÁé∞"><a href="#‰ª£‰ª∑ÂáΩÊï∞ÂíåÊ¢ØÂ∫¶Êõ¥Êñ∞ÂÆûÁé∞" class="headerlink" title="‰ª£‰ª∑ÂáΩÊï∞ÂíåÊ¢ØÂ∫¶Êõ¥Êñ∞ÂÆûÁé∞"></a>‰ª£‰ª∑ÂáΩÊï∞ÂíåÊ¢ØÂ∫¶Êõ¥Êñ∞ÂÆûÁé∞</h4><p>ËÆ°ÁÆó‰ª£‰ª∑ÂáΩÊï∞ <code>computeCost.m</code> </p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">J</span> = <span class="title">computeCost</span><span class="params">(X, y, theta)</span></span></span><br><span class="line"><span class="comment">%COMPUTECOST Compute cost for linear regression</span></span><br><span class="line"><span class="comment">%   J = COMPUTECOST(X, y, theta) computes the cost of using theta as the</span></span><br><span class="line"><span class="comment">%   parameter for linear regression to fit the data points in X and y</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Initialize some useful values</span></span><br><span class="line">m = <span class="built_in">length</span>(y); <span class="comment">% number of training examples</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% You need to return the following variables correctly </span></span><br><span class="line">J = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% ====================== YOUR CODE HERE ======================</span></span><br><span class="line"><span class="comment">% Instructions: Compute the cost of a particular choice of theta</span></span><br><span class="line"><span class="comment">%               You should set J to the cost.</span></span><br><span class="line">J = <span class="number">1</span>/(<span class="number">2</span>*m) * (X*theta - y)'*(X*theta -y)</span><br><span class="line"><span class="comment">% =========================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>Ê¢ØÂ∫¶Êõ¥Êñ∞ <code>gradientDescent.m</code></p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[theta, J_history]</span> = <span class="title">gradientDescent</span><span class="params">(X, y, theta, alpha, num_iters)</span></span></span><br><span class="line"><span class="comment">%GRADIENTDESCENT Performs gradient descent to learn theta</span></span><br><span class="line"><span class="comment">%   theta = GRADIENTDESCENT(X, y, theta, alpha, num_iters) updates theta by </span></span><br><span class="line"><span class="comment">%   taking num_iters gradient steps with learning rate alpha</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Initialize some useful values</span></span><br><span class="line">m = <span class="built_in">length</span>(y); <span class="comment">% number of training examples</span></span><br><span class="line">J_history = <span class="built_in">zeros</span>(num_iters, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> iter = <span class="number">1</span>:num_iters</span><br><span class="line"></span><br><span class="line">    <span class="comment">% ====================== YOUR CODE HERE ======================</span></span><br><span class="line">    <span class="comment">% Instructions: Perform a single gradient step on the parameter vector</span></span><br><span class="line">    <span class="comment">%               theta. </span></span><br><span class="line">    <span class="comment">%</span></span><br><span class="line">    <span class="comment">% Hint: While debugging, it can be useful to print out the values</span></span><br><span class="line">    <span class="comment">%       of the cost function (computeCost) and gradient here.</span></span><br><span class="line">    <span class="comment">%</span></span><br><span class="line"></span><br><span class="line">    theta = theta - alpha/m * X'*(X*theta - y);</span><br><span class="line"></span><br><span class="line">    <span class="comment">% ============================================================</span></span><br><span class="line">    <span class="comment">% Save the cost J in every iteration    </span></span><br><span class="line">    J_history(iter) = computeCost(X, y, theta);</span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>ÂÆûÁé∞Âπ∂ÊµãËØïÔºö</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">data = load(<span class="string">'ex1data1.txt'</span>);</span><br><span class="line">X = data(:, <span class="number">1</span>); y = data(:, <span class="number">2</span>);</span><br><span class="line">m = <span class="built_in">length</span>(y); <span class="comment">% number of training examples</span></span><br><span class="line"></span><br><span class="line">X = [ones(m, <span class="number">1</span>), data(:,<span class="number">1</span>)]; <span class="comment">% Add a column of ones to x</span></span><br><span class="line">theta = <span class="built_in">zeros</span>(<span class="number">2</span>, <span class="number">1</span>); <span class="comment">% initialize fitting parameters</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Some gradient descent settings</span></span><br><span class="line">iterations = <span class="number">1500</span>;</span><br><span class="line">alpha = <span class="number">0.01</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% compute and display initial cost</span></span><br><span class="line">J = computeCost(X, y, theta);</span><br><span class="line"></span><br><span class="line"><span class="comment">% further testing of the cost function</span></span><br><span class="line">J = computeCost(X, y, [<span class="number">-1</span> ; <span class="number">2</span>]);</span><br><span class="line"></span><br><span class="line"><span class="comment">% run gradient descent</span></span><br><span class="line">theta = gradientDescent(X, y, theta, alpha, iterations);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Plot the linear fit</span></span><br><span class="line">hold on; <span class="comment">% keep previous plot visible</span></span><br><span class="line">plot(X(:,<span class="number">2</span>), X*theta, <span class="string">'-'</span>)</span><br><span class="line">legend(<span class="string">'Training data'</span>, <span class="string">'Linear regression'</span>)</span><br><span class="line">hold off <span class="comment">% don't overlay any more plots on this figure</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Predict values for population sizes of 35,000 and 70,000</span></span><br><span class="line">predict1 = [<span class="number">1</span>, <span class="number">3.5</span>] *theta;</span><br><span class="line">fprintf(<span class="string">'For population = 35,000, we predict a profit of %f\n'</span>,...</span><br><span class="line">    predict1*<span class="number">10000</span>);</span><br><span class="line">predict2 = [<span class="number">1</span>, <span class="number">7</span>] * theta;</span><br><span class="line">fprintf(<span class="string">'For population = 70,000, we predict a profit of %f\n'</span>,...</span><br><span class="line">    predict2*<span class="number">10000</span>);</span><br></pre></td></tr></table></figure>
<p><img src="/qnsource/images/2018-04-25-machine-learning-notes/linear_regression_02.jpg" alt="linear_regression_02"></p>
<h4 id="J-theta-ÁöÑÂèØËßÜÂåñ"><a href="#J-theta-ÁöÑÂèØËßÜÂåñ" class="headerlink" title="$J(\theta)$ ÁöÑÂèØËßÜÂåñ"></a>$J(\theta)$ ÁöÑÂèØËßÜÂåñ</h4><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% ============= Part 4: Visualizing J(theta_0, theta_1) =============</span></span><br><span class="line">fprintf(<span class="string">'Visualizing J(theta_0, theta_1) ...\n'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">% Grid over which we will calculate J</span></span><br><span class="line">theta0_vals = <span class="built_in">linspace</span>(<span class="number">-10</span>, <span class="number">10</span>, <span class="number">100</span>);</span><br><span class="line">theta1_vals = <span class="built_in">linspace</span>(<span class="number">-1</span>, <span class="number">4</span>, <span class="number">100</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% initialize J_vals to a matrix of 0's</span></span><br><span class="line">J_vals = <span class="built_in">zeros</span>(<span class="built_in">length</span>(theta0_vals), <span class="built_in">length</span>(theta1_vals));</span><br><span class="line"></span><br><span class="line"><span class="comment">% Fill out J_vals</span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:<span class="built_in">length</span>(theta0_vals)</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">1</span>:<span class="built_in">length</span>(theta1_vals)</span><br><span class="line">	  t = [theta0_vals(i); theta1_vals(j)];</span><br><span class="line">	  J_vals(<span class="built_in">i</span>,<span class="built_in">j</span>) = computeCost(X, y, t);</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Because of the way meshgrids work in the surf command, we need to</span></span><br><span class="line"><span class="comment">% transpose J_vals before calling surf, or else the axes will be flipped</span></span><br><span class="line">J_vals = J_vals';</span><br><span class="line"><span class="comment">% Surface plot</span></span><br><span class="line">figure;</span><br><span class="line">surf(theta0_vals, theta1_vals, J_vals)</span><br><span class="line">xlabel(<span class="string">'\theta_0'</span>); ylabel(<span class="string">'\theta_1'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Contour plot</span></span><br><span class="line">figure;</span><br><span class="line"><span class="comment">% Plot J_vals as 15 contours spaced logarithmically between 0.01 and 100</span></span><br><span class="line">contour(theta0_vals, theta1_vals, J_vals, <span class="built_in">logspace</span>(<span class="number">-2</span>, <span class="number">3</span>, <span class="number">20</span>))</span><br><span class="line">xlabel(<span class="string">'\theta_0'</span>); ylabel(<span class="string">'\theta_1'</span>);</span><br><span class="line">hold on;</span><br><span class="line">plot(theta(<span class="number">1</span>), theta(<span class="number">2</span>), <span class="string">'rx'</span>, <span class="string">'MarkerSize'</span>, <span class="number">10</span>, <span class="string">'LineWidth'</span>, <span class="number">2</span>);</span><br></pre></td></tr></table></figure>
<p><img src="/qnsource/images/2018-04-25-machine-learning-notes/linear_regression_03.jpg" alt="linear_regression_03"></p>
<p><img src="/qnsource/images/2018-04-25-machine-learning-notes/linear_regression_04.jpg" alt="linear_regression_04"></p>
<h3 id="2-Â§öÂÖÉÁ∫øÊÄßÂõûÂΩí"><a href="#2-Â§öÂÖÉÁ∫øÊÄßÂõûÂΩí" class="headerlink" title="2. Â§öÂÖÉÁ∫øÊÄßÂõûÂΩí"></a>2. Â§öÂÖÉÁ∫øÊÄßÂõûÂΩí</h3><p>Âà©Áî®Â§öÂÖÉÁ∫øÊÄßÂõûÂΩíÈ¢ÑÊµãÊàø‰ª∑ÔºåËæìÂÖ•ÁöÑÁâπÂæÅÂåÖÊã¨ÊàøÂ≠êÂ§ßÂ∞è„ÄÅÊàøÈó¥Êï∞ÁõÆÔºåËæìÂá∫‰∏∫ÊàøÂ≠ê‰ª∑Ê†º„ÄÇ</p>
<h3 id="2-1-ÁâπÂæÅÂΩí‰∏ÄÂåñ"><a href="#2-1-ÁâπÂæÅÂΩí‰∏ÄÂåñ" class="headerlink" title="2.1 ÁâπÂæÅÂΩí‰∏ÄÂåñ"></a>2.1 ÁâπÂæÅÂΩí‰∏ÄÂåñ</h3><p><code>featureNormalize.m</code></p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[X_norm, mu, sigma]</span> = <span class="title">featureNormalize</span><span class="params">(X)</span></span></span><br><span class="line"><span class="comment">%FEATURENORMALIZE Normalizes the features in X </span></span><br><span class="line"><span class="comment">%   FEATURENORMALIZE(X) returns a normalized version of X where</span></span><br><span class="line"><span class="comment">%   the mean value of each feature is 0 and the standard deviation</span></span><br><span class="line"><span class="comment">%   is 1. This is often a good preprocessing step to do when</span></span><br><span class="line"><span class="comment">%   working with learning algorithms.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% You need to set these values correctly</span></span><br><span class="line">X_norm = X;</span><br><span class="line">mu = <span class="built_in">zeros</span>(<span class="number">1</span>, <span class="built_in">size</span>(X, <span class="number">2</span>));</span><br><span class="line">sigma = <span class="built_in">zeros</span>(<span class="number">1</span>, <span class="built_in">size</span>(X, <span class="number">2</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">% ====================== YOUR CODE HERE ======================</span></span><br><span class="line"><span class="comment">%       </span></span><br><span class="line">mu = mean(X,<span class="number">1</span>);</span><br><span class="line">sigma = std(X,<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">X_norm = (X - mu)./sigma;</span><br><span class="line"><span class="comment">% ============================================================</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<ul>
<li>The <code>bsxfun</code> is helpful for applying a function (limited to two arguments) in an element-wise fashion to rows of a matrix using a vector of source values. This is useful for feature normalization. An example you can enter at the octave command line:</li>
</ul>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Z=[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span>; <span class="number">2</span> <span class="number">2</span> <span class="number">2</span>;];</span><br><span class="line"></span><br><span class="line">v=[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span>];</span><br><span class="line"></span><br><span class="line"><span class="built_in">bsxfun</span>(@minus,Z,v);</span><br><span class="line"></span><br><span class="line"><span class="built_in">ans</span> =</span><br><span class="line"></span><br><span class="line">    <span class="number">0</span>   <span class="number">0</span>   <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="number">1</span>   <span class="number">1</span>   <span class="number">1</span></span><br></pre></td></tr></table></figure>
<ul>
<li>In this case, the corresponding elements of v are subtracted from each row of Z. The minus(a,b) function is equivalent to computing (a-b).</li>
</ul>
<ul>
<li>‰ª£‰ª∑ÂáΩÊï∞ÂíåÊ¢ØÂ∫¶Êõ¥Êñ∞‰∏éÁÆÄÂçïÁ∫øÊÄßÂõûÂΩíÁõ∏ÂêåÔºõ</li>
</ul>
<h3 id="2-2-ËÆ°ÁÆó-theta-ÁöÑÊï∞ÂÄºËß£"><a href="#2-2-ËÆ°ÁÆó-theta-ÁöÑÊï∞ÂÄºËß£" class="headerlink" title="2.2 ËÆ°ÁÆó $\theta$ ÁöÑÊï∞ÂÄºËß£"></a>2.2 ËÆ°ÁÆó $\theta$ ÁöÑÊï∞ÂÄºËß£</h3><p><code>normalEqn.m</code></p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[theta]</span> = <span class="title">normalEqn</span><span class="params">(X, y)</span></span></span><br><span class="line"><span class="comment">%NORMALEQN Computes the closed-form solution to linear regression </span></span><br><span class="line"><span class="comment">%   NORMALEQN(X,y) computes the closed-form solution to linear </span></span><br><span class="line"><span class="comment">%   regression using the normal equations.</span></span><br><span class="line"></span><br><span class="line">theta = <span class="built_in">zeros</span>(<span class="built_in">size</span>(X, <span class="number">2</span>), <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% ====================== YOUR CODE HERE ======================</span></span><br><span class="line"><span class="comment">% Instructions: Complete the code to compute the closed form solution</span></span><br><span class="line"><span class="comment">%               to linear regression and put the result in theta.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% ---------------------- Sample Solution ----------------------</span></span><br><span class="line">theta = pinv(X'*X)*X'*y;</span><br><span class="line"></span><br><span class="line"><span class="comment">% -------------------------------------------------------------</span></span><br><span class="line"><span class="comment">% ============================================================</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h2 id="Lab-2-Lab-5"><a href="#Lab-2-Lab-5" class="headerlink" title="Lab 2 - Lab 5:"></a>Lab 2 - Lab 5:</h2><blockquote>
<p>Áïô‰ΩúÂêéÁª≠Êõ¥Êñ∞ ‚Ä¶</p>
</blockquote>
<h2 id="Lab-6-SVM"><a href="#Lab-6-SVM" class="headerlink" title="Lab 6: SVM"></a>Lab 6: SVM</h2><p>Êú¨ÂÆûÈ™åÂà©Áî®SVMÂÆûÁé∞ÈùûÁ∫øÊÄßÂàÜÁ±ªÂô®ÔºåÊ†∏ÂáΩÊï∞ÈÄâÊã©È´òÊñØÊ†∏ÂáΩÊï∞ÔºåÈ´òÊñØÊ†∏ÂáΩÊï∞ÁöÑÂÆö‰πâÂ¶Ç‰∏ãÔºö</p>
<script type="math/tex; mode=display">
K_{gaussian}(x^{(i)},x^{(j)}) = exp(-\frac{||x^{(i)}-x^{(j)}||^2}{2\sigma^2})</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% ========== Part 5: Training SVM with RBF Kernel (Dataset 2) ==========</span></span><br><span class="line"><span class="comment">%  After you have implemented the kernel, we can now use it to train the </span></span><br><span class="line"><span class="comment">%  SVM classifier.</span></span><br><span class="line"><span class="comment">% </span></span><br><span class="line">load(<span class="string">'ex6data2.mat'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% SVM Parameters</span></span><br><span class="line">C = <span class="number">1</span>; sigma = <span class="number">0.1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% We set the tolerance and max_passes lower here so that the code will run</span></span><br><span class="line"><span class="comment">% faster. However, in practice, you will want to run the training to</span></span><br><span class="line"><span class="comment">% convergence.</span></span><br><span class="line">model= svmTrain(X, y, C, @(x1, x2) gaussianKernel(x1, x2, sigma)); </span><br><span class="line">visualizeBoundary(X, y, model);</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Áî±‰∫éÁõÆÂâçscikit-learnÂ∫ìÂØπÂêÑÁßçSVMÁÆóÊ≥ïÈÉΩÊúâÊØîËæÉÂ•ΩÁöÑÂ∞ÅË£ÖÔºåÊâÄ‰ª•‰πü‰∏çÂú®Ëøõ‰∏ÄÊ≠•Ê∑±Á©∂matlabÁöÑÂÆûÁé∞‰∫Ü„ÄÇ</p>
</blockquote>
<h2 id="Lab-7-1-K-Means"><a href="#Lab-7-1-K-Means" class="headerlink" title="Lab 7.1: K-Means"></a>Lab 7.1: K-Means</h2><p>Êú¨ÂÆûÈ™å‰ΩøÁî®K-MeansËøõË°åÂõæÂÉèÂéãÁº©ÔºåK-MeansÁÆóÊ≥ïÁöÑÂü∫Êú¨ÂÆûÁé∞Ôºö</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% Initialize centroids</span></span><br><span class="line">centroids = kMeansInitCentroids(X, K);</span><br><span class="line"><span class="keyword">for</span> iter = <span class="number">1</span>:iterations</span><br><span class="line">    <span class="comment">% Cluster assignment step: Assign each data point to the</span></span><br><span class="line">    <span class="comment">% closest centroid. idx(i) corresponds to cÀÜ(i), the index</span></span><br><span class="line">    <span class="comment">% of the centroid assigned to example i</span></span><br><span class="line">    idx = findClosestCentroids(X, centroids);</span><br><span class="line">    <span class="comment">% Move centroid step: Compute means based on centroid</span></span><br><span class="line">    <span class="comment">% assignments</span></span><br><span class="line">    centroids = computeMeans(X, idx, K);</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>Âú®Âæ™ÁéØ‰∏≠ÂÖ≥ÈîÆÂÆûÁé∞‰∏§‰∏™Ê≠•È™§Ôºö1ÔºâÈáçÊñ∞ÂàíÂàÜËÅöÁ±ªÔºõ2ÔºâËÆ°ÁÆóÊñ∞ÁöÑÂùáÂÄºÂèä‰∏≠ÂøÉÁÇπ</p>
<ol>
<li>ÂØªÊâæÊúÄËøëÁöÑËÅöÁ±ª‰∏≠ÂøÉÁÇπÔºåÂπ∂ËÅöÁ±ª<script type="math/tex; mode=display">
c^{(i)}:=j \ that \ minimizes \ ||x^{(i)} - \mu_j ||^2</script></li>
</ol>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">idx</span> = <span class="title">findClosestCentroids</span><span class="params">(X, centroids)</span></span></span><br><span class="line"><span class="comment">%FINDCLOSESTCENTROIDS computes the centroid memberships for every example</span></span><br><span class="line"><span class="comment">%   idx = FINDCLOSESTCENTROIDS (X, centroids) returns the closest centroids</span></span><br><span class="line"><span class="comment">%   in idx for a dataset X where each row is a single example. idx = m x 1 </span></span><br><span class="line"><span class="comment">%   vector of centroid assignments (i.e. each entry in range [1..K])</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Set K</span></span><br><span class="line">K = <span class="built_in">size</span>(centroids, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% You need to return the following variables correctly.</span></span><br><span class="line">idx = <span class="built_in">zeros</span>(<span class="built_in">size</span>(X,<span class="number">1</span>), <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Instructions: Go over every example, find its closest centroid, and store</span></span><br><span class="line"><span class="comment">%               the index inside idx at the appropriate location.</span></span><br><span class="line"><span class="comment">%               Concretely, idx(i) should contain the index of the centroid</span></span><br><span class="line"><span class="comment">%               closest to example i. Hence, it should be a value in the </span></span><br><span class="line"><span class="comment">%               range 1..K</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% Note: You can use a for-loop over the examples to compute this.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="built_in">size</span>(X,<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">1</span>: <span class="built_in">size</span>(centroids,<span class="number">1</span>)</span><br><span class="line">         dis(<span class="built_in">j</span>) = sum((centroids(<span class="built_in">j</span>, :) - X(<span class="built_in">i</span>, :)) .^ <span class="number">2</span>, <span class="number">2</span>);  </span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    [t,idx(i)] = min(dis);</span><br><span class="line"><span class="keyword">end</span>  </span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<ol>
<li>Êõ¥Êñ∞ËÅöÁ±ª‰∏≠ÂøÉÁÇπ‰ΩçÁΩÆ</li>
</ol>
<script type="math/tex; mode=display">
\mu_k = \frac{1}{|C_k|} \sum_{i \in C_k} x^{(i)}</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">centroids</span> = <span class="title">computeCentroids</span><span class="params">(X, idx, K)</span></span></span><br><span class="line"><span class="comment">%COMPUTECENTROIDS returns the new centroids by computing the means of the </span></span><br><span class="line"><span class="comment">%data points assigned to each centroid.</span></span><br><span class="line"><span class="comment">%   centroids = COMPUTECENTROIDS(X, idx, K) returns the new centroids by </span></span><br><span class="line"><span class="comment">%   computing the means of the data points assigned to each centroid. It is</span></span><br><span class="line"><span class="comment">%   given a dataset X where each row is a single data point, a vector</span></span><br><span class="line"><span class="comment">%   idx of centroid assignments (i.e. each entry in range [1..K]) for each</span></span><br><span class="line"><span class="comment">%   example, and K, the number of centroids. You should return a matrix</span></span><br><span class="line"><span class="comment">%   centroids, where each row of centroids is the mean of the data points</span></span><br><span class="line"><span class="comment">%   assigned to it.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Useful variables</span></span><br><span class="line">[m n] = <span class="built_in">size</span>(X);</span><br><span class="line"></span><br><span class="line"><span class="comment">% You need to return the following variables correctly.</span></span><br><span class="line">centroids = <span class="built_in">zeros</span>(K, n);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:K</span><br><span class="line">    centroids(<span class="built_in">i</span>,:) = mean(X(<span class="built_in">find</span>(idx==<span class="built_in">i</span>),:));</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p><img src="/qnsource/images/2018-04-26-machinelearning-labs/lab7_01.png" alt="lab7_01"></p>
<p>3.ÂàùÂßãËµ∑ÁÇπÁöÑÈöèÊú∫ÈÄâÂèñ</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% Randomly reorder the indices of examples </span></span><br><span class="line">randidx = randperm(<span class="built_in">size</span>(X, <span class="number">1</span>)); </span><br><span class="line"><span class="comment">% Take the first K examples as centroids </span></span><br><span class="line">centroids = X(randidx(<span class="number">1</span>:K), :);</span><br></pre></td></tr></table></figure>
<ol>
<li>‰ΩøÁî®K-MeansÂéãÁº©ÂõæÁâá</li>
</ol>
<p>Êàë‰ª¨Â∞Ü‰∏ÄÂº†24bitÁöÑÁÖßÁâáÔºåÂéãÁº©‰∏∫4-bitÔºà16‰∏™Ëâ≤ÂΩ©ÔºâÔºõÂØπ‰∫éÊØè‰∏™ÂÉèÁ¥†ÁÇπÔºåÂ∞ÜÈÄâÊã©ÊúÄËøëÁöÑÁ±ªÁ∞áËøõË°åÈ¢úËâ≤Ë°®Á§∫„ÄÇÈÄöËøáÂéãÁº©Â∞Ü128x128x24=393,216bitsÁöÑÂõæÂÉèÂéãÁº©‰∏∫16x24 + 128x128x4=65,920bitsÔºàÂÖ∂‰∏≠ÈúÄË¶ÅÈ¢ùÂ§ñÊØèÁßçÈ¢úËâ≤ÈúÄË¶Å‰∏Ä‰∏™24bitÁ©∫Èó¥Â≠òÂÇ®ÂêÑ‰∏™È¢úËâ≤Â≠óÂÖ∏Ôºâ„ÄÇ</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% ============= Part 4: K-Means Clustering on Pixels ===============</span></span><br><span class="line"><span class="comment">%  In this exercise, you will use K-Means to compress an image. To do this,</span></span><br><span class="line"><span class="comment">%  you will first run K-Means on the colors of the pixels in the image and</span></span><br><span class="line"><span class="comment">%  then you will map each pixel onto its closest centroid.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%  Load an image of a bird</span></span><br><span class="line">A = double(imread(<span class="string">'bird_small.png'</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">% If imread does not work for you, you can try instead</span></span><br><span class="line"><span class="comment">%   load ('bird_small.mat');</span></span><br><span class="line"></span><br><span class="line">A = A / <span class="number">255</span>; <span class="comment">% Divide by 255 so that all values are in the range 0 - 1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Size of the image</span></span><br><span class="line">img_size = <span class="built_in">size</span>(A);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Reshape the image into an Nx3 matrix where N = number of pixels.</span></span><br><span class="line"><span class="comment">% Each row will contain the Red, Green and Blue pixel values</span></span><br><span class="line"><span class="comment">% This gives us our dataset matrix X that we will use K-Means on.</span></span><br><span class="line">X = <span class="built_in">reshape</span>(A, img_size(<span class="number">1</span>) * img_size(<span class="number">2</span>), <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Run your K-Means algorithm on this data</span></span><br><span class="line"><span class="comment">% You should try different values of K and max_iters here</span></span><br><span class="line">K = <span class="number">16</span>; </span><br><span class="line">max_iters = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% When using K-Means, it is important the initialize the centroids</span></span><br><span class="line"><span class="comment">% randomly. </span></span><br><span class="line"><span class="comment">% You should complete the code in kMeansInitCentroids.m before proceeding</span></span><br><span class="line">initial_centroids = kMeansInitCentroids(X, K);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Run K-Means</span></span><br><span class="line">[centroids, idx] = runkMeans(X, initial_centroids, max_iters);</span><br><span class="line"></span><br><span class="line"><span class="comment">%% ================= Part 5: Image Compression ======================</span></span><br><span class="line"><span class="comment">%  In this part of the exercise, you will use the clusters of K-Means to</span></span><br><span class="line"><span class="comment">%  compress an image. To do this, we first find the closest clusters for</span></span><br><span class="line"><span class="comment">%  each example. After that, we </span></span><br><span class="line"><span class="comment">% Find closest cluster members</span></span><br><span class="line">idx = findClosestCentroids(X, centroids);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Essentially, now we have represented the image X as in terms of the</span></span><br><span class="line"><span class="comment">% indices in idx. </span></span><br><span class="line"></span><br><span class="line"><span class="comment">% We can now recover the image from the indices (idx) by mapping each pixel</span></span><br><span class="line"><span class="comment">% (specified by its index in idx) to the centroid value</span></span><br><span class="line">X_recovered = centroids(idx,:);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Reshape the recovered image into proper dimensions</span></span><br><span class="line">X_recovered = <span class="built_in">reshape</span>(X_recovered, img_size(<span class="number">1</span>), img_size(<span class="number">2</span>), <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Display the original image </span></span><br><span class="line">subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>);</span><br><span class="line">imagesc(A); </span><br><span class="line">title(<span class="string">'Original'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Display compressed image side by side</span></span><br><span class="line">subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>);</span><br><span class="line">imagesc(X_recovered)</span><br><span class="line">title(sprintf(<span class="string">'Compressed, with %d colors.'</span>, K));</span><br></pre></td></tr></table></figure>
<p><img src="/qnsource/images/2018-04-26-machinelearning-labs/lab7_02.png" alt="lab7_02"></p>
<h2 id="Lab-7-2Ôºö-PCA"><a href="#Lab-7-2Ôºö-PCA" class="headerlink" title="Lab 7.2Ôºö PCA"></a>Lab 7.2Ôºö PCA</h2><p>Êú¨ÂÆûÈ™åÂà©Áî®PCAÂÆûÁé∞Êï∞ÊçÆÈôçÁª¥ÂèäÂèØËßÜÂåñ„ÄÇ</p>
<p><img src="/qnsource/images/2018-04-26-machinelearning-labs/lab7_03.png" alt="lab7_03"></p>
<ol>
<li>Êï∞ÊçÆÂΩí‰∏ÄÂåñ</li>
<li>ËÆ°ÁÆóÂçèÊñπÂ∑ÆÂíåÂ•áÂºÇÂÄºÂàÜËß£</li>
</ol>
<script type="math/tex; mode=display">
\Sigma =\frac{1}{m}X^TX</script><script type="math/tex; mode=display">
[U, S, V] = svd(\Sigma)</script><p><img src="/qnsource/images/2018-04-26-machinelearning-labs/lab7_04.png" alt="lab7_04"></p>
<ol>
<li>ÈôçÁª¥</li>
</ol>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Z = X * U(:,<span class="number">1</span>:K);</span><br></pre></td></tr></table></figure>
<ol>
<li>Êï∞ÊçÆÊÅ¢Â§ç</li>
</ol>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_rec = Z * U(:,<span class="number">1</span>:K)';</span><br></pre></td></tr></table></figure>
<p><img src="/qnsource/images/2018-04-26-machinelearning-labs/lab7_05.png" alt="lab7_05"></p>
<h3 id="Êï∞ÊçÆÂèØËßÜÂåñÁöÑÈôçÁª¥ÊòæÁ§∫"><a href="#Êï∞ÊçÆÂèØËßÜÂåñÁöÑÈôçÁª¥ÊòæÁ§∫" class="headerlink" title="Êï∞ÊçÆÂèØËßÜÂåñÁöÑÈôçÁª¥ÊòæÁ§∫"></a>Êï∞ÊçÆÂèØËßÜÂåñÁöÑÈôçÁª¥ÊòæÁ§∫</h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% Use PCA to project this cloud to 2D for visualization</span></span><br><span class="line"><span class="comment">% X (16383,3)</span></span><br><span class="line"><span class="comment">% Subtract the mean to use PCA</span></span><br><span class="line">[X_norm, mu, sigma] = featureNormalize(X);</span><br><span class="line"></span><br><span class="line"><span class="comment">% PCA and project the data to 2D</span></span><br><span class="line">[U, S] = pca(X_norm);</span><br><span class="line">Z = projectData(X_norm, U, <span class="number">2</span>);</span><br></pre></td></tr></table></figure>
<p><img src="/qnsource/images/2018-04-26-machinelearning-labs/lab7_10.png" alt="lab7_10"></p>
<p><img src="/qnsource/images/2018-04-26-machinelearning-labs/lab7_09.png" alt="lab7_09"></p>
<h2 id="Lab-8-1-ÂºÇÂ∏∏Ê£ÄÊµã"><a href="#Lab-8-1-ÂºÇÂ∏∏Ê£ÄÊµã" class="headerlink" title="Lab 8.1: ÂºÇÂ∏∏Ê£ÄÊµã"></a>Lab 8.1: ÂºÇÂ∏∏Ê£ÄÊµã</h2><p>Êú¨ÂÆûÈ™åÊê≠Âª∫‰∏Ä‰∏™ÂºÇÂ∏∏Ê£ÄÊµãÁ≥ªÁªüÔºåÁî®Êù•Ê£ÄÊµãÊúçÂä°Âô®ÁöÑÂºÇÂ∏∏‰ø°ÊÅØÔºåËæìÂÖ•‰∏∫ÊØèÂè∞ÊúçÂä°Âô®ÁöÑÊØèÂàÜÈíüÂêûÂêê(mb/s)ÂíåÂìçÂ∫îÂª∂Êó∂ÔºàmsÔºâÔºåÊï∞ÊçÆÊèê‰æõ‰∫Üm=307ÁªÑÊ†∑Êú¨Êï∞ÊçÆ„ÄÇÊúüÊúõÈÄöËøáÈùûÁõëÁù£Â≠¶‰π†ÁöÑÊâãÊÆµÊù•Ê£ÄÊµãÂºÇÂ∏∏„ÄÇ</p>
<p><img src="/qnsource/images/2018-04-26-machinelearning-labs/lab8_01.png" alt="lab8_01"></p>
<p>‰∏∫‰∫ÜÂØπÊï∞ÊçÆÂºÇÂ∏∏ËøõË°åÊ£ÄÊµãÔºåÈ¶ñÂÖàÈúÄË¶ÅÂ∞ÜÂéüÂßãÊï∞ÊçÆÊãüÂêàÂà∞‰∏Ä‰∏™ÂàÜÂ∏ÉÊ®°ÂûãÈáåÔºåÊàë‰ª¨ÈÄâÊã©‰ΩøÁî®Â§öÂÖÉÈ´òÊñØÊ®°ÂûãËøõË°åÊï∞ÊçÆÊãüÂêà:</p>
<script type="math/tex; mode=display">
p(x;\mu,\Sigma) = \dfrac{1}{(2\pi)^{n/2} |\Sigma|^{1/2}} exp(-1/2(x-\mu)^T\Sigma^{-1}(x-\mu))</script><ol>
<li>È¶ñÂÖàÈúÄË¶ÅÂØπÂèÇÊï∞$\mu$ ,$\sigma$ ËøõË°å‰º∞ËÆ°ÔºåÂèÇËßÅÂ¶Ç‰∏ã‰ª£Á†ÅÔºö</li>
</ol>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mu = mean(X, <span class="number">1</span>);</span><br><span class="line">sigma2 = var(X, <span class="number">1</span>);</span><br><span class="line">p = multivariateGaussian(X, mu, sigma2);</span><br><span class="line"><span class="comment">%  Visualize the fit</span></span><br><span class="line">visualizeFit(X,  mu, sigma2);</span><br></pre></td></tr></table></figure>
<p>ÊãüÂêàÈ´òÊñØÂàÜÂ∏ÉÁöÑËΩÆÂªìÂõæÂ¶Ç‰∏ãÔºö</p>
<p><img src="/qnsource/images/2018-04-26-machinelearning-labs/lab8_02.png" alt="lab8_02"></p>
<p>Â§öÂÖÉÈ´òÊñØÂàÜÂ∏ÉÂáΩÊï∞<code>multivariateGaussian()</code>ÁöÑÂÆö‰πâÂ¶Ç‰∏ãÔºö</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">p</span> = <span class="title">multivariateGaussian</span><span class="params">(X, mu, Sigma2)</span></span></span><br><span class="line"><span class="comment">%MULTIVARIATEGAUSSIAN Computes the probability density function of the</span></span><br><span class="line"><span class="comment">%multivariate gaussian distribution.</span></span><br><span class="line"><span class="comment">%    p = MULTIVARIATEGAUSSIAN(X, mu, Sigma2) Computes the probability </span></span><br><span class="line"><span class="comment">%    density function of the examples X under the multivariate gaussian </span></span><br><span class="line"><span class="comment">%    distribution with parameters mu and Sigma2. If Sigma2 is a matrix, it is</span></span><br><span class="line"><span class="comment">%    treated as the covariance matrix. If Sigma2 is a vector, it is treated</span></span><br><span class="line"><span class="comment">%    as the \sigma^2 values of the variances in each dimension (a diagonal</span></span><br><span class="line"><span class="comment">%    covariance matrix)</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line">k = <span class="built_in">length</span>(mu);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">size</span>(Sigma2, <span class="number">2</span>) == <span class="number">1</span>) || (<span class="built_in">size</span>(Sigma2, <span class="number">1</span>) == <span class="number">1</span>)</span><br><span class="line">    Sigma2 = <span class="built_in">diag</span>(Sigma2);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">X = <span class="built_in">bsxfun</span>(@minus, X, mu(:)');</span><br><span class="line">p = (<span class="number">2</span> * <span class="built_in">pi</span>) ^ (- k / <span class="number">2</span>) * det(Sigma2) ^ (<span class="number">-0.5</span>) * ...</span><br><span class="line">    <span class="built_in">exp</span>(<span class="number">-0.5</span> * sum(<span class="built_in">bsxfun</span>(@times, X * pinv(Sigma2), X), <span class="number">2</span>));</span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<ol>
<li>ÈòàÂÄº$\epsilon$ ÁöÑÈÄâÊã©ÔºåÈÄöËøáËÆ°ÁÆóÊØè‰∏™ÈòàÂÄºÁöÑF1ÂæóÂàÜÊù•ËØÑ‰ª∑È™åËØÅÈõÜÊï∞ÊçÆÔºåÈÄâÊã©ÊúÄ‰ºòÂæóÂàÜÁöÑÈòàÂÄºÔºö</li>
</ol>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[bestEpsilon bestF1]</span> = <span class="title">selectThreshold</span><span class="params">(yval, pval)</span></span></span><br><span class="line"><span class="comment">%SELECTTHRESHOLD Find the best threshold (epsilon) to use for selecting</span></span><br><span class="line"><span class="comment">%outliers</span></span><br><span class="line"><span class="comment">%   [bestEpsilon bestF1] = SELECTTHRESHOLD(yval, pval) finds the best</span></span><br><span class="line"><span class="comment">%   threshold to use for selecting outliers based on the results from a</span></span><br><span class="line"><span class="comment">%   validation set (pval) and the ground truth (yval).</span></span><br><span class="line"></span><br><span class="line">bestEpsilon = <span class="number">0</span>;</span><br><span class="line">bestF1 = <span class="number">0</span>;</span><br><span class="line">F1 = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">stepsize = (max(pval) - min(pval)) / <span class="number">1000</span>;</span><br><span class="line"><span class="keyword">for</span> epsilon = min(pval):stepsize:max(pval)</span><br><span class="line">    <span class="comment">% Instructions: Compute the F1 score of choosing epsilon as the</span></span><br><span class="line">    <span class="comment">%               threshold and place the value in F1. The code at the</span></span><br><span class="line">    <span class="comment">%               end of the loop will compare the F1 score for this</span></span><br><span class="line">    <span class="comment">%               choice of epsilon and set it to be the best epsilon if</span></span><br><span class="line">    <span class="comment">%               it is better than the current choice of epsilon.</span></span><br><span class="line">    <span class="comment">%               </span></span><br><span class="line">    <span class="comment">% Note: You can use predictions = (pval &lt; epsilon) to get a binary vector</span></span><br><span class="line">    <span class="comment">%       of 0's and 1's of the outlier predictions</span></span><br><span class="line">    cvPredictions = (pval &lt; epsilon);</span><br><span class="line">    fp = sum((cvPredictions == <span class="number">1</span>)&amp; (yval == <span class="number">0</span>));</span><br><span class="line">    tp = sum((cvPredictions == <span class="number">1</span>)&amp;(yval == <span class="number">1</span>));</span><br><span class="line">    fn = sum((cvPredictions == <span class="number">0</span>)&amp;(yval == <span class="number">1</span>));</span><br><span class="line">    </span><br><span class="line">    prec = tp/(tp + fp);</span><br><span class="line">    rec = tp/(tp + fn);</span><br><span class="line"></span><br><span class="line">    F1 = <span class="number">2</span>*prec*rec/(prec + rec);</span><br><span class="line">    <span class="keyword">if</span> F1 &gt; bestF1</span><br><span class="line">       bestF1 = F1;</span><br><span class="line">       bestEpsilon = epsilon;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">pval = multivariateGaussian(Xval, mu, sigma2);</span><br><span class="line">[epsilon F1] = selectThreshold(yval, pval);</span><br></pre></td></tr></table></figure>
<p><img src="/qnsource/images/2018-04-26-machinelearning-labs/lab8_03.png" alt="lab8_03"></p>
<ol>
<li>Âú®Êõ¥Â§çÊùÇÂú∫ÊôØ‰∏ãÁöÑÂ∫îÁî®ÔºåÁ§∫‰æãÊèê‰æõ‰∫Ü‰∏™ËæìÂÖ•‰∏∫11Áª¥ÁâπÂæÅÁöÑÊï∞ÊçÆÔºåÂØπÂÖ∂ÂºÇÂ∏∏Êï∞ÊçÆËøõË°åÈ¢ÑÊµãÔºå‰ª£Á†ÅÁâáÊÆµÂ¶Ç‰∏ãÔºö</li>
</ol>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%  Apply the same steps to the larger dataset</span></span><br><span class="line">[mu sigma2] = estimateGaussian(X);</span><br><span class="line"></span><br><span class="line"><span class="comment">%  Training set </span></span><br><span class="line">p = multivariateGaussian(X, mu, sigma2);</span><br><span class="line"></span><br><span class="line"><span class="comment">%  Cross-validation set</span></span><br><span class="line">pval = multivariateGaussian(Xval, mu, sigma2);</span><br><span class="line"></span><br><span class="line"><span class="comment">%  Find the best threshold</span></span><br><span class="line">[epsilon F1] = selectThreshold(yval, pval);</span><br><span class="line"></span><br><span class="line">fprintf(<span class="string">'Best epsilon found using cross-validation: %e\n'</span>, epsilon);</span><br><span class="line">fprintf(<span class="string">'Best F1 on Cross Validation Set:  %f\n'</span>, F1);</span><br><span class="line">fprintf(<span class="string">'# Outliers found: %d\n\n'</span>, sum(p &lt; epsilon));</span><br></pre></td></tr></table></figure>
<p>‚Äã</p>
<h2 id="Lab-8-2ÔºöÊé®ËçêÁ≥ªÁªü"><a href="#Lab-8-2ÔºöÊé®ËçêÁ≥ªÁªü" class="headerlink" title="Lab 8.2ÔºöÊé®ËçêÁ≥ªÁªü"></a>Lab 8.2ÔºöÊé®ËçêÁ≥ªÁªü</h2><p>Êú¨ÂÆûÈ™åÂ∞ÜÂÆûÁé∞ÂçèÂêåËøáÊª§ÁÆóÊ≥ïÔºåÂπ∂Â∫îÁî®Âà∞ÁîµÂΩ±Êé®Ëçê‰πã‰∏≠„ÄÇÊï∞ÊçÆÈõÜÊù•Ëá™943‰∏™Áî®Êà∑ÁöÑ1682ÈÉ®ÁîµÂΩ±ÁöÑËØÑÂàÜÊï∞ÊçÆÔºåÊØè‰∏™ËØÑÂàÜËåÉÂõ¥‰∏∫1-5ÔºåÂèØ‰ª•Â≠òÂú®Â§ö‰∏™Êú™ËØÑÂàÜÊï∞ÊçÆ„ÄÇ</p>
<ul>
<li>$X$ ‰∏∫num_movies x num_featuresÔºåÊòØÁîµÂΩ±ÁöÑÁâπÂæÅÁü©Èòµ</li>
<li>$Y$ ‰∏∫num_movies x num_userÁü©ÈòµÔºåÊèèËø∞‰∫ÜÊØè‰∏™ËØÑÂàÜÂÄº$y^{(i,j)}$</li>
<li>$R$ ‰∏∫‰∏é$Y$ ÂêåÁª¥Â∫¶ÁöÑ‰∫åÂÄºÁü©ÈòµÔºå$R(i,j)=1$ ‰ª£Ë°®Áî®Êà∑$j$ ÂØπÁîµÂΩ±$i$ ËøõË°å‰∫ÜËØÑÂàÜ</li>
</ul>
<ol>
<li>‰ª£‰ª∑ÂáΩÊï∞ÁöÑÂÆö‰πâ</li>
</ol>
<script type="math/tex; mode=display">
J(x,\theta) = \dfrac{1}{2} \displaystyle \sum_{(i,j):r(i,j)=1}((\theta^{(j)})^Tx^{(i)} - y^{(i,j)})^2 + \dfrac{\lambda}{2}\sum_{i=1}^{n_m} \sum_{k=1}^{n} (x_k^{(i)})^2 + \dfrac{\lambda}{2}\sum_{j=1}^{n_u} \sum_{k=1}^{n} (\theta_k^{(j)})^2</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[J, grad]</span> = <span class="title">cofiCostFunc</span><span class="params">(params, Y, R, num_users, num_movies, ...</span></span></span><br><span class="line"><span class="function"><span class="params">                                  num_features, lambda)</span></span></span><br><span class="line"><span class="comment">%COFICOSTFUNC Collaborative filtering cost function</span></span><br><span class="line"><span class="comment">%   [J, grad] = COFICOSTFUNC(params, Y, R, num_users, num_movies, ...</span></span><br><span class="line"><span class="comment">%   num_features, lambda) returns the cost and gradient for the</span></span><br><span class="line"><span class="comment">%   collaborative filtering problem.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Unfold the U and W matrices from params</span></span><br><span class="line">X = <span class="built_in">reshape</span>(params(<span class="number">1</span>:num_movies*num_features), num_movies, num_features);</span><br><span class="line">Theta = <span class="built_in">reshape</span>(params(num_movies*num_features+<span class="number">1</span>:<span class="keyword">end</span>), ...</span><br><span class="line">                num_users, num_features);</span><br><span class="line">            </span><br><span class="line"><span class="comment">% You need to return the following values correctly</span></span><br><span class="line">J = <span class="number">0</span>;</span><br><span class="line">X_grad = <span class="built_in">zeros</span>(<span class="built_in">size</span>(X));</span><br><span class="line">Theta_grad = <span class="built_in">zeros</span>(<span class="built_in">size</span>(Theta));</span><br><span class="line"></span><br><span class="line"><span class="comment">% Instructions: Compute the cost function and gradient for collaborative</span></span><br><span class="line"><span class="comment">%               filtering. </span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% Notes: X - num_movies  x num_features matrix of movie features</span></span><br><span class="line"><span class="comment">%        Theta - num_users  x num_features matrix of user features</span></span><br><span class="line"><span class="comment">%        Y - num_movies x num_users matrix of user ratings of movies</span></span><br><span class="line"><span class="comment">%        R - num_movies x num_users matrix, where R(i, j) = 1 if the </span></span><br><span class="line"><span class="comment">%            i-th movie was rated by the j-th user</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% You should set the following variables correctly:</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">%        X_grad - num_movies x num_features matrix, containing the </span></span><br><span class="line"><span class="comment">%                 partial derivatives w.r.t. to each element of X</span></span><br><span class="line"><span class="comment">%        Theta_grad - num_users x num_features matrix, containing the </span></span><br><span class="line"><span class="comment">%                     partial derivatives w.r.t. to each element of Theta</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line">J = <span class="number">1</span>/<span class="number">2</span> * sum(sum(((X * Theta' - Y).*R).^<span class="number">2</span>));</span><br><span class="line"></span><br><span class="line">X_grad = ((X * Theta' - Y).*R) * Theta;</span><br><span class="line">Theta_grad = ((X*Theta' -Y).*R)' * X;</span><br><span class="line"></span><br><span class="line"><span class="comment">% Regular version</span></span><br><span class="line">J = J + lambda/<span class="number">2</span> * sum(sum(Theta .^<span class="number">2</span>)) + lambda/<span class="number">2</span> * sum(sum(X.^<span class="number">2</span>));</span><br><span class="line"></span><br><span class="line">X_grad = X_grad + lambda * X;</span><br><span class="line">Theta_grad = Theta_grad + lambda * Theta;</span><br><span class="line"></span><br><span class="line">grad = [X_grad(:); Theta_grad(:)];</span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%  Evaluate cost function</span></span><br><span class="line">J = cofiCostFunc([X(:) ; Theta(:)], Y, R, num_users, num_movies, num_features, <span class="number">1.5</span>);</span><br></pre></td></tr></table></figure>
<ol>
<li>ÂèëËµ∑È¢ÑÊµãÔºåÂú®Êï∞ÊçÆÂ∫ì‰∏≠Âä†ÂÖ•Ëá™Â∑±ÁöÑÊï∞ÊçÆÔºåÈöè‰æøÂØπ‰∏ÄÈÉ®ÂàÜÁîµÂΩ±ËøõË°åÊâìÂàÜÔºö</li>
</ol>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% ============== Part 6: Entering ratings for a new user ===============</span></span><br><span class="line"><span class="comment">%  Before we will train the collaborative filtering model, we will first</span></span><br><span class="line"><span class="comment">%  add ratings that correspond to a new user that we just observed. This</span></span><br><span class="line"><span class="comment">%  part of the code will also allow you to put in your own ratings for the</span></span><br><span class="line"><span class="comment">%  movies in our dataset!</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line">movieList = loadMovieList();</span><br><span class="line"></span><br><span class="line"><span class="comment">%  Initialize my ratings</span></span><br><span class="line">my_ratings = <span class="built_in">zeros</span>(<span class="number">1682</span>, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Check the file movie_idx.txt for id of each movie in our dataset</span></span><br><span class="line"><span class="comment">% For example, Toy Story (1995) has ID 1, so to rate it "4", you can set</span></span><br><span class="line">my_ratings(<span class="number">1</span>) = <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% Or suppose did not enjoy Silence of the Lambs (1991), you can set</span></span><br><span class="line">my_ratings(<span class="number">98</span>) = <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% We have selected a few movies we liked / did not like and the ratings we</span></span><br><span class="line"><span class="comment">% gave are as follows:</span></span><br><span class="line">my_ratings(<span class="number">7</span>) = <span class="number">3</span>;</span><br><span class="line">my_ratings(<span class="number">12</span>)= <span class="number">5</span>;</span><br><span class="line">my_ratings(<span class="number">54</span>) = <span class="number">4</span>;</span><br><span class="line">my_ratings(<span class="number">64</span>)= <span class="number">5</span>;</span><br><span class="line">my_ratings(<span class="number">66</span>)= <span class="number">3</span>;</span><br><span class="line">my_ratings(<span class="number">69</span>) = <span class="number">5</span>;</span><br><span class="line">my_ratings(<span class="number">183</span>) = <span class="number">4</span>;</span><br><span class="line">my_ratings(<span class="number">226</span>) = <span class="number">5</span>;</span><br><span class="line">my_ratings(<span class="number">355</span>)= <span class="number">5</span>;</span><br></pre></td></tr></table></figure>
<p>Êàë‰ª¨Êã•Êúâ‰∫Ü‰∏Ä‰ªΩÊñ∞ÁöÑÁî®Êà∑ÂØπÁîµÂΩ±ÊâìÂàÜÁöÑÊï∞ÊçÆÔºö</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">New user ratings:</span><br><span class="line">Rated 4 <span class="keyword">for</span> Toy Story (1995)</span><br><span class="line">Rated 3 <span class="keyword">for</span> Twelve Monkeys (1995)</span><br><span class="line">Rated 5 <span class="keyword">for</span> Usual Suspects, The (1995)</span><br><span class="line">Rated 4 <span class="keyword">for</span> Outbreak (1995)</span><br><span class="line">Rated 5 <span class="keyword">for</span> Shawshank Redemption, The (1994)</span><br><span class="line">Rated 3 <span class="keyword">for</span> While You Were Sleeping (1995)</span><br><span class="line">Rated 5 <span class="keyword">for</span> Forrest Gump (1994)</span><br><span class="line">Rated 2 <span class="keyword">for</span> Silence of the Lambs, The (1991)</span><br><span class="line">Rated 4 <span class="keyword">for</span> Alien (1979)</span><br><span class="line">Rated 5 <span class="keyword">for</span> Die Hard 2 (1990)</span><br><span class="line">Rated 5 <span class="keyword">for</span> Sphere (1998)</span><br></pre></td></tr></table></figure>
<ol>
<li>ËÆ≠ÁªÉÁÆóÊ≥ï</li>
</ol>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% ================== Part 7: Learning Movie Ratings ====================</span></span><br><span class="line"><span class="comment">%  Now, you will train the collaborative filtering model on a movie rating </span></span><br><span class="line"><span class="comment">%  dataset of 1682 movies and 943 users</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%  Load data</span></span><br><span class="line">load(<span class="string">'ex8_movies.mat'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">%  Add our own ratings to the data matrix</span></span><br><span class="line">Y = [my_ratings Y];</span><br><span class="line">R = [(my_ratings ~= <span class="number">0</span>) R];</span><br><span class="line"></span><br><span class="line"><span class="comment">%  Normalize Ratings</span></span><br><span class="line">[Ynorm, Ymean] = normalizeRatings(Y, R);</span><br><span class="line"></span><br><span class="line"><span class="comment">%  Useful Values</span></span><br><span class="line">num_users = <span class="built_in">size</span>(Y, <span class="number">2</span>);</span><br><span class="line">num_movies = <span class="built_in">size</span>(Y, <span class="number">1</span>);</span><br><span class="line">num_features = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% Set Initial Parameters (Theta, X)</span></span><br><span class="line">X = <span class="built_in">randn</span>(num_movies, num_features);</span><br><span class="line">Theta = <span class="built_in">randn</span>(num_users, num_features);</span><br><span class="line"></span><br><span class="line">initial_parameters = [X(:); Theta(:)];</span><br><span class="line"></span><br><span class="line"><span class="comment">% Set options for fmincg</span></span><br><span class="line">options = optimset(<span class="string">'GradObj'</span>, <span class="string">'on'</span>, <span class="string">'MaxIter'</span>, <span class="number">100</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Set Regularization</span></span><br><span class="line">lambda = <span class="number">10</span>;</span><br><span class="line">theta = fmincg (@(t)(cofiCostFunc(t, Ynorm, R, num_users, num_movies, ...</span><br><span class="line">                                num_features, lambda)), ...</span><br><span class="line">                initial_parameters, options);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Unfold the returned theta back into U and W</span></span><br><span class="line">X = <span class="built_in">reshape</span>(theta(<span class="number">1</span>:num_movies*num_features), num_movies, num_features);</span><br><span class="line">Theta = <span class="built_in">reshape</span>(theta(num_movies*num_features+<span class="number">1</span>:<span class="keyword">end</span>), ...</span><br><span class="line">                num_users, num_features);</span><br><span class="line"></span><br><span class="line">fprintf(<span class="string">'Recommender system learning completed.\n'</span>);</span><br><span class="line"></span><br><span class="line">fprintf(<span class="string">'\nProgram paused. Press enter to continue.\n'</span>);</span><br><span class="line">pause;</span><br></pre></td></tr></table></figure>
<p>ÂÖ∂‰∏≠ÔºåÂáΩÊï∞<code>normalizeRatings</code> Áî®‰∫éÂØπÊï∞ÊçÆËøõË°åÂΩí‰∏ÄÂåñÔºåÂáèÂéªÂùáÂÄºÔºõÂáΩÊï∞<code>fmincg</code>‰∏∫MATLABËá™Â∏¶ÁöÑ‰ºòÂåñÂáΩÊï∞Ôºõ</p>
<ol>
<li>Âà©Áî®ÁÆóÊ≥ïËøõË°åÊé®Ëçê</li>
</ol>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% ================== Part 8: Recommendation for you ====================</span></span><br><span class="line"><span class="comment">%  After training the model, you can now make recommendations by computing</span></span><br><span class="line"><span class="comment">%  the predictions matrix.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line">p = X * Theta';</span><br><span class="line">my_predictions = p(:,<span class="number">1</span>) + Ymean;</span><br><span class="line"></span><br><span class="line">movieList = loadMovieList();</span><br><span class="line"></span><br><span class="line">[r, ix] = sort(my_predictions, <span class="string">'descend'</span>);</span><br><span class="line">fprintf(<span class="string">'\nTop recommendations for you:\n'</span>);</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="number">10</span></span><br><span class="line">    <span class="built_in">j</span> = ix(<span class="built_in">i</span>);</span><br><span class="line">    fprintf(<span class="string">'Predicting rating %.1f for movie %s\n'</span>, my_predictions(<span class="built_in">j</span>), ...</span><br><span class="line">            movieList&#123;j&#125;);</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>ËæìÂá∫ÁªìÊûúÔºö</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Top recommendations <span class="keyword">for</span> you:</span><br><span class="line">Predicting rating 5.0 <span class="keyword">for</span> movie Someone Else<span class="string">'s America (1995)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Aiqing wansui (1994)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Great Day in Harlem, A (1994)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Prefontaine (1997)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie They Made Me a Criminal (1939)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Entertaining Angels: The Dorothy Day Story (1996)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Saint of Fort Washington, The (1993)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Santa with Muscles (1996)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Star Kid (1997)</span></span><br><span class="line"><span class="string">Predicting rating 5.0 for movie Marlene Dietrich: Shadow and Light (1996)</span></span><br></pre></td></tr></table></figure>
<h2 id="ÂèÇËÄÉ"><a href="#ÂèÇËÄÉ" class="headerlink" title="ÂèÇËÄÉ"></a>ÂèÇËÄÉ</h2><ol>
<li>‚Äã</li>
</ol>

      
    </div>
    <footer class="article-footer">

      
      

      
      <!--  -->

      <!--  -->
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ÂÖ¨ÂºÄËØæ/">ÂÖ¨ÂºÄËØæ</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ÂÆûÈ™å/">ÂÆûÈ™å</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Êú∫Âô®Â≠¶‰π†/">Êú∫Âô®Â≠¶‰π†</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Á∫øÊÄßÂõûÂΩí/">Á∫øÊÄßÂõûÂΩí</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ÈÄªËæëÂõûÂΩí/">ÈÄªËæëÂõûÂΩí</a></li></ul>

    </footer>
  </div>
  
</article>

<!-- Table of Contents -->


  
    <article id="post-machinelearning-notes"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2018/04/26/machinelearning-notes/">Machine Learning Notes</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2018/04/26/machinelearning-notes/" class="article-date">
	  <time datetime="2018-04-26T05:56:13.000Z" itemprop="datePublished">2018-04-26</time>
	</a>

      
    <a class="article-category-link" href="/categories/Êú∫Âô®Â≠¶‰π†/">Êú∫Âô®Â≠¶‰π†</a>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>ÊëòË¶ÅÔºö</strong> ÊúÄËøëËä±‰∫Ü‰∏§Âë®Êó∂Èó¥Âà∑ÂÆå‰∫ÜÂê¥ÊÅ©ËææÂú®Cousera‰∏äÂÖ≥‰∫é<a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="noopener">Êú∫Âô®Â≠¶‰π†</a>ÁöÑÁªèÂÖ∏ËØæÁ®ã, ËøôÂ∑≤ÁªèÊòØËøë‰∏§‰∏™ÊúàÊù•Âà∑ÂÆåÁöÑÁ¨¨ÂçÅ‰∏™CouseraËØæÁ®ã‰∫Ü„ÄÇËôΩÁÑ∂ËØæÁ®ãÊòØÂ§öÂπ¥ÂâçÂºÄËÆæÁöÑÔºå‰ΩÜÁõ∏ÂÖ≥Êú∫Âô®Â≠¶‰π†ÁêÜËÆ∫ÂíåÊñπÊ≥ïÂÜÖÂÆπ‰ªãÁªç‰ªçÁÑ∂ÂÖ∑Â§áÂæàÂº∫ÁöÑÊó∂ÊïàÊÄßÔºåÊòØÊú∫Âô®Â≠¶‰π†ÂÖ•Èó®ÁöÑÂøÖÈÄâËØæÁ®ã„ÄÇ</p>
<!-- excerpt -->
<p>@[toc]</p>
<blockquote>
<p>ÊúÄËøëËä±‰∫Ü‰∏§Âë®Êó∂Èó¥Âà∑ÂÆå‰∫ÜÂê¥ÊÅ©ËææÂú®Cousera‰∏äÂÖ≥‰∫é<a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="noopener">Êú∫Âô®Â≠¶‰π†</a>ÁöÑÁªèÂÖ∏ËØæÁ®ã, ËøôÂ∑≤ÁªèÊòØËøë‰∏§‰∏™ÊúàÊù•Âà∑ÂÆåÁöÑÁ¨¨ÂçÅ‰∏™CouseraËØæÁ®ã‰∫Ü„ÄÇËôΩÁÑ∂ËØæÁ®ãÊòØÂ§öÂπ¥ÂâçÂºÄËÆæÁöÑÔºå‰ΩÜÁõ∏ÂÖ≥Êú∫Âô®Â≠¶‰π†ÁêÜËÆ∫ÂíåÊñπÊ≥ïÂÜÖÂÆπ‰ªãÁªç‰ªçÁÑ∂ÂÖ∑Â§áÂæàÂº∫ÁöÑÊó∂ÊïàÊÄßÔºåÊòØÊú∫Âô®Â≠¶‰π†ÂÖ•Èó®ÁöÑÂøÖÈÄâËØæÁ®ã„ÄÇ‰∏∫‰∫ÜÂ∑©Âõ∫ÂØπËØæÁ®ãÂÜÖÂÆπÂíåËØæÂêéÂÆûÈ™åÁöÑÁêÜËß£ÔºåÂ∞ÜÂú®Êú™Êù•‰∏ÄÂë®ÂÆûË∑µÂÜôÂá†ÁØáÊÄªÁªìÊÄßÁ¨îËÆ∞Ôºå‰Ωú‰∏∫ÂØπËØæÁ®ãÂÜÖÂÆπÁöÑÂõûÈ°æÂíåÊÄªÁªì„ÄÇ</p>
</blockquote>
<h2 id="Lecture-1Ôºö-Êú∫Âô®Â≠¶‰π†ÁöÑÂÆö‰πâ"><a href="#Lecture-1Ôºö-Êú∫Âô®Â≠¶‰π†ÁöÑÂÆö‰πâ" class="headerlink" title="Lecture 1Ôºö Êú∫Âô®Â≠¶‰π†ÁöÑÂÆö‰πâ"></a>Lecture 1Ôºö Êú∫Âô®Â≠¶‰π†ÁöÑÂÆö‰πâ</h2><blockquote>
<p>Tom Mitchell provides a modern definition: ‚ÄúA computer program is said to learn from experience <strong>E</strong> with respect to some class of tasks <strong>T</strong> and performance measure <strong>P</strong>, if its performance at tasks in <strong>T</strong>, as measured by <strong>P</strong>, improves with experience <strong>E</strong>.‚Äù</p>
</blockquote>
<ol>
<li>ÁõëÁù£Â≠¶‰π†ÁöÑ‰∏Ä‰∏™‰∏ªË¶ÅÁâπÁÇπÔºåÊòØÂú®ÊãøÂà∞Êï∞ÊçÆÁöÑÈÇ£‰∏ÄÂàªÔºåÊàë‰ª¨Â∑≤ÁªèÁü•ÈÅìÊ≠£Á°ÆÁöÑËæìÂá∫ÁõÆÊ†áËåÉÂõ¥Ôºõ<ul>
<li>ÁõëÁù£Â≠¶‰π†ÂèØ‰ª•ÂàÜ‰∏∫ÂàÜÁ±ªÈóÆÈ¢òÂíåÂõûÂΩíÈóÆÈ¢òÔºõ</li>
</ul>
</li>
<li>È∏°Â∞æÈÖí‰ºöÈóÆÈ¢òÂèäÈ∏°Â∞æÈÖí‰ºöÁÆóÊ≥ïÔºö<a href="https://en.wikipedia.org/wiki/Cocktail_party_effect" target="_blank" rel="noopener">Wiki</a>, Â±û‰∫éÈùûËÅöÁ±ªÁöÑÈùûÁõëÁù£ÈóÆÈ¢ò</li>
</ol>
<h2 id="Lecture-2Ôºö-Á∫øÊÄßÂõûÂΩíÔºàÂ§öÂ±ûÊÄßÔºâ"><a href="#Lecture-2Ôºö-Á∫øÊÄßÂõûÂΩíÔºàÂ§öÂ±ûÊÄßÔºâ" class="headerlink" title="Lecture 2Ôºö Á∫øÊÄßÂõûÂΩíÔºàÂ§öÂ±ûÊÄßÔºâ"></a>Lecture 2Ôºö Á∫øÊÄßÂõûÂΩíÔºàÂ§öÂ±ûÊÄßÔºâ</h2><h3 id="ÂèòÈáèÂÆö‰πâ"><a href="#ÂèòÈáèÂÆö‰πâ" class="headerlink" title="ÂèòÈáèÂÆö‰πâ"></a>ÂèòÈáèÂÆö‰πâ</h3><p>$x_j^{(i)}$ : Á¨¨$i^{th}$ËÆ≠ÁªÉÊ†∑Êú¨ÁöÑÁ¨¨$j$‰∏™ÁâπÂæÅÂêëÈáèÔºõ</p>
<p>$x^{(i)}$ : Á¨¨$i^{th}$ËÆ≠ÁªÉÊ†∑Êú¨ÁöÑÁâπÂæÅÂêëÈáèÔºõ</p>
<p>$m$ Ôºö ËÆ≠ÁªÉÊ†∑Êú¨Êï∞ÁõÆÔºõ</p>
<p>$n$ Ôºö ÁâπÂæÅÊï∞ÁõÆ</p>
<h3 id="Â§öÂÖÉÁ∫øÊÄßËßÑÂàíÊ®°Âûã"><a href="#Â§öÂÖÉÁ∫øÊÄßËßÑÂàíÊ®°Âûã" class="headerlink" title="Â§öÂÖÉÁ∫øÊÄßËßÑÂàíÊ®°Âûã"></a>Â§öÂÖÉÁ∫øÊÄßËßÑÂàíÊ®°Âûã</h3><h4 id="ÂÅáËÆæÂáΩÊï∞"><a href="#ÂÅáËÆæÂáΩÊï∞" class="headerlink" title="ÂÅáËÆæÂáΩÊï∞"></a>ÂÅáËÆæÂáΩÊï∞</h4><script type="math/tex; mode=display">
\begin{equation} h_\theta (x) = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + \theta_3 x_3 + \cdots + \theta_n x_n = \theta ^T x  \tag{1.a} \end{equation}</script><blockquote>
<p>‰ª•‰∏äË°®ËææÂºè‰∏≠ÂØπ$\theta$ Âíå $x$ ËøõË°å‰∫ÜÁª¥Â∫¶ÂèòÊç¢Ôºå$x_0=1,for(i\in1,‚Ä¶,m)$</p>
<p>$\theta .shape = (n+1, 1)$</p>
<p>$x.shape = (m,n+1)$</p>
</blockquote>
<h4 id="‰ª£‰ª∑ÂáΩÊï∞"><a href="#‰ª£‰ª∑ÂáΩÊï∞" class="headerlink" title="‰ª£‰ª∑ÂáΩÊï∞"></a>‰ª£‰ª∑ÂáΩÊï∞</h4><script type="math/tex; mode=display">
J(\theta) = \dfrac {1}{2m} \displaystyle \sum_{i=1}^m \left (h_\theta (x^{(i)}) - y^{(i)} \right)^2 = \dfrac {1}{2m} (X\theta - \vec{y})^{T} (X\theta - \vec{y})</script><h4 id="Ê¢ØÂ∫¶"><a href="#Ê¢ØÂ∫¶" class="headerlink" title="Ê¢ØÂ∫¶"></a>Ê¢ØÂ∫¶</h4><script type="math/tex; mode=display">
\theta := \theta - \frac{\alpha}{m} X^{T} (X\theta - \vec{y})</script><h3 id="ÁâπÂæÅÊ≠£ÂàôÂåñ"><a href="#ÁâπÂæÅÊ≠£ÂàôÂåñ" class="headerlink" title="ÁâπÂæÅÊ≠£ÂàôÂåñ"></a>ÁâπÂæÅÊ≠£ÂàôÂåñ</h3><blockquote>
<ol>
<li>Feature scaling Âíå mean normalizationÂÆûÁé∞;</li>
<li>ÂΩí‰∏ÄÂåñÁöÑÁõÆÁöÑÔºåÊòØ‰∏∫‰∫ÜÊî∂ÊïõÂüüÂØπÂÖ∂ÔºåÊõ¥ÂÆπÊòìÊî∂ÊïõÔºåÊ¢ØÂ∫¶‰∏ãÈôçÊõ¥ÂÆπÊòìÊâæÂà∞ÊúÄ‰Ω≥ÊñπÂêëÔºõ</li>
<li>Âê¥ÊÅ©ËææÊâì‰∫Ü‰∏™ÂæàÂ•ΩÁöÑÊØîÂñªÔºå‰∏§‰∏™ÂèÇÊï∞ËåÉÂõ¥‰∏ç‰∏ÄËá¥ÔºåÊ¢ØÂ∫¶‰∏ãÈôçÊòØ‰∏Ä‰∏™Ê§≠ÂúÜÔºõ</li>
</ol>
</blockquote>
<script type="math/tex; mode=display">
x_i := \dfrac{x_i - \mu_i}{s_i}</script><h3 id="ÂèÇÊï∞ÂàÜÊûê"><a href="#ÂèÇÊï∞ÂàÜÊûê" class="headerlink" title="ÂèÇÊï∞ÂàÜÊûê"></a>ÂèÇÊï∞ÂàÜÊûê</h3><script type="math/tex; mode=display">
\theta = (X^T X)^{-1}X^T y</script><div class="table-container">
<table>
<thead>
<tr>
<th>Gradient Descent</th>
<th>Normal Equation</th>
</tr>
</thead>
<tbody>
<tr>
<td>Need to choose alpha</td>
<td>No need to choose alpha</td>
</tr>
<tr>
<td>Needs many iterations</td>
<td>No need to iterate</td>
</tr>
<tr>
<td>$O(kn^2)$</td>
<td>$O(n^3)$ ,ËÆ°ÁÆóÂ§çÊùÇÂ∫¶Êù•Ëá™$X^TX$ ÁöÑËÆ°ÁÆó</td>
</tr>
<tr>
<td>Works well when n is large</td>
<td>Slow if n is very large</td>
</tr>
</tbody>
</table>
</div>
<h2 id="Lecture-3ÔºöÈÄªËæëÂõûÂΩí"><a href="#Lecture-3ÔºöÈÄªËæëÂõûÂΩí" class="headerlink" title="Lecture 3ÔºöÈÄªËæëÂõûÂΩí"></a>Lecture 3ÔºöÈÄªËæëÂõûÂΩí</h2><blockquote>
<p><strong>ÈÄªËæëÂõûÂΩíÂêçÁß∞ÁöÑÁî±Êù•</strong>ÔºöÈÄªËæëÂõûÂΩíÊù•Ê∫ê‰∫éLogistic ÂàÜÂ∏ÉÔºåËôΩÁÑ∂ÂêçÂ≠óÂ∏¶ÂõûÂΩíÔºå‰ΩÜËß£ÂÜ≥ÁöÑÊòØÂàÜÁ±ªÈóÆÈ¢ò„ÄÇËÄåÂÖ∂ÂØÜÂ∫¶ÂáΩÊï∞Êõ≤Á∫øÊ≠£ÂØπÂ∫îÁùÄSigmoidÂáΩÊï∞ÁöÑÊõ≤Á∫øÂΩ¢Áä∂„ÄÇ</p>
</blockquote>
<h3 id="ÂÅáËÆæÂáΩÊï∞-1"><a href="#ÂÅáËÆæÂáΩÊï∞-1" class="headerlink" title="ÂÅáËÆæÂáΩÊï∞"></a>ÂÅáËÆæÂáΩÊï∞</h3><script type="math/tex; mode=display">
\begin{align*} h_\theta (x) =  g ( \theta^T x ) \\ z = \theta^T x \\g(z) = \dfrac{1}{1 + e^{-z}}\end{align*}</script><p>ÂÅáËÆæÂáΩÊï∞ËæìÂá∫ÁöÑÂàÜÁ±ªÁõÆÊ†áÁöÑÊù°‰ª∂Ê¶ÇÁéáÔºö</p>
<script type="math/tex; mode=display">
\begin{align*}& h_\theta(x) = P(y=1 | x ; \theta) = 1 - P(y=0 | x ; \theta) \newline& P(y = 0 | x;\theta) + P(y = 1 | x ; \theta) = 1\end{align*}</script><h3 id="‰ª£‰ª∑ÂáΩÊï∞-1"><a href="#‰ª£‰ª∑ÂáΩÊï∞-1" class="headerlink" title="‰ª£‰ª∑ÂáΩÊï∞"></a>‰ª£‰ª∑ÂáΩÊï∞</h3><script type="math/tex; mode=display">
\begin{align*}& J(\theta) = \dfrac{1}{m} \sum_{i=1}^m \mathrm{Cost}(h_\theta(x^{(i)}),y^{(i)})=-\frac{1}{m}(y^Tlog(h)+(1-y)^T(1-h)) \newline & \mathrm{Cost}(h_\theta(x),y) = -\log(h_\theta(x)) \; & \text{if y = 1} \newline & \mathrm{Cost}(h_\theta(x),y) = -\log(1-h_\theta(x)) \; & \text{if y = 0}\end{align*}</script><h3 id="Ê¢ØÂ∫¶-1"><a href="#Ê¢ØÂ∫¶-1" class="headerlink" title="Ê¢ØÂ∫¶"></a>Ê¢ØÂ∫¶</h3><script type="math/tex; mode=display">
\theta := \theta - \frac{\alpha}{m} X^{T} (g(X \theta ) - \vec{y})</script><script type="math/tex; mode=display">
\sigma(x)'=\sigma(x)(1 - \sigma(x))</script><blockquote>
<p>‰∏Ä‰∫õÊ¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ï‰πãÂ§ñÁöÑÈÄâÊã©Ôºö Èô§‰∫ÜÊ¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ï‰ª•Â§ñÔºåËøòÊúâ‰∏Ä‰∫õÂ∏∏Ë¢´Áî®Êù•‰ª§‰ª£‰ª∑ÂáΩÊï∞ÊúÄÂ∞èÁöÑÁÆóÊ≥ïÔºåËøô‰∫õÁÆóÊ≥ïÊõ¥Âä†Â§çÊùÇÂíå‰ºòË∂äÔºåËÄå‰∏îÈÄöÂ∏∏‰∏çÈúÄË¶Å‰∫∫Â∑•ÈÄâÊã©Â≠¶‰π†ÁéáÔºåÈÄöÂ∏∏ÊØîÊ¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ïË¶ÅÊõ¥Âä†Âø´ÈÄü„ÄÇËøô‰∫õÁÆóÊ≥ïÊúâÔºöÂÖ±ËΩ≠Ê¢ØÂ∫¶ÔºàConjugate GradientÔºâÔºåÂ±ÄÈÉ®‰ºòÂåñÊ≥ï(Broyden fletcher goldfarb shann,BFGS)ÂíåÊúâÈôêÂÜÖÂ≠òÂ±ÄÈÉ®‰ºòÂåñÊ≥ï(LBFGS)<br>fminuncÊòØ matlabÂíåoctave ‰∏≠ÈÉΩÂ∏¶ÁöÑ‰∏Ä‰∏™ÊúÄÂ∞èÂÄº‰ºòÂåñÂáΩÊï∞Ôºå‰ΩøÁî®Êó∂Êàë‰ª¨ÈúÄË¶ÅÊèê‰æõ‰ª£‰ª∑ÂáΩÊï∞ÂíåÊØè‰∏™ÂèÇÊï∞ÁöÑÊ±ÇÂØº</p>
</blockquote>
<h3 id="Â§öÂàÜÁ±ªÔºö-One-vs-all"><a href="#Â§öÂàÜÁ±ªÔºö-One-vs-all" class="headerlink" title="Â§öÂàÜÁ±ªÔºö One-vs-all"></a>Â§öÂàÜÁ±ªÔºö One-vs-all</h3><p>ÊØè‰∏™ÂàÜÁ±ªÁõÆÊ†áÂØπÂ∫î‰∏Ä‰∏™ÂàÜÁ±ªÂô®ÔºåËÆ°ÁÆóÂàÜÁ±ªËøáÁ®ã‰∏≠ÔºåÂèñÈ¢ÑÊµãÂÄºÊúÄÂ§ßÁöÑÂàÜÁ±ªÂô®ËæìÂá∫‰Ωú‰∏∫ÊúÄÁªàÂàÜÁ±ªÁªìÊûúÔºö</p>
<script type="math/tex; mode=display">
prediction = \max_i( h_\theta ^{(i)}(x) )</script><h3 id="Ê≠£ÂàôÂåñ"><a href="#Ê≠£ÂàôÂåñ" class="headerlink" title="Ê≠£ÂàôÂåñ"></a>Ê≠£ÂàôÂåñ</h3><h3 id="Ê≠£ÂàôÂåñÁöÑÁ∫øÊÄßÂõûÂΩí"><a href="#Ê≠£ÂàôÂåñÁöÑÁ∫øÊÄßÂõûÂΩí" class="headerlink" title="Ê≠£ÂàôÂåñÁöÑÁ∫øÊÄßÂõûÂΩí"></a>Ê≠£ÂàôÂåñÁöÑÁ∫øÊÄßÂõûÂΩí</h3><script type="math/tex; mode=display">
\begin{align*}
& \text{Repeat}\ \lbrace \newline
& \ \ \ \ \theta_0 := \theta_0 - \alpha\ \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_0^{(i)} \newline
& \ \ \ \ \theta_j := \theta_j - \alpha\ \left[ \left( \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \right) + \frac{\lambda}{m}\theta_j \right] &\ \ \ \ \ \ \ \ \ \ j \in \lbrace 1,2...n\rbrace\newline
& \rbrace
\end{align*}</script><h4 id="Ê∑ªÂä†Ê≠£ÂàôÂåñÁöÑÊï∞ÂÄºËß£"><a href="#Ê∑ªÂä†Ê≠£ÂàôÂåñÁöÑÊï∞ÂÄºËß£" class="headerlink" title="Ê∑ªÂä†Ê≠£ÂàôÂåñÁöÑÊï∞ÂÄºËß£"></a>Ê∑ªÂä†Ê≠£ÂàôÂåñÁöÑÊï∞ÂÄºËß£</h4><script type="math/tex; mode=display">
\begin{align*}& \theta = \left( X^TX + \lambda \cdot L \right)^{-1} X^Ty \newline& \text{where}\ \ L = \begin{bmatrix} 0 & & & & \newline & 1 & & & \newline & & 1 & & \newline & & & \ddots & \newline & & & & 1 \newline\end{bmatrix}\end{align*}</script><h3 id="Ê≠£ÂàôÂåñÁöÑÈÄªËæëÂõûÂΩí"><a href="#Ê≠£ÂàôÂåñÁöÑÈÄªËæëÂõûÂΩí" class="headerlink" title="Ê≠£ÂàôÂåñÁöÑÈÄªËæëÂõûÂΩí"></a>Ê≠£ÂàôÂåñÁöÑÈÄªËæëÂõûÂΩí</h3><script type="math/tex; mode=display">
J(\theta) = - \frac{1}{m} \sum_{i=1}^m \large[ y^{(i)}\ \log (h_\theta (x^{(i)})) + (1 - y^{(i)})\ \log (1 - h_\theta(x^{(i)}))\large] + \frac{\lambda}{2m}\sum_{j=1}^n \theta_j^2</script><script type="math/tex; mode=display">
\begin{array}& \text{Repeat}\ \lbrace \newline& \ \ \ \ \theta_0 := \theta_0 - \alpha\ \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_0^{(i)} \newline& \ \ \ \ \theta_j := \theta_j - \alpha\ \left[ \left( \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \right) + \frac{\lambda}{m}\theta_j \right] &\ \ \ \ \ \ \ \ \ \ j \in \lbrace 1,2...n\rbrace\newline& \rbrace\end{array}</script><h2 id="Lecture-4-5-Á•ûÁªèÁΩëÁªú"><a href="#Lecture-4-5-Á•ûÁªèÁΩëÁªú" class="headerlink" title="Lecture 4-5: Á•ûÁªèÁΩëÁªú"></a>Lecture 4-5: Á•ûÁªèÁΩëÁªú</h2><ul>
<li>Â§ßËÑëÂ≠¶‰π†ÁöÑÂéüÁêÜ‰∏æ‰æãÔºö ‰∫∫Á±ªÂ§±ÂéªÁúºÁùõÔºåÂèØ‰ª•Â≠¶‰π†ÈÄöËøáË∂ÖÂ£∞Êù•Âà§Êñ≠Áâ©‰ΩìÂíåÊñπ‰ΩçÔºåÂÖ∑Â§áÁúãÁöÑËÉΩÂäõÔºõ</li>
</ul>
<p>If networkhas $s_j$ units in layer j and $s_j +1$ units in layer j+1, then Œò(j) willbe of dimension sj+1√ó(sj+1).</p>
<h3 id="Â§öÂàÜÁ±ª"><a href="#Â§öÂàÜÁ±ª" class="headerlink" title="Â§öÂàÜÁ±ª"></a>Â§öÂàÜÁ±ª</h3><script type="math/tex; mode=display">
\begin{align*}\begin{bmatrix}x_0 \newline x_1 \newline x_2 \newline\cdots \newline x_n\end{bmatrix} \rightarrow\begin{bmatrix}a_0^{(2)} \newline a_1^{(2)} \newline a_2^{(2)} \newline\cdots\end{bmatrix} \rightarrow\begin{bmatrix}a_0^{(3)} \newline a_1^{(3)} \newline a_2^{(3)} \newline\cdots\end{bmatrix} \rightarrow \cdots \rightarrow\begin{bmatrix}h_\Theta(x)_1 \newline h_\Theta(x)_2 \newline h_\Theta(x)_3 \newline h_\Theta(x)_4 \newline\end{bmatrix} \rightarrow\end{align*}</script><h3 id="‰ª£‰ª∑ÂáΩÊï∞-2"><a href="#‰ª£‰ª∑ÂáΩÊï∞-2" class="headerlink" title="‰ª£‰ª∑ÂáΩÊï∞"></a>‰ª£‰ª∑ÂáΩÊï∞</h3><script type="math/tex; mode=display">
\begin{gather*}\large J(\Theta) = - \frac{1}{m} \sum_{i=1}^m \sum_{k=1}^K \left[y^{(i)}_k \log ((h_\Theta (x^{(i)}))_k) + (1 - y^{(i)}_k)\log (1 - (h_\Theta(x^{(i)}))_k)\right] + \frac{\lambda}{2m}\sum_{l=1}^{L-1} \sum_{i=1}^{s_l} \sum_{j=1}^{s_{l+1}} ( \Theta_{j,i}^{(l)})^2\end{gather*}</script><h3 id="ÂèçÂêë‰º†Êí≠"><a href="#ÂèçÂêë‰º†Êí≠" class="headerlink" title="ÂèçÂêë‰º†Êí≠"></a>ÂèçÂêë‰º†Êí≠</h3><blockquote>
<p>ÂèÇËßÅÔºö <a href="Backpropagation-in-Neural-Network/">Backpropagation-in-Neural-Network</a></p>
</blockquote>
<h3 id="Ê¢ØÂ∫¶Ê†°È™å"><a href="#Ê¢ØÂ∫¶Ê†°È™å" class="headerlink" title="Ê¢ØÂ∫¶Ê†°È™å"></a>Ê¢ØÂ∫¶Ê†°È™å</h3><script type="math/tex; mode=display">
\dfrac{\partial}{\partial\Theta_j}J(\Theta) \approx \dfrac{J(\Theta_1, \dots, \Theta_j + \epsilon, \dots, \Theta_n) - J(\Theta_1, \dots, \Theta_j - \epsilon, \dots, \Theta_n)}{2\epsilon}</script><h2 id="Lecture-6ÔºöÈááÁî®Êú∫Âô®Â≠¶‰π†ÁöÑÂª∫ËÆÆ"><a href="#Lecture-6ÔºöÈááÁî®Êú∫Âô®Â≠¶‰π†ÁöÑÂª∫ËÆÆ" class="headerlink" title="Lecture 6ÔºöÈááÁî®Êú∫Âô®Â≠¶‰π†ÁöÑÂª∫ËÆÆ"></a>Lecture 6ÔºöÈááÁî®Êú∫Âô®Â≠¶‰π†ÁöÑÂª∫ËÆÆ</h2><h3 id="bias-‰∏é-variance"><a href="#bias-‰∏é-variance" class="headerlink" title="bias ‰∏é variance"></a>bias ‰∏é variance</h3><ul>
<li>È´òÂÅèÂ∑Æ==Ê¨†ÊãüÂêà</li>
<li>È´òÊñπÂ∑Æ==ËøáÊãüÂêà</li>
</ul>
<p><img src="/qnsource/images/2018-04-25-machine-learning-notes/Features-and-polynom-degree.png" alt="Features-and-polynom-degree"></p>
<p>Ê≠£ÂàôÂåñ‰∏éÂÅèÂ∑Æ/ÊñπÂ∑ÆÔºö</p>
<ul>
<li>Â§ßÁöÑ$\lambda$ :È´òÂÅèÂ∑ÆÔºàÊ¨†ÊãüÂêàÔºâÔºõ</li>
<li>Â∞èÁöÑ$\lambda$ :È´òÊñπÂ∑ÆÔºàËøáÊãüÂêàÔºâÔºõ</li>
</ul>
<p><img src="/qnsource/images/2018-04-25-machine-learning-notes/Features-and-polynom-degree-fix.png" alt="Features-and-polynom-degree-fix"></p>
<blockquote>
<p>ÈÄâÊã©ÂêàÈÄÇÁöÑÊ≠£ÂàôÂåñÂèÇÊï∞</p>
</blockquote>
<h3 id="Â≠¶‰π†Êõ≤Á∫øÔºàLearning-CurvesÔºâ"><a href="#Â≠¶‰π†Êõ≤Á∫øÔºàLearning-CurvesÔºâ" class="headerlink" title="Â≠¶‰π†Êõ≤Á∫øÔºàLearning CurvesÔºâ"></a>Â≠¶‰π†Êõ≤Á∫øÔºàLearning CurvesÔºâ</h3><blockquote>
<p>ÈîôËØØÁéáÈöèÊ†∑Êú¨Êï∞ÁõÆÂèòÂåñÁöÑÊõ≤Á∫øÔºõ</p>
<p>Â¶ÇÊûúÁÆóÊ≥ïËøáÊãüÂêàÔºåÂ¢ûÂ§ßÊ†∑Êú¨Êï∞ÊúâÂä©‰∫éÊèêÂçáÁÆóÊ≥ïÊÄßËÉΩ</p>
</blockquote>
<p><img src="/qnsource/images/2018-04-25-machine-learning-notes/Learning2.png" alt="Learning2"></p>
<p><img src="/qnsource/images/2018-04-25-machine-learning-notes/Learning1.png" alt="Learning1"></p>
<h2 id="Lecture-7Ôºö-SVM"><a href="#Lecture-7Ôºö-SVM" class="headerlink" title="Lecture 7Ôºö SVM"></a>Lecture 7Ôºö SVM</h2><script type="math/tex; mode=display">
z = \theta^Tx</script><script type="math/tex; mode=display">
\text{cost}_0(z) = \max(0, k(1+z))</script><script type="math/tex; mode=display">
\text{cost}_1(z) = \max(0, k(1-z))</script><blockquote>
<p>Êõ¥Â§öÂÜÖÂÆπÊü•ÁúãWiKiÔºö <a href="https://en.wikipedia.org/wiki/Hinge_loss" target="_blank" rel="noopener">Hingle loss</a></p>
</blockquote>
<h3 id="‰ª£‰ª∑ÂáΩÊï∞-3"><a href="#‰ª£‰ª∑ÂáΩÊï∞-3" class="headerlink" title="‰ª£‰ª∑ÂáΩÊï∞"></a>‰ª£‰ª∑ÂáΩÊï∞</h3><script type="math/tex; mode=display">
J(\theta) = C\sum_{i=1}^m y^{(i)} \ \text{cost}_1(\theta^Tx^{(i)}) + (1 - y^{(i)}) \ \text{cost}_0(\theta^Tx^{(i)}) + \dfrac{1}{2}\sum_{j=1}^n \Theta^2_j</script><script type="math/tex; mode=display">
C = \frac{1}{\lambda}</script><blockquote>
<p>Âõ†‰∏∫SVMÁöÑ‰ºòÂåñÁõÆÊ†á‰∏∫ÊúÄÂ§ßÂåñËæπÁïå‰∏æ‰æãÔºåÊâÄÊúâSVM‰πüÂè´ÂÅöLarge Margin Classifier</p>
</blockquote>
<h3 id="Ê†∏ÂáΩÊï∞"><a href="#Ê†∏ÂáΩÊï∞" class="headerlink" title="Ê†∏ÂáΩÊï∞"></a>Ê†∏ÂáΩÊï∞</h3><p>ÂÆûÁé∞SVMÈùûÁ∫øÊÄßÂàÜÁ±ªÁöÑÂü∫Á°ÄÔºåÂ∞Ü‰ΩéÁª¥Á©∫Èó¥ÁÇπÊäïÂ∞ÑÂà∞È´òÁª¥Á©∫Èó¥ÔºåÂÆö‰πâËøë‰ººÂáΩÊï∞Ôºö</p>
<p>È´òÊñØÊ†∏ÂáΩÊï∞(‰∏ªË¶ÅÂèÇÊï∞‰∏∫ $\sigma$)</p>
<script type="math/tex; mode=display">
f_i = similarity(x, l^{(i)}) = \exp(-\dfrac{\sum^n_{j=1}(x_j-l_j^{(i)})^2}{2\sigma^2})</script><h3 id="ÂèÇÊï∞"><a href="#ÂèÇÊï∞" class="headerlink" title="ÂèÇÊï∞"></a>ÂèÇÊï∞</h3><ol>
<li><p>$C=\frac{1}{\lambda}$</p>
<p>Â¶ÇÊûú$C$ ËøáÂ§ßÔºåÈ´òÊñπÂ∑Æ„ÄÅ‰ΩéÂÅèÂ∑ÆÔºõ</p>
<p>Â¶ÇÊûú$C$ ËøáÂ∞èÔºåÈ´òÂÅèÂ∑Æ„ÄÅ‰ΩéÊñπÂ∑ÆÔºõ</p>
</li>
<li><p>$\sigma^2$</p>
<p>Â¶ÇÊûú$\sigma^2$ ËøáÂ§ßÔºåÁâπÂæÅÊõ¥Âä†Âπ≥ÁºìÔºåÂØºËá¥È´òÂÅèÂ∑ÆÔºå‰ΩéÊñπÂ∑ÆÔºõ</p>
<p>Â¶ÇÊûú$\sigma^2$ ËøáÂ∞èÔºåÁâπÂæÅÂàÜÂ∏ÉÊõ¥ÈõÜ‰∏≠ÔºåÂØºËá¥È´òÊñπÂ∑ÆÔºå‰ΩéÂÅèÂ∑ÆÔºõ</p>
</li>
</ol>
<h2 id="Lecture-8-K-Means-Âíå-PCA"><a href="#Lecture-8-K-Means-Âíå-PCA" class="headerlink" title="Lecture 8: K-Means Âíå PCA"></a>Lecture 8: K-Means Âíå PCA</h2><h3 id="K-Means"><a href="#K-Means" class="headerlink" title="K-Means"></a>K-Means</h3><p><img src="/qnsource/images/2018-04-25-machine-learning-notes/BILDt.png" alt="BILDt"></p>
<p>ÁÆóÊ≥ïÂÆûÁé∞(<code>Cluster Assignment</code>+<code>Move Centroid</code>)Ôºö</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Randomly initialize K cluster centroids mu(1), mu(2), ..., mu(K)</span><br><span class="line">Repeat:</span><br><span class="line">   <span class="keyword">for</span> i = 1 to m:</span><br><span class="line">      c(i):= index (from 1 to K) of cluster centroid closest to x(i)</span><br><span class="line">   <span class="keyword">for</span> k = 1 to K:</span><br><span class="line">      mu(k):= average (mean) of points assigned to cluster k</span><br></pre></td></tr></table></figure>
<script type="math/tex; mode=display">
c^{(i)} = argmin_k\ ||x^{(i)} - \mu_k||^2</script><h4 id="‰ºòÂåñÁõÆÊ†á"><a href="#‰ºòÂåñÁõÆÊ†á" class="headerlink" title="‰ºòÂåñÁõÆÊ†á"></a>‰ºòÂåñÁõÆÊ†á</h4><script type="math/tex; mode=display">
J(c^{(i)},\dots,c^{(m)},\mu_1,\dots,\mu_K) = \dfrac{1}{m}\sum_{i=1}^m ||x^{(i)} - \mu_{c^{(i)}}||^2</script><h4 id="Ê≥®ÊÑè‰∫ãÈ°π"><a href="#Ê≥®ÊÑè‰∫ãÈ°π" class="headerlink" title="Ê≥®ÊÑè‰∫ãÈ°π"></a>Ê≥®ÊÑè‰∫ãÈ°π</h4><ol>
<li>K‰∏™ÂàùÂßãÂØπË±°ÁöÑÈÄâÊã©Â∫î‰∏∫ÈöèÊú∫ÈÄâÂèñk‰∏™ËÆ≠ÁªÉÊ†∑Êú¨Ôºõ</li>
<li>‰∏∫‰∫ÜÂ∞ΩÈáèÈÅøÂÖçÈô∑ÂÖ•Â±ÄÈÉ®ÊûÅÂ∞èÂÄºÔºåÈúÄË¶ÅËøõË°åÂ§öÊ¨°ÈöèÊú∫ÂàùÂßãÂåñÊ±ÇËß£ÔºåÈÄâÊã©‰ª£‰ª∑ÂáΩÊï∞ÊúÄÂ∞èÁöÑËß£Ôºõ</li>
<li>KÁöÑÈÄâÊã©ÔºåÂèØ‰ª•ÈááÁî®<code>elbow method</code>Ôºö Choose K at the point where the cost function starts to flatten out.</li>
</ol>
<h3 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h3><p><strong>ÈôçÁª¥ÁöÑÁõÆÁöÑÔºö</strong> 1. Êï∞ÊçÆÂéãÁº©Ôºõ2. ÂèØËßÜÂåñÔºõ</p>
<ul>
<li>The <strong>goal of PCA</strong> is to <strong>reduce</strong> the average of all the distances of every feature to the projection line. </li>
<li>PCA‰∏éÁ∫øÊÄßÂõûÂΩí‰∏çÂêå‰πãÂ§ÑÂú®‰∫éÔºåËÆ°ÁÆóÁöÑÂêÑÁÇπÂà∞ÂàÜÂâ≤Á∫øÁöÑÊúÄÁü≠Ë∑ùÁ¶ªÔºõ</li>
</ul>
<h4 id="ÁÆóÊ≥ïÊµÅÁ®ã"><a href="#ÁÆóÊ≥ïÊµÅÁ®ã" class="headerlink" title="ÁÆóÊ≥ïÊµÅÁ®ã"></a>ÁÆóÊ≥ïÊµÅÁ®ã</h4><ol>
<li><p>Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºöÂΩí‰∏ÄÂåñÔºõ</p>
</li>
<li><p>ËÆ°ÁÆóÂçèÊñπÂ∑ÆÁü©Èòµ</p>
<script type="math/tex; mode=display">
\Sigma = \dfrac{1}{m}\sum^m_{i=1}(x^{(i)})(x^{(i)})^T</script></li>
<li><p>ËÆ°ÁÆó$\Sigma$ ÁöÑÁâπÂæÅÁü©Èòµ</p>
<figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[U,S,V]</span> = svd(Sigma);</span><br></pre></td></tr></table></figure>
</li>
<li><p>Âèñ$U$ ÁöÑÂâçkÂàóËÆ°ÁÆó$z$</p>
<script type="math/tex; mode=display">
z^{(i)} = Ureduce^T \cdot x^{(i)}</script></li>
</ol>
<h4 id="ÊÅ¢Â§ç"><a href="#ÊÅ¢Â§ç" class="headerlink" title="ÊÅ¢Â§ç"></a>ÊÅ¢Â§ç</h4><script type="math/tex; mode=display">
x_{approx}^{(1)} = U_{reduce} \cdot z^{(1)}</script><h4 id="kÂÄºÁöÑÈÄâÊã©"><a href="#kÂÄºÁöÑÈÄâÊã©" class="headerlink" title="kÂÄºÁöÑÈÄâÊã©"></a>kÂÄºÁöÑÈÄâÊã©</h4><script type="math/tex; mode=display">
\dfrac{\dfrac{1}{m}\sum^m_{i=1}||x^{(i)} - x_{approx}^{(i)}||^2}{\dfrac{1}{m}\sum^m_{i=1}||x^{(i)}||^2} \leq 0.01</script><blockquote>
<p>ÊèèËø∞‰∫Ü‰∏¢Â§±ÁâπÂæÅÁöÑÊØî‰æã</p>
</blockquote>
<p>ÂèØ‰ª•ÈÄöËøáSVDÂàÜËß£‰πãÂêéÁöÑSÂÄºÊù•ÂÅöÂêåÊ†∑ÁöÑ‰∫ãÊÉÖÔºö</p>
<script type="math/tex; mode=display">
\dfrac{\sum_{i=1}^kS_{ii}}{\sum_{i=1}^nS_{ii}} \geq 0.99</script><h2 id="Lecture-9Ôºö-Â∫îÁî®1-ÂºÇÂ∏∏Ê£ÄÊµã"><a href="#Lecture-9Ôºö-Â∫îÁî®1-ÂºÇÂ∏∏Ê£ÄÊµã" class="headerlink" title="Lecture 9Ôºö Â∫îÁî®1-ÂºÇÂ∏∏Ê£ÄÊµã"></a>Lecture 9Ôºö Â∫îÁî®1-ÂºÇÂ∏∏Ê£ÄÊµã</h2><ul>
<li>x(i)= features of user i‚Äôs activities</li>
<li>Model p(x) from the data.</li>
<li>Identify unusual users by checking which have p(x)&lt;œµ.</li>
</ul>
<h4 id="È´òÊñØÂàÜÂ∏É"><a href="#È´òÊñØÂàÜÂ∏É" class="headerlink" title="È´òÊñØÂàÜÂ∏É"></a>È´òÊñØÂàÜÂ∏É</h4><p> $x \sim \mathcal{N}(\mu, \sigma^2)$</p>
<script type="math/tex; mode=display">
p(x;\mu,\sigma^2) = \frac{1}{\sigma\sqrt{(2\pi)}}e^{-\frac{1}{2}(\frac{x - \mu}{\sigma})^2}</script><script type="math/tex; mode=display">
p(x) = p(x_1;\mu_1,\sigma_1^2)p(x_2;\mu_2,\sigma^2_2)\cdots p(x_n;\mu_n,\sigma^2_n)= \displaystyle \prod^n_{j=1} p(x_j;\mu_j,\sigma_j^2)</script><h4 id="ÁÆóÊ≥ïÊµÅÁ®ã-1"><a href="#ÁÆóÊ≥ïÊµÅÁ®ã-1" class="headerlink" title="ÁÆóÊ≥ïÊµÅÁ®ã"></a>ÁÆóÊ≥ïÊµÅÁ®ã</h4><ol>
<li><p>ËÆ°ÁÆóÂùáÂÄºÂíåÊñπÂ∑Æ</p>
</li>
<li><p>ËÆ°ÁÆóÊ¶ÇÁéáÂàÜÂ∏ÉÂáΩÊï∞</p>
<script type="math/tex; mode=display">
p(x) = \displaystyle \prod^n_{j=1} p(x_j;\mu_j,\sigma_j^2) = \prod\limits^n_{j=1} \dfrac{1}{\sqrt{2\pi}\sigma_j}exp(-\dfrac{(x_j - \mu_j)^2}{2\sigma^2_j})</script></li>
<li><p>Âà©Áî®Ê†áËÆ∞Êï∞ÊçÆÁ°ÆÂÆöœµ</p>
</li>
</ol>
<h4 id="Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ"><a href="#Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ" class="headerlink" title="Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ"></a>Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ</h4><p>‰∏∫‰∫ÜÊª°Ë∂≥È´òÊñØÂàÜÂ∏ÉÔºåÈúÄË¶ÅÂØπÂéüÂßãÊï∞ÊçÆËøõË°åËΩ¨Êç¢Ôºö</p>
<ul>
<li>log(x)</li>
<li>log(x+1)</li>
<li>log(x+c) for some constant</li>
<li>$\sqrt x$</li>
<li>$x^{1/3}$</li>
</ul>
<h4 id="Â§öÂÖÉÈ´òÊñØÂàÜÂ∏É"><a href="#Â§öÂÖÉÈ´òÊñØÂàÜÂ∏É" class="headerlink" title="Â§öÂÖÉÈ´òÊñØÂàÜÂ∏É"></a>Â§öÂÖÉÈ´òÊñØÂàÜÂ∏É</h4><script type="math/tex; mode=display">
p(x;\mu,\Sigma) = \dfrac{1}{(2\pi)^{n/2} |\Sigma|^{1/2}} exp(-1/2(x-\mu)^T\Sigma^{-1}(x-\mu))</script><blockquote>
<p>‰º†ÁªüÈ´òÊñØÊ®°Âûã‰πòÁßØÊòØÂ§öÂÖÉÂ§öÂÖÉÈ´òÊñØÁöÑ‰∏ÄÁßçÁâπ‰æã</p>
</blockquote>
<p>$\Sigma$ ‰∏∫ÂçèÊñπÂ∑ÆÁü©ÈòµÔºåÂ¶Ç‰ΩïÂÅáËÆæ$A$ ‰∏∫ÈùûÂ•áÂºÇÁü©ÈòµÔºåËøõË°åÁâπÂæÅÂèòÊç¢Ôºö$y=Ax$,Âàô$\Sigma = AA^T$</p>
<p>Â§öÂÖÉÈ´òÊñØÂàÜÂ∏É vs ‰º†ÁªüÈ´òÊñØÊ®°Âûã</p>
<ul>
<li>Â§öÂÖÉ Êõ¥ËÉΩÊçïËé∑ÁâπÂæÅ‰πãÈó¥ÁöÑÂÖ≥ËÅîÊÄßÔºõ</li>
<li>Â§öÂÖÉ ËÆ°ÁÆóÊõ¥ËÄóÊó∂Ôºõ</li>
<li>Â§öÂÖÉÁöÑÂâçÊèêÔºåÊ†∑Êú¨Êï∞ &gt; ÁâπÂæÅÊï∞Ôºõm&gt;10n</li>
</ul>
<h2 id="Lecture-10-Â∫îÁî®2-Êé®ËçêÁ≥ªÁªü"><a href="#Lecture-10-Â∫îÁî®2-Êé®ËçêÁ≥ªÁªü" class="headerlink" title="Lecture 10: Â∫îÁî®2-Êé®ËçêÁ≥ªÁªü"></a>Lecture 10: Â∫îÁî®2-Êé®ËçêÁ≥ªÁªü</h2><h3 id="ÈóÆÈ¢òÊäΩË±°"><a href="#ÈóÆÈ¢òÊäΩË±°" class="headerlink" title="ÈóÆÈ¢òÊäΩË±°"></a>ÈóÆÈ¢òÊäΩË±°</h3><p>‰ª•ÁîµÂΩ±Êé®Ëçê‰∏∫‰æãÔºåÂÆö‰πâÂ¶Ç‰∏ãÂèòÈáèÔºö</p>
<ul>
<li>$n_\mu$ = Áî®Êà∑Êï∞ÁõÆ</li>
<li>$n_m$ = ÁîµÂΩ±Êï∞ÁõÆ</li>
<li>$r(i,j)=1$ = 1,Â¶ÇÊûúÁî®Êà∑jÂØπÁîµÂΩ±iËØÑÂàÜ</li>
<li>$y(i,j)=rating_score$ </li>
</ul>
<h3 id="Âü∫‰∫éÂÜÖÂÆπÁöÑÊé®Ëçê"><a href="#Âü∫‰∫éÂÜÖÂÆπÁöÑÊé®Ëçê" class="headerlink" title="Âü∫‰∫éÂÜÖÂÆπÁöÑÊé®Ëçê"></a>Âü∫‰∫éÂÜÖÂÆπÁöÑÊé®Ëçê</h3><script type="math/tex; mode=display">
min_{\theta^{(1)},\dots,\theta^{(n_u)}} = \dfrac{1}{2}\displaystyle \sum_{j=1}^{n_u}  \sum_{i:r(i,j)=1} ((\theta^{(j)})^T(x^{(i)}) - y^{(i,j)})^2 + \dfrac{\lambda}{2} \sum_{j=1}^{n_u} \sum_{k=1}^n(\theta_k^{(j)})^2</script><h3 id="ÂçèÂêåËøáÊª§"><a href="#ÂçèÂêåËøáÊª§" class="headerlink" title="ÂçèÂêåËøáÊª§"></a>ÂçèÂêåËøáÊª§</h3><blockquote>
<p>Êó¢Â≠¶‰π†ÂèÇÊï∞ÂèàÂ≠¶‰π†ÁâπÂæÅË°®Á§∫</p>
</blockquote>
<script type="math/tex; mode=display">
J(x,\theta) = \dfrac{1}{2} \displaystyle \sum_{(i,j):r(i,j)=1}((\theta^{(j)})^Tx^{(i)} - y^{(i,j)})^2 + \dfrac{\lambda}{2}\sum_{i=1}^{n_m} \sum_{k=1}^{n} (x_k^{(i)})^2 + \dfrac{\lambda}{2}\sum_{j=1}^{n_u} \sum_{k=1}^{n} (\theta_k^{(j)})^2</script><h2 id="ÂèÇËÄÉ"><a href="#ÂèÇËÄÉ" class="headerlink" title="ÂèÇËÄÉ"></a>ÂèÇËÄÉ</h2><ol>
<li>SVMÔºö<a href="http://web.mit.edu/6.034/wwwbob/svm-notes-long-08.pdf" target="_blank" rel="noopener">http://web.mit.edu/6.034/wwwbob/svm-notes-long-08.pdf</a></li>
<li>‚Äã</li>
</ol>

      
    </div>
    <footer class="article-footer">

      
      

      
      <!--  -->

      <!--  -->
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Êú∫Âô®Â≠¶‰π†/">Êú∫Âô®Â≠¶‰π†</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Á•ûÁªèÁΩëÁªú/">Á•ûÁªèÁΩëÁªú</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Á¨îËÆ∞/">Á¨îËÆ∞</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ÁÆóÊ≥ï/">ÁÆóÊ≥ï</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Á∫øÊÄßÂõûÂΩí/">Á∫øÊÄßÂõûÂΩí</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ÈÄªËæëÂõûÂΩí/">ÈÄªËæëÂõûÂΩí</a></li></ul>

    </footer>
  </div>
  
</article>

<!-- Table of Contents -->


  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/6/">&laquo; ‰∏ä‰∏ÄÈ°µ</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><span class="page-number current">7</span><a class="page-number" href="/page/8/">8</a><a class="page-number" href="/page/9/">9</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><a class="extend next" rel="next" href="/page/8/">‰∏ã‰∏ÄÈ°µ &raquo;</a>
  </nav>

</section>
          <aside id="sidebar">
  
    <div class="widget-wrap">
<h3 class="widget-title">‰∏çÁßØË∑¨Ê≠•Êó†‰ª•Ëá≥ÂçÉÈáåÔºÅ</h3>
<div class="widget">
  <canvas id="c" style="background: url(/qnsource/site/window.jpg) no-repeat; 
  background-size: cover;"></canvas>
  <script type="text/javascript">

  	var width = 200,
  	height = 150,
  	physics_accuracy = 3,
	mouse_influence = 20,
	mouse_cut = 5,
	gravity = 1200,
	cloth_height = 29,
	cloth_width = 30,
	start_y = 10,
	spacing = (width-15)/cloth_width,
	tear_distance = 60;

	window.requestAnimFrame = window.requestAnimationFrame || window.webkitRequestAnimationFrame || window.mozRequestAnimationFrame || window.oRequestAnimationFrame || window.msRequestAnimationFrame ||
	function(callback) {
	    window.setTimeout(callback, 1000 / 60);
	};

	var canvas, ctx, cloth, boundsx, boundsy, mouse = {
	    down: false,
	    button: 1,
	    x: 0,
	    y: 0,
	    px: 0,
	    py: 0
	};

	var Point = function(x, y) {

	    this.x = x;
	    this.y = y;
	    this.px = x;
	    this.py = y;
	    this.vx = 0;
	    this.vy = 0;
	    this.pin_x = null;
	    this.pin_y = null;

	    this.constraints = [];
	};

	Point.prototype.update = function(delta) {

	    if (mouse.down) {

	        var diff_x = this.x - mouse.x,
	        diff_y = this.y - mouse.y,
	        dist = Math.sqrt(diff_x * diff_x + diff_y * diff_y);

	        if (mouse.button == 1) {

	            if (dist < mouse_influence) {
	                this.px = this.x - (mouse.x - mouse.px) * 1.8;
	                this.py = this.y - (mouse.y - mouse.py) * 1.8;
	            }

	        } else if (dist < mouse_cut) this.constraints = [];
	    }

	    this.add_force(0, gravity);

	    delta *= delta;
	    nx = this.x + ((this.x - this.px) * .99) + ((this.vx / 2) * delta);
	    ny = this.y + ((this.y - this.py) * .99) + ((this.vy / 2) * delta);

	    this.px = this.x;
	    this.py = this.y;

	    this.x = nx;
	    this.y = ny;

	    this.vy = this.vx = 0
	};

	Point.prototype.draw = function() {

	    if (this.constraints.length <= 0) return;

	    var i = this.constraints.length;
	    while (i--) this.constraints[i].draw();
	};

	Point.prototype.resolve_constraints = function() {

	    if (this.pin_x != null && this.pin_y != null) {

	        this.x = this.pin_x;
	        this.y = this.pin_y;
	        return;
	    }

	    var i = this.constraints.length;
	    while (i--) this.constraints[i].resolve();

	    if (this.x > boundsx) {

	        this.x = 2 * boundsx - this.x;

	    } else if (this.x < 1) {

	        this.x = 2 - this.x;
	    }

	    if (this.y > boundsy) {

	        this.y = 2 * boundsy - this.y;

	    } else if (this.y < 1) {

	        this.y = 2 - this.y;
	    }
	};

	Point.prototype.attach = function(point) {

	    this.constraints.push(new Constraint(this, point));
	};

	Point.prototype.remove_constraint = function(lnk) {

	    var i = this.constraints.length;
	    while (i--) if (this.constraints[i] == lnk) this.constraints.splice(i, 1);
	};

	Point.prototype.add_force = function(x, y) {

	    this.vx += x;
	    this.vy += y;
	};

	Point.prototype.pin = function(pinx, piny) {
	    this.pin_x = pinx;
	    this.pin_y = piny;
	};

	var Constraint = function(p1, p2) {

	    this.p1 = p1;
	    this.p2 = p2;
	    this.length = spacing;
	};

	Constraint.prototype.resolve = function() {

	    var diff_x = this.p1.x - this.p2.x,
	    diff_y = this.p1.y - this.p2.y,
	    dist = Math.sqrt(diff_x * diff_x + diff_y * diff_y),
	    diff = (this.length - dist) / dist;

	    if (dist > tear_distance) this.p1.remove_constraint(this);

	    var px = diff_x * diff * 0.5;
	    var py = diff_y * diff * 0.5;

	    this.p1.x += px;
	    this.p1.y += py;
	    this.p2.x -= px;
	    this.p2.y -= py;
	};

	Constraint.prototype.draw = function() {

	    ctx.moveTo(this.p1.x, this.p1.y);
	    ctx.lineTo(this.p2.x, this.p2.y);
	};

	var Cloth = function() {

	    this.points = [];

	    var start_x = canvas.width / 2 - cloth_width * spacing / 2;

	    for (var y = 0; y <= cloth_height; y++) {

	        for (var x = 0; x <= cloth_width; x++) {

	            var p = new Point(start_x + x * spacing, start_y + y * spacing);

	            x != 0 && p.attach(this.points[this.points.length - 1]);
	            y == 0 && p.pin(p.x, p.y);
	            y != 0 && p.attach(this.points[x + (y - 1) * (cloth_width + 1)])

	            this.points.push(p);
	        }
	    }
	};

	Cloth.prototype.update = function() {

	    var i = physics_accuracy;

	    while (i--) {
	        var p = this.points.length;
	        while (p--) this.points[p].resolve_constraints();
	    }

	    i = this.points.length;
	    while (i--) this.points[i].update(.016);
	};

	Cloth.prototype.draw = function() {

	    ctx.beginPath();

	    var i = cloth.points.length;
	    while (i--) cloth.points[i].draw();

	    ctx.stroke();
	};

	function update() {

	    ctx.clearRect(0, 0, canvas.width, canvas.height);

	    cloth.update();
	    cloth.draw();

	    requestAnimFrame(update);
	}

	function start() {

	    canvas.onmousedown = function(e) {
	        mouse.button = e.which;
	        mouse.px = mouse.x;
	        mouse.py = mouse.y;
	        var rect = canvas.getBoundingClientRect();
	        mouse.x = e.clientX - rect.left,
	        mouse.y = e.clientY - rect.top,
	        mouse.down = true;
	        e.preventDefault();
	    };

	    canvas.onmouseup = function(e) {
	        mouse.down = false;
	        e.preventDefault();
	    };

	    canvas.onmousemove = function(e) {
	        mouse.px = mouse.x;
	        mouse.py = mouse.y;
	        var rect = canvas.getBoundingClientRect();
	        mouse.x = e.clientX - rect.left,
	        mouse.y = e.clientY - rect.top,
	        e.preventDefault();
	    };

	    canvas.oncontextmenu = function(e) {
	        e.preventDefault();
	    };

	    boundsx = canvas.width - 1;
	    boundsy = canvas.height - 1;

	    ctx.strokeStyle = '#fff';
	    cloth = new Cloth();
	    update();
	}

	window.onload = function() {

	    canvas = document.getElementById('c');
	    ctx = canvas.getContext('2d');

	    canvas.width = width;
	    canvas.height = height;

	    start();
	};

  </script>
</div>
</div>
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">ÂÖ≥Ê≥®Êàë</h3>
    <div class="widget widget_athemes_social_icons">

    	<ul class="clearfix widget-social-icons">   
    	
          
     			  <li><a href="https://github.com/ddebby" title="Github"><i class="fa fa-github" aria-hidden="true"></i></a></li> 
          
   		
          
     			  <li><a href="https://weibo.com/ddebby" title="Weibo"><i class="fa fa-weibo" aria-hidden="true"></i></a></li> 
          
   		
          
     			  <li><a href="https://twitter.com/ebbydd" title="Twitter"><i class="fa fa-twitter" aria-hidden="true"></i></a></li> 
          
   		
          
     			  <li><a href="" title="Facebook"><i class="fa fa-facebook" aria-hidden="true"></i></a></li> 
          
   		
          
     			  <li><a href="" title="Google-plus"><i class="fa fa-google-plus" aria-hidden="true"></i></a></li> 
          
   		
          
     			  <li><a href="" title="Instagram"><i class="fa fa-instagram" aria-hidden="true"></i></a></li> 
          
   		
          
     			  <li><a href="" title="Pinterest"><i class="fa fa-pinterest" aria-hidden="true"></i></a></li> 
          
   		
          
     			  <li><a href="" title="Flickr"><i class="fa fa-flickr" aria-hidden="true"></i></a></li> 
          
   		
          
            <li><a href="mailto:ebby.dd@gmail.com?subject=ËØ∑ËÅîÁ≥ªÊàë&body=ÊàëËÉΩÂ∏Æ‰Ω†‰ªÄ‰πà" title="email"><i class="fa fa-envelope" aria-hidden="true"></i></a></li> 
          
   		
   		</ul>


   		<!--
   		<ul class="clearfix widget-social-icons">   		
   		<li class="widget-si-twitter"><a href="http://twitter.com" title="Twitter"><i class="ico-twitter"></i></a></li> 
		<li class="widget-si-facebook"><a href="http://facebook.com" title="Facebook"><i class="ico-facebook"></i></a></li>
			<li class="widget-si-gplus"><a href="http://plus.google.com" title="Google+"><i class="ico-gplus"></i></a></li>
			<li class="widget-si-pinterest"><a href="http://pinterest.com" title="Pinterest"><i class="ico-pinterest"></i></a></li>
			<li class="widget-si-flickr"><a href="http://flickr.com" title="Flickr"><i class="ico-flickr"></i></a></li>
			<li class="widget-si-instagram"><a href="http://instagram.com" title="Instagram"><i class="ico-instagram"></i></a></li>
		</ul> -->

    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">ÂàÜÁ±ª</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/‰∫ëÂ≠òÂÇ®/">‰∫ëÂ≠òÂÇ®</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Âä®ÊâãÂÆûË∑µËê•/">Âä®ÊâãÂÆûË∑µËê•</a><span class="category-list-count">11</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Âä®ÊâãÂÆûË∑µËê•/Êú∫Âô®ËßÜËßâ/">Êú∫Âô®ËßÜËßâ</a><span class="category-list-count">2</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Â∑•ÂÖ∑/">Â∑•ÂÖ∑</a><span class="category-list-count">5</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Â∑•ÂÖ∑/Keras/">Keras</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Â∑•ÂÖ∑/MarkDown/">MarkDown</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Â∑•ÂÖ∑/Êú∫Âô®ËßÜËßâ/">Êú∫Âô®ËßÜËßâ</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Êú∫Âô®Â≠¶‰π†/">Êú∫Âô®Â≠¶‰π†</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Ê∑±Â∫¶Â≠¶‰π†/">Ê∑±Â∫¶Â≠¶‰π†</a><span class="category-list-count">12</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Ê∑±Â∫¶Â≠¶‰π†/Âü∫Á°ÄÁü•ËØÜ/">Âü∫Á°ÄÁü•ËØÜ</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Ê∑±Â∫¶Â≠¶‰π†/Êú∫Âô®ËßÜËßâ/">Êú∫Âô®ËßÜËßâ</a><span class="category-list-count">2</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/ÁÆóÊ≥ï/">ÁÆóÊ≥ï</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/ÁÆóÊ≥ï/ËøÅÁßªÂ≠¶‰π†/">ËøÅÁßªÂ≠¶‰π†</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/ËØª‰π¶Á¨îËÆ∞/">ËØª‰π¶Á¨îËÆ∞</a><span class="category-list-count">10</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/ËØª‰π¶Á¨îËÆ∞/Êú∫Âô®ËßÜËßâ/">Êú∫Âô®ËßÜËßâ</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/ËØª‰π¶Á¨îËÆ∞/ËØæÁ®ãÁ¨îËÆ∞/">ËØæÁ®ãÁ¨îËÆ∞</a><span class="category-list-count">5</span></li></ul></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Ê†áÁ≠æ‰∫ë</h3>
    <div class="widget tagcloud">
      <a href="/tags/AI/" style="font-size: 17px;">AI</a> <a href="/tags/Ceph/" style="font-size: 11px;">Ceph</a> <a href="/tags/FastText/" style="font-size: 10px;">FastText</a> <a href="/tags/Git/" style="font-size: 10px;">Git</a> <a href="/tags/Keras/" style="font-size: 10px;">Keras</a> <a href="/tags/Markdown/" style="font-size: 10px;">Markdown</a> <a href="/tags/OpenCV/" style="font-size: 10px;">OpenCV</a> <a href="/tags/Prophet/" style="font-size: 10px;">Prophet</a> <a href="/tags/SARIMA/" style="font-size: 10px;">SARIMA</a> <a href="/tags/Time-Series/" style="font-size: 10px;">Time Series</a> <a href="/tags/word2vec/" style="font-size: 11px;">word2vec</a> <a href="/tags/‰π¶Á±ç/" style="font-size: 10px;">‰π¶Á±ç</a> <a href="/tags/‰∫ëÂ≠òÂÇ®/" style="font-size: 11px;">‰∫ëÂ≠òÂÇ®</a> <a href="/tags/‰∫∫Â∑•Êô∫ËÉΩ/" style="font-size: 20px;">‰∫∫Â∑•Êô∫ËÉΩ</a> <a href="/tags/‰ºòÂåñ/" style="font-size: 10px;">‰ºòÂåñ</a> <a href="/tags/ÂÖ¨ÂºÄËØæ/" style="font-size: 10px;">ÂÖ¨ÂºÄËØæ</a> <a href="/tags/ÂçöÂÆ¢/" style="font-size: 10px;">ÂçöÂÆ¢</a> <a href="/tags/ÂéüÁêÜËß£Êûê/" style="font-size: 10px;">ÂéüÁêÜËß£Êûê</a> <a href="/tags/ÂèØËßÜÂåñ/" style="font-size: 10px;">ÂèØËßÜÂåñ</a> <a href="/tags/ÂõæÂÉèÂàÜÁ±ª/" style="font-size: 11px;">ÂõæÂÉèÂàÜÁ±ª</a> <a href="/tags/ÂÆûË∑µ/" style="font-size: 12px;">ÂÆûË∑µ</a> <a href="/tags/ÂÆûÈ™å/" style="font-size: 10px;">ÂÆûÈ™å</a> <a href="/tags/Â∑•ÂÖ∑/" style="font-size: 11px;">Â∑•ÂÖ∑</a> <a href="/tags/Â∑•Á®ãÂÆûË∑µ/" style="font-size: 10px;">Â∑•Á®ãÂÆûË∑µ</a> <a href="/tags/ÂºÄÊîæÊï∞ÊçÆÈõÜ/" style="font-size: 11px;">ÂºÄÊîæÊï∞ÊçÆÈõÜ</a> <a href="/tags/ÂºÄÊ∫êÂπ≥Âè∞/" style="font-size: 10px;">ÂºÄÊ∫êÂπ≥Âè∞</a> <a href="/tags/ÊÄªÁªì/" style="font-size: 10px;">ÊÄªÁªì</a> <a href="/tags/ÊÑüÁü•Êú∫/" style="font-size: 10px;">ÊÑüÁü•Êú∫</a> <a href="/tags/ÊäÄÂ∑ß/" style="font-size: 12px;">ÊäÄÂ∑ß</a> <a href="/tags/ÊäÄÊúØ/" style="font-size: 11px;">ÊäÄÊúØ</a> <a href="/tags/ÊîØÊåÅÂêëÈáèÊú∫/" style="font-size: 10px;">ÊîØÊåÅÂêëÈáèÊú∫</a> <a href="/tags/ÊïôÂ≠¶/" style="font-size: 10px;">ÊïôÂ≠¶</a> <a href="/tags/Êï∞ÊçÆÈõÜ/" style="font-size: 10px;">Êï∞ÊçÆÈõÜ</a> <a href="/tags/ÊñáÁåÆ/" style="font-size: 18px;">ÊñáÁåÆ</a> <a href="/tags/Êó∂Â∫èÊï∞ÊçÆ/" style="font-size: 10px;">Êó∂Â∫èÊï∞ÊçÆ</a> <a href="/tags/Êú∫Âô®Â≠¶‰π†/" style="font-size: 13px;">Êú∫Âô®Â≠¶‰π†</a> <a href="/tags/Êú∫Âô®ËßÜËßâ/" style="font-size: 16px;">Êú∫Âô®ËßÜËßâ</a> <a href="/tags/Ê®°Âûã/" style="font-size: 11px;">Ê®°Âûã</a> <a href="/tags/Ê≠£ÂàôÂåñ/" style="font-size: 10px;">Ê≠£ÂàôÂåñ</a> <a href="/tags/Áâ©‰ΩìËØÜÂà´/" style="font-size: 12px;">Áâ©‰ΩìËØÜÂà´</a> <a href="/tags/ÁâπÂæÅÊäΩÂèñ/" style="font-size: 10px;">ÁâπÂæÅÊäΩÂèñ</a> <a href="/tags/Á•ûÁªèÁΩëÁªú/" style="font-size: 10px;">Á•ûÁªèÁΩëÁªú</a> <a href="/tags/Á¨îËÆ∞/" style="font-size: 15px;">Á¨îËÆ∞</a> <a href="/tags/Á≠ñÁï•/" style="font-size: 10px;">Á≠ñÁï•</a> <a href="/tags/ÁÆóÊ≥ï/" style="font-size: 19px;">ÁÆóÊ≥ï</a> <a href="/tags/Á∫øÊÄßÂõûÂΩí/" style="font-size: 11px;">Á∫øÊÄßÂõûÂΩí</a> <a href="/tags/ÁΩëÁªúÂ§çÁé∞/" style="font-size: 14px;">ÁΩëÁªúÂ§çÁé∞</a> <a href="/tags/ËØçÂêëÈáè/" style="font-size: 10px;">ËØçÂêëÈáè</a> <a href="/tags/ËØçÂµåÂÖ•/" style="font-size: 11px;">ËØçÂµåÂÖ•</a> <a href="/tags/ËØª‰π¶Á¨îËÆ∞/" style="font-size: 13px;">ËØª‰π¶Á¨îËÆ∞</a> <a href="/tags/ËµÑÊ∫êË∞ÉÂ∫¶/" style="font-size: 10px;">ËµÑÊ∫êË∞ÉÂ∫¶</a> <a href="/tags/ËøÅÁßªÂ≠¶‰π†/" style="font-size: 10px;">ËøÅÁßªÂ≠¶‰π†</a> <a href="/tags/ÈÄªËæëÂõûÂΩí/" style="font-size: 11px;">ÈÄªËæëÂõûÂΩí</a> <a href="/tags/ÈÉ®ÁΩ≤/" style="font-size: 11px;">ÈÉ®ÁΩ≤</a> <a href="/tags/ÈÖçÁΩÆ/" style="font-size: 10px;">ÈÖçÁΩÆ</a> <a href="/tags/È¢ÑÂ§ÑÁêÜ/" style="font-size: 11px;">È¢ÑÂ§ÑÁêÜ</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">ÂΩíÊ°£</h3>

    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">ÂçÅ‰∫åÊúà 2018</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">ÂçÅ‰∏ÄÊúà 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">‰πùÊúà 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">ÂÖ´Êúà 2018</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">‰∏ÉÊúà 2018</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">ÂÖ≠Êúà 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">‰∫îÊúà 2018</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">ÂõõÊúà 2018</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">‰∏âÊúà 2018</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">‰∫åÊúà 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">‰∏ÄÊúà 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">‰∫åÊúà 2017</a><span class="archive-list-count">2</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">ÊúÄÊñ∞ÊñáÁ´†</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/12/26/Ê∑±Â∫¶Â≠¶‰π†ËµÑÊ∫êË∞ÉÂ∫¶Âπ≥Âè∞OpenPAIÈÉ®ÁΩ≤/">Ê∑±Â∫¶Â≠¶‰π†ËµÑÊ∫êË∞ÉÂ∫¶Âπ≥Âè∞OpenPAIÈÉ®ÁΩ≤</a>
          </li>
        
          <li>
            <a href="/2018/12/11/Êú∫Âô®Âú®Â≠¶‰π†‚Äî‚ÄîEDA/">Êú∫Âô®Âú®Â≠¶‰π†‚Äî‚ÄîEDA</a>
          </li>
        
          <li>
            <a href="/2018/12/04/Êú∫Âô®Âú®Â≠¶‰π†-Êó∂Â∫èÊï∞ÊçÆÂàÜÊûê/">Êú∫Âô®Âú®Â≠¶‰π†-Êó∂Â∫èÊï∞ÊçÆÂàÜÊûê</a>
          </li>
        
          <li>
            <a href="/2018/11/29/Êú∫Âô®Âú®Â≠¶‰π†-ÈöèÊú∫Ê£ÆÊûó/">Êú∫Âô®Âú®Â≠¶‰π†-Á∫øÊÄßÂõûÂΩí‰∏éÂàÜÁ±ª</a>
          </li>
        
          <li>
            <a href="/2018/11/23/Êú∫Âô®Âú®Â≠¶‰π†‚Äî-KNN/">Êú∫Âô®Âú®Â≠¶‰π†-KNN</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <!--        
        <div align="center" style="margin-top: 30px;"><hr class="hr" style="margin:0px; height:3px;"></div>
       -->
      <footer id="footer">
  

  <div class="container">
      	<div class="row">
	      <p> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/iTimeTraveler/hexo-theme-hiker" target="_blank">Hexo-theme-hiker</a> </p>
	      <p id="copyRightEn">Copyright &copy; 2017 - 2018 Ebby&#39;s Notes All Rights Reserved.</p>
	      
	      
  		   	<p id="copyRightCn">Ebby DD ‰øùÁïôÊâÄÊúâÊùÉÂà©</p>
  		   
		</div>

		
  </div>
</footer>


<!-- min height -->

<script>
    var wrapdiv = document.getElementById("wrap");
    var contentdiv = document.getElementById("content");
    var allheader = document.getElementById("allheader");

    wrapdiv.style.minHeight = document.body.offsetHeight + "px";
    if (allheader != null) {
      contentdiv.style.minHeight = document.body.offsetHeight - allheader.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    } else {
      contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    }
</script>
    </div>    
    <!-- <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
    <a href="/reading" class="mobile-nav-link">Reading</a>
  
    <a href="/resources" class="mobile-nav-link">Resources</a>
  
    <a href="/notebooks" class="mobile-nav-link">üìù</a>
  
</nav> -->
    

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/scripts.js"></script>


  <script src="/js/home.js"></script>













	<script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?{{ theme.baidu_analytics }}";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  </div>

  <div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true" style="display: none;">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h2 class="modal-title" id="myModalLabel">ËÆæÁΩÆ</h2>
      </div>
      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">


      <div class="modal-body">
          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseOne" onclick="javascript:setFontSize();" aria-expanded="true" aria-controls="collapseOne">
              Ê≠£ÊñáÂ≠óÂè∑Â§ßÂ∞è
            </a>
          </div>
          <div id="collapseOne" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingOne">
          <div class="panel-body">
            ÊÇ®Â∑≤Ë∞ÉÊï¥È°µÈù¢Â≠ó‰ΩìÂ§ßÂ∞è
          </div>
        </div>
      


          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseTwo" onclick="javascript:setBackground();" aria-expanded="true" aria-controls="collapseTwo">
              Â§úÈó¥Êä§ÁúºÊ®°Âºè
            </a>
        </div>
          <div id="collapseTwo" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTwo">
          <div class="panel-body">
            Â§úÈó¥Ê®°ÂºèÂ∑≤ÁªèÂºÄÂêØÔºåÂÜçÊ¨°ÂçïÂáªÊåâÈíÆÂç≥ÂèØÂÖ≥Èó≠ 
          </div>
        </div>

        <div>
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseThree" aria-expanded="true" aria-controls="collapseThree">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ÂÖ≥ ‰∫é&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
        </div>
         <div id="collapseThree" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingThree">
          <div class="panel-body">
            Ebby&#39;s Notes
          </div>
          <div class="panel-body">
            Copyright ¬© 2018 Ebby DD All Rights Reserved.
          </div>
        </div>
      </div>


      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <div class="modal-footer">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">√ó</span></button>
      </div>
    </div>
  </div>
</div>
  
  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
  
</body>
</html>